---
sidebar: sidebar 
permalink: data-analytics/dremio-lakehouse-deployment.html 
keywords: certification, setup, configuration, benchmark 
summary: Wir haben die Zertifizierung mit der Dremio-Plattform mit Lakehouse-Validierung im NetApp Object Storage durchgeführt. 
---
= Bereitstellungsverfahren
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
Bei dieser Referenzarchitekturvalidierung verwendeten wir eine Dremio-Konfiguration, die aus einem Koordinator und vier Executoren besteht.image:dremio-lakehouse-architecture.png["Abbildung zeigt die Dremio-Architektur mit NetApp -Speichercontroller"]



=== NetApp -Setup

* Initialisierung des Speichersystems
* Erstellen einer virtuellen Speichermaschine (SVM)
* Zuordnung logischer Netzwerkschnittstellen
* NFS, S3-Konfiguration und -Lizenzierung


Bitte befolgen Sie die folgenden Schritte für NFS (Network File System): 1.  Erstellen Sie ein Flex Group-Volume für NFSv4 oder NFSv3.  In unserem Setup für diese Validierung haben wir 48 SSDs verwendet, 1 SSD für das Root-Volume des Controllers und 47 SSDs, verteilt für NFSv4]].  Stellen Sie sicher, dass die NFS-Exportrichtlinie für das Flex Group-Volume über Lese-/Schreibberechtigungen für das Dremio-Servernetzwerk verfügt.

. Erstellen Sie auf allen Dremio-Servern einen Ordner und mounten Sie das Flex Group-Volume über eine logische Schnittstelle (LIF) auf jedem Dremio-Server in diesen Ordner.


Bitte befolgen Sie die folgenden Schritte für S3 (Simple Storage Service):

. Richten Sie mit dem Befehl „vserver object-store-server create“ einen Object-Store-Server mit aktiviertem HTTP und dem Administratorstatus „up“ ein.  Sie haben die Möglichkeit, HTTPS zu aktivieren und einen benutzerdefinierten Listener-Port festzulegen.
. Erstellen Sie einen Object-Store-Server-Benutzer mit dem Befehl „vserver object-store-server user create -user <Benutzername>“.
. Um den Zugriffsschlüssel und den geheimen Schlüssel zu erhalten, können Sie den folgenden Befehl ausführen: „set diag; vserver object-store-server user show -user <Benutzername>“.  In Zukunft werden diese Schlüssel jedoch während des Benutzererstellungsprozesses bereitgestellt oder können mithilfe von REST-API-Aufrufen abgerufen werden.
. Richten Sie mit dem in Schritt 2 erstellten Benutzer eine Object-Store-Server-Gruppe ein und gewähren Sie Zugriff.  In diesem Beispiel haben wir „FullAccess“ bereitgestellt.
. Erstellen Sie zwei S3-Buckets, indem Sie ihren Typ auf „S3“ festlegen.  Eine für die Dremio-Konfiguration und eine für Kundendaten.




=== Zookeeper-Setup

Sie können die von Dremio bereitgestellte Zookeeper-Konfiguration verwenden.  Bei dieser Validierung haben wir einen separaten Zookeeper verwendet. Wir haben die in diesem Weblink genannten Schritte befolgt https://medium.com/@ahmetfurkandemir/distributed-hadoop-cluster-1-spark-with-all-dependincies-03c8ec616166[]



=== Dremio-Einrichtung

Wir sind diesem Weblink gefolgt, um Dremio per Tarball zu installieren.

. Erstellen Sie eine Dremio-Gruppe.
+
....
sudo groupadd -r dremio
....
. Erstellen Sie einen Dremio-Benutzer.
+
....
sudo useradd -r -g dremio -d /var/lib/dremio -s /sbin/nologin dremio
....
. Erstellen Sie Dremio-Verzeichnisse.
+
....
sudo mkdir /opt/dremio
sudo mkdir /var/run/dremio && sudo chown dremio:dremio /var/run/dremio
sudo mkdir /var/log/dremio && sudo chown dremio:dremio /var/log/dremio
sudo mkdir /var/lib/dremio && sudo chown dremio:dremio /var/lib/dremio
....
. Laden Sie die Tar-Datei herunter von https://download.dremio.com/community-server/[]
. Entpacken Sie Dremio in das Verzeichnis /opt/dremio.
+
....
sudo tar xvf dremio-enterprise-25.0.3-202405170357270647-d2042e1b.tar.gz -C /opt/dremio --strip-components=1
....
. Erstellen Sie einen symbolischen Link für den Konfigurationsordner.
+
....
sudo ln -s /opt/dremio/conf /etc/dremio
....
. Richten Sie Ihre Dienstkonfiguration ein (SystemD-Setup).
+
.. Kopieren Sie die Unit-Datei für den Dremio-Daemon von /opt/dremio/share/dremio.service nach /etc/systemd/system/dremio.service.
.. System neu starten
+
....
sudo systemctl daemon-reload
....
.. Aktivieren Sie Dremio, um beim Booten zu starten.
+
....
sudo systemctl enable dremio
....


. Konfigurieren Sie Dremio auf dem Koordinator.  Weitere Informationen finden Sie unter Dremio-Konfiguration
+
.. Dremio.conf
+
....
root@hadoopmaster:/usr/src/tpcds# cat /opt/dremio/conf/dremio.conf

paths: {
  # the local path for dremio to store data.
  local: ${DREMIO_HOME}"/dremiocache"

  # the distributed path Dremio data including job results, downloads, uploads, etc
  #dist: "hdfs://hadoopmaster:9000/dremiocache"
  dist: "dremioS3:///dremioconf"
}

services: {
  coordinator.enabled: true,
  coordinator.master.enabled: true,
  executor.enabled: false,
  flight.use_session_service: false
}

zookeeper: "10.63.150.130:2181,10.63.150.153:2181,10.63.150.151:2181"
services.coordinator.master.embedded-zookeeper.enabled: false
root@hadoopmaster:/usr/src/tpcds#
....
.. Core-site.xml
+
....
root@hadoopmaster:/usr/src/tpcds# cat /opt/dremio/conf/core-site.xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->

<!-- Put site-specific property overrides in this file. -->

<configuration>
	<property>
		<name>fs.dremioS3.impl</name>
		<value>com.dremio.plugins.s3.store.S3FileSystem</value>
	</property>
	<property>
                <name>fs.s3a.access.key</name>
                <value>24G4C1316APP2BIPDE5S</value>
	</property>
	<property>
                <name>fs.s3a.endpoint</name>
                <value>10.63.150.69:80</value>
        </property>
	<property>
       		<name>fs.s3a.secret.key</name>
       		<value>Zd28p43rgZaU44PX_ftT279z9nt4jBSro97j87Bx</value>
   	</property>
   	<property>
       		<name>fs.s3a.aws.credentials.provider</name>
       		<description>The credential provider type.</description>
       		<value>org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider</value>
   	</property>
	<property>
                <name>fs.s3a.path.style.access</name>
                <value>false</value>
        </property>
	<property>
    		<name>hadoop.proxyuser.dremio.hosts</name>
    		<value>*</value>
  	</property>
  	<property>
    		<name>hadoop.proxyuser.dremio.groups</name>
    		<value>*</value>
  	</property>
  	<property>
    		<name>hadoop.proxyuser.dremio.users</name>
    		<value>*</value>
	</property>
	<property>
		<name>dremio.s3.compat</name>
		<description>Value has to be set to true.</description>
		<value>true</value>
	</property>
	<property>
		<name>fs.s3a.connection.ssl.enabled</name>
		<description>Value can either be true or false, set to true to use SSL with a secure Minio server.</description>
		<value>false</value>
	</property>
</configuration>
root@hadoopmaster:/usr/src/tpcds#
....


. Die Dremio-Konfiguration wird im NetApp Objektspeicher gespeichert.  Bei unserer Validierung befindet sich der Bucket „dremioconf“ in einem Ontap S3-Bucket.  Das folgende Bild zeigt einige Details aus den Ordnern „Scratch“ und „Uploads“ des S3-Buckets „dremioconf“.


image:dremio-lakehouse-objectstorage.png["Abbildung zeigt dremio mit NetApp Objektspeicher"]

. Konfigurieren Sie Dremio auf Executoren.  In unserem Setup haben wir 3 Executoren.
+
.. dremio.conf
+
....
paths: {
  # the local path for dremio to store data.
  local: ${DREMIO_HOME}"/dremiocache"

  # the distributed path Dremio data including job results, downloads, uploads, etc
  #dist: "hdfs://hadoopmaster:9000/dremiocache"
  dist: "dremioS3:///dremioconf"
}

services: {
  coordinator.enabled: false,
  coordinator.master.enabled: false,
  executor.enabled: true,
  flight.use_session_service: true
}

zookeeper: "10.63.150.130:2181,10.63.150.153:2181,10.63.150.151:2181"
services.coordinator.master.embedded-zookeeper.enabled: false
....
.. Core-site.xml – dasselbe wie die Koordinatorkonfiguration.





NOTE: NetApp empfiehlt StorageGRID als primäre Objektspeicherlösung für Datalake- und Lakehouse-Umgebungen.  Zusätzlich wird NetApp ONTAP für die Datei-/Objekt-Dualität eingesetzt.  Im Rahmen dieses Dokuments haben wir auf Kundenanfrage Tests mit ONTAP S3 durchgeführt und es funktioniert erfolgreich als Datenquelle.



=== Einrichtung mehrerer Quellen

. Konfigurieren Sie ONTAP S3 und storageGRID als S3-Quelle in Dremio.
+
.. Dremio-Dashboard -> Datensätze -> Quellen -> Quelle hinzufügen.
.. Aktualisieren Sie im allgemeinen Abschnitt den AWS-Zugriff und den geheimen Schlüssel
.. Aktivieren Sie in der erweiterten Option den Kompatibilitätsmodus und aktualisieren Sie die Verbindungseigenschaften mit den folgenden Details.  Die Endpunkt-IP/der Endpunktname vom NetApp -Speichercontroller, entweder von Ontap S3 oder StorageGRID.
+
....
fs.s3a.endoint = 10.63.150.69
fs.s3a.path.style.access = true
fs.s3a.connection.maximum=1000
....
.. Aktivieren Sie nach Möglichkeit das lokale Caching. Maximaler Prozentsatz des insgesamt verfügbaren Caches, der nach Möglichkeit verwendet werden soll = 100
.. Zeigen Sie dann die Liste der Buckets aus dem NetApp Objektspeicher an.image:dremio-lakehouse-objectstorage-list.png["Abbildung zeigt eine Liste der Dateien aus dem NetApp Objektspeicher"]
.. Beispielansicht der StorageGRID-Bucket-Detailsimage:dremio-lakehouse-storagegrid-list.png["Abbildung zeigt eine Liste der Dateien aus dem NetApp Objektspeicher"]


. Konfigurieren Sie NAS (insbesondere NFS) als Quelle in Dremio.
+
.. Dremio-Dashboard -> Datensätze -> Quellen -> Quelle hinzufügen.
.. Geben Sie im allgemeinen Abschnitt den Namen und den NFS-Mount-Pfad ein.  Stellen Sie sicher, dass der NFS-Mount-Pfad auf allen Knoten im Dremio-Cluster im selben Ordner gemountet ist.




image:dremio-lakehouse-nas-list.png["Abbildung zeigt eine Liste der Dateien aus dem NetApp Objektspeicher"]

+

....
root@hadoopmaster:~# for i in hadoopmaster hadoopnode1 hadoopnode2 hadoopnode3 hadoopnode4; do ssh $i "date;hostname;du -hs /opt/dremio/data/spill/ ; df -h //dremionfsdata "; done
Fri Sep 13 04:13:19 PM UTC 2024
hadoopmaster
du: cannot access '/opt/dremio/data/spill/': No such file or directory
Filesystem                   Size  Used Avail Use% Mounted on
10.63.150.69:/dremionfsdata  2.1T  921M  2.0T   1% /dremionfsdata
Fri Sep 13 04:13:19 PM UTC 2024
hadoopnode1
12K	/opt/dremio/data/spill/
Filesystem                   Size  Used Avail Use% Mounted on
10.63.150.69:/dremionfsdata  2.1T  921M  2.0T   1% /dremionfsdata
Fri Sep 13 04:13:19 PM UTC 2024
hadoopnode2
12K	/opt/dremio/data/spill/
Filesystem                   Size  Used Avail Use% Mounted on
10.63.150.69:/dremionfsdata  2.1T  921M  2.0T   1% /dremionfsdata
Fri Sep 13 16:13:20 UTC 2024
hadoopnode3
16K	/opt/dremio/data/spill/
Filesystem                   Size  Used Avail Use% Mounted on
10.63.150.69:/dremionfsdata  2.1T  921M  2.0T   1% /dremionfsdata
Fri Sep 13 04:13:21 PM UTC 2024
node4
12K	/opt/dremio/data/spill/
Filesystem                   Size  Used Avail Use% Mounted on
10.63.150.69:/dremionfsdata  2.1T  921M  2.0T   1% /dremionfsdata
root@hadoopmaster:~#
....