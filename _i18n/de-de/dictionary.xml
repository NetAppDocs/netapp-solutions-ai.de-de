<?xml version="1.0" encoding="UTF-8"?>
<blocks>
  <block id="2b185d63fe43e391e79f2722fa9c01f4" category="summary">Lesen Sie KI/ML-Blogs, die Branchentrends, Innovationen und Auswirkungen auf die Praxis hervorheben, sowie Entwicklerressourcen, Community-Einblicke und praktische Tools für die Arbeit mit NetApp KI-Lösungen.</block>
  <block id="7a206e7f1f7bd7df4f649256e750768b" category="doc">Lesen Sie KI-Lösungsblogs von NetApp Experten</block>
  <block id="683be49e9105a56d06431bcdc1630cb6" category="paragraph">Lesen Sie die KI/ML-Blogs, die Branchentrends, Innovationen und Auswirkungen auf die Praxis hervorheben, sowie Entwicklerressourcen, Community-Einblicke und praktische Tools für die Arbeit mit NetApp KI-Lösungen.</block>
  <block id="5bbe94ba0a14c52be3cc9534b43f4713" category="paragraph-title">KI-Trends und Brancheneinblicke</block>
  <block id="78463a384a5aa4fad5fa73e2f506ecfc" category="inline-link-macro">Englisch</block>
  <block id="69501f595c5bd3cdb17ea63c90291622" category="paragraph">Erkunden Sie Branchentrends, Innovationen und die Auswirkungen der KI in der Praxis in verschiedenen Sektoren. <block ref="3b277c3e8740f32e48fe9dd888ed34aa" category="inline-link-macro-rx"></block> &amp;f:@facet_soultion_mktg=[KI,Analytik,künstliche Intelligenz]++[Lesen Sie KI-Blogs auf NetApp^]</block>
  <block id="d5769d364696d52f17c7b56bd51573f8" category="paragraph-title">Entwicklerressourcen und Community</block>
  <block id="bb765a119d53333b43f301b6a00a388a" category="inline-link-macro">Lesen Sie KI-Blogs im Pub</block>
  <block id="43c273574ee7233878bcc9fc0bd893c9" category="paragraph">Technische Einblicke, praktische Tools und Community-gesteuerte Inhalte für KI/ML-Praktiker.<block ref="f89e2ffa35ae5933259a8ae6e49a69ad" category="inline-link-macro-rx"></block></block>
  <block id="e7ee239a021c71c67431ac1c23b9cf1e" category="summary">Der Artikel bietet eine Anleitung zum Erstellen einer MLOps-Pipeline mit AWS-Diensten und konzentriert sich dabei auf die automatische Neuschulung, Bereitstellung und Kostenoptimierung von Modellen.</block>
  <block id="b77650c231f63812b48a3802736172ae" category="doc">Teil 3 – Erstellen einer vereinfachten MLOps-Pipeline (CI/CT/CD)</block>
  <block id="3fc6ea95b9f9aac82c7a39c3743664ba" category="paragraph">Dieser Artikel bietet eine Anleitung zum Erstellen einer MLOps-Pipeline mit AWS-Diensten und konzentriert sich dabei auf die automatische Neuschulung, Bereitstellung und Kostenoptimierung von Modellen.</block>
  <block id="0b79795d3efc95b9976c7c5b933afce2" category="section-title">Einführung</block>
  <block id="4c04d3884cafb85369c7a0a6b81d10b0" category="paragraph">In diesem Tutorial erfahren Sie, wie Sie verschiedene AWS-Dienste nutzen, um eine einfache MLOps-Pipeline zu erstellen, die Continuous Integration (CI), Continuous Training (CT) und Continuous Deployment (CD) umfasst.  Im Gegensatz zu herkömmlichen DevOps-Pipelines erfordert MLOps zusätzliche Überlegungen, um den Betriebszyklus abzuschließen.  In diesem Tutorial erhalten Sie Einblicke in die Integration von CT in die MLOps-Schleife, wodurch ein kontinuierliches Training Ihrer Modelle und eine nahtlose Bereitstellung für die Inferenz ermöglicht wird.  Das Tutorial führt Sie durch den Prozess der Nutzung von AWS-Diensten zum Einrichten dieser End-to-End-MLOps-Pipeline.</block>
  <block id="76c3e002d3c052bd6a909366a8dc3845" category="section-title">Manifest</block>
  <block id="e7e0038bb30579a3120d266861982881" category="cell">Funktionalität</block>
  <block id="49ee3087348e8d44e1feda1917443987" category="cell">Name</block>
  <block id="0be8406951cdfda82f00f79328cf4efc" category="cell">Kommentar</block>
  <block id="dc21b082b0947a93d387b8c7e8f89ee5" category="cell">Datenspeicherung</block>
  <block id="f3eec26de1c09022af7c97255f0dfee6" category="cell">AWS FSx ONTAP</block>
  <block id="ae8cde6d64ec0b4ed71f7e4d5a28d65f" category="inline-link-macro">Teil 1 – Integration von Amazon FSx for NetApp ONTAP (FSx ONTAP) als privater S3-Bucket in AWS SageMaker</block>
  <block id="273b64842c06632a1f361f1a341b8c24" category="cell">Weitere Informationen finden Sie unter <block ref="a4f6db8ee799d71c8436c5d66421c857" category="inline-link-macro-rx"></block> .</block>
  <block id="4c5f43ed06df4b05c18ca410c7016249" category="cell">Data Science-IDE</block>
  <block id="5a1439989b12745b5a4ed4b944539247" category="cell">AWS SageMaker</block>
  <block id="4c99a9cb175cf27f5edb2b2a9e21f32c" category="inline-link-macro">Teil 2 – Nutzung von Amazon FSx for NetApp ONTAP (FSx ONTAP) als Datenquelle für das Modelltraining in SageMaker</block>
  <block id="077914145dbaab3cc9a1f25998b4b703" category="cell">Dieses Tutorial basiert auf dem Jupyter-Notebook, das in<block ref="3f7fd29e3ed2add54c00cc8c8501cde7" category="inline-link-macro-rx"></block> .</block>
  <block id="e1d9ae96a3cc2d87549ec614a5eea75b" category="cell">Funktion zum Auslösen der MLOps-Pipeline</block>
  <block id="10740b99bf79c58d32e1a8e73062d05c" category="cell">AWS Lambda-Funktion</block>
  <block id="336d5ebc5436534e61d16e63ddfca327" category="cell">-</block>
  <block id="0fc1223c31c6d7d5d233235c0a8f3ee0" category="cell">Cron-Job-Trigger</block>
  <block id="0abaf4e46241f987a0b4e6a434e596cd" category="cell">AWS EventBridge</block>
  <block id="e015867873eac103879d29f569610c66" category="cell">Deep-Learning-Framework</block>
  <block id="95b88f180e9eb5678e0f9ebac2cbe643" category="cell">PyTorch</block>
  <block id="6af8c08e3948b664c72a8cc3c2709254" category="cell">AWS Python SDK</block>
  <block id="6686853da3491a56c98917cc5c4ddea2" category="cell">boto3</block>
  <block id="4f465e36f699fcf0570d854d9f692508" category="cell">Programmiersprache</block>
  <block id="a7f5f35426b927411fc9231b56382173" category="cell">Python</block>
  <block id="cd9ec78e2cad962acfcab027dd62d904" category="cell">v3.10</block>
  <block id="925335f81021de4d22fde55ae7f0e86a" category="section-title">Voraussetzung</block>
  <block id="368743a79699dd2e9a1db93cb728196a" category="list-text">Ein vorkonfiguriertes FSx ONTAP Dateisystem.  Dieses Tutorial verwendet für den Trainingsprozess in FSx ONTAP gespeicherte Daten.</block>
  <block id="73d970f5582fe283900cc4b125f71ab0" category="list-text">Eine *SageMaker Notebook-Instanz*, die so konfiguriert ist, dass sie dieselbe VPC wie das oben erwähnte FSx ONTAP Dateisystem gemeinsam nutzt.</block>
  <block id="cd201faac7e3cf792faa46c93195c65b" category="list-text">Stellen Sie vor dem Auslösen der *AWS Lambda-Funktion* sicher, dass sich die *SageMaker Notebook-Instanz* im Status *gestoppt* befindet.</block>
  <block id="238f736fdf6bcdcd7f397969fe6eb36e" category="list-text">Der Instanztyp *ml.g4dn.xlarge* ist erforderlich, um die für die Berechnungen tiefer neuronaler Netzwerke erforderliche GPU-Beschleunigung zu nutzen.</block>
  <block id="2d242bb36ec91b32005f9296ff03a912" category="section-title">Architektur</block>
  <block id="2c03bdafce7f1816c8faa5db2e5d1258" category="paragraph"><block ref="2c03bdafce7f1816c8faa5db2e5d1258" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e320ad9e531a78d8b06272138f0f29b7" category="paragraph">Diese MLOps-Pipeline ist eine praktische Implementierung, die einen Cron-Job verwendet, um eine serverlose Funktion auszulösen, die wiederum einen AWS-Dienst ausführt, der mit einer Lebenszyklus-Callback-Funktion registriert ist.  Als Cronjob fungiert die *AWS EventBridge*.  Es ruft regelmäßig eine *AWS Lambda-Funktion* auf, die für die Neuschulung und erneute Bereitstellung des Modells verantwortlich ist.  Bei diesem Vorgang wird die *AWS SageMaker Notebook*-Instanz hochgefahren, um die erforderlichen Aufgaben auszuführen.</block>
  <block id="2f53ab942978849d906d82a87554a1e2" category="section-title">Schritt-für-Schritt-Konfiguration</block>
  <block id="ecce3b4394f7f06232bad571a96a0391" category="section-title">Lebenszykluskonfigurationen</block>
  <block id="8482e23b03456ee8ac2760d540c11442" category="paragraph">Um die Lebenszyklus-Rückruffunktion für die AWS SageMaker Notebook-Instanz zu konfigurieren, verwenden Sie *Lebenszykluskonfigurationen*.  Mit diesem Dienst können Sie die erforderlichen Aktionen definieren, die beim Hochfahren der Notebook-Instanz ausgeführt werden sollen.  Insbesondere kann innerhalb der *Lebenszykluskonfigurationen* ein Shell-Skript implementiert werden, um die Notebook-Instanz automatisch herunterzufahren, sobald die Trainings- und Bereitstellungsprozesse abgeschlossen sind.  Dies ist eine erforderliche Konfiguration, da die Kosten einer der wichtigsten Aspekte bei MLOps sind.</block>
  <block id="79d14d6493dc1a7a7d33bf031166f9a9" category="paragraph">Es ist wichtig zu beachten, dass die Konfiguration für *Lebenszykluskonfigurationen* im Voraus eingerichtet werden muss.  Daher wird empfohlen, die Konfiguration dieses Aspekts zu priorisieren, bevor Sie mit der Einrichtung der anderen MLOps-Pipeline fortfahren.</block>
  <block id="29beb103651093d4e75530e25a50f4bd" category="list-text">Um eine Lebenszykluskonfiguration einzurichten, öffnen Sie das *Sagemaker*-Bedienfeld und navigieren Sie zu *Lebenszykluskonfigurationen* im Abschnitt *Admin-Konfigurationen*.</block>
  <block id="e40d22b369f011035946ad31f47b655a" category="inline-image-macro">SageMaker-Panel</block>
  <block id="808aecfbb727487113195461863f7b8f" category="paragraph"><block ref="808aecfbb727487113195461863f7b8f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="706c89d427897aa8c9093c9ea4ddf1cb" category="list-text">Wählen Sie die Registerkarte *Notebook-Instanz* und klicken Sie auf die Schaltfläche *Konfiguration erstellen*</block>
  <block id="6d548bb5536b7ca36996b9a2bf7f3fc9" category="inline-image-macro">Willkommensseite zur Lebenszykluskonfiguration</block>
  <block id="533585f6e9e5ce51a2cd2322d75dfd10" category="paragraph"><block ref="533585f6e9e5ce51a2cd2322d75dfd10" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4bfce2cb9f46fa7b22c7f04d6aa38b9e" category="list-text">Fügen Sie den folgenden Code in den Eingabebereich ein.</block>
  <block id="a3c7be0a54a45c8a39d852df0ffe5795" category="list-text">Dieses Skript führt das Jupyter-Notebook aus, das das erneute Trainieren und die erneute Bereitstellung des Modells für die Inferenz übernimmt.  Nach Abschluss der Ausführung wird das Notebook innerhalb von 5 Minuten automatisch heruntergefahren.  Weitere Informationen zur Problemstellung und zur Codeimplementierung finden Sie unter<block ref="3f7fd29e3ed2add54c00cc8c8501cde7" category="inline-link-macro-rx"></block> .</block>
  <block id="f8d2f79250f54a742eec560a47022213" category="inline-image-macro">Lebenszykluskonfiguration erstellen</block>
  <block id="32868d8eaf16b0e5d6cc389594591fa8" category="paragraph"><block ref="32868d8eaf16b0e5d6cc389594591fa8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a835fb020d342258f64fe6be9b11cc29" category="list-text">Navigieren Sie nach der Erstellung zu den Notebook-Instanzen, wählen Sie die Zielinstanz aus und klicken Sie im Dropdown-Menü „Aktionen“ auf „Einstellungen aktualisieren“.</block>
  <block id="386c8dd530ade6b4cdc15f9f6ebad5c4" category="inline-image-macro">Dropdown-Liste „Update-Einstellungen“</block>
  <block id="c2ba792fac24b100bacf8cb5998dfc1e" category="paragraph"><block ref="c2ba792fac24b100bacf8cb5998dfc1e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2f80499d713c8d9fe19313ec1dc9bd45" category="list-text">Wählen Sie die erstellte *Lebenszykluskonfiguration* aus und klicken Sie auf *Notebook-Instanz aktualisieren*.</block>
  <block id="929b843b11b6f17c62198cd38020bfe6" category="inline-image-macro">Aktualisieren der Lebenszykluskonfiguration des Notebooks</block>
  <block id="e0dc07a964d60792b3ec801e8395ef77" category="paragraph"><block ref="e0dc07a964d60792b3ec801e8395ef77" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a0f9cbbefa9b9603cf2241f33621e37" category="section-title">Serverlose AWS Lambda-Funktion</block>
  <block id="4a799fa8d490fae92d630fe6cc65b928" category="paragraph">Wie bereits erwähnt, ist die *AWS Lambda-Funktion* für das Hochfahren der *AWS SageMaker Notebook-Instanz* verantwortlich.</block>
  <block id="be107f93440a41fcae408e1abec6403e" category="list-text">Um eine *AWS Lambda-Funktion* zu erstellen, navigieren Sie zum entsprechenden Bereich, wechseln Sie zur Registerkarte *Funktionen* und klicken Sie auf *Funktion erstellen*.</block>
  <block id="d28550fe1b16be91a51602ddd8c1d60f" category="inline-image-macro">Willkommensseite der AWS-Lambda-Funktion</block>
  <block id="627b95a2fda6260f5df8d487a291ceea" category="paragraph"><block ref="627b95a2fda6260f5df8d487a291ceea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a60f634c6f68222d8abaaa29bd057217" category="list-text">Bitte tragen Sie alle erforderlichen Angaben auf der Seite ein und denken Sie daran, die Runtime auf *Python 3.10* umzustellen.</block>
  <block id="267b7733eb14e4bbd98146ea3f8501b1" category="inline-image-macro">Erstellen einer AWS-Lambda-Funktion</block>
  <block id="cce551decdf09efb16caf7432d6c7eba" category="paragraph"><block ref="cce551decdf09efb16caf7432d6c7eba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6bee22bc8ca787cbf1475d27ae7429d6" category="list-text">Bitte überprüfen Sie, ob die angegebene Rolle über die erforderliche Berechtigung *AmazonSageMakerFullAccess* verfügt, und klicken Sie auf die Schaltfläche *Funktion erstellen*.</block>
  <block id="3f6a1b36a855303ea55de235a44c52b0" category="inline-image-macro">Ausführungsrolle auswählen</block>
  <block id="fa8e9001a3295e1f7a1f8d3ef3e92572" category="paragraph"><block ref="fa8e9001a3295e1f7a1f8d3ef3e92572" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fcc43af2494337ee641b41a13f71fc46" category="list-text">Wählen Sie die erstellte Lambda-Funktion aus.  Kopieren Sie auf der Registerkarte „Code“ den folgenden Code und fügen Sie ihn in den Textbereich ein.  Dieser Code startet die Notebook-Instanz mit dem Namen *fsxn-ontap*.</block>
  <block id="c2edd2bdf75433b7f31062be9571f528" category="list-text">Klicken Sie auf die Schaltfläche *Bereitstellen*, um diese Codeänderung anzuwenden.</block>
  <block id="ea355214fd4bc7c57f471bd92918879b" category="inline-image-macro">Einsatz</block>
  <block id="64446fff99d978434b172f7c745ece52" category="paragraph"><block ref="64446fff99d978434b172f7c745ece52" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b9bb44167ffa5f5dc2d30616b32fe21b" category="list-text">Um anzugeben, wie diese AWS Lambda-Funktion ausgelöst werden soll, klicken Sie auf die Schaltfläche „Trigger hinzufügen“.</block>
  <block id="c8d04adc09d32f5c953177228f96826b" category="inline-image-macro">AWS-Funktionstrigger hinzufügen</block>
  <block id="6297ab474f745fe7abc72cd5f148311b" category="paragraph"><block ref="6297ab474f745fe7abc72cd5f148311b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9ba138d79283b1a8aad0ef0cc35ce105" category="list-text">Wählen Sie EventBridge aus dem Dropdown-Menü aus und klicken Sie dann auf das Optionsfeld „Neue Regel erstellen“.  Geben Sie im Feld „Zeitplanausdruck“ Folgendes ein:<block ref="5bb28b828095c4a920fb3d34b89c2b84" prefix=" " category="inline-code"></block> und klicken Sie auf die Schaltfläche „Hinzufügen“, um diese neue Cronjob-Regel zu erstellen und auf die AWS Lambda-Funktion anzuwenden.</block>
  <block id="4ab295fce5805d57b17ce3316bf007fa" category="inline-image-macro">Auslöser abschließen</block>
  <block id="46f9833b45661170323abab7808e6219" category="paragraph"><block ref="46f9833b45661170323abab7808e6219" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3643e50ab12ef03d2731f0654366409d" category="paragraph">Nach Abschluss der zweistufigen Konfiguration initiiert die *AWS Lambda-Funktion* täglich das *SageMaker-Notebook*, führt eine erneute Modellschulung mithilfe der Daten aus dem *FSx ONTAP*-Repository durch, stellt das aktualisierte Modell erneut in der Produktionsumgebung bereit und fährt die *SageMaker-Notebook-Instanz* automatisch herunter, um die Kosten zu optimieren.  Dadurch wird sichergestellt, dass das Modell aktuell bleibt.</block>
  <block id="0be5bfaeb8f14cd39a235e5050cecbc9" category="paragraph">Damit ist das Tutorial zur Entwicklung einer MLOps-Pipeline abgeschlossen.</block>
  <block id="fbf39511561166f560c51e6bdf601a0e" category="summary">Dies ist die Einführungsseite zum Abschnitt FSx ONTAP MLOps.</block>
  <block id="28cd7fd0e401ee73677b7f7441149a51" category="doc">Amazon FSx for NetApp ONTAP (FSx ONTAP) für MLOps</block>
  <block id="fba7ee1ae1e1979f64e6e11317d235ff" category="paragraph">Dieser Abschnitt befasst sich mit der praktischen Anwendung der Entwicklung von KI-Infrastrukturen und bietet eine umfassende Anleitung zum Erstellen einer MLOps-Pipeline mit FSx ONTAP.  Es umfasst drei umfassende Beispiele und führt Sie durch die Erfüllung Ihrer MLOps-Anforderungen mithilfe dieser leistungsstarken Datenverwaltungsplattform.</block>
  <block id="e2e58416305212ecee9fc44a8a57e389" category="paragraph">Diese Artikel konzentrieren sich auf:</block>
  <block id="a4f6db8ee799d71c8436c5d66421c857" category="list-text"><block ref="a4f6db8ee799d71c8436c5d66421c857" category="inline-link-macro-rx"></block></block>
  <block id="3f7fd29e3ed2add54c00cc8c8501cde7" category="list-text"><block ref="3f7fd29e3ed2add54c00cc8c8501cde7" category="inline-link-macro-rx"></block></block>
  <block id="71b4f7c054c855f2e85df08fc5e39095" category="list-text"><block ref="71b4f7c054c855f2e85df08fc5e39095" category="inline-link-macro-rx"></block></block>
  <block id="8b34d4c412144b306293274a1964c465" category="paragraph">Am Ende dieses Abschnitts haben Sie ein solides Verständnis dafür erlangt, wie Sie FSx ONTAP zur Optimierung von MLOps-Prozessen verwenden können.</block>
  <block id="f3be583adfbfc01a44597d4c6f7e4ef5" category="summary">Dieser Beitrag bietet eine Anleitung zum Konfigurieren von FSx ONTAP als privatem S3-Bucket mit AWS SageMaker.</block>
  <block id="405642837c20faf5ee6d81b4d039206f" category="paragraph">Dieser Abschnitt enthält eine Anleitung zum Konfigurieren von FSx ONTAP als privater S3-Bucket mit AWS SageMaker.</block>
  <block id="8c52c9bdd7d9ef6a6f82004af97fae7b" category="paragraph">Am Beispiel von SageMaker bietet diese Seite eine Anleitung zum Konfigurieren von FSx ONTAP als privatem S3-Bucket.</block>
  <block id="69620f6919f430e72c0f67207535605b" category="inline-link-macro">Videolink</block>
  <block id="2b6442845e4dd1bf2e9140ac796e1a93" category="paragraph">Weitere Informationen zu FSx ONTAP finden Sie in dieser Präsentation (<block ref="f781ab67717d91cabffd32c6ef2dd731" category="inline-link-macro-rx"></block> )</block>
  <block id="7a97419a6312bf2f5dcdb87d844f3d07" category="section-title">User Guide</block>
  <block id="2f5513954af7462427835c65fbeeac6d" category="section-title">Servererstellung</block>
  <block id="aa5fe14483191172e4fb6ae032e063db" category="section-title">Erstellen einer SageMaker-Notebook-Instanz</block>
  <block id="22a9741b15ba6b8515c1bcf1eb1e2424" category="list-text">Öffnen Sie die AWS-Konsole.  Suchen Sie im Suchfeld nach SageMaker und klicken Sie auf den Dienst *Amazon SageMaker*.</block>
  <block id="f81ad91c4e9a7e4840e3c7a28ad316cb" category="inline-image-macro">Öffnen Sie die AWS-Konsole</block>
  <block id="91ff4fb5f0a57e0f0b2c24cdefb4f12b" category="paragraph"><block ref="91ff4fb5f0a57e0f0b2c24cdefb4f12b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7b8d9a34ee98c3b1e7231bdb38a022c7" category="list-text">Öffnen Sie die *Notebook-Instanzen* unter der Registerkarte „Notebook“ und klicken Sie auf die orangefarbene Schaltfläche „Notebook-Instanz erstellen“*.</block>
  <block id="519925d609277093d7d2ace0457f720a" category="inline-image-macro">AWS SageMaker Notebook-Instance-Konsole</block>
  <block id="d8d17e525889b2a89d32645cb06938f6" category="paragraph"><block ref="d8d17e525889b2a89d32645cb06938f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b070f651df156f54539ea886d6fdb252" category="list-text">Geben Sie auf der Erstellungsseite den *Namen der Notebook-Instanz* ein. Erweitern Sie das *Netzwerk*-Bedienfeld. Belassen Sie die anderen Einträge auf den Standardwerten und wählen Sie eine *VPC*, ein *Subnetz* und *Sicherheitsgruppe(n)* aus.  (Diese *VPC* und dieses *Subnetz* werden später zum Erstellen des FSx ONTAP Dateisystems verwendet.) Klicken Sie unten rechts auf die orangefarbene Schaltfläche *Notebook-Instanz erstellen*.</block>
  <block id="02ca97619a6b22b9a2f189b3ebb82b57" category="inline-image-macro">Erstellen einer Notebook-Instanz</block>
  <block id="39578328ea9c3b8e5a35ce1c48b45447" category="paragraph"><block ref="39578328ea9c3b8e5a35ce1c48b45447" category="inline-image-macro-rx" type="image"></block></block>
  <block id="08bf44c8870f044a9c29ec0decd4506f" category="section-title">Erstellen Sie ein FSx ONTAP Dateisystem</block>
  <block id="a0de53cada8c076391cb766a21d191f7" category="list-text">Öffnen Sie die AWS-Konsole.  Suchen Sie im Suchfeld nach Fsx und klicken Sie auf den Dienst *FSx*.</block>
  <block id="f815343e909cc0c69784c51630a10b2d" category="inline-image-macro">FSx-Panel</block>
  <block id="eb780b87d03905721f4484288ab2cde0" category="paragraph"><block ref="eb780b87d03905721f4484288ab2cde0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="55ecf05d044f8d3b179ea6daf134664f" category="list-text">Klicken Sie auf *Dateisystem erstellen*.</block>
  <block id="77d148bb10790640cfe7639dbc11e075" category="inline-image-macro">Dateisystem erstellen</block>
  <block id="af10909a9067ddaba9079a1b5b37ca6d" category="paragraph"><block ref="af10909a9067ddaba9079a1b5b37ca6d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="83c8e65862a92cd7eadb9812c8c5f780" category="list-text">Wählen Sie die erste Karte *FSx ONTAP* aus und klicken Sie auf *Weiter*.</block>
  <block id="6277f28f413aee819a82e3e0058bc5ee" category="inline-image-macro">Dateisystemtyp auswählen</block>
  <block id="03ad22f430d1bae0e9c295ff4191eac1" category="paragraph"><block ref="03ad22f430d1bae0e9c295ff4191eac1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9b05d3465523c46c6ece6e36ff05bba" category="list-text">Auf der Detailkonfigurationsseite.</block>
  <block id="720e4d0907f5f98d25c99b23a410c93c" category="list-text">Wählen Sie die Option *Standard erstellen*.</block>
  <block id="fb23d0162f70b1382f3c50cb5b513f4d" category="inline-image-macro">Fenster „Dateisystem erstellen“</block>
  <block id="69ff48a0fa8eb8c1e7999c1ff581fe73" category="paragraph"><block ref="69ff48a0fa8eb8c1e7999c1ff581fe73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bea7f738749e0c476b2d1c016021ec5b" category="list-text">Geben Sie den *Dateisystemnamen* und die *SSD-Speicherkapazität* ein.</block>
  <block id="aad9529851b728c0fb560a0f7d9b8a5b" category="inline-image-macro">Dateisystemdetails angeben</block>
  <block id="1c15f13ef7a0d9e6720f0178a39c5dde" category="paragraph"><block ref="1c15f13ef7a0d9e6720f0178a39c5dde" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5db4aeb81b94a1ba5cdcc12c96b36cb1" category="list-text">Stellen Sie sicher, dass Sie dasselbe *VPC* und *Subnetz* wie für die *SageMaker Notebook*-Instanz verwenden.</block>
  <block id="84e88a3298035d04334f19541c31a16a" category="inline-image-macro">Netzwerk- und Sicherheitskonfiguration</block>
  <block id="3788a93ec701a347dfa0def01330fa09" category="paragraph"><block ref="1832dc909b2a82e8c4b70afb493963cc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8cb695bdcb362931108f41ff0ec65293" category="list-text">Geben Sie den Namen der *Storage Virtual Machine* ein und *Geben Sie ein Kennwort an* für Ihre SVM (Storage Virtual Machine).</block>
  <block id="691a3c3a3ffee99887addcf66bcceeec" category="inline-image-macro">Standardkonfiguration der virtuellen Speichermaschine</block>
  <block id="68cc70fed3a17a1a1caec811e0d01f03" category="paragraph"><block ref="68cc70fed3a17a1a1caec811e0d01f03" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c4c7ba1524cf2b18e8592e9ceb83df71" category="list-text">Belassen Sie die anderen Einträge auf Standard und klicken Sie unten rechts auf die orangefarbene Schaltfläche *Weiter*.</block>
  <block id="38f46900c7e5018a4d712fad6dde98ea" category="inline-image-macro">Konfiguration bestätigen</block>
  <block id="c715f26fb866d18303643cfaf886a63c" category="paragraph"><block ref="c715f26fb866d18303643cfaf886a63c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6d5ce0306761971a734da357efdf9e6f" category="list-text">Klicken Sie unten rechts auf der Überprüfungsseite auf die orangefarbene Schaltfläche *Dateisystem erstellen*.</block>
  <block id="c0e0aca15b43c5f4360b8e6c8f2451d9" category="inline-image-macro">Überprüfen Sie die Konfiguration und bestätigen Sie die Erstellung</block>
  <block id="29fe6a20d375efc9f6e4ae1a07258da3" category="paragraph"><block ref="29fe6a20d375efc9f6e4ae1a07258da3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c12346192a59739b1315d8d07143db6e" category="list-text">Das Hochfahren des FSx-Dateisystems kann etwa *20–40 Minuten* dauern.</block>
  <block id="391b09977b768e724f35dad726f1f3ef" category="inline-image-macro">Überprüfen Sie die FSx-Konsole</block>
  <block id="37f274b71add0d0952db64f7c20abd4f" category="paragraph"><block ref="37f274b71add0d0952db64f7c20abd4f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="01ecbbb2b353cf4d915bbe1c1cd5505c" category="section-title">Serverkonfiguration</block>
  <block id="d36647d06b353fcd6fedc60898e43187" category="section-title">ONTAP -Konfiguration</block>
  <block id="07afa2af969623c48103624cdb58551c" category="list-text">Öffnen Sie das erstellte FSx-Dateisystem.  Bitte stellen Sie sicher, dass der Status *Verfügbar* ist.</block>
  <block id="69d4f895c19503f5e9f518c3b74993bb" category="inline-image-macro">Warten Sie auf die Backend-Erstellung</block>
  <block id="a29e057394c30462c97d0a046428ccc6" category="paragraph"><block ref="a29e057394c30462c97d0a046428ccc6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6cbcfc771dc80f5ee77c4deba078b135" category="list-text">Wählen Sie die Registerkarte *Administration* und behalten Sie die *IP-Adresse des Verwaltungsendpunkts* und den * ONTAP -Administratorbenutzernamen* bei.</block>
  <block id="a63e6273ab6f9d27c79b63c3e31a3f35" category="inline-image-macro">Dateisystem-Detailkonsole</block>
  <block id="3a0eb32361b0c7bfba5fc5c8da00fec5" category="paragraph"><block ref="3a0eb32361b0c7bfba5fc5c8da00fec5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c0164aebedfb5a99b6386ba01ffbc963" category="list-text">Öffnen Sie die erstellte *SageMaker Notebook-Instanz* und klicken Sie auf *JupyterLab öffnen*.</block>
  <block id="5f42fc26006705fa3b9ffe25fe3d881d" category="inline-image-macro">AWS SageMaker Notebook-Instanzkonsole</block>
  <block id="85c4a421924bf2d8fbb4d65b5fcd0317" category="paragraph"><block ref="85c4a421924bf2d8fbb4d65b5fcd0317" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12dbc394c66b065a1aef771f11914dad" category="list-text">Öffnen Sie auf der Jupyter Lab-Seite ein neues *Terminal*.</block>
  <block id="f3970717b786c14ff186b01681be062f" category="inline-image-macro">Jupyter Lab-Willkommensseite</block>
  <block id="6774664dc7058399d3db96209da79e83" category="paragraph"><block ref="6774664dc7058399d3db96209da79e83" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ad2ec02537c0b93a2b5a7937ea89048" category="list-text">Geben Sie den SSH-Befehl ssh &lt;Administrator-Benutzername&gt;@ &lt;ONTAP&gt; ein, um sich beim FSx ONTAP Dateisystem anzumelden.  (Benutzername und IP-Adresse werden aus Schritt 2 abgerufen) Bitte verwenden Sie das Kennwort, das Sie beim Erstellen der *Storage-virtuellen Maschine* verwendet haben.</block>
  <block id="7d71a86e3b4885ad307f3e18ba62c9cb" category="inline-image-macro">Jupyter Lab-Terminal</block>
  <block id="3907af7edeccc904e748efdec97a698b" category="paragraph"><block ref="3907af7edeccc904e748efdec97a698b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e7fe5b2fa5a8ec0c7d2b2e65bce4c302" category="list-text">Führen Sie die Befehle in der folgenden Reihenfolge aus.  Wir verwenden *fsxn-ontap* als Namen für den *Namen des privaten S3-Buckets von FSx ONTAP *.  Bitte verwenden Sie den *Namen der virtuellen Speichermaschine* für das Argument *-vserver*.</block>
  <block id="9166665a24ce86a4cdc78ee5dc10b99e" category="inline-image-macro">Jupyter Lab-Terminalausgabe</block>
  <block id="f953d25a23501b488d1729dde1bcbfec" category="paragraph"><block ref="f953d25a23501b488d1729dde1bcbfec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09b48d43c330baa7527d4d5b785ddc78" category="list-text">Führen Sie die folgenden Befehle aus, um die Endpunkt-IP und Anmeldeinformationen für FSx ONTAP private S3 abzurufen.</block>
  <block id="1025c82e986534d7a6a941036fce2afd" category="list-text">Bewahren Sie die Endpunkt-IP und die Anmeldeinformationen für die zukünftige Verwendung auf.</block>
  <block id="8d5111b0ef521165f30cc6043e79b8b4" category="paragraph"><block ref="8d5111b0ef521165f30cc6043e79b8b4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb11dcb3b0575af26386e753c028e37d" category="section-title">Client-Konfiguration</block>
  <block id="d885926aec2cdf1253c078102968eb8d" category="list-text">Erstellen Sie in der SageMaker-Notebook-Instanz ein neues Jupyter-Notebook.</block>
  <block id="6aa1a9a77e640f5f5edc06a932b6ed8a" category="inline-image-macro">Öffnen Sie ein neues Jupyter-Notebook</block>
  <block id="28f138d5d6604c9e1a6788b166239c3f" category="paragraph"><block ref="28f138d5d6604c9e1a6788b166239c3f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e248de3aba6cefa5adacaaee03aaa6e8" category="inline-link-macro">fsxn_demo.ipynb</block>
  <block id="3161057d478204432fe5225e86346e57" category="list-text">Verwenden Sie den folgenden Code als Workaround-Lösung, um Dateien in den privaten S3-Bucket von FSx ONTAP hochzuladen.  Ein umfassendes Codebeispiel finden Sie in diesem Notizbuch.<block ref="5926c62f2c3d59c789081e1f0aff3f08" category="inline-link-macro-rx"></block></block>
  <block id="9c715084d36062c3ee5a47d1e528cd94" category="paragraph">Damit ist die Integration zwischen FSx ONTAP und der SageMaker-Instanz abgeschlossen.</block>
  <block id="6d8aee76fb8c09877162ad6d9e5fdac9" category="section-title">Nützliche Checkliste zum Debuggen</block>
  <block id="c00ea068fc81a9c0fcad0e38fbc7bb94" category="list-text">Stellen Sie sicher, dass sich die SageMaker Notebook-Instance und das FSx ONTAP Dateisystem im selben VPC befinden.</block>
  <block id="2ec57b268e910c39ad70e1b259d09e1a" category="list-text">Denken Sie daran, den Befehl *set dev* auf ONTAP auszuführen, um die Berechtigungsstufe auf *dev* festzulegen.</block>
  <block id="5a7d7d5f81481db284cc081576a810b0" category="section-title">FAQ (Stand: 27.09.2023)</block>
  <block id="de9370dee0783c12eee2dcba49377c0c" category="paragraph">F: Warum erhalte ich beim Hochladen von Dateien auf FSx ONTAP die Fehlermeldung „*Beim Aufrufen des Vorgangs „CreateMultipartUpload“ ist ein Fehler aufgetreten (NotImplemented): Der von Ihnen angeforderte S3-Befehl ist nicht implementiert*“?</block>
  <block id="b17f3ba7d3e19cd555784a4d2fd9e51b" category="paragraph">A: Als privater S3-Bucket unterstützt FSx ONTAP das Hochladen von Dateien mit bis zu 100 MB.  Bei Verwendung des S3-Protokolls werden Dateien, die größer als 100 MB sind, in 100-MB-Blöcke aufgeteilt und die Funktion „CreateMultipartUpload“ aufgerufen.  Die aktuelle Implementierung von FSx ONTAP private S3 unterstützt diese Funktion jedoch nicht.</block>
  <block id="89551e14b23206a9d9d14f16530fc28d" category="paragraph">F: Warum erhalte ich beim Hochladen von Dateien auf FSx ONTAP die Fehlermeldung „*Beim Aufrufen der PutObject-Operationen ist ein Fehler aufgetreten (Zugriff verweigert): Zugriff verweigert*“?</block>
  <block id="21ba2b927703c559d6b74e6dbc961ebb" category="paragraph">A: Um von einer SageMaker Notebook-Instanz auf den privaten S3-Bucket von FSx ONTAP zuzugreifen, ändern Sie die AWS-Anmeldeinformationen in die FSx ONTAP Anmeldeinformationen.  Um der Instanz Schreibberechtigungen zu erteilen, ist jedoch eine Problemumgehungslösung erforderlich, bei der der Bucket gemountet und der Shell-Befehl „chmod“ ausgeführt wird, um die Berechtigungen zu ändern.</block>
  <block id="a713cfa91c4b5642352b00e081eca0ce" category="paragraph">F: Wie kann ich den privaten S3-Bucket von FSx ONTAP in andere SageMaker ML-Dienste integrieren?</block>
  <block id="eae99a039ae09d5e28c061d7218d0efb" category="paragraph">A: Leider bietet das SageMaker Services SDK keine Möglichkeit, den Endpunkt für den privaten S3-Bucket anzugeben.  Daher ist FSx ONTAP S3 nicht mit SageMaker-Diensten wie Sagemaker Data Wrangler, Sagemaker Clarify, Sagemaker Glue, Sagemaker Athena, Sagemaker AutoML und anderen kompatibel.</block>
  <block id="7892d93cdad4bcd1c3e8157592ed858e" category="summary">Der Artikel ist ein Tutorial zur Verwendung von Amazon FSx for NetApp ONTAP (FSx ONTAP) zum Trainieren von PyTorch-Modellen in SageMaker, insbesondere für ein Projekt zur Klassifizierung der Reifenqualität.</block>
  <block id="ecccb638c3da2e33f2ce538fc895233a" category="doc">Teil 2 – Nutzung von AWS Amazon FSx for NetApp ONTAP (FSx ONTAP) als Datenquelle für das Modelltraining in SageMaker</block>
  <block id="ca3ef01192dfa69eac50d8be997f6b51" category="paragraph">Dieser Artikel ist ein Tutorial zur Verwendung von Amazon FSx for NetApp ONTAP (FSx ONTAP) zum Trainieren von PyTorch-Modellen in SageMaker, insbesondere für ein Projekt zur Klassifizierung der Reifenqualität.</block>
  <block id="23851f05df4c2ebe4433cd559cf23e55" category="paragraph">Dieses Tutorial bietet ein praktisches Beispiel für ein Computer Vision-Klassifizierungsprojekt und vermittelt praktische Erfahrung beim Erstellen von ML-Modellen, die FSx ONTAP als Datenquelle innerhalb der SageMaker-Umgebung verwenden.  Das Projekt konzentriert sich auf die Verwendung von PyTorch, einem Deep-Learning-Framework, um die Reifenqualität anhand von Reifenbildern zu klassifizieren.  Der Schwerpunkt liegt auf der Entwicklung von Modellen für maschinelles Lernen unter Verwendung von FSx ONTAP als Datenquelle in Amazon SageMaker.</block>
  <block id="516bec227f44816f7ecc2d58aae01bb2" category="section-title">Was ist FSx ONTAP</block>
  <block id="e586360cf616ba9b2800383d7e36b444" category="paragraph">Amazon FSx ONTAP ist tatsächlich eine vollständig verwaltete Speicherlösung, die von AWS angeboten wird.  Es nutzt das ONTAP Dateisystem von NetApp, um zuverlässigen und leistungsstarken Speicher bereitzustellen.  Mit Unterstützung für Protokolle wie NFS, SMB und iSCSI ermöglicht es nahtlosen Zugriff von verschiedenen Compute-Instanzen und Containern.  Der Dienst ist auf außergewöhnliche Leistung ausgelegt und gewährleistet schnelle und effiziente Datenvorgänge.  Darüber hinaus bietet es eine hohe Verfügbarkeit und Haltbarkeit und stellt sicher, dass Ihre Daten zugänglich und geschützt bleiben.  Darüber hinaus ist die Speicherkapazität von Amazon FSx ONTAP skalierbar, sodass Sie sie problemlos an Ihre Bedürfnisse anpassen können.</block>
  <block id="05ec336213c5aa3c3a49c743c5fbad19" category="section-title">Netzwerkumgebung</block>
  <block id="9e7ee35cf251304984a47d590762e1d2" category="inline-image-macro">Netzwerkumgebung</block>
  <block id="8ebf7b35e6a40f5a75092ae4b590f9d1" category="paragraph"><block ref="8ebf7b35e6a40f5a75092ae4b590f9d1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a431daf3a478d96ed5ffc10a4056228" category="paragraph">FSx ONTAP (Amazon FSx ONTAP) ist ein AWS-Speicherdienst.  Es umfasst ein Dateisystem, das auf dem NetApp ONTAP -System ausgeführt wird, und eine von AWS verwaltete System-Virtual-Machine (SVM), die eine Verbindung damit herstellt.  Im bereitgestellten Diagramm befindet sich der von AWS verwaltete NetApp ONTAP -Server außerhalb des VPC.  Der SVM dient als Vermittler zwischen SageMaker und dem NetApp ONTAP -System, empfängt Betriebsanforderungen von SageMaker und leitet sie an den zugrunde liegenden Speicher weiter.  Um auf FSx ONTAP zuzugreifen, muss SageMaker im selben VPC wie die FSx ONTAP Bereitstellung platziert werden.  Diese Konfiguration gewährleistet die Kommunikation und den Datenzugriff zwischen SageMaker und FSx ONTAP.</block>
  <block id="f8aacfa5c683858912c498f517c9b457" category="section-title">Datenzugriff</block>
  <block id="70385d02db6379c01d4b7b17101f2004" category="paragraph">In realen Szenarien verwenden Datenwissenschaftler normalerweise die vorhandenen, in FSx ONTAP gespeicherten Daten, um ihre Modelle für maschinelles Lernen zu erstellen.  Da das FSx ONTAP Dateisystem nach der Erstellung jedoch zunächst leer ist, ist es zu Demonstrationszwecken erforderlich, die Trainingsdaten manuell hochzuladen.  Dies kann erreicht werden, indem FSx ONTAP als Volume in SageMaker eingebunden wird.  Sobald das Dateisystem erfolgreich gemountet ist, können Sie Ihren Datensatz an den gemounteten Speicherort hochladen und ihn so für das Training Ihrer Modelle innerhalb der SageMaker-Umgebung zugänglich machen.  Mit diesem Ansatz können Sie die Speicherkapazität und Funktionen von FSx ONTAP nutzen, während Sie mit SageMaker zur Modellentwicklung und -schulung arbeiten.</block>
  <block id="23ea498668d1fa717fb7cfb600bf3238" category="inline-link-macro">Teil 1 – Integration von Amazon FSx for NetApp ONTAP (FSx ONTAP) als privater S3-Bucket in AWS SageMaker</block>
  <block id="95d89db7f4a106e280e1c30cde658610" category="paragraph">Der Datenlesevorgang umfasst die Konfiguration von FSx ONTAP als privater S3-Bucket.  Um die detaillierten Konfigurationsanweisungen zu erfahren, lesen Sie bitte<block ref="8e7379c67a0724b1a49308a7ae6ac3d5" category="inline-link-macro-rx"></block></block>
  <block id="30eaeebc8f9611f55e018d1dd51789ba" category="section-title">Integrationsübersicht</block>
  <block id="7ffc912d31a398685c5667622bb5ed7f" category="inline-image-macro">Trainingsablauf</block>
  <block id="29e5f040e75c8e4e628e90efc594e3ef" category="paragraph"><block ref="29e5f040e75c8e4e628e90efc594e3ef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da4169484addf29c5d1d35a28a5073fd" category="paragraph">Der Workflow zur Verwendung von Trainingsdaten in FSx ONTAP zum Erstellen eines Deep-Learning-Modells in SageMaker lässt sich in drei Hauptschritte zusammenfassen: Definition des Datenladers, Modelltraining und Bereitstellung.  Auf hoher Ebene bilden diese Schritte die Grundlage einer MLOps-Pipeline.  Für eine umfassende Umsetzung sind jedoch zu jedem Schritt mehrere detaillierte Unterschritte erforderlich.  Diese Unterschritte umfassen verschiedene Aufgaben wie Datenvorverarbeitung, Datensatzaufteilung, Modellkonfiguration, Hyperparameter-Tuning, Modellbewertung und Modellbereitstellung.  Diese Schritte gewährleisten einen gründlichen und effektiven Prozess zum Erstellen und Bereitstellen von Deep-Learning-Modellen mithilfe von Trainingsdaten von FSx ONTAP innerhalb der SageMaker-Umgebung.</block>
  <block id="2870e83ec05413b09bc7de07f60f54fa" category="section-title">Schrittweise Integration</block>
  <block id="e3364bc8e125077137411ae17c13b771" category="section-title">Loader</block>
  <block id="220b880a3d218e80d8fde5901827649a" category="paragraph">Um ein PyTorch-Deep-Learning-Netzwerk mit Daten zu trainieren, wird ein Datenlader erstellt, der die Dateneingabe erleichtert.  Der Datenlader definiert nicht nur die Batchgröße, sondern bestimmt auch das Verfahren zum Lesen und Vorverarbeiten jedes Datensatzes innerhalb des Batches.  Durch die Konfiguration des Datenladers können wir die Verarbeitung der Daten in Stapeln durchführen und so das Training des Deep-Learning-Netzwerks ermöglichen.</block>
  <block id="cc0322e5278f21d6001e3995e46e2810" category="paragraph">Der Datenlader besteht aus 3 Teilen.</block>
  <block id="0cee527e2a952dcfca00fb6de192e2a1" category="section-title">Vorverarbeitungsfunktion</block>
  <block id="50a46eb952358276ed306b6d88aadc7d" category="paragraph">Der obige Codeausschnitt demonstriert die Definition von Bildvorverarbeitungstransformationen mithilfe des Moduls *torchvision.transforms*.  In diesem Tutorial wird das Vorverarbeitungsobjekt erstellt, um eine Reihe von Transformationen anzuwenden.  Zunächst wandelt die *ToTensor()*-Transformation das Bild in eine Tensordarstellung um.  Anschließend wird die Bildgröße durch die Transformation *Resize((224,224))* auf eine feste Größe von 224 x 224 Pixeln geändert.  Schließlich normalisiert die *Normalize()*-Transformation die Tensorwerte, indem sie den Mittelwert subtrahiert und durch die Standardabweichung entlang jedes Kanals dividiert.  Die zur Normalisierung verwendeten Mittelwert- und Standardabweichungswerte werden üblicherweise in vortrainierten neuronalen Netzwerkmodellen verwendet.  Insgesamt bereitet dieser Code die Bilddaten für die weitere Verarbeitung oder Eingabe in ein vortrainiertes Modell vor, indem er sie in einen Tensor umwandelt, ihre Größe ändert und die Pixelwerte normalisiert.</block>
  <block id="578a55cb1cfe6e1363a1c73fec7d9c6f" category="section-title">Die PyTorch-Dataset-Klasse</block>
  <block id="7895a195c178ff4c5e59638a3c762dd2" category="paragraph">Diese Klasse bietet Funktionen zum Abrufen der Gesamtzahl der Datensätze im Datensatz und definiert die Methode zum Lesen der Daten für jeden Datensatz.  Innerhalb der Funktion *__getitem__* verwendet der Code das S3-Bucket-Objekt boto3, um die Binärdaten von FSx ONTAP abzurufen.  Der Codestil für den Zugriff auf Daten von FSx ONTAP ähnelt dem Lesen von Daten von Amazon S3.  Die folgende Erklärung befasst sich eingehend mit dem Erstellungsprozess des privaten S3-Objekts *Bucket*.</block>
  <block id="76d805ebfad939474c22611b1a64ec91" category="section-title">FSx ONTAP als privates S3-Repository</block>
  <block id="3d67de2c700f42063d686e92a37a82aa" category="paragraph">Um Daten von FSx ONTAP in SageMaker zu lesen, wird ein Handler erstellt, der mithilfe des S3-Protokolls auf den FSx ONTAP -Speicher verweist.  Dadurch kann FSx ONTAP als privater S3-Bucket behandelt werden.  Die Handler-Konfiguration umfasst die Angabe der IP-Adresse des FSx ONTAP SVM, des Bucket-Namens und der erforderlichen Anmeldeinformationen.  Eine umfassende Erklärung zum Erhalt dieser Konfigurationselemente finden Sie im Dokument unter<block ref="a4f6db8ee799d71c8436c5d66421c857" category="inline-link-macro-rx"></block> .</block>
  <block id="ac5d6406e8dadcbc23e9cf65fe528510" category="paragraph">Im oben genannten Beispiel wird das Bucket-Objekt verwendet, um das PyTorch-Dataset-Objekt zu instanziieren.  Das Dataset-Objekt wird im folgenden Abschnitt näher erläutert.</block>
  <block id="e03717a5c1692689919250506bf382a0" category="section-title">Der PyTorch Data Loader</block>
  <block id="0c919f2bf87f2c6df41e7bbc52c68d04" category="paragraph">Im bereitgestellten Beispiel wird eine Batchgröße von 64 angegeben, was bedeutet, dass jeder Batch 64 Datensätze enthält.  Durch die Kombination der PyTorch-Klasse *Dataset*, der Vorverarbeitungsfunktion und der Trainings-Batchgröße erhalten wir den Datenlader für das Training.  Dieser Datenlader erleichtert den Prozess der stapelweisen Iteration durch den Datensatz während der Trainingsphase.</block>
  <block id="74415cec8ae4d65c228c7fa8da8eae8a" category="section-title">Modelltraining</block>
  <block id="74492eb8210f5168d9ee3eff7524ecde" category="paragraph">Dieser Code implementiert einen standardmäßigen PyTorch-Trainingsprozess.  Es definiert ein neuronales Netzwerkmodell namens *TyreQualityClassifier*, das Faltungsschichten und eine lineare Schicht zur Klassifizierung der Reifenqualität verwendet.  Die Trainingsschleife iteriert über Datenstapel, berechnet den Verlust und aktualisiert die Parameter des Modells mithilfe von Backpropagation und Optimierung.  Darüber hinaus werden zu Überwachungszwecken die aktuelle Zeit, Epoche, Charge und der Verlust gedruckt.</block>
  <block id="4d2e185dfba9f3df542300054ad07998" category="section-title">Modellbereitstellung</block>
  <block id="6116a0f9a85671aec95cc56a205cf186" category="paragraph">Der Code speichert das PyTorch-Modell in *Amazon S3*, da SageMaker für die Bereitstellung die Speicherung des Modells in S3 erfordert.  Durch das Hochladen des Modells auf *Amazon S3* wird es für SageMaker zugänglich, was die Bereitstellung und Inferenz des bereitgestellten Modells ermöglicht.</block>
  <block id="075e4fb3d67ee1fb4bc39dbc5d72b129" category="paragraph">Dieser Code erleichtert die Bereitstellung eines PyTorch-Modells auf SageMaker.  Es definiert einen benutzerdefinierten Serialisierer, *TyreQualitySerializer*, der Eingabedaten als PyTorch-Tensor vorverarbeitet und serialisiert.  Die Klasse *TyreQualityPredictor* ist ein benutzerdefinierter Prädiktor, der den definierten Serialisierer und einen *JSONDeserializer* verwendet.  Der Code erstellt außerdem ein *PyTorchModel*-Objekt, um den S3-Speicherort, die IAM-Rolle, die Framework-Version und den Einstiegspunkt für die Inferenz des Modells anzugeben.  Der Code generiert einen Zeitstempel und erstellt einen Endpunktnamen basierend auf dem Modell und dem Zeitstempel.  Schließlich wird das Modell mithilfe der Bereitstellungsmethode bereitgestellt, wobei die Anzahl der Instanzen, der Instanztyp und der generierte Endpunktname angegeben werden.  Dadurch kann das PyTorch-Modell bereitgestellt und für Inferenzen auf SageMaker zugänglich gemacht werden.</block>
  <block id="bfc7647fbfe6e589911d2da73377b475" category="section-title">Schlussfolgerung</block>
  <block id="99e1766840e675b2dbd8230be049188f" category="paragraph">Dies ist ein Beispiel für die Verwendung des bereitgestellten Endpunkts zur Durchführung der Inferenz.</block>
  <block id="727c63651b565bca2eb7d8a48e0fefd9" category="summary">Dieser Abschnitt fasst dieses Dokument zu den NetApp -Speicherlösungen für Apache Spark zusammen.</block>
  <block id="6f8b794f3246b0c1e1780bb4d4d5dc53" category="doc">Abschluss</block>
  <block id="900200cfc3f2577215c327d16f34840a" category="paragraph">In diesem Dokument besprechen wir die Apache Spark-Architektur, Anwendungsfälle von Kunden und das NetApp -Speicherportfolio im Zusammenhang mit Big Data, moderner Analytik sowie KI, ML und DL.  In unseren Leistungsvalidierungstests auf Basis branchenüblicher Benchmarking-Tools und der Kundennachfrage zeigten die NetApp Spark-Lösungen eine höhere Leistung als native Hadoop-Systeme.  Eine Kombination aus den in diesem Bericht vorgestellten Anwendungsfällen und Leistungsergebnissen von Kunden kann Ihnen bei der Auswahl einer geeigneten Spark-Lösung für Ihre Bereitstellung helfen.</block>
  <block id="ca052b24845534e817869836d49d519a" category="summary">Der Schwerpunkt dieses Dokuments liegt auf der Apache Spark-Architektur, Anwendungsfällen von Kunden und dem NetApp -Speicherportfolio im Zusammenhang mit Big Data-Analysen und künstlicher Intelligenz.  Darüber hinaus werden verschiedene Testergebnisse präsentiert, bei denen branchenübliche KI-, Machine-Learning- und Deep-Learning-Tools mit einem typischen Hadoop-System verglichen wurden, sodass Sie die geeignete Spark-Lösung auswählen können.</block>
  <block id="58b2293adcda372fb415412d23f01a8e" category="doc">TR-4570: NetApp -Speicherlösungen für Apache Spark: Architektur, Anwendungsfälle und Leistungsergebnisse</block>
  <block id="057e5f9ddc5d049ab86855dceffd6d14" category="paragraph">Rick Huang, Karthikeyan Nagalingam, NetApp</block>
  <block id="550fd771b94cb8eb3739d16af31243f3" category="paragraph">Der Schwerpunkt dieses Dokuments liegt auf der Apache Spark-Architektur, Anwendungsfällen von Kunden und dem NetApp -Speicherportfolio im Zusammenhang mit Big Data-Analysen und künstlicher Intelligenz (KI).  Darüber hinaus werden verschiedene Testergebnisse präsentiert, bei denen branchenübliche KI-, Machine-Learning- (ML) und Deep-Learning- (DL) Tools mit einem typischen Hadoop-System verglichen wurden, sodass Sie die geeignete Spark-Lösung auswählen können.  Zu Beginn benötigen Sie eine Spark-Architektur, entsprechende Komponenten und zwei Bereitstellungsmodi (Cluster und Client).</block>
  <block id="9e19cfda234e917201ce19469f25275b" category="paragraph">Dieses Dokument enthält außerdem Anwendungsfälle von Kunden zur Lösung von Konfigurationsproblemen und bietet einen Überblick über das NetApp -Speicherportfolio, das für Big Data-Analysen sowie KI, ML und DL mit Spark relevant ist.  Abschließend präsentieren wir Testergebnisse aus Spark-spezifischen Anwendungsfällen und dem NetApp Spark-Lösungsportfolio.</block>
  <block id="d4612e7dc1347f1ccbfd5e470dda2295" category="section-title">Kundenherausforderungen</block>
  <block id="ce663ffc6a85b2c97e60368b5a9c76e3" category="paragraph">Dieser Abschnitt konzentriert sich auf die Herausforderungen für Kunden im Zusammenhang mit Big Data Analytics und KI/ML/DL in Datenwachstumsbranchen wie Einzelhandel, digitales Marketing, Bankwesen, diskrete Fertigung, Prozessfertigung, Behörden und professionelle Dienstleistungen.</block>
  <block id="8a5bab0d8f4c0d1b73de5ada6b1c91e6" category="section-title">Unvorhersehbare Leistung</block>
  <block id="9790dc49aa09b4759e4c6ebc65fb4c42" category="paragraph">Bei herkömmlichen Hadoop-Bereitstellungen wird normalerweise Standardhardware verwendet.  Um die Leistung zu verbessern, müssen Sie das Netzwerk, das Betriebssystem, den Hadoop-Cluster, Ökosystemkomponenten wie Spark und die Hardware optimieren.  Selbst wenn Sie jede Ebene optimieren, kann es schwierig sein, das gewünschte Leistungsniveau zu erreichen, da Hadoop auf Standardhardware ausgeführt wird, die nicht für hohe Leistung in Ihrer Umgebung ausgelegt ist.</block>
  <block id="b496a0269649d7b570c2052646fd23b6" category="section-title">Medien- und Knotenfehler</block>
  <block id="21af95409591262fb36555acb96262d8" category="paragraph">Selbst unter normalen Bedingungen ist Standardhardware anfällig für Ausfälle.  Wenn eine Festplatte auf einem Datenknoten ausfällt, betrachtet der Hadoop-Master diesen Knoten standardmäßig als fehlerhaft.  Anschließend werden bestimmte Daten von diesem Knoten über das Netzwerk von Replikaten auf einen fehlerfreien Knoten kopiert.  Dieser Prozess verlangsamt die Netzwerkpakete für alle Hadoop-Jobs.  Der Cluster muss die Daten dann erneut zurückkopieren und die überreplizierten Daten entfernen, wenn der fehlerhafte Knoten wieder in einen fehlerfreien Zustand zurückkehrt.</block>
  <block id="03d4836e0d1deb07679d400b8c88a880" category="section-title">Hadoop-Anbieterbindung</block>
  <block id="bb33286c56b053ae85ab21a377bd4347" category="paragraph">Hadoop-Distributoren verfügen über ihre eigene Hadoop-Distribution mit eigener Versionierung, wodurch der Kunde an diese Distributionen gebunden ist.  Viele Kunden benötigen jedoch Unterstützung für In-Memory-Analysen, die den Kunden nicht an bestimmte Hadoop-Distributionen bindet.  Sie müssen die Freiheit haben, die Verteilung zu ändern und trotzdem ihre Analysen mitzunehmen.</block>
  <block id="a940c960f38c44b75bf1da78215690c2" category="section-title">Fehlende Unterstützung für mehr als eine Sprache</block>
  <block id="65a27ee7da3f8c68004d31f60ab65e55" category="paragraph">Kunden benötigen zur Ausführung ihrer Aufgaben häufig zusätzlich zu MapReduce-Java-Programmen Unterstützung für mehrere Sprachen.  Optionen wie SQL und Skripte bieten mehr Flexibilität beim Erhalten von Antworten, mehr Optionen zum Organisieren und Abrufen von Daten und schnellere Möglichkeiten zum Verschieben von Daten in ein Analyseframework.</block>
  <block id="f3e2f69098f73bd8bb3cf61330433955" category="section-title">Schwierigkeit der Verwendung</block>
  <block id="e2bdfb6bb3e956b38b6aacde957996df" category="paragraph">Seit einiger Zeit beschweren sich Leute, dass Hadoop schwierig zu verwenden sei.  Obwohl Hadoop mit jeder neuen Version einfacher und leistungsfähiger geworden ist, hält sich diese Kritik hartnäckig.  Hadoop erfordert, dass Sie die Programmiermuster von Java und MapReduce verstehen, was für Datenbankadministratoren und Personen mit herkömmlichen Skriptkenntnissen eine Herausforderung darstellt.</block>
  <block id="5f5f8f99cf4c6ebc0b81445be5328bf6" category="section-title">Komplizierte Frameworks und Tools</block>
  <block id="74faacaf156cd022099bed5469595b3e" category="paragraph">KI-Teams in Unternehmen stehen vor zahlreichen Herausforderungen.  Selbst mit Expertenwissen im Bereich Data Science lassen sich Tools und Frameworks für unterschiedliche Bereitstellungsökosysteme und Anwendungen möglicherweise nicht einfach von einem zum anderen übertragen.  Eine Data-Science-Plattform sollte sich nahtlos in entsprechende Big-Data-Plattformen integrieren lassen, die auf Spark basieren, und dabei einfache Datenbewegungen, wiederverwendbare Modelle, sofort einsatzbereiten Code und Tools bieten, die Best Practices für das Prototyping, Validieren, Versionieren, Teilen, Wiederverwenden und schnelle Bereitstellen von Modellen in der Produktion unterstützen.</block>
  <block id="067be0651f3de8fd60ec45827a4078ed" category="section-title">Warum NetApp?</block>
  <block id="8ff43bcedde084850831da9cdcc5a43a" category="paragraph">NetApp kann Ihr Spark-Erlebnis auf folgende Weise verbessern:</block>
  <block id="dc5106ccf618944587be46565f5585cd" category="list-text">Der direkte NetApp NFS-Zugriff (siehe Abbildung unten) ermöglicht es Kunden, Big-Data-Analysejobs auf ihren vorhandenen oder neuen NFSv3- oder NFSv4-Daten auszuführen, ohne die Daten zu verschieben oder zu kopieren.  Es verhindert mehrere Kopien der Daten und macht die Synchronisierung der Daten mit einer Quelle überflüssig.</block>
  <block id="38bc62edaebd471500fa64a4758f7f04" category="list-text">Effizientere Speicherung und weniger Serverreplikation.  Beispielsweise erfordert die NetApp E-Series Hadoop-Lösung zwei statt drei Replikate der Daten, und die FAS Hadoop-Lösung erfordert eine Datenquelle, jedoch keine Replikation oder Kopien der Daten.  NetApp -Speicherlösungen erzeugen außerdem weniger Server-zu-Server-Verkehr.</block>
  <block id="2fc945668748ad0173e63b5db34773e7" category="list-text">Besseres Verhalten von Hadoop-Jobs und Clustern bei Laufwerk- und Knotenausfällen.</block>
  <block id="343500ea6d724fe727d127f6409b86c2" category="list-text">Bessere Datenaufnahmeleistung.</block>
  <block id="109f256618c8d9037bb2cd6cc28f5959" category="inline-image-macro">Alternative Apache Spark-Konfigurationen.</block>
  <block id="0c0038bcea5bace3c716607bdf5ea55f" category="paragraph"><block ref="0c0038bcea5bace3c716607bdf5ea55f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="40771867b1bf0db74b9505757197a17a" category="paragraph">Im Finanz- und Gesundheitssektor beispielsweise muss die Datenübertragung von einem Ort zum anderen gesetzlichen Verpflichtungen entsprechen, was keine leichte Aufgabe ist.  In diesem Szenario analysiert der NetApp NFS-Direktzugriff die Finanz- und Gesundheitsdaten von ihrem ursprünglichen Speicherort aus.  Ein weiterer wichtiger Vorteil besteht darin, dass die Verwendung des direkten NetApp NFS-Zugriffs den Schutz von Hadoop-Daten durch die Verwendung nativer Hadoop-Befehle vereinfacht und Datenschutz-Workflows mit dem umfangreichen Datenverwaltungsportfolio von NetApp ermöglicht.</block>
  <block id="a9e81b3240a7c1ae64fc23e96c84f4ea" category="paragraph">Der direkte NetApp NFS-Zugriff bietet zwei Arten von Bereitstellungsoptionen für Hadoop/Spark-Cluster:</block>
  <block id="4e8fe573a9fe74b6429508c87337b99b" category="list-text">Standardmäßig verwenden Hadoop- oder Spark-Cluster das Hadoop Distributed File System (HDFS) zur Datenspeicherung und als Standarddateisystem.  Der direkte NetApp NFS-Zugriff kann das Standard-HDFS durch NFS-Speicher als Standarddateisystem ersetzen und so eine direkte Analyse von NFS-Daten ermöglichen.</block>
  <block id="071998ed00d39b3ff27f5410b196f9cc" category="list-text">In einer weiteren Bereitstellungsoption unterstützt der direkte NetApp NFS-Zugriff die Konfiguration von NFS als zusätzlichen Speicher zusammen mit HDFS in einem einzelnen Hadoop- oder Spark-Cluster.  In diesem Fall kann der Kunde Daten über NFS-Exporte freigeben und zusammen mit HDFS-Daten vom selben Cluster aus darauf zugreifen.</block>
  <block id="c1923befca33cfe6cc9ace80af8580b6" category="paragraph">Zu den wichtigsten Vorteilen des NetApp NFS-Direktzugriffs zählen die folgenden:</block>
  <block id="91221d408b0c171556751f29fb9d8071" category="list-text">Analysieren der Daten von ihrem aktuellen Standort aus, wodurch die zeit- und leistungsintensive Aufgabe des Verschiebens von Analysedaten in eine Hadoop-Infrastruktur wie HDFS vermieden wird.</block>
  <block id="1675635f440b61b7219bf7ed2bb2ed27" category="list-text">Reduzierung der Anzahl der Replikate von drei auf eins.</block>
  <block id="16f81b84f137a7a52da9ba8d798af622" category="list-text">Ermöglicht Benutzern, Rechenleistung und Speicher zu entkoppeln, um sie unabhängig voneinander zu skalieren.</block>
  <block id="71946d3c421aea3a8238a481bebe1919" category="list-text">Bietet Unternehmensdatenschutz durch Nutzung der umfassenden Datenverwaltungsfunktionen von ONTAP.</block>
  <block id="abebb9b977d736f599ab76c517961b24" category="list-text">Zertifizierung mit der Hortonworks-Datenplattform.</block>
  <block id="3c41c2d3511fa95c83687fae6fb57754" category="list-text">Ermöglicht die Bereitstellung hybrider Datenanalysen.</block>
  <block id="05550a44691e53e07f81616af5d58e20" category="list-text">Verkürzung der Sicherungszeit durch Nutzung der dynamischen Multithread-Funktion.</block>
  <block id="6a604a825549ac87ecf8a00412ee6365" category="inline-link-macro">TR-4657: NetApp Hybrid Cloud-Datenlösungen – Spark und Hadoop basierend auf Kundenanwendungsfällen</block>
  <block id="c5153856e4d13c48696624c702620995" category="paragraph">Sehen<block ref="46ae0631eaa2b1a19769e051f280e3cf" category="inline-link-macro-rx"></block> zum Sichern von Hadoop-Daten, zur Sicherung und Notfallwiederherstellung von der Cloud vor Ort, zum Aktivieren von DevTest auf vorhandenen Hadoop-Daten, zum Datenschutz und zur Multicloud-Konnektivität sowie zum Beschleunigen von Analyse-Workloads.</block>
  <block id="3100ca44a05fa97ed5f07875f442084e" category="paragraph">In den folgenden Abschnitten werden Speicherfunktionen beschrieben, die für Spark-Kunden wichtig sind.</block>
  <block id="da2518ef48c60077e2b2c0be7fed7193" category="section-title">Speicher-Tiering</block>
  <block id="d9a83ca3a623dce37a2f84027f1495ce" category="paragraph">Mit Hadoop Storage Tiering können Sie Dateien gemäß einer Speicherrichtlinie in verschiedenen Speichertypen speichern.  Zu den Speichertypen gehören<block ref="27369b3bf4483e8dcfd85ba9a39a947f" prefix=" " category="inline-code"></block> ,<block ref="75e52a0ecfafeda17a34fc60111c1f0b" prefix=" " category="inline-code"></block> ,<block ref="a957a3153eb7126b1c5f8b6aac35de53" prefix=" " category="inline-code"></block> ,<block ref="714f8e54e71566bd1c2e29328288a62c" prefix=" " category="inline-code"></block> ,<block ref="7fc1aa11178f33b4f796d69c73f7f0b4" prefix=" " category="inline-code"></block> , Und<block ref="fa4fdcc80e19a0848c6360538fdd86ef" prefix=" " category="inline-code"></block> .</block>
  <block id="c2398745386edbb0221cc4ee496ff79f" category="paragraph">Wir haben die Validierung der Hadoop-Speicherschichtung auf einem NetApp AFF Speichercontroller und einem E-Series-Speichercontroller mit SSD- und SAS-Laufwerken mit unterschiedlichen Speicherrichtlinien durchgeführt.  Der Spark-Cluster mit AFF-A800 verfügt über vier Compute-Worker-Knoten, während der Cluster mit E-Series acht hat.  Dabei geht es hauptsächlich darum, die Leistung von Solid-State-Laufwerken (SSDs) mit der von Festplatten (HDDs) zu vergleichen.</block>
  <block id="36edc8f5974bdf6ad51a220254b99dfb" category="paragraph">Die folgende Abbildung zeigt die Leistung von NetApp -Lösungen für eine Hadoop-SSD.</block>
  <block id="d09520ed9b4a17ada38e70314907675f" category="inline-image-macro">Zeit, 1 TB Daten zu sortieren.</block>
  <block id="12b6622989087d668bc9d1da31e9fb70" category="paragraph"><block ref="12b6622989087d668bc9d1da31e9fb70" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c2f530d95c6332b106d86a53b41e4a36" category="inline-link">TR-3969 NetApp E-Series-Lösung für Hadoop</block>
  <block id="bd9ad8221382748a4f008c3af02731bd" category="list-text">Die NL-SAS-Basiskonfiguration verwendete acht Rechenknoten und 96 NL-SAS-Laufwerke.  Diese Konfiguration generierte 1 TB Daten in 4 Minuten und 38 Sekunden.  Sehen<block ref="264d8d379e3a34fdac32f9057509bf65" category="inline-link-rx"></block> für Details zur Cluster- und Speicherkonfiguration.</block>
  <block id="f895fa75cdc40f4e672bba6f7a873e25" category="list-text">Mit TeraGen generierte die SSD-Konfiguration 1 TB Daten 15,66-mal schneller als die NL-SAS-Konfiguration.  Darüber hinaus verwendete die SSD-Konfiguration nur die Hälfte der Rechenknoten und die Hälfte der Festplattenlaufwerke (insgesamt 24 SSD-Laufwerke).  Basierend auf der Zeit, die für die Auftragserledigung benötigt wurde, war es fast doppelt so schnell wie die NL-SAS-Konfiguration.</block>
  <block id="459f180fc71a8f8bb773d3c879314e39" category="list-text">Mit TeraSort sortierte die SSD-Konfiguration 1 TB Daten 1138,36-mal schneller als die NL-SAS-Konfiguration.  Darüber hinaus verwendete die SSD-Konfiguration nur die Hälfte der Rechenknoten und die Hälfte der Festplattenlaufwerke (insgesamt 24 SSD-Laufwerke).  Daher war es pro Laufwerk ungefähr dreimal schneller als die NL-SAS-Konfiguration.</block>
  <block id="52be2edb04819f386804af38bd53a55d" category="list-text">Das Fazit ist, dass die Umstellung von rotierenden Festplatten auf reine Flash-Speicher die Leistung verbessert.  Die Anzahl der Rechenknoten war nicht der Engpass.  Mit dem All-Flash-Speicher von NetApp lässt sich die Laufzeitleistung gut skalieren.</block>
  <block id="8cc25131075ed11b8263304fceebc5c6" category="list-text">Mit NFS waren die Daten funktional gleichbedeutend mit einer gemeinsamen Bündelung, wodurch die Anzahl der Rechenknoten je nach Arbeitslast reduziert werden kann.  Die Benutzer des Apache Spark-Clusters müssen die Daten nicht manuell neu ausbalancieren, wenn sie die Anzahl der Compute-Knoten ändern.</block>
  <block id="c13c2e056adb51078f3067ba570d2780" category="section-title">Leistungsskalierung – Scale-Out</block>
  <block id="beb08cca1e99e0bdbf11c74ebb62d5ea" category="paragraph">Wenn Sie mehr Rechenleistung von einem Hadoop-Cluster in einer AFF Lösung benötigen, können Sie Datenknoten mit einer entsprechenden Anzahl von Speichercontrollern hinzufügen.  NetApp empfiehlt, mit vier Datenknoten pro Speichercontroller-Array zu beginnen und die Anzahl je nach Arbeitslastmerkmalen auf acht Datenknoten pro Speichercontroller zu erhöhen.</block>
  <block id="431bd1a68814e184bc49ff7231450049" category="paragraph">AFF und FAS eignen sich perfekt für In-Place-Analysen.  Basierend auf den Rechenanforderungen können Sie Knotenmanager hinzufügen und unterbrechungsfreie Vorgänge ermöglichen Ihnen, bei Bedarf und ohne Ausfallzeiten einen Speichercontroller hinzuzufügen.  Wir bieten umfangreiche Funktionen mit AFF und FAS, wie z. B. NVME-Medienunterstützung, garantierte Effizienz, Datenreduzierung, QOS, prädiktive Analysen, Cloud-Tiering, Replikation, Cloud-Bereitstellung und Sicherheit.  Um Kunden bei der Erfüllung ihrer Anforderungen zu unterstützen, bietet NetApp Funktionen wie Dateisystemanalyse, Kontingente und On-Box-Lastausgleich ohne zusätzliche Lizenzkosten.  NetApp bietet eine bessere Leistung bei der Anzahl gleichzeitiger Jobs, eine geringere Latenz, einfachere Vorgänge und einen höheren Durchsatz in Gigabyte pro Sekunde als unsere Wettbewerber.  Darüber hinaus läuft NetApp Cloud Volumes ONTAP auf allen drei großen Cloud-Anbietern.</block>
  <block id="ccfed4ad520d8db8b13dc91438d30680" category="section-title">Leistungsskalierung – Hochskalieren</block>
  <block id="9341bdabe891be81d2be3440a4c413b5" category="paragraph">Mithilfe der Scale-up-Funktionen können Sie Festplattenlaufwerke zu AFF, FAS und E-Series-Systemen hinzufügen, wenn Sie zusätzliche Speicherkapazität benötigen.  Mit Cloud Volumes ONTAP ist die Skalierung des Speichers auf PB-Ebene eine Kombination aus zwei Faktoren: der Auslagerung selten verwendeter Daten aus dem Blockspeicher in den Objektspeicher und dem Stapeln von Cloud Volumes ONTAP -Lizenzen ohne zusätzliche Rechenleistung.</block>
  <block id="1a4f71bef2c7cfcc6846e82e9e0e0331" category="section-title">Mehrere Protokolle</block>
  <block id="11d6ae97757031ae53e1437c9c9b61bd" category="paragraph">NetApp -Systeme unterstützen die meisten Protokolle für Hadoop-Bereitstellungen, einschließlich SAS, iSCSI, FCP, InfiniBand und NFS.</block>
  <block id="98ed4f29e9a08c43fe10dda6782e567e" category="section-title">Operative und unterstützte Lösungen</block>
  <block id="464e596f1568de8e5f19e16e09beaaa8" category="inline-link">Hortonworks</block>
  <block id="f1fd1913c968a1c383c88631e335a7ca" category="inline-link">Zertifizierung</block>
  <block id="7454739e907f5595ae61d84b8547f574" category="inline-link">Partner</block>
  <block id="24cd9f53ddcc21c3360cfbf1ab787373" category="paragraph">Die in diesem Dokument beschriebenen Hadoop-Lösungen werden von NetApp unterstützt.  Diese Lösungen sind auch bei den wichtigsten Hadoop-Distributoren zertifiziert.  Weitere Informationen finden Sie im<block ref="030fa12946d3d4653223853ac09b7183" category="inline-link-rx"></block> Site und die Cloudera<block ref="110185abc20d52e7eb83135b84742416" category="inline-link-rx"></block> Und<block ref="a573734769be98dedf1aa2242c0eb40c" category="inline-link-rx"></block> Websites.</block>
  <block id="7e838102a13e780977b21c90f648a5d0" category="summary">In diesem Abschnitt werden die Art und die Komponenten von Apache Spark beschrieben und wie sie zu dieser Lösung beitragen.</block>
  <block id="8f4c7939e8a42e023939df947aba54f6" category="doc">Lösungstechnologie</block>
  <block id="f4387c90411f7b92618497bc53b16256" category="paragraph">Apache Spark ist ein beliebtes Programmierframework zum Schreiben von Hadoop-Anwendungen, das direkt mit dem Hadoop Distributed File System (HDFS) arbeitet.  Spark ist produktionsbereit, unterstützt die Verarbeitung von Streaming-Daten und ist schneller als MapReduce.  Spark verfügt über konfigurierbares In-Memory-Datencaching für effiziente Iteration und die Spark-Shell ist interaktiv zum Lernen und Erkunden von Daten.  Mit Spark können Sie Anwendungen in Python, Scala oder Java erstellen.  Spark-Anwendungen bestehen aus einem oder mehreren Jobs, die eine oder mehrere Aufgaben haben.</block>
  <block id="6a696023a577a0d26763ef9c382b4b1f" category="paragraph">Jede Spark-Anwendung verfügt über einen Spark-Treiber.  Im YARN-Client-Modus wird der Treiber lokal auf dem Client ausgeführt.  Im YARN-Cluster-Modus läuft der Treiber im Cluster auf dem Anwendungsmaster.  Im Clustermodus wird die Anwendung auch dann weiter ausgeführt, wenn die Verbindung zum Client getrennt wird.</block>
  <block id="5e8f0f670e38fbdf628b0883f946934f" category="inline-image-macro">Abbildung, die einen Eingabe-/Ausgabedialog zeigt oder schriftlichen Inhalt darstellt</block>
  <block id="bb21b729c47dce20f94160002efec039" category="paragraph"><block ref="bb21b729c47dce20f94160002efec039" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6feb0bd2b4db4693572a9fc2e517e888" category="paragraph">Es gibt drei Cluster-Manager:</block>
  <block id="4c79d7007667a60b712836e2f93d6bfc" category="list-text">*Eigenständig.*  Dieser Manager ist Teil von Spark, wodurch die Einrichtung eines Clusters vereinfacht wird.</block>
  <block id="c0a5bce529ff277ee2735538a7b43913" category="list-text">*Apache Mesos.*  Dies ist ein allgemeiner Cluster-Manager, der auch MapReduce und andere Anwendungen ausführt.</block>
  <block id="24683e4dfc33dc5b20a0d9a75c0ff150" category="list-text">*Hadoop YARN.*  Dies ist ein Ressourcenmanager in Hadoop 3.</block>
  <block id="569531fd384ec251943946598eb00dcb" category="paragraph">Der widerstandsfähige verteilte Datensatz (RDD) ist die Hauptkomponente von Spark.  RDD erstellt die verlorenen und fehlenden Daten aus den im Speicher des Clusters gespeicherten Daten neu und speichert die ursprünglichen Daten, die aus einer Datei stammen oder programmgesteuert erstellt werden.  RDDs werden aus Dateien, Daten im Speicher oder einem anderen RDD erstellt.  Die Spark-Programmierung führt zwei Vorgänge aus: Transformation und Aktionen.  Durch die Transformation wird ein neues RDD basierend auf einem vorhandenen erstellt.  Aktionen geben einen Wert aus einem RDD zurück.</block>
  <block id="1af693ed22a2df92eb5adff8c506d0ef" category="paragraph">Transformationen und Aktionen gelten auch für Spark-Datasets und DataFrames.  Ein Dataset ist eine verteilte Datensammlung, die die Vorteile von RDDs (starke Typisierung, Verwendung von Lambda-Funktionen) mit den Vorteilen der optimierten Ausführungs-Engine von Spark SQL kombiniert.  Ein Datensatz kann aus JVM-Objekten erstellt und dann mithilfe funktionaler Transformationen (Map, FlatMap, Filter usw.) bearbeitet werden.  Ein DataFrame ist ein in benannte Spalten organisierter Datensatz.  Es ist konzeptionell gleichwertig mit einer Tabelle in einer relationalen Datenbank oder einem Datenrahmen in R/Python.  DataFrames können aus einer Vielzahl von Quellen erstellt werden, beispielsweise strukturierten Datendateien, Tabellen in Hive/HBase, externen Datenbanken vor Ort oder in der Cloud oder vorhandenen RDDs.</block>
  <block id="89d836212e4c5086ebcd9e5fbd6a4b37" category="paragraph">Spark-Anwendungen umfassen einen oder mehrere Spark-Jobs.  Jobs führen Aufgaben in Executoren aus und Executoren werden in YARN-Containern ausgeführt.  Jeder Executor wird in einem einzelnen Container ausgeführt und Executoren existieren während der gesamten Lebensdauer einer Anwendung.  Ein Executor wird nach dem Start der Anwendung fixiert und YARN ändert die Größe des bereits zugewiesenen Containers nicht.  Ein Executor kann Aufgaben gleichzeitig auf Daten im Arbeitsspeicher ausführen.</block>
  <block id="bd8f37587e7778e9d19d350dd4bd6d3a" category="summary">In diesem Abschnitt wird beschrieben, wer an den Inhalten dieser Lösung interessiert sein könnte.</block>
  <block id="bf8dd94f74c5878ba969abeeef0286d1" category="doc">Zielgruppe</block>
  <block id="49997701037fef2c24b57a2e7186d0ab" category="paragraph">Die Welt der Analytik und Datenwissenschaft berührt mehrere Disziplinen in IT und Wirtschaft:</block>
  <block id="cddde51824956f407b4c02c1e4bc8004" category="list-text">Der Datenwissenschaftler benötigt die Flexibilität, die Tools und Bibliotheken seiner Wahl zu verwenden.</block>
  <block id="310a768ecb4689bcaf80072231d73e83" category="list-text">Der Dateningenieur muss wissen, wie die Daten fließen und wo sie sich befinden.</block>
  <block id="529ac4605b034914d0e8b489a81e45e0" category="list-text">Ein DevOps-Ingenieur benötigt die Tools, um neue KI- und ML-Anwendungen in seine CI- und CD-Pipelines zu integrieren.</block>
  <block id="090e55ccd8633a454f9d471ca3ed004d" category="list-text">Cloud-Administratoren und -Architekten müssen in der Lage sein, Hybrid-Cloud-Ressourcen einzurichten und zu verwalten.</block>
  <block id="3cb782c6019ddcbb4e7f6bf8ae154d40" category="list-text">Geschäftsanwender möchten Zugriff auf Analyse-, KI-, ML- und DL-Anwendungen haben.</block>
  <block id="3dfd24951a51ec1661b0294f59bea86e" category="paragraph">In diesem technischen Bericht beschreiben wir, wie NetApp AFF, E-Series, StorageGRID, NFS-Direktzugriff, Apache Spark, Horovod und Keras jeder dieser Rollen dabei helfen, einen Mehrwert für das Unternehmen zu schaffen.</block>
  <block id="49c9a66d1f76b5f264fea5d54130b82a" category="summary">Wir haben die Skripte TeraSort und TeraValidate im Benchmarking-Tool TeraGen verwendet, um die Spark-Leistungsvalidierung mit den Konfigurationen E5760, E5724 und AFF-A800 zu messen.  Darüber hinaus wurden drei wichtige Anwendungsfälle getestet: Spark NLP-Pipelines und verteiltes TensorFlow-Training, verteiltes Horovod-Training und Multi-Worker-Deep-Learning mit Keras zur CTR-Vorhersage mit DeepFM.</block>
  <block id="41be8de44faa8ba43210d7494ee095d2" category="doc">Testergebnisse</block>
  <block id="60637296d8b6dcd84aaff3afc778241d" category="paragraph">Wir haben die Skripte TeraSort und TeraValidate im Benchmarking-Tool TeraGen verwendet, um die Spark-Leistungsvalidierung mit den Konfigurationen E5760, E5724 und AFF-A800 zu messen.  Darüber hinaus wurden drei wichtige Anwendungsfälle getestet: Spark NLP-Pipelines und verteiltes TensorFlow-Training, verteiltes Horovod-Training und Multi-Worker-Deep-Learning mit Keras zur CTR-Vorhersage mit DeepFM.</block>
  <block id="653a9ba51c0af0c11aab6af3ecfdc8c6" category="paragraph">Für die Validierung sowohl der E-Serie als auch der StorageGRID haben wir den Hadoop-Replikationsfaktor 2 verwendet.  Für die AFF Validierung haben wir nur eine Datenquelle verwendet.</block>
  <block id="6cdf0c4c6177a49f44f3688dd2a5b9ad" category="paragraph">In der folgenden Tabelle ist die Hardwarekonfiguration für die Spark-Leistungsvalidierung aufgeführt.</block>
  <block id="a1fa27779242b4902f7ae3bdd5c6d508" category="cell">Typ</block>
  <block id="00e536f9715964bf964b4961d7287f95" category="cell">Hadoop-Workerknoten</block>
  <block id="ce1dc110e77caccbe12e51dce2d1c9b7" category="cell">Antriebstyp</block>
  <block id="c8fafade5cff4119459018fc205beed1" category="cell">Laufwerke pro Knoten</block>
  <block id="bb43878952414106e66a5d3e8902dd46" category="cell">Speichercontroller</block>
  <block id="c69ff1785c16ab7db216e04b62e5ef4f" category="cell">SG6060</block>
  <block id="a87ff679a2f3e71d9181a67b7542122c" category="cell">4</block>
  <block id="2db46c628cfb3bd1545d3b5a14b4a9c5" category="cell">SAS</block>
  <block id="c20ad4d76fe97759aa27a0c99bff6710" category="cell">12</block>
  <block id="d748fcab9e84c60a5a7b1e5ed2d052c8" category="cell">Einzelnes Hochverfügbarkeitspaar (HA)</block>
  <block id="fb5e436e0878dfd2227011932c4eb93c" category="cell">E5760</block>
  <block id="072b030ba126b2f4b2374f342be9ed44" category="cell">60</block>
  <block id="6303aa59a000812ac121a6f5238d6c2c" category="cell">Einzelnes HA-Paar</block>
  <block id="83ac07c2ad3d90f5c6608cfaa2eec573" category="cell">E5724</block>
  <block id="1ff1de774005f8da13f42943881c655f" category="cell">24</block>
  <block id="26b9fff68b23131979be5c2d9a456454" category="cell">AFF800</block>
  <block id="34df20bab5e85dc75bfc94ef569cced9" category="cell">SSD</block>
  <block id="1679091c5a880faf6fb5e6087eb1b2dc" category="cell">6</block>
  <block id="bddda15d92b567df6d8aa197c281ddc4" category="paragraph">In der folgenden Tabelle sind die Softwareanforderungen aufgeführt.</block>
  <block id="719d067b229178f03bcfa1da4ac4dede" category="cell">Software</block>
  <block id="34b6cd75171affba6957e308dcbd92be" category="cell">Version</block>
  <block id="8b6f93f33bce541c7f50f8aff637e2e1" category="cell">RHEL</block>
  <block id="299e5505ce975112afaefec130cc83e0" category="cell">7,9</block>
  <block id="bedb19167c4cde670f36a4985efbadd2" category="cell">OpenJDK-Laufzeitumgebung</block>
  <block id="4fda350b2148254bcd9e67bbdbecdc93" category="cell">1.8.0</block>
  <block id="b185818332a596af6cda9cae4dc594f6" category="cell">OpenJDK 64-Bit-Server-VM</block>
  <block id="681eea6b2a996d12035edc50dc4cb4c2" category="cell">25,302</block>
  <block id="0bcc70105ad279503e31fe7b3f47b665" category="cell">Git</block>
  <block id="30a2ec41610037af662087fe85d19a4d" category="cell">2.24.1</block>
  <block id="87f16b82c65c9274a67305d08b5dfecb" category="cell">GCC/G++</block>
  <block id="b87ed8b82b1cf2cb4e4ddaa75ec9e0e4" category="cell">11.2.1</block>
  <block id="8cde774d6f7333752ed72cacddb05126" category="cell">Funke</block>
  <block id="f2f87b58be0d57ecf71ada8df361a2d9" category="cell">3.2.1</block>
  <block id="17e918efeeeb8f100c695e284d5c0a08" category="cell">PySpark</block>
  <block id="1f4e00506ff9fb5fe179f2ba1c60ff61" category="cell">3.1.2</block>
  <block id="401534b4a193f467279a370076ccb955" category="cell">SparkNLP</block>
  <block id="de8a4e99bb5f22ded6d686cfd948274b" category="cell">3.4.2</block>
  <block id="074dd699710da0ec1eb45f13b31788e3" category="cell">TensorFlow</block>
  <block id="0d6f7e6ce6f1553544acb14682c8eb07" category="cell">2.9.0</block>
  <block id="7fee7bb66f4294c3e32783efa7d9bafc" category="cell">Keras</block>
  <block id="f5f1c35a78d5584cdb787d4e3b6b10b6" category="cell">Horovod</block>
  <block id="35a0c5fdc22109515a67a96e5e7fb914" category="cell">0.24.3</block>
  <block id="14bdb1335d2386afb42f726416a2a83b" category="section-title">Finanzstimmungsanalyse</block>
  <block id="494027a6b5e9fc8bb84443d03b97a9b7" category="inline-link-macro">TR-4910: Stimmungsanalyse aus der Kundenkommunikation mit NetApp AI</block>
  <block id="74bef786b12cb9d03a6c04df1f605181" category="inline-link">NetApp DataOps Toolkit</block>
  <block id="559cf37b505e9001d46e6d6bd73e746c" category="inline-link">NVIDIA Riva SDK</block>
  <block id="e65b49198d65919095402991b0cf5624" category="inline-link">Tao-Rahmen</block>
  <block id="460926218a6b1ab3e124f410ee69f408" category="paragraph">Wir veröffentlichten<block ref="d791c48f7898bbaecde983abed6ac7c1" category="inline-link-macro-rx"></block> , in dem eine End-to-End-Konversations-KI-Pipeline mithilfe der<block ref="5d9fb1d86d92052bc5dca8ba91d13ff2" category="inline-link-rx"></block> , AFF -Speicher und NVIDIA DGX-System.  Die Pipeline führt Batch-Audiosignalverarbeitung, automatische Spracherkennung (ASR), Transferlernen und Stimmungsanalyse durch und nutzt dabei das DataOps Toolkit.<block ref="8702bd0254f484bdfe9f1ec1c2a853b1" category="inline-link-rx"></block> und die<block ref="bba656873bd8ccd45c0c4fc908390474" category="inline-link-rx"></block> .  Wir haben den Anwendungsfall der Stimmungsanalyse auf die Finanzdienstleistungsbranche ausgeweitet, einen SparkNLP-Workflow erstellt, drei BERT-Modelle für verschiedene NLP-Aufgaben wie die Erkennung benannter Entitäten geladen und die Stimmung auf Satzebene für die vierteljährlichen Gewinnaufrufe der Top 10-Unternehmen des NASDAQ ermittelt.</block>
  <block id="ffeb7ccd27ad1e7d783757733dadec57" category="paragraph">Das folgende Skript<block ref="e313c2865ad76497c3eaf980ccfa3d03" prefix=" " category="inline-code"></block> verwendet das FinBERT-Modell, um Transkripte in HDFS zu verarbeiten und positive, neutrale und negative Stimmungszahlen zu erzeugen, wie in der folgenden Tabelle gezeigt:</block>
  <block id="077259b584adffb379f7f2638be91edc" category="paragraph">In der folgenden Tabelle ist die Stimmungsanalyse auf Satzebene zu den Gewinnaufrufen der Top 10-Unternehmen des NASDAQ von 2016 bis 2020 aufgeführt.</block>
  <block id="30702e828192097c5634358e6047d0cf" category="cell">Stimmungszählung und Prozentsatz</block>
  <block id="7838fb6ed7918fca8c7797b3b68952d2" category="cell">Alle 10 Unternehmen</block>
  <block id="8b10e4ae9eeb5684921a9ab27e4d87aa" category="cell">AAPL</block>
  <block id="48af4341f745163f945fa838eeabb062" category="cell">AMD</block>
  <block id="261fd26b0151a81370d097e4ed4c6505" category="cell">AMZN</block>
  <block id="85fd1bb0e226da6a33e9b5dc1a4952f1" category="cell">CSCO</block>
  <block id="e15ce71ff533c9125f11a46c09e2412b" category="cell">GOOGL</block>
  <block id="fc39dab34bbe435680d30933db783ba0" category="cell">INTC</block>
  <block id="b004b3ecde24c85e32c1923f10d3fb62" category="cell">MSFT</block>
  <block id="7f5f6a07b14840f4d8a22caa3df2aed0" category="cell">NVDA</block>
  <block id="4f65a47dc5d0d8a27379f2b1b4d9281b" category="cell">Positive Zählungen</block>
  <block id="9e6adb1432c4a75a33d48693328e4159" category="cell">7447</block>
  <block id="18d10dc6e666eab6de9215ae5b3d54df" category="cell">1567</block>
  <block id="5c572eca050594c7bc3c36e7e8ab9550" category="cell">743</block>
  <block id="f90f2aca5c640289d0a29417bcb63a37" category="cell">290</block>
  <block id="08d98638c6fcd194a4b1e6992063e944" category="cell">682</block>
  <block id="795c7a7a5ec6b460ec00c5841019b9e9" category="cell">826</block>
  <block id="677e09724f0e2df9b6c000b75b5da10d" category="cell">824</block>
  <block id="f47d0ad31c4c49061b9e505593e3db98" category="cell">904</block>
  <block id="41ae36ecb9b3eee609d05b90c14222fb" category="cell">417</block>
  <block id="be201b8b1b0b81005e46d49fd301124c" category="cell">Neutrale Zählungen</block>
  <block id="1ab0418ab8dc5325176cd1e26660234f" category="cell">64067</block>
  <block id="34ad9bc83e3c72c62281cb2c744ac966" category="cell">6856</block>
  <block id="1796a48fa1968edd5c5d10d42c7b1813" category="cell">7596</block>
  <block id="71e63ef5b7249cfc60852f0e0f5bf4c8" category="cell">5086</block>
  <block id="126c2da128e5b044dc53405c25b4d8de" category="cell">6650</block>
  <block id="dd5bfdeb57f7c75d400de61e99d78e2e" category="cell">5914</block>
  <block id="80c0e8c4457441901351e4abbcf8c75c" category="cell">6099</block>
  <block id="6e4243f5511fd6ef0f03e9f386d54403" category="cell">5715</block>
  <block id="67ba02d73c54f0b83c05507b7fb7267f" category="cell">6189</block>
  <block id="e65849536f4b2170d6b42c8309222fac" category="cell">Negative Zählungen</block>
  <block id="d860bd12ce9c026814bbdfc1c573f0f5" category="cell">1787</block>
  <block id="c24cd76e1ce41366a4bbe8a49b02a028" category="cell">253</block>
  <block id="979d472a84804b9f647bc185a877a8b5" category="cell">213</block>
  <block id="68d30a9594728bc39aa24be94b319d21" category="cell">84</block>
  <block id="a2557a7b2e94197ff767970b67041697" category="cell">189</block>
  <block id="e2ef524fbf3d9fe611d5a8e90fefdc9c" category="cell">97</block>
  <block id="6a9aeddfc689c1d0e3b9ccc3ab651bc5" category="cell">282</block>
  <block id="854d6fae5ee42911677c739ee1734486" category="cell">202</block>
  <block id="7647966b7343c29048673252e490f736" category="cell">89</block>
  <block id="691ec36991472d115c60f32cd84bfc5b" category="cell">Nicht kategorisierte Zählungen</block>
  <block id="084b6fbb10729ed4da8c3d3f5a3ae7c9" category="cell">196</block>
  <block id="cfcd208495d565ef66e7dff9f98764da" category="cell">0</block>
  <block id="fbd7939d674997cdb4692d34de8633c4" category="cell">76</block>
  <block id="c4ca4238a0b923820dcc509a6f75849b" category="cell">1</block>
  <block id="2706e1e04688749582425d394866306e" category="cell">(Gesamtzahl)</block>
  <block id="b72e37e992d9e460ce2a491a974d13b5" category="cell">73497</block>
  <block id="9f6f2381bc56ef668e94f6d1fb4f6309" category="cell">8676</block>
  <block id="a563b6d5abbf137175059d6bb14672cc" category="cell">8552</block>
  <block id="1134ac57b5b1d38b7d70c1b6feaa28cf" category="cell">5536</block>
  <block id="e1e1f667ce4596e5644be6fab627c226" category="cell">7521</block>
  <block id="176bf6219855a6eb1f3a30903e34b6fb" category="cell">6837</block>
  <block id="75da5036f659fe64b53f3d9b39412967" category="cell">7205</block>
  <block id="e6be4c22a5963ab00dfe8f3b695b5332" category="cell">6822</block>
  <block id="2ea1202aed1e0ce30d41be4919b0cc99" category="cell">6695</block>
  <block id="14d1ed13bbef7783a73cfb9346480ce2" category="paragraph">Prozentual gesehen sind die meisten Sätze der CEOs und CFOs sachlich und daher neutral.  Während einer Telefonkonferenz zu den Quartalsergebnissen stellen Analysten Fragen, die eine positive oder negative Stimmung zum Ausdruck bringen können.  Es lohnt sich, quantitativ weiter zu untersuchen, wie sich eine negative oder positive Stimmung auf die Aktienkurse am selben oder am nächsten Handelstag auswirkt.</block>
  <block id="3957e5ecad1215aa086504cf2c9ba9cc" category="paragraph">In der folgenden Tabelle ist die Stimmungsanalyse auf Satzebene für die Top 10-Unternehmen des NASDAQ in Prozent aufgeführt.</block>
  <block id="e8a6f3527192d64ba338192ce83f6283" category="cell">Stimmungsprozentsatz</block>
  <block id="3289297424e01eda5b788c083bbf3147" category="cell">Positiv</block>
  <block id="d41d8cd98f00b204e9800998ecf8427e" category="doc"></block>
  <block id="3e263985564016f5774bfb75e31efb0d" category="paragraph">10,13 %</block>
  <block id="d983b23f5dc08dfb28a31a898b6fbb6a" category="cell">18,06 %</block>
  <block id="ed5f9ec0b398f0f53408828898412855" category="cell">8,69 %</block>
  <block id="4d8e8cc0a97724584c1cd94c9485d555" category="cell">5,24 %</block>
  <block id="d43cdfa633a84f9ca5043f4eb9363a38" category="cell">9,07 %</block>
  <block id="a134c476ebd0c219b3cc879185d436ce" category="cell">12,08 %</block>
  <block id="27cd80a0bdc79a724fdc31fa8841e19b" category="cell">11,44 %</block>
  <block id="e954976d9376dfe5860acd553772a6df" category="cell">13,25 %</block>
  <block id="d30929e6786318e19a22c88447dcc97c" category="cell">6,23 %</block>
  <block id="e9bb5320b3890b6747c91b5a71ae5a01" category="cell">Neutral</block>
  <block id="6c3d5ec0fc8197d1a8f8366e142e37aa" category="cell">87,17 %</block>
  <block id="578429551436bef848f19eccdd93fb73" category="cell">79,02 %</block>
  <block id="bd443bde0360eb444a5906bea9d081b0" category="cell">88,82 %</block>
  <block id="97840fcb1a1f07bef3a12ef2d7975f09" category="cell">91,87 %</block>
  <block id="32edca53c1f1f00d865543b435d4ce3a" category="cell">88,42 %</block>
  <block id="407967ec786c26ce4ee7608c076fa6d7" category="cell">86,50 %</block>
  <block id="9784395b081e78ec535161a5ba0ffd1e" category="cell">84,65 %</block>
  <block id="5d4b03024bcea7385ffc5808dd9c3b74" category="cell">83,77 %</block>
  <block id="b73c3663139621b36cfdafbeab44fae9" category="cell">92,44 %</block>
  <block id="ffb9356ff2b7da85c75c92fa7ea03b8b" category="cell">Negativ</block>
  <block id="672484e7c4fb5894b2ec75fd7e277fe4" category="cell">2,43 %</block>
  <block id="c1fbc8ff600d3f571e0c440833db1a10" category="cell">2,92 %</block>
  <block id="161a790eac04cd27fc3e4ffd23ba452d" category="cell">2,49 %</block>
  <block id="5fd44dd7fb1198b1903141531424bb54" category="cell">1,52 %</block>
  <block id="6916237a9f5c4ed45ddfff6fe37f45e7" category="cell">2,51 %</block>
  <block id="43045dfce9b4c190cfa4dad2e4bf9457" category="cell">1,42 %</block>
  <block id="248199b9ac50bd355476016ad093ac09" category="cell">3,91 %</block>
  <block id="1cdf97682ca1bcd645e8dbcebb105529" category="cell">2,96 %</block>
  <block id="8098f29a2cea86e839d8ca03f50d52ce" category="cell">1,33 %</block>
  <block id="0d015d96f63a8c12d96b8399482b593f" category="cell">Unkategorisiert</block>
  <block id="1291f0b93a9f9d5a7e7391a09b5ec0cc" category="cell">0,27 %</block>
  <block id="9f1ef07877f9d85a82bd500f408b4814" category="cell">0 %</block>
  <block id="6a040d1ee7200a1dc349a598a163cc38" category="cell">1,37 %</block>
  <block id="d9fd62085e1ade721df051f8bc4c320d" category="cell">0,01 %</block>
  <block id="28bf86a8e29245437d4ad59ea6e80962" category="paragraph">In Bezug auf die Workflow-Laufzeit konnten wir eine signifikante Verbesserung um das 4,78-fache gegenüber<block ref="f5ddaf0ca7929578b408c909429f68f2" prefix=" " category="inline-code"></block> Modus zu einer verteilten Umgebung in HDFS und eine weitere Verbesserung von 0,14 % durch Nutzung von NFS.</block>
  <block id="87509d62c8804cdab48bea9e54013be4" category="paragraph">Wie die folgende Abbildung zeigt, verbesserte die Daten- und Modellparallelität die Geschwindigkeit der Datenverarbeitung und der verteilten TensorFlow-Modellinferenz.  Die Datenspeicherung in NFS führte zu einer etwas besseren Laufzeit, da der Engpass im Workflow das Herunterladen vortrainierter Modelle ist.  Wenn wir die Größe des Transkriptdatensatzes erhöhen, wird der Vorteil von NFS deutlicher.</block>
  <block id="493d0790c882abcf160f461d269c7ec5" category="inline-image-macro">Spark NLP-Sentimentanalyse – End-to-End-Workflow-Laufzeit.</block>
  <block id="44ec3b18d4516fc85f1a9789d47bd91c" category="paragraph"><block ref="44ec3b18d4516fc85f1a9789d47bd91c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3484d035679c83a95496eb633ffde0d3" category="section-title">Verteiltes Training mit Horovod-Leistung</block>
  <block id="43fc68a998702bc80e46c46de6c28621" category="inline-link-macro">Python-Skripte für jeden wichtigen Anwendungsfall</block>
  <block id="1bdfd0f4247bc70668e65a97471adcb5" category="paragraph">Der folgende Befehl erzeugte Laufzeitinformationen und eine Protokolldatei in unserem Spark-Cluster unter Verwendung eines einzigen<block ref="eb0a191797624dd3a48fa681d3061212" prefix=" " category="inline-code"></block> Knoten mit 160 Executoren mit jeweils einem Kern.  Der Executor-Speicher wurde auf 5 GB begrenzt, um Speicherfehler zu vermeiden.  Siehe den Abschnitt<block ref="bda46a99ea3f7d5775466396b660e993" category="inline-link-macro-rx"></block> Weitere Einzelheiten zur Datenverarbeitung, zum Modelltraining und zur Berechnung der Modellgenauigkeit in<block ref="b502aa50c7ae6d7ea7adaf15de40ffe5" prefix=" " category="inline-code"></block> .</block>
  <block id="6281f693bbc375a45312622b626d3bcd" category="paragraph">Die resultierende Laufzeit mit zehn Trainingsepochen war wie folgt:</block>
  <block id="842bc4f8403cd2df9f22939e3df59aee" category="paragraph">Es dauerte mehr als 43 Minuten, um Eingabedaten zu verarbeiten, ein DNN-Modell zu trainieren, die Genauigkeit zu berechnen und TensorFlow-Checkpoints und eine CSV-Datei für Vorhersageergebnisse zu erstellen.  Wir haben die Anzahl der Trainingsepochen auf 10 begrenzt, in der Praxis wird sie jedoch oft auf 100 gesetzt, um eine zufriedenstellende Modellgenauigkeit zu gewährleisten.  Die Trainingszeit skaliert normalerweise linear mit der Anzahl der Epochen.</block>
  <block id="1e580bbdb11118035631867d15ad9f25" category="paragraph">Als nächstes nutzten wir die vier im Cluster verfügbaren Worker-Knoten und führten das gleiche Skript in<block ref="bb3462b62cd8db3f9ba007d86f8d1c6d" prefix=" " category="inline-code"></block> Modus mit Daten in HDFS:</block>
  <block id="3661bcf870f3d2b11b0489ed7f0585a7" category="paragraph">Die resultierende Laufzeit wurde wie folgt verbessert:</block>
  <block id="68b0154732e3239041317d0c7d4ac636" category="paragraph">Mit Horovods Modell- und Datenparallelität in Spark konnten wir eine 5,29-fache Laufzeitbeschleunigung von<block ref="bb3462b62cd8db3f9ba007d86f8d1c6d" prefix=" " category="inline-code"></block> gegen<block ref="f5ddaf0ca7929578b408c909429f68f2" prefix=" " category="inline-code"></block> Modus mit zehn Trainingsepochen.  Dies wird in der folgenden Abbildung mit den Legenden dargestellt<block ref="99c35850ff7cf7e436b03acedd4c59b3" prefix=" " category="inline-code"></block> Und<block ref="509820290d57f333403f490dde7316f4" prefix=" " category="inline-code"></block> .  Das Training des zugrunde liegenden TensorFlow-DNN-Modells kann mit GPUs, sofern verfügbar, weiter beschleunigt werden.  Wir planen, diese Tests durchzuführen und die Ergebnisse in einem zukünftigen technischen Bericht zu veröffentlichen.</block>
  <block id="216851565edc166c4409515484cac08b" category="paragraph">Unser nächster Test verglich die Laufzeiten mit Eingabedaten in NFS und HDFS.  Das NFS-Volume auf der AFF A800 wurde gemountet auf<block ref="e5f5dfd1cb98e0a4c27a3ce6df3ca358" prefix=" " category="inline-code"></block> über die fünf Knoten (ein Master, vier Worker) in unserem Spark-Cluster.  Wir haben einen ähnlichen Befehl wie bei den vorherigen Tests ausgeführt, mit dem<block ref="97a9c2c856bc676ba715d3eecc314be6" prefix=" " category="inline-code"></block> Parameter, der jetzt auf die NFS-Einbindung zeigt:</block>
  <block id="3ba4d622f15813cc383c433722b46d27" category="paragraph">Die resultierende Laufzeit mit NFS war wie folgt:</block>
  <block id="7e1d2a49ae0a0e06a39a62e2c7c74877" category="paragraph">Es kam zu einer weiteren Beschleunigung um das 1,43-Fache, wie in der folgenden Abbildung gezeigt.  Daher profitieren Kunden mit einem an ihren Cluster angeschlossenen NetApp All-Flash-Speicher von den Vorteilen einer schnellen Datenübertragung und -verteilung für Horovod Spark-Workflows und erreichen eine 7,55-fache Beschleunigung im Vergleich zur Ausführung auf einem einzelnen Knoten.</block>
  <block id="88caa92ecc3ebb345f81205aa696e3ac" category="inline-image-macro">Horovod Spark Workflow-Laufzeit.</block>
  <block id="aab5160a7c41d499723acfc13e430eef" category="paragraph"><block ref="aab5160a7c41d499723acfc13e430eef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b32c8309a0c0ca3edc35cb1597b9182c" category="section-title">Deep-Learning-Modelle für die CTR-Vorhersageleistung</block>
  <block id="6ff877f80b732c197c0a432029ad1920" category="paragraph">Für Empfehlungssysteme, die auf die Maximierung der Klickrate ausgelegt sind, müssen Sie die komplexen Funktionsinteraktionen hinter dem Benutzerverhalten erlernen, die sich mathematisch von der niedrigsten bis zur höchsten Ordnung berechnen lassen.  Für ein gutes Deep-Learning-Modell sollten sowohl Merkmalsinteraktionen niedriger als auch höherer Ordnung gleichermaßen wichtig sein, ohne dass das eine oder das andere bevorzugt wird.  Deep Factorization Machine (DeepFM), ein auf Faktorisierungsmaschinen basierendes neuronales Netzwerk, kombiniert Faktorisierungsmaschinen für Empfehlungen und Deep Learning für das Merkmalslernen in einer neuen neuronalen Netzwerkarchitektur.</block>
  <block id="a22645195470eca2abbe24e7d40cde8e" category="inline-link">Breite und tiefe Modelle</block>
  <block id="8a7e0c5a65151889fa193b20e6ea6484" category="paragraph">Obwohl herkömmliche Faktorisierungsmaschinen paarweise Merkmalsinteraktionen als inneres Produkt latenter Vektoren zwischen Merkmalen modellieren und theoretisch Informationen höherer Ordnung erfassen können, verwenden Anwender des maschinellen Lernens in der Praxis aufgrund der hohen Rechen- und Speicherkomplexität normalerweise nur Merkmalsinteraktionen zweiter Ordnung.  Varianten tiefer neuronaler Netzwerke wie die von Google<block ref="6c51a2ff49c9929908a73e863a1421f0" category="inline-link-rx"></block> lernt andererseits anspruchsvolle Merkmalsinteraktionen in einer hybriden Netzwerkstruktur durch die Kombination eines linearen breiten Modells und eines tiefen Modells.</block>
  <block id="a22f6dcc8bc499f7332ab04cdb36fcf9" category="paragraph">Es gibt zwei Eingaben für dieses Wide &amp; Deep-Modell, eine für das zugrunde liegende Wide-Modell und die andere für das Deep-Modell. Letzterer Teil erfordert noch immer eine fachmännische Feature-Entwicklung und macht die Technik daher weniger auf andere Domänen übertragbar.  Anders als das Wide &amp; Deep-Modell kann DeepFM effizient mit Rohmerkmalen trainiert werden, ohne dass ein Feature-Engineering erforderlich ist, da der breite und der tiefe Teil denselben Input und Einbettungsvektor verwenden.</block>
  <block id="fa3406903536d0cf09bf8e66ae33aebf" category="inline-link-macro">Python-Skripte für jeden wichtigen Anwendungsfall.</block>
  <block id="e78769fdc1aff8f5383517c0dc3ec750" category="paragraph">Wir haben zunächst die Criteo<block ref="171acae65b8e3fcd025aa9ba171b4a96" prefix=" " category="inline-code"></block> (11 GB) in eine CSV-Datei mit dem Namen<block ref="a39c9c52aed083c0688cd4974ec80881" prefix=" " category="inline-code"></block> in einem NFS-Mount gespeichert<block ref="17d831727f14e5379e2f4773837ccfa4" prefix=" " category="inline-code"></block> mit<block ref="5e1386bf4aaea9725a3cc5bc8e2bc9f4" prefix=" " category="inline-code"></block> aus dem Abschnitt<block ref="b6cb6fe53e443d0379ed59c804a7a30d" category="inline-link-macro-rx"></block> Innerhalb dieses Skripts wird die Funktion<block ref="000f75d2ea65c8a3d82d62e405ce82ee" prefix=" " category="inline-code"></block> führt mehrere String-Methoden aus, um Tabs zu entfernen und einzufügen<block ref="433beb9a090abf694184e96d76b3046d" prefix=" " category="inline-code"></block> als Trennzeichen und<block ref="11b282e345a74511901532f5c84b59ee" prefix=" " category="inline-code"></block> als Zeilenumbruch.  Beachten Sie, dass Sie nur das Original verarbeiten müssen<block ref="171acae65b8e3fcd025aa9ba171b4a96" prefix=" " category="inline-code"></block> einmal, sodass der Codeblock als Kommentar angezeigt wird.</block>
  <block id="02aeed17192e292b1708094a50785b65" category="paragraph">Für die folgenden Tests verschiedener DL-Modelle verwendeten wir<block ref="a39c9c52aed083c0688cd4974ec80881" prefix=" " category="inline-code"></block> als Eingabedatei.  In nachfolgenden Testläufen wurde die CSV-Eingabedatei in einen Spark DataFrame mit Schema eingelesen, das ein Feld von<block ref="182ea3b4ea8b947ba1626831aa9debbe" prefix=" " category="inline-code"></block> , ganzzahlige dichte Merkmale<block ref="2c94c76f60323031573497e25961744a" prefix=" " category="inline-code"></block> und spärliche Merkmale<block ref="57fae172685844997d173fa4248d66f8" prefix=" " category="inline-code"></block> .  Die folgende<block ref="78d07f07ead3482e696c0c224c2a7ed5" prefix=" " category="inline-code"></block> Der Befehl nimmt eine CSV-Eingabe entgegen, trainiert DeepFM-Modelle mit 20 % Aufteilung für die Kreuzvalidierung und wählt nach zehn Trainingsepochen das beste Modell aus, um die Vorhersagegenauigkeit im Testsatz zu berechnen:</block>
  <block id="52703dd8fd8c710b0aed616d19ddc0fb" category="paragraph">Beachten Sie, dass die Datendatei<block ref="a39c9c52aed083c0688cd4974ec80881" prefix=" " category="inline-code"></block> über 11 GB liegt, müssen Sie eine ausreichende<block ref="af770896b1954b7c355d9becfe487e40" prefix=" " category="inline-code"></block> größer als die Datensatzgröße, um Fehler zu vermeiden.</block>
  <block id="650f108a9978f10b1e3b0a8cbdcd6ac1" category="inline-link">Apache-Pfeil</block>
  <block id="caa01fc7f9a1a61f1bc803760af8e97f" category="paragraph">Im obigen<block ref="0ce62b6d4610e91242b63139adeb9432" prefix=" " category="inline-code"></block> Konfiguration haben wir auch aktiviert<block ref="d19d750623d06d371730c4055a0fbbbf" category="inline-link-rx"></block> , das einen Spark DataFrame in einen Pandas DataFrame mit dem<block ref="5d77cff4a1fdffb38c875e9a11a310fb" prefix=" " category="inline-code"></block> Verfahren.</block>
  <block id="e20380d4fed48eae6cd24a0df1477ba7" category="paragraph">Nach der zufälligen Aufteilung gibt es über 36 Millionen Zeilen im Trainingsdatensatz und 9 Millionen Stichproben im Testdatensatz:</block>
  <block id="a390a463e93dd87edffb2c8b23242507" category="paragraph">Da sich dieser technische Bericht auf CPU-Tests ohne Verwendung von GPUs konzentriert, ist es zwingend erforderlich, dass Sie TensorFlow mit entsprechenden Compiler-Flags erstellen.  Dieser Schritt vermeidet den Aufruf von GPU-beschleunigten Bibliotheken und nutzt die Advanced Vector Extensions (AVX) und AVX2-Anweisungen von TensorFlow voll aus.  Diese Funktionen sind für lineare algebraische Berechnungen wie vektorisierte Addition, Matrixmultiplikationen innerhalb eines Feedforward- oder Backpropagation-DNN-Trainings konzipiert.  Der mit AVX2 verfügbare Fused Multiply Add (FMA)-Befehl mit 256-Bit-Gleitkommaregistern (FP) ist ideal für ganzzahligen Code und Datentypen und führt zu einer bis zu zweifachen Beschleunigung.  Bei FP-Code und Datentypen erreicht AVX2 eine um 8 % höhere Geschwindigkeit als AVX.</block>
  <block id="6c396013ff0ebff6a2a96cdc20a4ba4c" category="inline-link">Bazel</block>
  <block id="97139e366bae36e316c93ce5b5e7e10b" category="paragraph">Um TensorFlow aus dem Quellcode zu erstellen, empfiehlt NetApp die Verwendung<block ref="0bf1f7ee55f693a3c117cb75493ba615" category="inline-link-rx"></block> .  Für unsere Umgebung haben wir die folgenden Befehle in der Shell-Eingabeaufforderung ausgeführt, um zu installieren<block ref="ffd93b30364fb8893d5bbb6fdb312666" prefix=" " category="inline-code"></block> ,<block ref="1208feb4bf9c4dd21156d8231d098ba1" prefix=" " category="inline-code"></block> und Bazel.</block>
  <block id="29fe549665f940a68b9303eae3e3a61e" category="paragraph">Sie müssen GCC 5 oder neuer aktivieren, um während des Build-Prozesses C++17-Funktionen zu verwenden, die von RHEL mit der Software Collections Library (SCL) bereitgestellt werden.  Die folgenden Befehle installieren<block ref="188b06575e77785e6b73e5e85b8e6ada" prefix=" " category="inline-code"></block> und GCC 11.2.1 auf unserem RHEL 7.9-Cluster:</block>
  <block id="92a2b5cb9c6906035c2864fa225e1940" category="inline-link">Artikel</block>
  <block id="d4b82f54dfee1e5c527d0d5f8cb0d7aa" category="paragraph">Beachten Sie, dass die letzten beiden Befehle<block ref="1dde0514b51c7c8f49cc63e4b54b8b37" prefix=" " category="inline-code"></block> , das verwendet<block ref="03fec70ce2bd12477f18ac0667e43d67" prefix=" " category="inline-code"></block> (GCC 11.2.1).  Stellen Sie außerdem sicher, dass Ihre<block ref="ba9f11ecc3497d9993b933fdc2bd61e5" prefix=" " category="inline-code"></block> Version ist höher als 1.8.3 (diese wird mit RHEL 7.9 geliefert).  Siehe hierzu<block ref="7d93914bddb4046675adee0145ba45bd" category="inline-link-rx"></block> zur Aktualisierung<block ref="ba9f11ecc3497d9993b933fdc2bd61e5" prefix=" " category="inline-code"></block> bis 2.24.1.</block>
  <block id="ba89c701879ec1f07e28185e3446d252" category="inline-link-macro">Python-Skripte für jeden wichtigen Anwendungsfall,</block>
  <block id="a33b7755e5f9b504d2d038eaca4ff28d" category="inline-link">CUDA</block>
  <block id="e63cc75a56452201d199b8b0694ad9c1" category="paragraph">Wir gehen davon aus, dass Sie das neueste TensorFlow-Master-Repo bereits geklont haben.  Erstellen Sie dann eine<block ref="1629dee48cc4e53161f9b2be8614e062" prefix=" " category="inline-code"></block> Verzeichnis mit einem<block ref="09498dbadf45966909850dc8a47ebb13" prefix=" " category="inline-code"></block> Datei zum Erstellen von TensorFlow aus dem Quellcode mit AVX, AVX2 und FMA.  Führen Sie den<block ref="e2d5a00791bce9a01f99bc6fd613a39d" prefix=" " category="inline-code"></block> Datei und geben Sie den richtigen Python-Binärspeicherort an.<block ref="be1c72ed18fb5f637a2d34d959decb73" category="inline-link-rx"></block> ist für unsere Tests deaktiviert, da wir keine GPU verwendet haben.  A<block ref="f55b2f358053ad76fb5ac3f776f78ef8" prefix=" " category="inline-code"></block> Die Datei wird entsprechend Ihren Einstellungen generiert.  Weiter haben wir die Datei bearbeitet und eingestellt<block ref="4e1b2fd49a68e112bae6de1bc453f18c" prefix=" " category="inline-code"></block> um die HDFS-Unterstützung zu aktivieren.  Siehe<block ref="f55b2f358053ad76fb5ac3f776f78ef8" prefix=" " category="inline-code"></block> im Abschnitt<block ref="f76831928c99e33a4e51e1e38bb9ab3c" category="inline-link-macro-rx"></block> für eine vollständige Liste der Einstellungen und Flags.</block>
  <block id="8329b0f29ec7368fd026b86d981f9dc7" category="paragraph">Nachdem Sie TensorFlow mit den richtigen Flags erstellt haben, führen Sie das folgende Skript aus, um den Criteo Display Ads-Datensatz zu verarbeiten, ein DeepFM-Modell zu trainieren und die Fläche unter der Receiver Operating Characteristic Curve (ROC AUC) aus den Vorhersagewerten zu berechnen.</block>
  <block id="d5a94c8db568912353007fdff822667e" category="paragraph">Nach zehn Trainingsepochen haben wir den AUC-Score für den Testdatensatz erhalten:</block>
  <block id="e3c9ed451390735cd8c4f8e5eb0e31f5" category="paragraph">Ähnlich wie bei früheren Anwendungsfällen haben wir die Spark-Workflow-Laufzeit mit Daten verglichen, die an verschiedenen Standorten gespeichert sind.  Die folgende Abbildung zeigt einen Vergleich der Deep-Learning-CTR-Vorhersage für eine Spark-Workflow-Laufzeit.</block>
  <block id="3737826be0460f743becdc4c64050946" category="inline-image-macro">Vergleich der Deep-Learning-CTR-Vorhersage für eine Spark-Workflow-Laufzeit.</block>
  <block id="f68ffbfae290c4d8a7f8381ad0cad4ff" category="paragraph"><block ref="f68ffbfae290c4d8a7f8381ad0cad4ff" category="inline-image-macro-rx" type="image"></block></block>
  <block id="edeeafbd44ff39ea2ff14f5de4488b69" category="summary">Auf dieser Seite werden die verschiedenen Bereiche beschrieben, in denen diese Lösung eingesetzt werden kann.</block>
  <block id="bf9bdab57c82171f2cc9bcebdc37b2c2" category="doc">Zusammenfassung des Anwendungsfalls</block>
  <block id="badfbf9255d6b555592b41ab34e4efc6" category="section-title">Streaming-Daten</block>
  <block id="4cc7dbb8e0e56a0e190e0ad588a8ba78" category="paragraph">Apache Spark kann Streaming-Daten verarbeiten, die für Streaming-Extract-, Transform- und Load-Prozesse (ETL), Datenanreicherung, Auslösen von Ereigniserkennung und komplexe Sitzungsanalysen verwendet werden:</block>
  <block id="35658693f34a1c5dc8b752f79caeb198" category="list-text">*Streaming ETL.*  Daten werden kontinuierlich bereinigt und aggregiert, bevor sie in Datenspeicher übertragen werden.  Netflix verwendet Kafka- und Spark-Streaming, um eine Echtzeit-Lösung für Online-Filmempfehlungen und Datenüberwachung zu erstellen, die täglich Milliarden von Ereignissen aus verschiedenen Datenquellen verarbeiten kann.  Traditionelles ETL für die Stapelverarbeitung wird jedoch anders behandelt.  Diese Daten werden zuerst gelesen und dann in ein Datenbankformat konvertiert, bevor sie in die Datenbank geschrieben werden.</block>
  <block id="1e8d9d663f583499f32f92ca2486e7df" category="list-text">*Datenanreicherung.*  Spark-Streaming reichert die Live-Daten mit statischen Daten an, um eine Datenanalyse in Echtzeit zu ermöglichen.  Beispielsweise können Online-Werbetreibende personalisierte, zielgerichtete Anzeigen schalten, die auf Informationen zum Kundenverhalten basieren.</block>
  <block id="c8fc01958b8b24afef85387342bc2aef" category="list-text">*Ereigniserkennung auslösen.*  Mit Spark-Streaming können Sie ungewöhnliches Verhalten, das auf potenziell schwerwiegende Probleme hinweisen könnte, schnell erkennen und darauf reagieren.  Finanzinstitute verwenden beispielsweise Trigger, um betrügerische Transaktionen zu erkennen und zu stoppen, und Krankenhäuser verwenden Trigger, um gefährliche gesundheitliche Veränderungen anhand der Vitalfunktionen eines Patienten zu erkennen.</block>
  <block id="af8f12b6a4cff696802c46442e36e264" category="list-text">*Komplexe Sitzungsanalyse.*  Spark Streaming sammelt Ereignisse wie Benutzeraktivitäten nach der Anmeldung bei einer Website oder Anwendung, die dann gruppiert und analysiert werden.  Netflix nutzt diese Funktion beispielsweise, um Filmempfehlungen in Echtzeit bereitzustellen.</block>
  <block id="22f51db51c9641d5358726fa5e03f67b" category="inline-link-macro">TR-4912: Best Practice-Richtlinien für Confluent Kafka Tiered Storage mit NetApp</block>
  <block id="519be207be9b1131f1e8524db61cf335" category="paragraph">Weitere Informationen zur Konfiguration von Streaming-Daten, zur Confluent Kafka-Verifizierung und zu Leistungstests finden Sie unter<block ref="474863345040f8931cecadcc38733702" category="inline-link-macro-rx"></block> .</block>
  <block id="2a80513f40f0c2a9c11009fa83049bd9" category="section-title">Maschinelles Lernen</block>
  <block id="c2e9a1abebd45c1d446eb49fb690afd7" category="paragraph">Das integrierte Spark-Framework unterstützt Sie beim Ausführen wiederholter Abfragen von Datensätzen mithilfe der Machine Learning-Bibliothek (MLlib).  MLlib wird in Bereichen wie Clustering, Klassifizierung und Dimensionsreduktion für einige gängige Big-Data-Funktionen wie Predictive Intelligence, Kundensegmentierung für Marketingzwecke und Stimmungsanalyse verwendet.  MLlib wird in der Netzwerksicherheit verwendet, um Datenpakete in Echtzeit auf Anzeichen böswilliger Aktivitäten zu überprüfen.  Es hilft Sicherheitsanbietern, sich über neue Bedrohungen zu informieren, Hackern immer einen Schritt voraus zu sein und gleichzeitig ihre Kunden in Echtzeit zu schützen.</block>
  <block id="03d3e10f072ae25d491b55767b4fc37e" category="section-title">Tiefes Lernen</block>
  <block id="b45690b6bb62bd55da7e1911ed880ec6" category="paragraph">TensorFlow ist ein beliebtes Deep-Learning-Framework, das in der gesamten Branche verwendet wird.  TensorFlow unterstützt das verteilte Training auf einem CPU- oder GPU-Cluster.  Dieses verteilte Training ermöglicht es Benutzern, es auf einer großen Datenmenge mit vielen tiefen Schichten auszuführen.</block>
  <block id="9981faa66d13ca7ba415a6c70dc52893" category="paragraph">Wenn wir TensorFlow mit Apache Spark verwenden wollten, mussten wir bis vor Kurzem alle erforderlichen ETL-Prozesse für TensorFlow in PySpark durchführen und dann die Daten in den Zwischenspeicher schreiben.  Diese Daten würden dann für den eigentlichen Trainingsprozess in den TensorFlow-Cluster geladen.  Dieser Workflow erforderte, dass der Benutzer zwei verschiedene Cluster verwaltete, einen für ETL und einen für das verteilte Training von TensorFlow.  Das Ausführen und Warten mehrerer Cluster war normalerweise mühsam und zeitaufwändig.</block>
  <block id="082ad29f115c5cd4ab167c596b90688c" category="paragraph">DataFrames und RDD in früheren Spark-Versionen waren für Deep Learning nicht gut geeignet, da der wahlfreie Zugriff eingeschränkt war.  In Spark 3.0 mit Project Hydrogen wird native Unterstützung für die Deep-Learning-Frameworks hinzugefügt.  Dieser Ansatz ermöglicht eine nicht auf MapReduce basierende Planung auf dem Spark-Cluster.</block>
  <block id="44cd5d1ec9ffc51f82d838faf685ef6e" category="section-title">Interaktive Analyse</block>
  <block id="9650da7c8eb40c14055202b3dd7f4443" category="paragraph">Apache Spark ist schnell genug, um explorative Abfragen ohne Sampling mit anderen Entwicklungssprachen als Spark durchzuführen, darunter SQL, R und Python.  Spark verwendet Visualisierungstools, um komplexe Daten zu verarbeiten und interaktiv zu visualisieren.  Spark mit strukturiertem Streaming führt interaktive Abfragen für Livedaten in der Webanalyse durch, die es Ihnen ermöglichen, interaktive Abfragen für die aktuelle Sitzung eines Webbesuchers auszuführen.</block>
  <block id="d89f01bf7c0ceacaf30849bab08e0939" category="section-title">Empfehlungssystem</block>
  <block id="38c79706797b854a06f30876828ee766" category="paragraph">Im Laufe der Jahre haben Empfehlungssysteme enorme Veränderungen in unser Leben gebracht, da Unternehmen und Verbraucher auf dramatische Veränderungen beim Online-Shopping, der Online-Unterhaltung und vielen anderen Branchen reagiert haben.  Tatsächlich gehören diese Systeme zu den offensichtlichsten Erfolgsgeschichten der KI in der Produktion.  In vielen praktischen Anwendungsfällen werden Empfehlungssysteme mit Konversations-KI oder Chatbots kombiniert, die mit einem NLP-Backend verbunden sind, um relevante Informationen zu erhalten und nützliche Schlussfolgerungen zu ziehen.</block>
  <block id="6346d11f3fda24eb2d12fa4ac478fe3b" category="paragraph">Heutzutage setzen viele Einzelhändler auf neuere Geschäftsmodelle wie Online-Kauf und Abholung im Geschäft, Abholung am Straßenrand, Self-Checkout, Scan-and-Go und mehr.  Diese Modelle haben während der COVID-19-Pandemie an Bedeutung gewonnen, da sie das Einkaufen für die Verbraucher sicherer und bequemer machen.  KI ist für diese wachsenden digitalen Trends von entscheidender Bedeutung, die vom Verbraucherverhalten beeinflusst werden und umgekehrt.  Um den wachsenden Ansprüchen der Verbraucher gerecht zu werden, das Kundenerlebnis zu verbessern, die Betriebseffizienz zu steigern und den Umsatz zu steigern, unterstützt NetApp seine Unternehmenskunden und Unternehmen dabei, mithilfe von Algorithmen für maschinelles Lernen und Deep Learning schnellere und präzisere Empfehlungssysteme zu entwickeln.</block>
  <block id="b32f1d719ba1fea2cad3538a4795c552" category="paragraph">Es gibt mehrere gängige Techniken zum Bereitstellen von Empfehlungen, darunter kollaboratives Filtern, inhaltsbasierte Systeme, das Deep Learning Recommender Model (DLRM) und Hybridtechniken.  Kunden nutzten PySpark zuvor, um kollaboratives Filtern zur Erstellung von Empfehlungssystemen zu implementieren.  Spark MLlib implementiert Alternating Least Squares (ALS) für kollaboratives Filtern, einen in Unternehmen vor dem Aufkommen von DLRM sehr beliebten Algorithmus.</block>
  <block id="9389b39b238fbd5ad61de2fea371853d" category="section-title">Verarbeitung natürlicher Sprache</block>
  <block id="18bfab6309a4addeb7e1dae07d2a4b89" category="inline-link">Gartner</block>
  <block id="47fa981bf7641c90f0ce83a88c21234e" category="paragraph">Konversations-KI, die durch die Verarbeitung natürlicher Sprache (NLP) ermöglicht wird, ist der Zweig der KI, der Computern bei der Kommunikation mit Menschen hilft.  NLP ist in allen Branchen und vielen Anwendungsfällen weit verbreitet, von intelligenten Assistenten und Chatbots bis hin zur Google-Suche und Textvorhersage.  Laut einer<block ref="be3a50ddc5683c6936ee69409b86e212" category="inline-link-rx"></block> Prognosen zufolge werden bis 2022 70 % der Menschen täglich mit Konversations-KI-Plattformen interagieren.  Für eine qualitativ hochwertige Konversation zwischen Mensch und Maschine müssen die Antworten schnell, intelligent und natürlich klingen.</block>
  <block id="9cac4209da8ee0481a45fa299b66e587" category="paragraph">Kunden benötigen große Datenmengen, um ihre NLP- und automatischen Spracherkennungsmodelle (ASR) zu verarbeiten und zu trainieren.  Sie müssen außerdem Daten zwischen Edge, Core und Cloud verschieben und benötigen die Fähigkeit, in Millisekunden Schlussfolgerungen zu ziehen, um eine natürliche Kommunikation mit Menschen herzustellen.  NetApp AI und Apache Spark sind eine ideale Kombination für Computing, Speicherung, Datenverarbeitung, Modelltraining, Feinabstimmung und Bereitstellung.</block>
  <block id="6ecf226f4b849e3111584c1eebd25f3c" category="paragraph">Die Stimmungsanalyse ist ein Forschungsgebiet innerhalb der NLP, in dem positive, negative oder neutrale Stimmungen aus Texten extrahiert werden.  Die Sentimentanalyse bietet vielfältige Anwendungsfälle, von der Ermittlung der Leistung von Supportcenter-Mitarbeitern in Gesprächen mit Anrufern bis hin zur Bereitstellung geeigneter automatisierter Chatbot-Antworten.  Es wurde auch verwendet, um den Aktienkurs eines Unternehmens auf der Grundlage der Interaktionen zwischen Unternehmensvertretern und dem Publikum bei vierteljährlichen Telefonkonferenzen zu den Unternehmensergebnissen vorherzusagen.  Darüber hinaus kann mithilfe der Stimmungsanalyse die Meinung eines Kunden zu den Produkten, Dienstleistungen oder dem Support der Marke ermittelt werden.</block>
  <block id="635dbe8a61ae76776533cf731db5ca3d" category="inline-link">Spark NLP</block>
  <block id="511405f2428e9a6a71530b7f2cdcbc21" category="inline-link">John Snow Labs</block>
  <block id="351594930581e8fa82cf694de7562fd2" category="inline-link">Stimmung in den Finanznachrichten</block>
  <block id="8f1fadc17d848b3be53c2009f5f9070a" category="inline-link">FinBERT</block>
  <block id="c1856f13b6ce4dd1f710cf08138e0c51" category="paragraph">Wir nutzten die<block ref="0f17ea1334fb20ed83c3ab03268616d7" category="inline-link-rx"></block> Bibliothek von<block ref="22825786ea861b373c2a5fdda9f62d81" category="inline-link-rx"></block> zum Laden vortrainierter Pipelines und Bidirectional Encoder Representations from Transformers (BERT)-Modelle, einschließlich<block ref="1a3a0057856cc0bfa7cb2c9343eb2415" category="inline-link-rx"></block> Und<block ref="ac723dc3fc44f63057a74e935ae9db52" category="inline-link-rx"></block> , Durchführung von Tokenisierung, Named Entity Recognition, Modelltraining, Anpassung und Stimmungsanalyse im großen Maßstab.  Spark NLP ist die einzige Open-Source-NLP-Bibliothek in der Produktion, die hochmoderne Transformatoren wie BERT, ALBERT, ELECTRA, XLNet, DistilBERT, RoBERTa, DeBERTa, XLM-RoBERTa, Longformer, ELMO, Universal Sentence Encoder, Google T5, MarianMT und GPT2 bietet.  Die Bibliothek funktioniert nicht nur in Python und R, sondern auch im JVM-Ökosystem (Java, Scala und Kotlin) im großen Maßstab, indem sie Apache Spark nativ erweitert.</block>
  <block id="e353dbe42c8654f33588d4da0b517469" category="doc">Abstrakt</block>
  <block id="c9da861bd07fd9446a0e4f9108517532" category="paragraph">In diesem Dokument wird beschrieben, wie Daten aus Big-Data-Analyse- und High-Performance-Computing-Systemen (HPC) verschoben werden, damit sie in Workflows der künstlichen Intelligenz (KI) verwendet werden können.  AI verarbeitet NFS-Daten normalerweise über NFS-Exporte.  Möglicherweise befinden sich Ihre KI-Daten jedoch auf einer Big-Data-Analyse- und High-Performance-Computing-Plattform (HPC).  Dies könnte das Hadoop Distributed File System (HDFS), ein Binary Large Object (Blob), S3-Speicher oder das General Parallel File System (GPFS) von IBM sein.  In diesem Dokument beschreiben wir, wie Sie Daten von einer Big-Data-Analyseplattform und GPFS mithilfe von Hadoop-nativen Befehlen, dem NetApp In-Place Analytics Module (NIPAM) und NetApp XCP nach NFS verschieben.  In diesem Dokument werden auch die geschäftlichen Vorteile der Datenverschiebung von Big Data und HPC zu KI erörtert.</block>
  <block id="4bb047f8c530785002e490ef17fa725e" category="doc">Wo Sie weitere Informationen finden</block>
  <block id="7d5b957cd473f6eaf5ad335a9c63c4ff" category="paragraph">Weitere Informationen zu den in diesem Dokument beschriebenen Informationen finden Sie in den folgenden Dokumenten und/oder auf den folgenden Websites:</block>
  <block id="f5ac1e3c252855373c7f660dbd89699d" category="list-text">Best Practices und Implementierungshandbuch für NetApp FlexGroup Volume</block>
  <block id="7d72333a4556beea0bd57e4b8a007b47" category="paragraph"><block ref="7d72333a4556beea0bd57e4b8a007b47" category="inline-link-rx"></block></block>
  <block id="bc4fe2352063642d68529f2aa0ca7ca3" category="list-text">NetApp Produktdokumentation</block>
  <block id="c9617ae303d0bce89d13bebecca2ea1b" category="paragraph"><block ref="c9617ae303d0bce89d13bebecca2ea1b" category="inline-link-rx"></block></block>
  <block id="e0a1057b7f63b9621d22a28a118e4a79" category="summary">In diesem Abschnitt werden die geschäftlichen Vorteile dieser Lösung beschrieben.</block>
  <block id="7f0cbc7391fd4e971628295e6bff035a" category="doc">Geschäftsvorteile</block>
  <block id="239f77225835899839f2d1318d1cc1c4" category="paragraph">Die Verlagerung von Daten aus der Big Data-Analyse in die KI bietet die folgenden Vorteile:</block>
  <block id="c07548816e2d37db2db301172209009e" category="list-text">Die Möglichkeit, Daten aus verschiedenen Hadoop-Dateisystemen und GPFS in ein einheitliches NFS-Speichersystem zu extrahieren</block>
  <block id="17480f22ec6a36806354b84f9824ff80" category="list-text">Eine Hadoop-integrierte und automatisierte Möglichkeit zur Datenübertragung</block>
  <block id="626dfcaeea53c1bdef78276b0f594dbf" category="list-text">Eine Reduzierung der Kosten für die Bibliotheksentwicklung zum Verschieben von Daten aus Hadoop-Dateisystemen</block>
  <block id="8576c8e67d6540e2f677340d38ec60e9" category="list-text">Maximale Leistung durch aggregierten Durchsatz mehrerer Netzwerkschnittstellen aus einer einzigen Datenquelle durch Verwendung von NIPAM</block>
  <block id="28338c61f9a9de656b504b14a75bb824" category="list-text">Geplante und On-Demand-Methoden zur Datenübertragung</block>
  <block id="3c70d03dd35337605475e972b74654c8" category="list-text">Speichereffizienz und Enterprise-Management-Funktionen für einheitliche NFS-Daten durch den Einsatz der ONTAP Datenmanagementsoftware</block>
  <block id="2b602714583b0c6daac65349c0e00e16" category="list-text">Null Kosten für Datenbewegung mit der Hadoop-Methode zur Datenübertragung</block>
  <block id="eea7b9fa88f883b7983320cb8dd802ac" category="summary">Auf dieser Seite werden die Herausforderungen erörtert, denen sich ein Kunde möglicherweise gegenübersieht, wenn er versucht, für KI-Operationen auf Daten aus Big-Data-Analysen zuzugreifen.</block>
  <block id="b794cc731a2a9499d064b08a32552e78" category="paragraph">Kunden stehen möglicherweise vor den folgenden Herausforderungen, wenn sie versuchen, für KI-Operationen auf Daten aus Big-Data-Analysen zuzugreifen:</block>
  <block id="593806557377bd8506b6705484962785" category="list-text">Kundendaten befinden sich in einem Data Lake-Repository.  Der Datensee kann verschiedene Arten von Daten enthalten, z. B. strukturierte, unstrukturierte, halbstrukturierte, Protokoll- und Machine-to-Machine-Daten.  Alle diese Datentypen müssen in KI-Systemen verarbeitet werden.</block>
  <block id="43d7d5ce8487763157eabcf01d1cf6ef" category="list-text">AI ist nicht mit Hadoop-Dateisystemen kompatibel.  Eine typische KI-Architektur kann nicht direkt auf HDFS- und HCFS-Daten zugreifen, die in ein für KI verständliches Dateisystem (NFS) verschoben werden müssen.</block>
  <block id="e032c722c87677b6dfba13af108c61b8" category="list-text">Das Verschieben von Data Lake-Daten in die KI erfordert in der Regel spezielle Prozesse.  Die Datenmenge im Datensee kann sehr groß sein.  Ein Kunde muss über eine effiziente, durchsatzstarke und kostengünstige Möglichkeit verfügen, Daten in KI-Systeme zu übertragen.</block>
  <block id="30bd7dc66c05e60d2ea66d09e568cb06" category="list-text">Daten werden synchronisiert.  Wenn ein Kunde Daten zwischen der Big-Data-Plattform und KI synchronisieren möchte, können die durch KI verarbeiteten Daten manchmal zusammen mit Big Data für die analytische Verarbeitung verwendet werden.</block>
  <block id="c877e65bbe37324c3309ace4aa7745d1" category="summary">In einem Big-Data-Cluster werden Daten in HDFS oder HCFS gespeichert, beispielsweise in MapR-FS, dem Windows Azure Storage Blob, S3 oder dem Google-Dateisystem.  Wir haben Tests mit HDFS, MapR-FS und S3 als Quelle durchgeführt, um Daten mithilfe von NIPAM in den NetApp ONTAP NFS-Export zu kopieren, indem wir den Befehl hadoop distcp von der Quelle aus verwendet haben.</block>
  <block id="d73e7d11401e9256a0dea0d1e174e1de" category="doc">Data Mover-Lösung</block>
  <block id="013c5604f73da0e909c46aa5d3a670f3" category="paragraph">In einem Big-Data-Cluster werden Daten in HDFS oder HCFS gespeichert, beispielsweise in MapR-FS, dem Windows Azure Storage Blob, S3 oder dem Google-Dateisystem.  Wir haben Tests mit HDFS, MapR-FS und S3 als Quelle durchgeführt, um Daten mit Hilfe von NIPAM in den NetApp ONTAP NFS-Export zu kopieren, indem wir die<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> Befehl von der Quelle.</block>
  <block id="9fabfa5fcba2e539b6d2c5eff5bb2116" category="paragraph">Das folgende Diagramm veranschaulicht die typische Datenbewegung von einem Spark-Cluster mit HDFS-Speicher zu einem NetApp ONTAP NFS-Volume, damit NVIDIA KI-Operationen verarbeiten kann.</block>
  <block id="67ed14506d4065a668f7cb0136039d8b" category="paragraph"><block ref="67ed14506d4065a668f7cb0136039d8b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da6616575a7b32d3eb2fa505007a9a4a" category="paragraph">Der<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> Der Befehl verwendet das MapReduce-Programm zum Kopieren der Daten.  NIPAM arbeitet mit MapReduce zusammen, um beim Kopieren von Daten als Treiber für den Hadoop-Cluster zu fungieren.  NIPAM kann eine Last für einen einzelnen Export auf mehrere Netzwerkschnittstellen verteilen.  Dieser Prozess maximiert den Netzwerkdurchsatz, indem die Daten beim Kopieren von HDFS oder HCFS nach NFS auf mehrere Netzwerkschnittstellen verteilt werden.</block>
  <block id="c2cad9f038dfeecd75697cb4bebe4c68" category="admonition">NIPAM wird von MapR weder unterstützt noch zertifiziert.</block>
  <block id="20220b4c576eeca673151438f5ee1da9" category="summary">Die Data Mover-Lösung für KI basiert auf den Anforderungen der Kunden, Hadoop-Daten aus KI-Operationen zu verarbeiten.  NetApp verschiebt Daten mithilfe von NIPAM von HDFS nach NFS.  In einem Anwendungsfall musste der Kunde Daten vor Ort in NFS verschieben und ein anderer Kunde musste Daten vom Windows Azure Storage Blob in Google Cloud NetApp Volumes verschieben, um die Daten von den GPU-Cloud-Instanzen in der Cloud zu verarbeiten.</block>
  <block id="7f10e017358079527e7045a68782eb14" category="doc">Data Mover-Lösung für KI</block>
  <block id="b6392eaf0ddf0463d633e69aaeeef3ce" category="paragraph">Das folgende Diagramm veranschaulicht die Details der Data Mover-Lösung.</block>
  <block id="44c3f61c0684bc5b43b5e243a139152c" category="paragraph"><block ref="44c3f61c0684bc5b43b5e243a139152c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e01b73324e59213b14e79f9d912546bc" category="paragraph">Zum Erstellen der Data Mover-Lösung sind folgende Schritte erforderlich:</block>
  <block id="03337d241355e58cdaa3df5a4bb980ef" category="list-text">ONTAP SAN stellt HDFS bereit und NAS stellt das NFS-Volume über NIPAM für den Produktions-Data-Lake-Cluster bereit.</block>
  <block id="625dd6cfdf4a097dff4340366eec8942" category="list-text">Die Daten des Kunden liegen in HDFS und NFS.  Bei den NFS-Daten kann es sich um Produktionsdaten aus anderen Anwendungen handeln, die für Big Data-Analysen und KI-Operationen verwendet werden.</block>
  <block id="32477fa182341c04b6e8076232250f76" category="list-text">Die NetApp FlexClone -Technologie erstellt einen Klon des Produktions-NFS-Volumes und stellt ihn dem KI-Cluster vor Ort bereit.</block>
  <block id="4e7e9a946510d25d1b28cc93a3723e69" category="list-text">Daten aus einem HDFS SAN LUN werden mit NIPAM in ein NFS-Volume kopiert und die<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> Befehl.  NIPAM nutzt die Bandbreite mehrerer Netzwerkschnittstellen zur Datenübertragung.  Dieser Vorgang verkürzt die Datenkopierzeit, sodass mehr Daten übertragen werden können.</block>
  <block id="b0dd56fceeaba1e1db258d1b06d2572d" category="list-text">Beide NFS-Volumes werden dem AI-Cluster für AI-Operationen bereitgestellt.</block>
  <block id="344c1652d7730f66d822b6ed5d07ff77" category="list-text">Um lokale NFS-Daten mit GPUs in der Cloud zu verarbeiten, werden die NFS-Volumes mit der NetApp SnapMirror -Technologie auf NetApp Private Storage (NPS) gespiegelt und bei Cloud-Service-Providern für GPUs bereitgestellt.</block>
  <block id="98105737f8ac55863a4e0763f588cab5" category="list-text">Der Kunde möchte Daten in EC2/EMR-, HDInsight- oder DataProc-Diensten in GPUs von Cloud-Dienstanbietern verarbeiten.  Der Hadoop Data Mover verschiebt die Daten von Hadoop-Diensten in die Google Cloud NetApp Volumes mit NIPAM und dem<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> Befehl.</block>
  <block id="f490cd633c8e7648911d95daf043af8f" category="list-text">Die Google Cloud NetApp Volumes Daten werden der KI über das NFS-Protokoll bereitgestellt. Über die KI verarbeitete Daten können zusätzlich zum NVIDIA Cluster über NIPAM, SnapMirror und NPS an einen lokalen Standort für Big Data-Analysen gesendet werden.</block>
  <block id="f13f02e9fbfc272070bb10c4ae60e707" category="paragraph">In diesem Szenario verfügt der Kunde über eine große Anzahl von Dateidaten im NAS-System an einem Remote-Standort, die für die KI-Verarbeitung auf dem NetApp Speichercontroller vor Ort benötigt werden.  In diesem Szenario ist es besser, das XCP-Migrationstool zu verwenden, um die Daten schneller zu migrieren.</block>
  <block id="74c03e6f525ff7a5f56d15dd77d9d7ee" category="paragraph">Der Kunde mit Hybridanwendungsfall kann BlueXP Copy and Sync verwenden, um lokale Daten von NFS-, CIFS- und S3-Daten in die Cloud und umgekehrt zu migrieren, um sie für die KI-Verarbeitung mithilfe von GPUs wie denen in einem NVIDIA Cluster zu verwenden.  Für die NFS-Datenmigration zu NetApp ONTAP NFS werden sowohl BlueXP Copy and Sync als auch das XCP Migration Tool verwendet.</block>
  <block id="ae1992b408fce873deb0f11eb017ea19" category="summary">Bei dieser Validierung haben wir vier Server als Network Shared Disk (NSD)-Server verwendet, um physische Festplatten für GPFS bereitzustellen.  GPFS wird auf den NSD-Festplatten erstellt, um sie als NFS-Exporte zu exportieren, sodass NFS-Clients auf sie zugreifen können, wie in der folgenden Abbildung dargestellt.  Wir haben XCP verwendet, um die Daten vom GPFS-exportierten NFS auf ein NetApp NFS-Volume zu kopieren.</block>
  <block id="bc64aad447f072e96947f5d02f7e8134" category="doc">GPFS zu NetApp ONTAP NFS</block>
  <block id="f0987b9b1ed71523f2b4be4961e35e12" category="paragraph"><block ref="f0987b9b1ed71523f2b4be4961e35e12" category="inline-image-macro-rx" type="image"></block></block>
  <block id="86339fb1bc11f77d6e48efc42d910f0f" category="section-title">GPFS-Grundlagen</block>
  <block id="d859f99e3b66fbd7305cfd50ba2d4566" category="paragraph">Die folgenden Knotentypen werden in GPFS verwendet:</block>
  <block id="4ac5c1b5474a4920e2433b8f1610729f" category="list-text">*Admin-Knoten.*  Gibt ein optionales Feld an, das einen Knotennamen enthält, der von den Verwaltungsbefehlen zur Kommunikation zwischen Knoten verwendet wird.  Zum Beispiel der Admin-Knoten<block ref="f2fde43b571e78e29f67743af45165cb" prefix=" " category="inline-code"></block> könnte eine Netzwerkprüfung an alle anderen Knoten im Cluster weitergeben.</block>
  <block id="6659be8d3c5ae97ae05588383a9efb5a" category="list-text">*Quorum-Knoten.*  Bestimmt, ob ein Knoten in den Pool der Knoten aufgenommen wird, aus denen das Quorum abgeleitet wird.  Sie benötigen mindestens einen Knoten als Quorumknoten.</block>
  <block id="504f43a7f6382dae9e638f1c396a1779" category="list-text">*Manager-Knoten.*  Gibt an, ob ein Knoten Teil des Knotenpools ist, aus dem Dateisystem-Manager und Token-Manager ausgewählt werden können.  Es ist eine gute Idee, mehr als einen Knoten als Managerknoten zu definieren.  Wie viele Knoten Sie als Manager festlegen, hängt von der Arbeitslast und der Anzahl Ihrer GPFS-Serverlizenzen ab.  Wenn Sie große parallele Jobs ausführen, benötigen Sie möglicherweise mehr Managerknoten als in einem Cluster mit vier Knoten, der eine Webanwendung unterstützt.</block>
  <block id="48b637b1e31141b7e6faae1b7c6d8be2" category="list-text">*NSD-Server.*  Der Server, der jede physische Festplatte für die Verwendung mit GPFS vorbereitet.</block>
  <block id="8cd64755dc629d6061cef8f3bdddfe8f" category="list-text">*Protokollknoten.*  Der Knoten, der GPFS-Daten direkt über ein beliebiges Secure Shell (SSH)-Protokoll mit dem NFS teilt.  Dieser Knoten erfordert eine GPFS-Serverlizenz.</block>
  <block id="d1a65ffa2a3768b3a494baba34855023" category="section-title">Liste der Vorgänge für GPFS, NFS und XCP</block>
  <block id="089009e49dc3cafdc4329d07f11c5250" category="paragraph">Dieser Abschnitt enthält die Liste der Vorgänge zum Erstellen von GPFS, zum Exportieren von GPFS als NFS-Export und zum Übertragen der Daten mithilfe von XCP.</block>
  <block id="1d9da206467eb5273c4b522820cfddb2" category="section-title">GPFS erstellen</block>
  <block id="454f38a55393f7773c6e59f13eb6fef5" category="paragraph">Führen Sie zum Erstellen von GPFS die folgenden Schritte aus:</block>
  <block id="a69093440b15d387cf13aadb026e36a9" category="list-text">Laden Sie den Spectrum-Scale-Datenzugriff für die Linux-Version herunter und installieren Sie ihn auf einem der Server.</block>
  <block id="8a3d13c75e4dd8c8cffdf92d8e9dd956" category="list-text">Installieren Sie das erforderliche Paket (z. B. Chef) auf allen Knoten und deaktivieren Sie Security-Enhanced Linux (SELinux) auf allen Knoten.</block>
  <block id="9356dbe859ed4334d7e27c641d7dd594" category="list-text">Richten Sie den Installationsknoten ein und fügen Sie den Admin-Knoten und den GPFS-Knoten zur Clusterdefinitionsdatei hinzu.</block>
  <block id="1bdc86658a65033989c8064812818633" category="list-text">Fügen Sie den Managerknoten, den Quorumknoten, die NSD-Server und den GPFS-Knoten hinzu.</block>
  <block id="d55b679ec8a82b729ae03c882f27b80e" category="list-text">Fügen Sie die GUI-, Admin- und GPFS-Knoten hinzu und fügen Sie bei Bedarf einen zusätzlichen GUI-Server hinzu.</block>
  <block id="f4e47c4647a3dafebf21a5f40cfa7f9c" category="list-text">Fügen Sie einen weiteren GPFS-Knoten hinzu und überprüfen Sie die Liste aller Knoten.</block>
  <block id="303364b5437159140dc70a76a77e8aa8" category="list-text">Geben Sie einen Clusternamen, ein Profil, eine Remote-Shell-Binärdatei, eine Remote-Dateikopie-Binärdatei und einen Portbereich an, der auf allen GPFS-Knoten in der Clusterdefinitionsdatei festgelegt werden soll.</block>
  <block id="30d14bbe638530772662c104a30d53d3" category="list-text">Zeigen Sie die GPFS-Konfigurationseinstellungen an und fügen Sie einen zusätzlichen Admin-Knoten hinzu.</block>
  <block id="d6daa755d449b0cec4c1c23153b9a0be" category="list-text">Deaktivieren Sie die Datenerfassung und laden Sie das Datenpaket in das IBM Support Center hoch.</block>
  <block id="765ad728fb1bb9eb3c981693321a01ef" category="list-text">Aktivieren Sie NTP und überprüfen Sie die Konfigurationen vor der Installation.</block>
  <block id="1deb66562b5d0f8ce755a102f2731d8d" category="list-text">Konfigurieren, erstellen und überprüfen Sie die NSD-Datenträger.</block>
  <block id="f54668a02541c80dd54234689ef58ad4" category="list-text">Erstellen Sie die GPFS.</block>
  <block id="048c1f8a018373ca436ef1a91fe6be57" category="list-text">Hängen Sie das GPFS ein.</block>
  <block id="18a8260437fd56c8bdc1f994d860e490" category="list-text">Überprüfen Sie, ob die erforderlichen Berechtigungen für das GPFS vorhanden sind, und erteilen Sie diese.</block>
  <block id="a150a1930bbf429fc0204993b66d46cb" category="list-text">Überprüfen Sie die GPFS-Lese- und Schreibvorgänge, indem Sie den<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> Befehl.</block>
  <block id="83cd36fb568894200fe5f9cf7f7e1193" category="section-title">GPFS in NFS exportieren</block>
  <block id="e2fc86fc4827b925f5cccecdcd51d6b1" category="paragraph">Führen Sie die folgenden Schritte aus, um GPFS in NFS zu exportieren:</block>
  <block id="af125b713cb0d82420980798e0276ea7" category="list-text">Exportieren Sie GPFS als NFS über die<block ref="9c8ea389db0c545c0a8c9ca08caecb34" prefix=" " category="inline-code"></block> Datei.</block>
  <block id="c953ca93794388b6266ed8529319d420" category="list-text">Installieren Sie die erforderlichen NFS-Serverpakete.</block>
  <block id="c0d11d4c7c65daa849ff313e229d632c" category="list-text">Starten Sie den NFS-Dienst.</block>
  <block id="873ad6aeda101f4e6c3a2cb8a46e84ad" category="list-text">Listen Sie die Dateien im GPFS auf, um den NFS-Client zu validieren.</block>
  <block id="f9b2649730ae4997f650bc4a2f8c1773" category="section-title">Konfigurieren des NFS-Clients</block>
  <block id="25be8238edbbbd8936c0385098957520" category="paragraph">Führen Sie zum Konfigurieren des NFS-Clients die folgenden Schritte aus:</block>
  <block id="d11e3a3b633c68e9cc37f13adcdfd95a" category="list-text">Exportieren Sie das GPFS als NFS über die<block ref="9c8ea389db0c545c0a8c9ca08caecb34" prefix=" " category="inline-code"></block> Datei.</block>
  <block id="64aef4f16c4a9f913379e9668323ed4f" category="list-text">Starten Sie die NFS-Clientdienste.</block>
  <block id="b7eb10685995437ddaa0df5b09b22fb8" category="list-text">Mounten Sie das GPFS über das NFS-Protokoll auf dem NFS-Client.</block>
  <block id="bb8a91cbc28d52ebb4edab31956c7f58" category="list-text">Überprüfen Sie die Liste der GPFS-Dateien im NFS-gemounteten Ordner.</block>
  <block id="690b19ed08f992a8a2d6e3e872641b2e" category="list-text">Verschieben Sie die Daten mithilfe von XCP vom GPFS-exportierten NFS zum NetApp NFS.</block>
  <block id="f919d4d761d618912a13cac0895236af" category="list-text">Validieren Sie die GPFS-Dateien auf dem NFS-Client.</block>
  <block id="0e0fdc9fc616f1d8648561d150679a8c" category="summary">Dieser Abschnitt enthält die detaillierten Schritte zum Konfigurieren von GPFS und zum Verschieben von Daten in NFS mithilfe von NetApp XCP.</block>
  <block id="2cf43976b964350d85af88e8c7c56bfc" category="doc">GPFS zu NFS – Detaillierte Schritte</block>
  <block id="7f1260d8686ace0468fd1c74b243b7a1" category="section-title">GPFS konfigurieren</block>
  <block id="de00400b12b028274700d1385b53c26d" category="list-text">Laden Sie Spectrum Scale Data Access für Linux herunter und installieren Sie es auf einem der Server.</block>
  <block id="61a030f51cd790deb6f1374ae7e4d88f" category="list-text">Installieren Sie das erforderliche Paket (einschließlich Chef und Kernel-Header) auf allen Knoten.</block>
  <block id="cea532f5e6d51ac7b08d9f6d71886efe" category="list-text">Deaktivieren Sie SELinux auf allen Knoten.</block>
  <block id="e116db66dcd3a8a38d53716cdd97c179" category="list-text">Richten Sie den Installationsknoten ein.</block>
  <block id="6021211d885ba9ec28a1dfcdb72b0542" category="list-text">Fügen Sie den Admin-Knoten und den GPFS-Knoten zur Clusterdefinitionsdatei hinzu.</block>
  <block id="8b361b52f2d7d8ddca7c364e1826015d" category="list-text">Fügen Sie den Managerknoten und den GPFS-Knoten hinzu.</block>
  <block id="d98e392ead2711bea231821e3cafe06e" category="list-text">Fügen Sie den Quorum-Knoten und den GPFS-Knoten hinzu.</block>
  <block id="549101fb45a9a42ca05a3b680ea6dcdc" category="list-text">Fügen Sie die NSD-Server und den GPFS-Knoten hinzu.</block>
  <block id="0150b7ec1d76a294c8fce802481a2e2d" category="list-text">Fügen Sie die GUI-, Admin- und GPFS-Knoten hinzu.</block>
  <block id="5076e582b15cea2e7319261b9eb2dc4e" category="list-text">Fügen Sie einen weiteren GUI-Server hinzu.</block>
  <block id="65d8f0643532859908a7e9616439572a" category="list-text">Fügen Sie einen weiteren GPFS-Knoten hinzu.</block>
  <block id="8c6e090e52befa2e95e6d658661749dc" category="list-text">Überprüfen und listen Sie alle Knoten auf.</block>
  <block id="6a21679cbbcb8a64de6016e8efb6b2ea" category="list-text">Geben Sie in der Clusterdefinitionsdatei einen Clusternamen an.</block>
  <block id="0e890aabbc215ad4497b26965a0435ad" category="list-text">Geben Sie das Profil an.</block>
  <block id="3296b6b95878e4a01015b9d97691cd23" category="list-text">Geben Sie die Remote-Shell-Binärdatei an, die von GPFS verwendet werden soll.<block ref="f8b2a03096b35c105ccb9e1687ea4d21" prefix=" " category="inline-code"></block> .</block>
  <block id="6b1edec7f7c05cc2bc9fb41ef76dc8c9" category="list-text">Geben Sie die Binärdatei für die Remote-Dateikopie an, die von GPFS verwendet werden soll.<block ref="795f05204859c09fe2f151b742bf82f9" prefix=" " category="inline-code"></block> .</block>
  <block id="f35c3f5ce8fa5fca13e0eb96082b73fe" category="list-text">Geben Sie den Portbereich an, der auf allen GPFS-Knoten festgelegt werden soll. Verwenden Sie<block ref="3b552a3fb3ecdff1af07892680e6d03a" prefix=" " category="inline-code"></block> .</block>
  <block id="84807c9c164a1fd83db3680e7b5a6587" category="list-text">Zeigen Sie die GPFS-Konfigurationseinstellungen an.</block>
  <block id="0addd886868e88c985dddc68658e5767" category="list-text">Fügen Sie einen Admin-Knoten hinzu.</block>
  <block id="d2e4082ff74b3d592d15b584ec3e64a9" category="list-text">Aktivieren Sie NTP.</block>
  <block id="bc5f73d061ad4090dd4180838b34fc5a" category="list-text">Überprüfen Sie die Konfigurationen vor der Installation.</block>
  <block id="7f2019dce6ead5054cb5c0d5ccac9d68" category="list-text">Konfigurieren Sie die NSD-Festplatten.</block>
  <block id="bd625aeaf0eb9674912c4c51a421cdb6" category="list-text">Erstellen Sie die NSD-Datenträger.</block>
  <block id="bfc7a92fefcdbb8be49ae2f09a04c609" category="list-text">Überprüfen Sie den NSD-Festplattenstatus.</block>
  <block id="abe092e554a73bb99bd2fd85086ffdce" category="list-text">Überprüfen Sie die erforderlichen Berechtigungen und erteilen Sie sie dem GPFS.</block>
  <block id="737cdea6c4302200061636f408685896" category="list-text">Überprüfen Sie die GPFS-Lese- und Schreibvorgänge, indem Sie Folgendes ausführen:<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> Befehl.</block>
  <block id="978d4e591d532e5741bf55bbe09b8672" category="paragraph">Führen Sie die folgenden Schritte aus, um GPFS in NFS zu exportieren:</block>
  <block id="67ae9e67c637e0c39f8d92303b0a9c01" category="list-text">Listen Sie die Dateien in GPFS auf, um den NFS-Client zu validieren.</block>
  <block id="e90c8e55eda7dc2ebdbef5659a22a517" category="section-title">Konfigurieren des NFS-Clients</block>
  <block id="bc2bba568f2fe74e5616fa8f5953b1bf" category="list-text">Installieren Sie Pakete im NFS-Client.</block>
  <block id="7e4215ed068d7218ec28fe900e8feb16" category="list-text">Überprüfen Sie die Liste der GPFS-Dateien im NFS-gemounteten Ordner.</block>
  <block id="77086f36ad335fd9c2cc6a63c1d21d84" category="list-text">Verschieben Sie die Daten mithilfe von XCP vom GPFS-exportierten NFS zum NetApp NFS.</block>
  <block id="29fb90c4a1468e178582858240052f4c" category="summary">Für diese Lösung hat NetApp die Migration von Daten aus Data Lake (HDFS) und MapR-Clusterdaten zu ONTAP NFS validiert.  Die Daten befanden sich in MapR-FS und HDFS.  NetApp XCP hat eine neue Funktion eingeführt, die die Daten direkt von einem verteilten Dateisystem wie HDFS und MapR-FS zu ONTAP NFS migriert.</block>
  <block id="d233c10a88f93c454d0e84cd34840512" category="doc">HDFS und MapR-FS zu ONTAP NFS</block>
  <block id="676df8e27b06b6dd639822191d432dc2" category="paragraph">Für diese Lösung hat NetApp die Migration von Daten aus Data Lake (HDFS) und MapR-Clusterdaten zu ONTAP NFS validiert.  Die Daten befanden sich in MapR-FS und HDFS.  NetApp XCP hat eine neue Funktion eingeführt, die die Daten direkt von einem verteilten Dateisystem wie HDFS und MapR-FS zu ONTAP NFS migriert.  XCP verwendet asynchrone Threads und HDFS C-API-Aufrufe zur Kommunikation und Datenübertragung von MapR-FS sowie HDFS.</block>
  <block id="adc95e83c5f5ce743bb6468ffdef4fc3" category="paragraph">Die folgende Abbildung zeigt die Datenmigration von Data Lake (HDFS) und MapR-FS zu ONTAP NFS.  Mit dieser neuen Funktion müssen Sie die Quelle nicht als NFS-Freigabe exportieren.</block>
  <block id="3789ec0eac19c6a55506d3fe4f2e880e" category="paragraph"><block ref="3789ec0eac19c6a55506d3fe4f2e880e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c11c71088d0987243547dd8fc322c2ad" category="section-title">Warum wechseln Kunden von HDFS und MapR-FS zu NFS?</block>
  <block id="8616e2393304ffc26da9b5e853b8db33" category="paragraph">Die meisten Hadoop-Distributionen wie Cloudera und Hortonworks verwenden HDFS und MapR-Distributionen verwenden ihr eigenes Dateisystem namens Mapr-FS zum Speichern von Daten.  HDFS- und MapR-FS-Daten liefern Datenwissenschaftlern wertvolle Erkenntnisse, die beim maschinellen Lernen (ML) und Deep Learning (DL) genutzt werden können.  Die Daten in HDFS und MapR-FS werden nicht geteilt, was bedeutet, dass sie nicht von anderen Anwendungen verwendet werden können.  Kunden suchen nach gemeinsam genutzten Daten, insbesondere im Bankensektor, wo vertrauliche Kundendaten von mehreren Anwendungen verwendet werden.  Die neueste Version von Hadoop (3.x oder höher) unterstützt NFS-Datenquellen, auf die ohne zusätzliche Software von Drittanbietern zugegriffen werden kann.  Mit der neuen NetApp XCP-Funktion können Daten direkt von HDFS und MapR-FS nach NetApp NFS verschoben werden, um den Zugriff auf mehrere Anwendungen zu ermöglichen.</block>
  <block id="fa2772759fe171754d3e04460b417464" category="paragraph">Für den ersten Leistungstest mit 12 MAPR-Knoten und 4 NFS-Servern wurden Tests in Amazon Web Services (AWS) durchgeführt, um die Daten von MapR-FS auf NFS zu übertragen.</block>
  <block id="694e8d1f2ee056f98ee488bdc4982d73" category="cell">Menge</block>
  <block id="6f6cb72d544962fa333e2e34ce64f719" category="cell">Größe</block>
  <block id="5d56dbd20d9ee1ab8a722ff12e331953" category="cell">vCPU</block>
  <block id="4789f23283b3a61f858b641a1bef19a3" category="cell">Erinnerung</block>
  <block id="8c4aa541ee911e8d80451ef8cc304806" category="cell">Storage</block>
  <block id="eec89088ee408b80387155272b113256" category="cell">Netzwerk</block>
  <block id="e83e5674ab295a6613b60f5e12d1bfe3" category="cell">NFS-Server</block>
  <block id="6215b1525ff41917096b1eb923fe894f" category="cell">i3en.24xlarge</block>
  <block id="26657d5ff9020d2abefe558796b99584" category="cell">96</block>
  <block id="c45b008ff7fe72f83bb47cba575960c7" category="cell">488GiB</block>
  <block id="9f8ce2ff912e3931e4fc14876f3097f2" category="cell">8x 7500 NVMe SSD</block>
  <block id="f899139df5e1059396431415e770c6dd" category="cell">100</block>
  <block id="899f7b8a7c3e28d3161a77da8f1c8e33" category="cell">MapR-Knoten</block>
  <block id="6ac0fbf236c6d341a7f2c6c92933f744" category="cell">I3en.12xlarge</block>
  <block id="642e92efb79421734881b53e1e1b18b6" category="cell">48</block>
  <block id="1aa80378346dacbf8ce58aaadcefc35e" category="cell">384GiB</block>
  <block id="3ce58620106227953b9e12e2e0633095" category="cell">4x 7500 NVMe SSD</block>
  <block id="c0c7c76d30bd3dcaefc96f40275bdc0a" category="cell">50</block>
  <block id="03e4c674f628169124f81fb7b98f9c92" category="paragraph">Basierend auf ersten Tests erreichten wir einen Durchsatz von 20 GB/s und konnten 2 PB Daten pro Tag übertragen.</block>
  <block id="fce5332d471cfbe0baf7fa83eb2d427d" category="inline-link-macro">TR-4863: TR-4863: Best-Practice-Richtlinien für NetApp XCP – Data Mover, Dateimigration und Analyse</block>
  <block id="d7b251f310540db8b677090e4068b718" category="paragraph">Weitere Informationen zur HDFS-Datenmigration ohne Export von HDFS nach NFS finden Sie im Abschnitt „Bereitstellungsschritte – NAS“ in<block ref="8057f0a15e6751a5fa14293a5e88f017" category="inline-link-macro-rx"></block> .</block>
  <block id="5e1ee998c60aed58b6080afc9d8903a3" category="summary">Dieses Dokument enthält Richtlinien zum Verschieben von Big-Data-Analysedaten und HPC-Daten in die KI mithilfe von NetApp XCP und NIPAM.  Wir diskutieren auch die geschäftlichen Vorteile der Datenverschiebung von Big Data und HPC zu KI.</block>
  <block id="82a406843faa25e62de32fd044584709" category="doc">TR-4732: Von Big Data Analytics-Daten bis hin zu künstlicher Intelligenz</block>
  <block id="439be0f3df9ab229e224aa3c8dbeca77" category="paragraph">Karthikeyan Nagalingam, NetApp</block>
  <block id="bdd40c24689e02e4043333640734a44e" category="paragraph">In diesem Dokument wird beschrieben, wie Big-Data-Analysedaten und HPC-Daten in die KI verschoben werden.  KI verarbeitet NFS-Daten über NFS-Exporte, während Kunden ihre KI-Daten häufig auf einer Big-Data-Analyseplattform wie HDFS, Blob oder S3-Speicher sowie auf HPC-Plattformen wie GPFS haben.  Dieses Dokument enthält Richtlinien zum Verschieben von Big-Data-Analysedaten und HPC-Daten in die KI mithilfe von NetApp XCP und NIPAM.  Wir diskutieren auch die geschäftlichen Vorteile der Datenverschiebung von Big Data und HPC zu KI.</block>
  <block id="9895310afc8a3755fef2e679c38f32f8" category="section-title">Konzepte und Komponenten</block>
  <block id="8ba5fcae463371ff85de74be48ced059" category="section-title">Big Data-Analysespeicher</block>
  <block id="b5b25f8714075ee7aa7cae37cabc6e77" category="paragraph">Big Data Analytics ist der wichtigste Speicheranbieter für HDFS.  Ein Kunde verwendet häufig ein Hadoop-kompatibles Dateisystem (HCFS) wie Windows Azure Blob Storage, MapR File System (MapR-FS) und S3-Objektspeicher.</block>
  <block id="201dde15c75147909c8154fe3e727aed" category="section-title">Allgemeines paralleles Dateisystem</block>
  <block id="510b2e746f7cab5126465c64edad8541" category="paragraph">GPFS von IBM ist ein Enterprise-Dateisystem, das eine Alternative zu HDFS bietet.  GPFS bietet Anwendungen die Flexibilität, über die Blockgröße und das Replikationslayout zu entscheiden, was für gute Leistung und Effizienz sorgt.</block>
  <block id="49d7c87b66a2b688ec65b1a4fe9b5ddc" category="section-title">NetApp In-Place Analytics-Modul</block>
  <block id="f1b570aebec7f92867ad62cf2fe7c50c" category="paragraph">Das NetApp In-Place Analytics Module (NIPAM) dient als Treiber für Hadoop-Cluster zum Zugriff auf NFS-Daten.  Es besteht aus vier Komponenten: einem Verbindungspool, einem NFS-InputStream, einem Dateihandle-Cache und einem NFS-OutputStream. Weitere Informationen finden Sie unter <block ref="ead8bf031afc74347ebd06de968e5895" category="inline-link-rx"></block> .</block>
  <block id="0be6a753178a606f6e24a10fde5ec644" category="section-title">Verteilte Hadoop-Kopie</block>
  <block id="3cc73009b533164939781f9f6a4a1aa0" category="paragraph">Hadoop Distributed Copy (DistCp) ist ein verteiltes Kopiertool, das für große Inter-Cluster- und Intra-Cluster-Coping-Aufgaben verwendet wird.  Dieses Tool verwendet MapReduce zur Datenverteilung, Fehlerbehandlung und Berichterstellung.  Es erweitert die Liste der Dateien und Verzeichnisse und gibt sie in Zuordnungsaufgaben ein, um die Daten aus der Quellliste zu kopieren.  Das Bild unten zeigt den DistCp-Vorgang in HDFS und Nicht-HDFS.</block>
  <block id="513bd70b6fe800dda2548dae1bc404df" category="paragraph"><block ref="513bd70b6fe800dda2548dae1bc404df" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8f54af1bdcb54a020503d81bc3b2114" category="paragraph">Hadoop DistCp verschiebt Daten zwischen den beiden HDFS-Systemen, ohne einen zusätzlichen Treiber zu verwenden.  NetApp stellt den Treiber für Nicht-HDFS-Systeme bereit.  Für ein NFS-Ziel stellt NIPAM den Treiber zum Kopieren von Daten bereit, den Hadoop DistCp beim Kopieren von Daten zur Kommunikation mit NFS-Zielen verwendet.</block>
  <block id="1215f8190533dfdf63d2224a6d88266f" category="section-title">Google Cloud NetApp Volumes</block>
  <block id="e6b6086807cb6588f15ae36a2a999e8f" category="paragraph">Die Google Cloud NetApp Volumes sind ein Cloud-nativer Dateidienst mit extremer Leistung.  Dieser Service hilft Kunden, ihre Markteinführungszeit zu verkürzen, indem Ressourcen schnell hoch- und heruntergefahren werden und NetApp -Funktionen genutzt werden, um die Produktivität zu verbessern und Ausfallzeiten der Mitarbeiter zu reduzieren.  Google Cloud NetApp Volumes ist die richtige Alternative für die Notfallwiederherstellung und Sicherung in der Cloud, da es den gesamten Platzbedarf des Rechenzentrums reduziert und weniger nativen öffentlichen Cloud-Speicher verbraucht.</block>
  <block id="6efa8f47d1a76af77ce311b436e4dca9" category="section-title">NetApp XCP</block>
  <block id="a12ce47d330a9ea070b4fd322ca5f890" category="paragraph">NetApp XCP ist eine Client-Software, die eine schnelle und zuverlässige Datenmigration von beliebigen Geräten zu NetApp und von NetApp zu NetApp ermöglicht.  Dieses Tool dient zum Kopieren großer Mengen unstrukturierter NAS-Daten von jedem NAS-System auf einen NetApp -Speichercontroller.  Das XCP Migration Tool verwendet eine Multicore-, Multichannel-E/A-Streaming-Engine, die viele Anfragen parallel verarbeiten kann, wie etwa Datenmigration, Datei- oder Verzeichnislisten und Speicherplatzberichte.  Dies ist das standardmäßige NetApp Datenmigrationstool.  Sie können XCP verwenden, um Daten von einem Hadoop-Cluster und HPC in den NetApp NFS-Speicher zu kopieren.  Das folgende Diagramm zeigt die Datenübertragung von einem Hadoop- und HPC-Cluster zu einem NetApp NFS-Volume mithilfe von XCP.</block>
  <block id="31e2e6a49223ff3b99782fced8ae2f33" category="paragraph"><block ref="31e2e6a49223ff3b99782fced8ae2f33" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ccf66760432e212bf920c4b630bf24a8" category="section-title">NetApp BlueXP Kopieren und Synchronisieren</block>
  <block id="182c915d2a513090f731fbf85d4576bd" category="paragraph">NetApp BlueXP Copy and Sync ist eine hybride Datenreplikationssoftware als Service, die NFS-, S3- und CIFS-Daten nahtlos und sicher zwischen lokalem Speicher und Cloud-Speicher überträgt und synchronisiert.  Diese Software wird für Datenmigration, Archivierung, Zusammenarbeit, Analysen und mehr verwendet.  Nachdem die Daten übertragen wurden, synchronisiert BlueXP Copy and Sync die Daten kontinuierlich zwischen Quelle und Ziel.  In Zukunft überträgt es dann das Delta.  Darüber hinaus sichert es die Daten in Ihrem eigenen Netzwerk, in der Cloud oder vor Ort.  Diese Software basiert auf einem Pay-as-you-go-Modell, das eine kostengünstige Lösung bietet und Überwachungs- und Berichtsfunktionen für Ihren Datentransfer bereitstellt.</block>
  <block id="600c9e3e31c7cdf2c69044801b9ea998" category="summary">Dieser Abschnitt enthält die detaillierten Schritte zum Verschieben von MapR-FS-Daten in ONTAP NFS mithilfe von NetApp XCP.</block>
  <block id="6a848946dc9169e87668bb9f057c56c2" category="doc">MapR-FS zu ONTAP NFS</block>
  <block id="3362be4f8dc0d043bec6bb8bf22a565b" category="list-text">Stellen Sie für jeden MapR-Knoten drei LUNs bereit und weisen Sie den LUNs den Besitz aller MapR-Knoten zu.</block>
  <block id="a74eeec8d29cc5a609b980af2aee2fb3" category="list-text">Wählen Sie während der Installation neu hinzugefügte LUNs für MapR-Cluster-Festplatten aus, die für MapR-FS verwendet werden.</block>
  <block id="87ae055df3def21f83bbbb9e287167b6" category="list-text">Installieren Sie einen MapR-Cluster gemäß der MapR 6.1-Dokumentation.</block>
  <block id="7549eec0595c1177d1a3b1a8c556ea8e" category="list-text">Überprüfen Sie die grundlegenden Hadoop-Operationen mit MapReduce-Befehlen wie<block ref="b5a58cfcf19813db2fae678c75e004c8" prefix=" " category="inline-code"></block> .</block>
  <block id="455177bd981566b3ae1e0084e3381b11" category="list-text">Bewahren Sie Kundendaten in MapR-FS auf.  Beispielsweise haben wir mithilfe von Teragen etwa ein Terabyte Beispieldaten in MapR-FS generiert.</block>
  <block id="570bd2111387f5da50ad7d54e23e5fb2" category="list-text">Konfigurieren Sie MapR-FS als NFS-Export.</block>
  <block id="4fe9587feb0e4de26dff3d33bbaf046e" category="list-text">Deaktivieren Sie den nlockmgr-Dienst auf allen MapR-Knoten.</block>
  <block id="8c5d6c82648b5d5b2a4c82d33569b1c4" category="list-text">Exportieren Sie bestimmte Ordner aus MapR-FS auf allen MapR-Knoten im<block ref="84a05a173e6cd86a4169f3dbd5897873" prefix=" " category="inline-code"></block> Datei.  Exportieren Sie den übergeordneten Ordner nicht mit unterschiedlichen Berechtigungen, wenn Sie Unterordner exportieren.</block>
  <block id="e78b84d9c1ff3b973293510503e86b95" category="list-text">Aktualisieren Sie den MapR-FS NFS-Dienst.</block>
  <block id="341009af7864703863b08f0bd1df43b5" category="list-text">Weisen Sie einem bestimmten Server oder einer Gruppe von Servern im MapR-Cluster einen virtuellen IP-Bereich zu.  Anschließend weist der MapR-Cluster einem bestimmten Server eine IP für den NFS-Datenzugriff zu.  Die IPs ermöglichen eine hohe Verfügbarkeit, d. h., wenn ein Server oder Netzwerk mit einer bestimmten IP ausfällt, kann die nächste IP aus dem IP-Bereich für den NFS-Zugriff verwendet werden.</block>
  <block id="5165f49b44f610d03a79da336b53e8f2" category="admonition">Wenn Sie NFS-Zugriff von allen MapR-Knoten bereitstellen möchten, können Sie jedem Server einen Satz virtueller IPs zuweisen und die Ressourcen jedes MapR-Knotens für den NFS-Datenzugriff verwenden.</block>
  <block id="c508683f7afca451e58f95b67197d51f" category="paragraph"><block ref="c508683f7afca451e58f95b67197d51f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54b9596f082ff106a71134b100eee486" category="paragraph"><block ref="54b9596f082ff106a71134b100eee486" category="inline-image-macro-rx" type="image"></block></block>
  <block id="be91199bb393028826e953c78a526a54" category="paragraph"><block ref="be91199bb393028826e953c78a526a54" category="inline-image-macro-rx" type="image"></block></block>
  <block id="97532f358124e4f3087e522bb35f2cb8" category="list-text">Überprüfen Sie die jedem MapR-Knoten zugewiesenen virtuellen IPs und verwenden Sie sie für den NFS-Datenzugriff.</block>
  <block id="d1ed36990409b90ebe749d4e8ddab8b7" category="list-text">Mounten Sie das per NFS exportierte MapR-FS mithilfe der zugewiesenen virtuellen IP, um den NFS-Vorgang zu überprüfen.  Für die Datenübertragung mit NetApp XCP ist dieser Schritt jedoch nicht erforderlich.</block>
  <block id="6288e9b84b4573721ff701d3bdc55fed" category="list-text">Konfigurieren Sie NetApp XCP, um Daten vom MapR-FS NFS-Gateway zu ONTAP NFS zu übertragen.</block>
  <block id="47bcc9815ee0b47ea9de7729c9c727f7" category="list-text">Konfigurieren Sie den Katalogspeicherort für XCP.</block>
  <block id="e125588061821db7957020ded3b976f0" category="list-text">Kopieren Sie die Lizenzdatei nach<block ref="0c8468e8bc6e9c8ce8e4de412fee0c10" prefix=" " category="inline-code"></block> .</block>
  <block id="76725a579a117275c078f16fdbe1fd04" category="list-text">Aktivieren Sie XCP mit dem<block ref="974d7928831087bfbec5968aec9bea85" prefix=" " category="inline-code"></block> Befehl.</block>
  <block id="07f3313db35fd32ada5426648ae5817d" category="list-text">Überprüfen Sie die Quelle für den NFS-Export.</block>
  <block id="7eefcefaba7483a2c7d6c71e934d0f28" category="list-text">Übertragen Sie die Daten mithilfe von XCP von mehreren MapR-Knoten von mehreren Quell-IPs und mehreren Ziel-IPs (ONTAP LIFs).</block>
  <block id="c2cb3a97c34a702522aba4d19b7a1d39" category="list-text">Überprüfen Sie die Lastverteilung auf dem Speichercontroller.</block>
  <block id="af7ba099603ccd4070a5102166f2c998" category="summary">Basierend auf dieser Validierung können Datenwissenschaftler und Ingenieure über S3-Buckets von NetApp Cloud Volumes ONTAP auf NFS-Daten von AWS SageMaker Jupyter Notebooks zugreifen.  Dieser Ansatz ermöglicht den einfachen Zugriff und die gemeinsame Nutzung derselben Daten sowohl von NFS als auch von S3, ohne dass zusätzliche Software erforderlich ist.</block>
  <block id="8053f00cf5e08f449b7cafe189c73a39" category="list-text">Textklassifizierung mit SageMaker BlazingText</block>
  <block id="d6667429b7c60bcbf5e5d593e91d6cae" category="list-text">ONTAP -Versionsunterstützung für S3-Objektspeicher</block>
  <block id="91ef54d96688b56bf968f57803df6675" category="inline-link"><block ref="91ef54d96688b56bf968f57803df6675" category="inline-link-rx"></block></block>
  <block id="53a581d907d105a589be9419e91b16fa" category="paragraph"><block ref="53a581d907d105a589be9419e91b16fa" category="inline-link-rx"></block></block>
  <block id="6e74710636e2da95cda4899adcdf891e" category="summary">Die Daten sind in NFS verfügbar und können über S3 von AWS SageMaker abgerufen werden.</block>
  <block id="8394db253ec71ed9d59b9429983b8eb4" category="doc">Datendualität für Datenwissenschaftler und andere Anwendungen</block>
  <block id="3c438be737391744e2fed6f73c418638" category="section-title">Technologieanforderungen</block>
  <block id="f4900d1d4a0a26325c4c9514e57c2c75" category="paragraph">Sie benötigen NetApp BlueXP, NetApp Cloud Volumes ONTAP und AWS SageMaker Notebooks für den Anwendungsfall der Datendualität.</block>
  <block id="7ddb33edf227a18eb76201fcb9e2c9db" category="section-title">Softwareanforderungen</block>
  <block id="6e6b6052efed2574e2dc05cbdc5d66d5" category="paragraph">In der folgenden Tabelle sind die Softwarekomponenten aufgelistet, die zur Umsetzung des Anwendungsfalls erforderlich sind.</block>
  <block id="9b9477e579c3b44dd623d5a6e1ea8d78" category="cell">BlueXP</block>
  <block id="0f0b99ea2f70cd363c2c6a279f74e760" category="cell">NetApp Cloud Volumes ONTAP</block>
  <block id="dda9f6d67571441afa5cfb6b54b70873" category="cell">AWS SageMaker-Notebook</block>
  <block id="5ac7b083aa99c6ec0d7a272c37dc611d" category="section-title">Bereitstellungsverfahren</block>
  <block id="cc5f7f3bee6dcb16913051d6fc267977" category="paragraph">Die Bereitstellung der Datendualitätslösung umfasst die folgenden Aufgaben:</block>
  <block id="6bb1f60bf0d00924a1bba54557e1feae" category="list-text">BlueXP -Anschluss</block>
  <block id="cf25fa6cf104cc1a67119acb6d4d364d" category="list-text">Daten für maschinelles Lernen</block>
  <block id="59b20c2117a395af59d54a6533498e99" category="list-text">Validiertes maschinelles Lernen von Jupyter Notebooks</block>
  <block id="46e0bb4f28dbf5013a68a8a69a3cf9f5" category="section-title">BlueXP -Anschluss</block>
  <block id="6ff27f6b5b95b177c735d22a2783e9ef" category="paragraph">Bei dieser Validierung haben wir AWS verwendet.  Es ist auch für Azure und Google Cloud anwendbar.  Führen Sie die folgenden Schritte aus, um einen BlueXP Connector in AWS zu erstellen:</block>
  <block id="4d7b48a5181bdd203b2ff52910c67d94" category="list-text">Wir haben die Anmeldeinformationen basierend auf dem mcarl-marketplace-subscription in BlueXP verwendet.</block>
  <block id="c0caffb5ab49caead75d39f6416ba841" category="list-text">Wählen Sie die für Ihre Umgebung geeignete Region (z. B. us-east-1 [N. Virginia]) und wählen Sie die Authentifizierungsmethode (z. B. Rolle übernehmen oder AWS-Schlüssel).  Bei dieser Validierung verwenden wir AWS-Schlüssel.</block>
  <block id="86b72593a2ce2f4e46e7669ced916111" category="list-text">Geben Sie den Namen des Connectors an und erstellen Sie eine Rolle.</block>
  <block id="71ffd00d3592df40d0db94a71ceab12d" category="list-text">Geben Sie die Netzwerkdetails wie VPC, Subnetz oder Schlüsselpaar an, je nachdem, ob Sie eine öffentliche IP benötigen oder nicht.</block>
  <block id="b5b37cef840fa0a17af0ef55c09a0e1f" category="list-text">Geben Sie die Details für die Sicherheitsgruppe an, z. B. HTTP-, HTTPS- oder SSH-Zugriff vom Quelltyp, z. B. Informationen zu einem beliebigen Ort und dem IP-Bereich.</block>
  <block id="45b20434e20aeebd5991cd84f2cf11c9" category="list-text">Überprüfen und erstellen Sie den BlueXP Connector.</block>
  <block id="92043f8a1dc0b0180854c25bcf5ff79d" category="list-text">Stellen Sie sicher, dass der Status der BlueXP EC2-Instanz in der AWS-Konsole ausgeführt wird, und überprüfen Sie die IP-Adresse auf der Registerkarte *Netzwerk*.</block>
  <block id="7044ee6a43ee2152ca6d008fcb8228c3" category="list-text">Melden Sie sich über das BlueXP -Portal bei der Connector-Benutzeroberfläche an, oder verwenden Sie die IP-Adresse für den Zugriff über den Browser.</block>
  <block id="064d933c0c02c4fe7ef1a07ad3a537d7" category="paragraph">Führen Sie die folgenden Schritte aus, um eine Cloud Volumes ONTAP Instanz in BlueXP zu erstellen:</block>
  <block id="35d88740e5ca53f6cabb06b3fce807b7" category="list-text">Erstellen Sie eine neue Arbeitsumgebung, wählen Sie den Cloud-Anbieter und den Typ der Cloud Volumes ONTAP Instanz aus (z. B. Single-CVO, HA oder Amazon FSx ONTAP für ONTAP).</block>
  <block id="dcb89e397dde3dedb1a32224f0c15b78" category="list-text">Geben Sie Details wie den Namen und die Anmeldeinformationen des Cloud Volumes ONTAP Clusters an.  Bei dieser Validierung haben wir eine Cloud Volumes ONTAP Instanz namens<block ref="c7e44ecb645a5c83f843ae05090c5940" prefix=" " category="inline-code"></block> .</block>
  <block id="9cf479af21359b2928a1b672d60577f2" category="list-text">Wählen Sie die für Cloud Volumes ONTAP benötigten Dienste aus.  Bei dieser Validierung haben wir uns für die reine Überwachung entschieden und daher *Data Sense &amp; Compliance* und *Backup to Cloud Services* deaktiviert.</block>
  <block id="cb95ef3838d59d553c71f50b1cadee27" category="list-text">Wählen Sie im Abschnitt *Standort und Konnektivität* die AWS-Region, VPC, das Subnetz, die Sicherheitsgruppe, die SSH-Authentifizierungsmethode und entweder ein Kennwort oder ein Schlüsselpaar aus.</block>
  <block id="fdd5d37c21ee01084537317345b3d78b" category="list-text">Wählen Sie die Lademethode.  Für diese Validierung haben wir *Professional* verwendet.</block>
  <block id="00efec60d606ea6ad0bafe93bc77df92" category="list-text">Sie können ein vorkonfiguriertes Paket auswählen, beispielsweise *POC und kleine Workloads*, *Produktions-Workloads für Datenbanken und Anwendungsdaten*, *Kostengünstige Notfallwiederherstellung* oder *Produktions-Workloads mit höchster Leistung*.  Bei dieser Validierung wählen wir *Poc und kleine Workloads*.</block>
  <block id="f22934293c2f2a761ea26fa4ae1828e1" category="list-text">Erstellen Sie ein Volume mit einer bestimmten Größe, zulässigen Protokollen und Exportoptionen.  Bei dieser Validierung haben wir ein Volume namens<block ref="2b0d59c7031769e80c8e5118b6ec7694" prefix=" " category="inline-code"></block> .</block>
  <block id="f2706214c4a60177d14fb8495cbc6924" category="list-text">Wählen Sie einen Profildatenträgertyp und eine Tiering-Richtlinie.  Bei dieser Validierung haben wir *Speichereffizienz* und *Allzweck-SSD – Dynamische Leistung* deaktiviert.</block>
  <block id="40d3f73a73f67ce67b286aef7a5d3ecb" category="list-text">Überprüfen und erstellen Sie abschließend die Cloud Volumes ONTAP -Instanz.  Warten Sie dann 15–20 Minuten, bis BlueXP die Cloud Volumes ONTAP Arbeitsumgebung erstellt hat.</block>
  <block id="a8b538b74c3f662c2248af9c6d4742db" category="list-text">Konfigurieren Sie die folgenden Parameter, um das Duality-Protokoll zu aktivieren.  Das Duality-Protokoll (NFS/S3) wird ab ONTAP 9 unterstützt.  12.1 und höher.</block>
  <block id="15b53c14b58ee146309847451d1eb90a" category="list-text">Bei dieser Validierung haben wir eine SVM namens<block ref="c7e44ecb645a5c83f843ae05090c5940" prefix=" " category="inline-code"></block> und Lautstärke<block ref="2b0d59c7031769e80c8e5118b6ec7694" prefix=" " category="inline-code"></block> .</block>
  <block id="3514969b2381af83551c246e34b74403" category="list-text">Überprüfen Sie, ob die SVM die Protokollunterstützung für NFS und S3 hat.  Wenn nicht, ändern Sie die SVM, um sie zu unterstützen.</block>
  <block id="e41c06ffff0f8c9cadbc7f8bb37f8ae5" category="list-text">Erstellen und installieren Sie bei Bedarf ein CA-Zertifikat.</block>
  <block id="0395f8062a8a7f4af05113bae8133737" category="list-text">Erstellen Sie eine Servicedatenrichtlinie.</block>
  <block id="6e16e110899749a795fe713253d850e7" category="list-text">Überprüfen Sie die Gesamtdetails.</block>
  <block id="5d3f8e127103f0d5cf3de305db892b4d" category="list-text">Erstellen Sie einen Benutzer und eine Gruppe.</block>
  <block id="efa22127bde2d3ab2e4f5b9a42d14814" category="list-text">Erstellen Sie einen Bucket auf dem NFS-Volume.</block>
  <block id="c3fd6f44bf88d3f0eae4742edb58eafc" category="paragraph">Führen Sie die folgenden Schritte aus, um ein AWS-Notebook aus AWS SageMaker zu erstellen:</block>
  <block id="31378aab1ee6190e0b7fe33c501a5625" category="list-text">Stellen Sie sicher, dass der Benutzer, der die Notebook-Instanz erstellt, über eine AmazonSageMakerFullAccess-IAM-Richtlinie verfügt oder Teil einer vorhandenen Gruppe mit AmazonSageMakerFullAccess-Rechten ist.  Bei dieser Validierung ist der Benutzer Teil einer bestehenden Gruppe.</block>
  <block id="13c1455885d16af64f1bb96c4e48680a" category="list-text">Geben Sie die folgenden Informationen an:</block>
  <block id="bb8101aed18120fa18dedaa994ffeea0" category="list-text">Name der Notebook-Instanz.</block>
  <block id="6239d232142a089e53e7a13fa721237a" category="list-text">Instanztyp.</block>
  <block id="37056dac7373f7e1b74382036d25b69e" category="list-text">Plattformkennung.</block>
  <block id="38e2059c32c628cf89e90a6844a93800" category="list-text">Wählen Sie die IAM-Rolle aus, die über AmazonSageMakerFullAccess-Rechte verfügt.</block>
  <block id="55d7da5ede713135b1c2ebd7a615c3b4" category="list-text">Root-Zugriff – aktivieren.</block>
  <block id="8f0e92e4434abc32ff62a914ae9f2ba6" category="list-text">Verschlüsselungsschlüssel – Wählen Sie keine benutzerdefinierte Verschlüsselung.</block>
  <block id="8b77028d248afd826900d895636b4e98" category="list-text">Behalten Sie die verbleibenden Standardoptionen bei.</block>
  <block id="78456ee20793f732edfa9105bbb4e490" category="list-text">Bei dieser Validierung lauten die Details der SageMaker-Instanz wie folgt:</block>
  <block id="e90e797343ea3f751b0c32e808edaff8" category="inline-image-macro">Screenshot, der den Schritt darstellt.</block>
  <block id="e987fe9ec5699958a73a8f310b4d99e8" category="paragraph"><block ref="e987fe9ec5699958a73a8f310b4d99e8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4414f1275568cfaaea91b68f1514516e" category="paragraph"><block ref="4414f1275568cfaaea91b68f1514516e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4789a9ab6472480889e111503d068623" category="list-text">Starten Sie das AWS-Notebook.</block>
  <block id="ce1d8475b6a4d461318eb3139cc54a3b" category="paragraph"><block ref="ce1d8475b6a4d461318eb3139cc54a3b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cbfbebd805ee7945ad38bc26f8fa9f1b" category="list-text">Öffnen Sie das Jupyter-Labor.</block>
  <block id="d81c10b932515c107a06a3737d985eaf" category="paragraph"><block ref="d81c10b932515c107a06a3737d985eaf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ab3269ab0de58f5611205f6ace06f3af" category="list-text">Melden Sie sich beim Terminal an und mounten Sie das Cloud Volumes ONTAP -Volume.</block>
  <block id="cc0649b0871fde24c4a46e09186a36e0" category="list-text">Überprüfen Sie den auf dem Cloud Volumes ONTAP -Volume erstellten Bucket mithilfe der AWS CLI-Befehle.</block>
  <block id="4f31ff9815d3a8a959e7c557213068d6" category="paragraph">Bei dieser Validierung haben wir einen Datensatz von DBpedia verwendet, einem Crowdsourcing-Community-Projekt, um strukturierte Inhalte aus den in verschiedenen Wikimedia-Projekten erstellten Informationen zu extrahieren.</block>
  <block id="06d6ccf33b49ed20a34cdc26b6820253" category="list-text">Laden Sie die Daten vom DBpedia-GitHub-Speicherort herunter und extrahieren Sie sie.  Verwenden Sie dasselbe Terminal wie im vorherigen Abschnitt.</block>
  <block id="7f50b7f719282741fdf7ce5b8ca1f3dd" category="list-text">Kopieren Sie die Daten an den Cloud Volumes ONTAP -Speicherort und überprüfen Sie sie mithilfe der AWS CLI aus dem S3-Bucket.</block>
  <block id="0ecfbac978ab3f5979ec31eb5574d93e" category="list-text">Führen Sie eine grundlegende Validierung durch, um sicherzustellen, dass die Lese-/Schreibfunktion im S3-Bucket funktioniert.</block>
  <block id="877169a066e14f0512d5f119945ef14d" category="section-title">Validieren Sie maschinelles Lernen aus Jupyter Notebooks</block>
  <block id="6f73420916237ed836932ccf967d82ba" category="paragraph">Die folgende Validierung ermöglicht das Erstellen, Trainieren und Bereitstellen von Modellen für maschinelles Lernen durch Textklassifizierung unter Verwendung des folgenden SageMaker BlazingText-Beispiels:</block>
  <block id="3cf03767e04159d1ec88e7fb0827b487" category="list-text">Installieren Sie die Pakete boto3 und SageMaker.</block>
  <block id="b1282d58a4dcde0a2015d98ad33afd4c" category="paragraph">Ausgabe:</block>
  <block id="39017441ac701ebaef8de7116e7f71a0" category="list-text">Im nächsten Schritt werden die Daten<block ref="0a726fdd06082d233cd4eade40f12612" prefix="(" category="inline-code"></block> ) wird aus dem S3-Bucket heruntergeladen<block ref="90d9a986b9b5e7c07c50a03ccc06a244" prefix=" " category="inline-code"></block> zu einer Jupyter Notebook-Instanz, die im maschinellen Lernen verwendet wird.</block>
  <block id="a270350e3527fea9a36815fa5fe04ba0" category="list-text">Der folgende Code erstellt die Zuordnung von ganzzahligen Indizes zu Klassenbezeichnungen, die zum Abrufen des tatsächlichen Klassennamens während der Inferenz verwendet werden.</block>
  <block id="d17fa3d0aed3f8aaa5e78b447054126d" category="paragraph">Die Ausgabe listet die Dateien und Ordner in der<block ref="90d9a986b9b5e7c07c50a03ccc06a244" prefix=" " category="inline-code"></block> Bucket, die als Daten für die AWS SageMaker-Maschinenlernvalidierung verwendet werden.</block>
  <block id="0cfbf64679378e3e5367734fd2bd69aa" category="list-text">Starten Sie die Datenvorverarbeitungsphase, um die Trainingsdaten in ein durch Leerzeichen getrenntes, tokenisiertes Textformat vorzuverarbeiten, das vom BlazingText-Algorithmus und der NLTK-Bibliothek verwendet werden kann, um die Eingabesätze aus dem DBPedia-Datensatz zu tokenisieren.  Laden Sie den NLTK-Tokenizer und andere Bibliotheken herunter.  Der<block ref="6d49a792c1080aa5b33d27ec694621b6" prefix=" " category="inline-code"></block> Die parallele Anwendung auf jede Dateninstanz verwendet das Python-Multiprocessing-Modul.</block>
  <block id="d68566815a7248bae03e105c2db8853a" category="list-text">Laden Sie den formatierten Trainingsdatensatz auf S3 hoch, damit er von SageMaker zum Ausführen von Trainingsaufträgen verwendet werden kann.  Laden Sie dann mithilfe des Python SDK zwei Dateien in den Bucket hoch und präfixieren Sie den Speicherort.</block>
  <block id="e886ad36e527d85b26c492618651edad" category="list-text">Richten Sie bei S3 einen Ausgabeort ein, an dem das Modellartefakt geladen wird, sodass Artefakte die Ausgabe des Trainingsjobs des Algorithmus sein können.  Erstellen Sie ein<block ref="6e3281884db83f9ee468a6e798b6bdfb" prefix=" " category="inline-code"></block> Objekt, um den Trainingsjob zu starten.</block>
  <block id="41215e143c2b3810b37c4e4f47819077" category="list-text">Definieren Sie den SageMaker<block ref="a0b1f5f7b93af313b6e2452f52c8f3f6" prefix=" " category="inline-code"></block> mit Ressourcenkonfigurationen und Hyperparametern, um die Textklassifizierung im DBPedia-Datensatz im überwachten Modus auf einer c4.4xlarge-Instanz zu trainieren.</block>
  <block id="6c773c4d6e4a7dda7e00352894786bdb" category="list-text">Bereiten Sie einen Handshake zwischen den Datenkanälen und dem Algorithmus vor.  Erstellen Sie dazu die<block ref="0e021845d2c0e4ad94a91ce444c13681" prefix=" " category="inline-code"></block> Objekte aus den Datenkanälen und speichern Sie sie in einem Wörterbuch, damit der Algorithmus sie verwenden kann.</block>
  <block id="3b29bef19a742b8ab66cddf620871d31" category="list-text">Nachdem der Auftrag abgeschlossen ist, wird die Meldung „Auftrag abgeschlossen“ angezeigt.  Das trainierte Modell befindet sich im S3-Bucket, der als<block ref="212ad7a4c11069727ffd02f333d7d8b1" prefix=" " category="inline-code"></block> im Schätzer.</block>
  <block id="6cb5683d87e53b375bd915572f960759" category="list-text">Stellen Sie nach Abschluss des Trainings das trainierte Modell als in Echtzeit gehosteten Amazon SageMaker-Endpunkt bereit, um Vorhersagen zu treffen.</block>
  <block id="4254a612097ca58653de7c0c39da8df2" category="list-text">Standardmäßig gibt das Modell eine Vorhersage mit der höchsten Wahrscheinlichkeit zurück.  Um die Spitze abzurufen<block ref="8ce4b16b22b58894aa86c421e8759df3" prefix=" " category="inline-code"></block> Vorhersagen, Set<block ref="8ce4b16b22b58894aa86c421e8759df3" prefix=" " category="inline-code"></block> in der Konfigurationsdatei.</block>
  <block id="67be4f1bb90039baec0d8f73ff82a47e" category="list-text">Löschen Sie den Endpunkt, bevor Sie das Notebook schließen.</block>
  <block id="16147684eb6910d9d73a43bb83091da4" category="summary">Datenwissenschaftler und -ingenieure müssen häufig auf im NFS-Format gespeicherte Daten zugreifen. Der direkte Zugriff auf diese Daten über das S3-Protokoll in AWS SageMaker kann jedoch eine Herausforderung darstellen, da AWS nur den Zugriff auf S3-Buckets unterstützt.  NetApp ONTAP bietet jedoch eine Lösung, indem es den Dual-Protokoll-Zugriff für NFS und S3 ermöglicht.  Mit dieser Lösung können Datenwissenschaftler und Ingenieure über S3-Buckets von NetApp Cloud Volumes ONTAP auf NFS-Daten von AWS SageMaker-Notebooks zugreifen.  Dieser Ansatz ermöglicht den einfachen Zugriff und die gemeinsame Nutzung derselben Daten sowohl von NFS als auch von S3, ohne dass zusätzliche Software erforderlich ist.</block>
  <block id="e8ce8afdd7d335aed5b93d4a41ae0115" category="doc">TR-4967: Cloud-Datenverwaltung mit NetApp File-Object Duality und AWS SageMaker</block>
  <block id="7caace9abf76a798c629a9134d1bb259" category="summary">Ein potenzieller Anwendungsfall für den Dualprotokollzugriff von NFS und S3 liegt in den Bereichen maschinelles Lernen und Datenwissenschaft.  Beispielsweise könnte ein Team von Datenwissenschaftlern an einem Machine-Learning-Projekt mit AWS SageMaker arbeiten, das Zugriff auf im NFS-Format gespeicherte Daten erfordert.  Möglicherweise müssen die Daten jedoch auch über S3-Buckets abgerufen und freigegeben werden, um mit anderen Teammitgliedern zusammenzuarbeiten oder sie in andere Anwendungen zu integrieren, die S3 verwenden.</block>
  <block id="ee8cf3bf54dea46135e299d79fa1c179" category="paragraph">Diese Lösung nutzt die folgenden Technologien:</block>
  <block id="a03ea23912d3b35c875ff398aa4888af" category="list-text">*AWS SageMaker-Notizbuch.*  Bietet Entwicklern und Datenwissenschaftlern Machine-Learning-Funktionen zum effizienten Erstellen, Trainieren und Bereitstellen hochwertiger ML-Modelle.</block>
  <block id="bbe2552dc6295d353c02fd85c243f334" category="list-text">* NetApp BlueXP.*  Ermöglicht die Erkennung, Bereitstellung und den Betrieb von Speicher vor Ort sowie auf AWS, Azure und Google Cloud.  Es bietet Datenschutz vor Datenverlust, Cyberbedrohungen und ungeplanten Ausfällen und optimiert die Datenspeicherung und Infrastruktur.</block>
  <block id="aa6fa71ab9848c5875470d36bbc2138a" category="list-text">* NetApp Cloud Volumes ONTAP.*  Bietet Speichervolumes der Unternehmensklasse mit NFS-, SMB/CIFS-, iSCSI- und S3-Protokollen auf AWS, Azure und Google Cloud und bietet Benutzern so mehr Flexibilität beim Zugriff auf und der Verwaltung ihrer Daten in der Cloud.</block>
  <block id="eea496572a01ca3e5ced1dfe99a5809c" category="paragraph">Aus BlueXP erstelltes NetApp Cloud Volumes ONTAP zum Speichern von ML-Daten.</block>
  <block id="923baf107dc23ca10f968a4fdecd4f4f" category="paragraph">Die folgende Abbildung zeigt die technischen Komponenten der Lösung.</block>
  <block id="8afbfe3aeb9c594404d5c244cf8f6024" category="inline-image-macro">Diese Abbildung zeigt die technischen Komponenten der Lösung.</block>
  <block id="d3d9ae40ce6d205245ae4b8c9649b6e2" category="paragraph"><block ref="d3d9ae40ce6d205245ae4b8c9649b6e2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="55c5281d80934f950192f768715495f0" category="paragraph">Durch die Nutzung von NetApp Cloud Volumes ONTAP kann das Team seine Daten an einem einzigen Ort speichern und darauf sowohl mit NFS- als auch mit S3-Protokollen zugreifen.  Die Datenwissenschaftler können direkt von AWS SageMaker auf die Daten im NFS-Format zugreifen, während andere Teammitglieder oder Anwendungen über S3-Buckets auf dieselben Daten zugreifen können.</block>
  <block id="f8ba1b513231e9ca54a5c3b94733c28d" category="paragraph">Dieser Ansatz ermöglicht einen einfachen und effizienten Zugriff auf die Daten und deren gemeinsame Nutzung, ohne dass zusätzliche Software oder eine Datenmigration zwischen verschiedenen Speicherlösungen erforderlich ist.  Darüber hinaus ermöglicht es einen optimierten Arbeitsablauf und eine bessere Zusammenarbeit zwischen den Teammitgliedern, was zu einer schnelleren und effektiveren Entwicklung von Modellen für maschinelles Lernen führt.</block>
  <block id="7747c0c1913888384e25d3a99b247187" category="summary">Dieses Dokument enthält Best-Practice-Richtlinien für die Verwendung von Kafka mit NetApp -Speicher, einschließlich Confluent Kafka-Zertifizierungstests, Leistungsergebnissen, Optimierung, Kafka-Konnektoren und der Funktion zur Selbstausgleichung.</block>
  <block id="d17096a4e247d84eba8c623e8df7bb38" category="paragraph">Dieses Dokument enthält Best-Practice-Richtlinien für die Verwendung von Confluent Tiered Storage mit NetApp -Speicher, einschließlich Verifizierungstests, Leistungsergebnissen für Tiered Storage, Optimierung, Confluent S3-Konnektoren und der Selbstausgleichsfunktion.  Unter Berücksichtigung von ILM-Richtlinien, Confluent-Leistung mit mehreren Leistungstests zur Überprüfung und branchenüblichen S3-APIs ist der NetApp StorageGRID Objektspeicher die optimale Wahl für Confluent-Tiered-Storage.</block>
  <block id="06bf7cdac46014ea728ea73ea94f29ed" category="list-text">Was ist Apache Kafka</block>
  <block id="9411b66537bb375699af4bbf90c682d3" category="inline-link"><block ref="9411b66537bb375699af4bbf90c682d3" category="inline-link-rx"></block></block>
  <block id="a2b6e6fe4a206b71df85cc00f128ef0c" category="paragraph"><block ref="a2b6e6fe4a206b71df85cc00f128ef0c" category="inline-link-rx"></block></block>
  <block id="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link"><block ref="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link-rx"></block></block>
  <block id="6bfac05f3cc2c0adace9c385ef708fd9" category="paragraph"><block ref="6bfac05f3cc2c0adace9c385ef708fd9" category="inline-link-rx"></block></block>
  <block id="8f74869149421fffb3c139e146a83d10" category="list-text">S3-Sink-Parameterdetails</block>
  <block id="015ac233ccf3051a25abbbd7f56a39e9" category="inline-link"><block ref="015ac233ccf3051a25abbbd7f56a39e9" category="inline-link-rx"></block></block>
  <block id="26f8d9a8c1177c17a089f9a5c18628f4" category="paragraph"><block ref="26f8d9a8c1177c17a089f9a5c18628f4" category="inline-link-rx"></block></block>
  <block id="bb2bd99338b18762ef6953ad2cbfafc7" category="list-text">Apache Kafka</block>
  <block id="14bdc4a7a7b448924b5fe68d2a843973" category="inline-link"><block ref="14bdc4a7a7b448924b5fe68d2a843973" category="inline-link-rx"></block></block>
  <block id="c001bbfb62e45f662fe697182fa82240" category="paragraph"><block ref="c001bbfb62e45f662fe697182fa82240" category="inline-link-rx"></block></block>
  <block id="4f6236b021284cc85e87f1145d34e74b" category="list-text">Unbegrenzter Speicherplatz in der Confluent-Plattform</block>
  <block id="43a9697f317e04e185bacb99ee76b7fb" category="inline-link"><block ref="43a9697f317e04e185bacb99ee76b7fb" category="inline-link-rx"></block></block>
  <block id="a156036c426dcb5d87fc97e5eacdc183" category="paragraph"><block ref="a156036c426dcb5d87fc97e5eacdc183" category="inline-link-rx"></block></block>
  <block id="a53b0667612f6e25b1d426569d860cac" category="list-text">Confluent Tiered Storage – Best Practices und Dimensionierung</block>
  <block id="a2e63818a36c6308885f4c0109e99b56" category="inline-link"><block ref="a2e63818a36c6308885f4c0109e99b56" category="inline-link-rx"></block></block>
  <block id="0c2ea24bb29ad03d1f43efe9a08c7da0" category="paragraph"><block ref="0c2ea24bb29ad03d1f43efe9a08c7da0" category="inline-link-rx"></block></block>
  <block id="ee764f7614a20c6500a54f1abc769567" category="list-text">Amazon S3-Sink-Connector für die Confluent-Plattform</block>
  <block id="e1ca3ac3d812689b98c4cf79bf597e4b" category="inline-link"><block ref="e1ca3ac3d812689b98c4cf79bf597e4b" category="inline-link-rx"></block></block>
  <block id="ca80d8d3004f0fce6bc195b6b43ccaeb" category="paragraph"><block ref="ca80d8d3004f0fce6bc195b6b43ccaeb" category="inline-link-rx"></block></block>
  <block id="5cbad2383ea03d52c73feba910ccb4a9" category="list-text">Kafka-Dimensionierung</block>
  <block id="7a8c563c1b96991ca597759bb447eb65" category="inline-link"><block ref="7a8c563c1b96991ca597759bb447eb65" category="inline-link-rx"></block></block>
  <block id="a2d2c0cad325abb54e33c688d54ce125" category="paragraph"><block ref="a2d2c0cad325abb54e33c688d54ce125" category="inline-link-rx"></block></block>
  <block id="989772944133ad8cd766bbdfe91cb365" category="list-text">StorageGRID -Dimensionierung</block>
  <block id="a81a58c7d51f312f40511a68d8e0d40c" category="inline-link"><block ref="a81a58c7d51f312f40511a68d8e0d40c" category="inline-link-rx"></block></block>
  <block id="1e9dcc0360cfc46d71d6e0c3effa6379" category="paragraph"><block ref="1e9dcc0360cfc46d71d6e0c3effa6379" category="inline-link-rx"></block></block>
  <block id="5f750332aea13a67a316c81c03a35752" category="list-text">Kafka-Anwendungsfälle</block>
  <block id="c97a8ddb222f78361f59ac027aa08c70" category="inline-link"><block ref="c97a8ddb222f78361f59ac027aa08c70" category="inline-link-rx"></block></block>
  <block id="58f7c8dd51e4199a8f2caf79409bada1" category="paragraph"><block ref="58f7c8dd51e4199a8f2caf79409bada1" category="inline-link-rx"></block></block>
  <block id="f51439b4d8807e7a73cb24b6f11e16e2" category="list-text">Selbstausgleichende Kafka-Cluster in der Confluent-Plattform 6.0</block>
  <block id="866d1bcab8bac705e171a01e8fe2e717" category="inline-link"><block ref="866d1bcab8bac705e171a01e8fe2e717" category="inline-link-rx"></block></block>
  <block id="b6251e175649ca2d0108725f99fc225f" category="paragraph"><block ref="b6251e175649ca2d0108725f99fc225f" category="inline-link-rx"></block></block>
  <block id="aa3c3c6442ddbda62fd0694691e34122" category="inline-link"><block ref="aa3c3c6442ddbda62fd0694691e34122" category="inline-link-rx"></block></block>
  <block id="f7365ec0514100387d644210374998c1" category="paragraph"><block ref="f7365ec0514100387d644210374998c1" category="inline-link-rx"></block></block>
  <block id="69fc1008ccb741113af5042f04fcbc8b" category="summary">Dieses Dokument beschreibt die Best-Practice-Richtlinien für die Verwendung von Kafka auf einem NetApp -Speichercontroller.</block>
  <block id="a29b982ab81cd1d74045ee43e3378135" category="paragraph">Karthikeyan Nagalingam, Joseph Kandatilparambil, NetApp Rankesh Kumar, Confluent</block>
  <block id="37281d123cc59a7c05b3ce30b5ea435e" category="paragraph">Apache Kafka ist eine von der Community verteilte Event-Streaming-Plattform, die Billionen von Ereignissen pro Tag verarbeiten kann.  Kafka wurde ursprünglich als Nachrichtenwarteschlange konzipiert und basiert auf der Abstraktion eines verteilten Commit-Protokolls.  Seit seiner Erstellung und Open-Source-Veröffentlichung durch LinkedIn im Jahr 2011 hat sich Kafka von einer Nachrichtenwarteschlange zu einer vollwertigen Event-Streaming-Plattform entwickelt.  Confluent liefert die Distribution von Apache Kafka mit der Confluent-Plattform.  Die Confluent-Plattform ergänzt Kafka um zusätzliche Community- und kommerzielle Funktionen, die das Streaming-Erlebnis von Betreibern und Entwicklern in der Produktion in großem Maßstab verbessern sollen.</block>
  <block id="4a967c3b711955b2fd888bf0abedb515" category="paragraph">Dieses Dokument beschreibt die Best-Practice-Richtlinien für die Verwendung von Confluent Tiered Storage auf einem Object Storage-Angebot von NetApp und stellt die folgenden Inhalte bereit:</block>
  <block id="2717b4b699259a5e59279aac92d526a2" category="list-text">Konfluente Verifizierung mit NetApp Object Storage – NetApp StorageGRID</block>
  <block id="0939eec6a072b9deba2d6aa39249110d" category="list-text">Leistungstests für mehrstufigen Speicher</block>
  <block id="7607a859995debe77df0676d09d8270b" category="list-text">Best-Practice-Richtlinien für Confluent auf NetApp -Speichersystemen</block>
  <block id="59cb8890508bcaf057fd0360eb8ff783" category="section-title">Warum Confluent Tiered Storage?</block>
  <block id="7a3966946c615eb57ae930f6948a1c65" category="inline-link-macro">dieser Artikel von Confluent</block>
  <block id="eced8e0ff3a0cd0f66b3a8845f1e08be" category="paragraph">Confluent hat sich zur Standard-Echtzeit-Streaming-Plattform für viele Anwendungen entwickelt, insbesondere für Big Data-, Analyse- und Streaming-Workloads.  Mit Tiered Storage können Benutzer in der Confluent-Plattform Rechenleistung und Speicher trennen.  Es macht die Datenspeicherung kostengünstiger, ermöglicht Ihnen die Speicherung nahezu unbegrenzter Datenmengen und die Skalierung von Arbeitslasten nach Bedarf nach oben (oder unten) und vereinfacht Verwaltungsaufgaben wie die Neuverteilung von Daten und Mandanten.  S3-kompatible Speichersysteme können alle diese Funktionen nutzen, um Daten mit allen Ereignissen an einem Ort zu demokratisieren, wodurch die Notwendigkeit einer komplexen Datentechnik entfällt.  Weitere Informationen dazu, warum Sie Tiered Storage für Kafka verwenden sollten, finden Sie unter<block ref="3c87b0bff8160b787f5bf29d10131d5e" category="inline-link-macro-rx"></block> .</block>
  <block id="911086e7904dbc449b09545eba850304" category="section-title">Warum NetApp StorageGRID für Tiered Storage?</block>
  <block id="ee6c2a9cd0205695027987ec8da32dfe" category="paragraph">StorageGRID ist eine branchenführende Objektspeicherplattform von NetApp.  StorageGRID ist eine softwaredefinierte, objektbasierte Speicherlösung, die branchenübliche Objekt-APIs unterstützt, einschließlich der Amazon Simple Storage Service (S3)-API.  StorageGRID speichert und verwaltet unstrukturierte Daten in großem Umfang, um einen sicheren, dauerhaften Objektspeicher bereitzustellen.  Inhalte werden zur richtigen Zeit am richtigen Ort und auf der richtigen Speicherebene platziert, wodurch Arbeitsabläufe optimiert und die Kosten für global verteilte Rich Media gesenkt werden.</block>
  <block id="5e5ef53b540f19d6746e6645de37cbb4" category="paragraph">Das größte Unterscheidungsmerkmal von StorageGRID ist die Policy-Engine für Information Lifecycle Management (ILM), die ein richtliniengesteuertes Datenlebenszyklusmanagement ermöglicht.  Die Richtlinien-Engine kann Metadaten verwenden, um zu verwalten, wie Daten während ihrer gesamten Lebensdauer gespeichert werden, um zunächst die Leistung zu optimieren und mit zunehmendem Alter der Daten automatisch die Kosten und Haltbarkeit zu optimieren.</block>
  <block id="a7f9d3e4bde145f56bcbec81a6dc2ef3" category="section-title">Aktivieren von Confluent Tiered Storage</block>
  <block id="a5cb83c3eb7e8757a8f985f8d935e700" category="paragraph">Die Grundidee des Tiered Storage besteht darin, die Aufgaben der Datenspeicherung von denen der Datenverarbeitung zu trennen.  Durch diese Trennung wird es für die Datenspeicherungsebene und die Datenverarbeitungsebene wesentlich einfacher, unabhängig voneinander zu skalieren.</block>
  <block id="ec4d623bd1019ab2fabc3a02ae9dc70d" category="paragraph">Eine mehrstufige Speicherlösung für Confluent muss zwei Faktoren berücksichtigen.  Erstens müssen allgemeine Konsistenz- und Verfügbarkeitseigenschaften von Objektspeichern, wie etwa Inkonsistenzen bei LIST-Operationen und gelegentliche Nichtverfügbarkeit von Objekten, umgangen oder vermieden werden.  Zweitens muss die Interaktion zwischen mehrstufigem Speicher und dem Replikations- und Fehlertoleranzmodell von Kafka korrekt gehandhabt werden, einschließlich der Möglichkeit, dass Zombie-Leader weiterhin Offset-Bereiche stufen.  NetApp Object Storage bietet sowohl die konsistente Objektverfügbarkeit als auch das HA-Modell und stellt den erschöpften Speicher für Tier-Offset-Bereiche zur Verfügung.  NetApp Objektspeicher bietet konsistente Objektverfügbarkeit und ein HA-Modell, um den erschöpften Speicher für Tier-Offset-Bereiche verfügbar zu machen.</block>
  <block id="104f1daa661d4c74d5bfd4e54946a4f4" category="paragraph">Mit Tiered Storage können Sie Hochleistungsplattformen für Lese- und Schreibvorgänge mit geringer Latenz am Ende Ihrer Streaming-Daten verwenden. Außerdem können Sie günstigere, skalierbare Objektspeicher wie NetApp StorageGRID für historische Lesevorgänge mit hohem Durchsatz nutzen.  Wir haben auch eine technische Lösung für Spark mit NetApp-Speichercontroller. Einzelheiten finden Sie hier.  Die folgende Abbildung zeigt, wie Kafka in eine Echtzeit-Analyse-Pipeline passt.</block>
  <block id="eea5b5aaa7bc893f83efe26850f04584" category="paragraph"><block ref="eea5b5aaa7bc893f83efe26850f04584" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0977e5b84fa31f5087efbbc1dc355236" category="paragraph">Die folgende Abbildung zeigt, wie NetApp StorageGRID als Objektspeicherebene von Confluent Kafka passt.</block>
  <block id="baa92f35a9209359bb52e9fa325d0e29" category="paragraph"><block ref="baa92f35a9209359bb52e9fa325d0e29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="35f99fa939062899487754f637210a25" category="summary">Dieser Abschnitt behandelt die für die Confluent-Zertifizierung verwendete Hardware und Software.  Diese Informationen gelten für die Kafka-Bereitstellung mit NetApp -Speicher.</block>
  <block id="92672a7a2b909945fbfa9f44f057c7a1" category="doc">Größen</block>
  <block id="faa5cf9412df3e7266db15b6f1a5070d" category="paragraph">Die Kafka-Dimensionierung kann mit vier Konfigurationsmodi durchgeführt werden: einfach, granular, umgekehrt und Partitionen.</block>
  <block id="1fbb1e3943c2c6c560247ac8f9289780" category="section-title">Einfach</block>
  <block id="580c6adb23970405f45409b06eb3ba39" category="paragraph">Der einfache Modus eignet sich für Erstbenutzer von Apache Kafka oder Anwendungsfälle im Frühstadium.  Für diesen Modus geben Sie Anforderungen wie Durchsatz-MBps, Lese-Fanout, Aufbewahrung und den Prozentsatz der Ressourcennutzung an (60 % ist der Standard).  Sie geben auch die Umgebung ein, z. B. vor Ort (Bare-Metal, VMware, Kubernetes oder OpenStack) oder in der Cloud.  Basierend auf diesen Informationen liefert die Dimensionierung eines Kafka-Clusters die Anzahl der Server, die für den Broker, den Zookeeper, die Apache Kafka Connect Worker, das Schema-Register, einen REST-Proxy, ksqlDB und das Confluent-Kontrollzentrum erforderlich sind.</block>
  <block id="ae20e37661048a8d6cd37c4dbacac985" category="paragraph">Berücksichtigen Sie bei mehrstufigem Speicher den granularen Konfigurationsmodus zur Größenbestimmung eines Kafka-Clusters.  Der Granularmodus eignet sich für erfahrene Apache Kafka-Benutzer oder klar definierte Anwendungsfälle.  In diesem Abschnitt wird die Dimensionierung für Produzenten, Stream-Prozessoren und Konsumenten beschrieben.</block>
  <block id="40d2d6f5a1dfde1a3b5ba2a70377fa0f" category="section-title">Produzenten</block>
  <block id="05318fa579b7e76a65531afd94250ed3" category="paragraph">Um die Produzenten für Apache Kafka zu beschreiben (z. B. einen nativen Client, einen REST-Proxy oder einen Kafka-Connector), geben Sie die folgenden Informationen an:</block>
  <block id="91be21e4458c6c8f0d6f61c307faf194" category="list-text">*Name.*  Funke.</block>
  <block id="b39a7ae16ea364375daa4f600ebed072" category="list-text">*Produzententyp.*  Anwendung oder Dienst, Proxy (REST, MQTT, andere) und vorhandene Datenbank (RDBMS, NOSQL, andere).  Sie können auch „Ich weiß nicht“ auswählen.</block>
  <block id="3fd4bc385cb0a0f62ae4183f316ff707" category="list-text">*Durchschnittlicher Durchsatz.*  In Ereignissen pro Sekunde (z. B. 1.000.000).</block>
  <block id="14ec4c2c8c9edf10c6aeefaf27f1f713" category="list-text">*Spitzendurchsatz.*  In Ereignissen pro Sekunde (z. B. 4.000.000).</block>
  <block id="b4672ddde5cb9c30e0e682084a411123" category="list-text">*Durchschnittliche Nachrichtengröße.*  In Bytes, unkomprimiert (max. 1 MB; beispielsweise 1000).</block>
  <block id="f56fd2104d8bf51910ee81196e8b4751" category="list-text">*Nachrichtenformat.*  Zu den Optionen gehören Avro, JSON, Protokollpuffer, Binär, Text, „Ich weiß nicht“ und andere.</block>
  <block id="b26274df5f3f47d18e40ee961fa8c5b5" category="list-text">*Replikationsfaktor.*  Optionen sind 1, 2, 3 (Confluent-Empfehlung), 4, 5 oder 6.</block>
  <block id="6320400b940be83033b0ce5ea91a3799" category="list-text">*Aufbewahrungszeit.*  Eines Tages (zum Beispiel).  Wie lange sollen Ihre Daten in Apache Kafka gespeichert werden?  Geben Sie -1 mit einer beliebigen Einheit für eine unendliche Zeit ein.  Der Rechner geht bei unbegrenzter Aufbewahrung von einer Aufbewahrungsdauer von 10 Jahren aus.</block>
  <block id="eb46bfc819d70448200241a8f1efec72" category="list-text">Aktivieren Sie das Kontrollkästchen „Tiered Storage aktivieren, um die Anzahl der Broker zu verringern und unbegrenzten Speicher zu ermöglichen?“</block>
  <block id="d66063041931961a7565ee71f7a7dd67" category="list-text">Wenn die mehrstufige Speicherung aktiviert ist, steuern die Aufbewahrungsfelder den Hotset der Daten, der lokal auf dem Broker gespeichert wird.  Die Felder für die Archivaufbewahrung steuern, wie lange Daten im Archivobjektspeicher gespeichert werden.</block>
  <block id="13bc2bec2c4039bad2d63b4ccf9611d4" category="list-text">*Archivspeicherung.*  Ein Jahr (zum Beispiel).  Wie lange sollen Ihre Daten im Archivspeicher aufbewahrt werden?  Geben Sie -1 mit einer beliebigen Einheit für eine unendliche Dauer ein.  Der Rechner geht bei unbegrenzter Aufbewahrung von einer Aufbewahrungsdauer von 10 Jahren aus.</block>
  <block id="841d5d94c8cc645b8a35f0b58d3d5c6d" category="list-text">*Wachstumsmultiplikator.*  1 (zum Beispiel).  Wenn der Wert dieses Parameters auf dem aktuellen Durchsatz basiert, setzen Sie ihn auf 1.  Um die Größe auf Grundlage zusätzlichen Wachstums anzupassen, legen Sie diesen Parameter auf einen Wachstumsmultiplikator fest.</block>
  <block id="5f044353fac0e72b8b68a9608cdfea2d" category="list-text">*Anzahl der Produzenteninstanzen.*  10 (zum Beispiel).  Wie viele Produzenteninstanzen werden ausgeführt?  Diese Eingabe ist erforderlich, um die CPU-Auslastung in die Größenberechnung einzubeziehen.  Ein leerer Wert zeigt an, dass die CPU-Auslastung nicht in die Berechnung einbezogen wird.</block>
  <block id="585e13820ff765aec3c094fbb66fb358" category="paragraph">Basierend auf dieser Beispieleingabe hat die Größenanpassung die folgenden Auswirkungen auf die Hersteller:</block>
  <block id="5504abde59477d70ee34b7c970af3ed2" category="list-text">Durchschnittlicher Durchsatz in unkomprimierten Bytes: 1 GBps.  Spitzendurchsatz in unkomprimierten Bytes: 4 GB/s.  Durchschnittlicher Durchsatz in komprimierten Bytes: 400 MB/s.  Spitzendurchsatz in komprimierten Bytes: 1,6 GB/s.  Dies basiert auf einer Standardkomprimierungsrate von 60 % (Sie können diesen Wert ändern).</block>
  <block id="fe685c6164262035f3c0407347a3d38d" category="inline-link-macro"><block ref="fe685c6164262035f3c0407347a3d38d" category="inline-link-rx"></block></block>
  <block id="d6730cec7284a7856088b8a49563caef" category="list-text">Gesamter On-Broker-Hotset-Speicher erforderlich: 31.104 TB, einschließlich Replikation, komprimiert.  Gesamter Off-Broker-Archivspeicherbedarf: 378.432 TB, komprimiert.  Verwenden<block ref="e132e1b42fc350f637835189d38d8bdf" category="inline-link-macro-rx"></block> zur StorageGRID -Dimensionierung.</block>
  <block id="65541f1c1daa682e605090dda4f5581b" category="paragraph">Stream-Prozessoren müssen ihre Anwendungen oder Dienste beschreiben, die Daten von Apache Kafka verbrauchen und wieder in Apache Kafka produzieren.  In den meisten Fällen werden diese in ksqlDB oder Kafka Streams erstellt.</block>
  <block id="47bf3a39e68a8e88ad9fff34b58afc0a" category="list-text">*Name.*  Spark-Streamer.</block>
  <block id="23f4b8037342e7943a6f549d7868281e" category="list-text">*Bearbeitungszeit.*  Wie lange braucht dieser Prozessor, um eine einzelne Nachricht zu verarbeiten?</block>
  <block id="0d4a13e2166384d926575e139fe3c68c" category="list-text">1 ms (einfache, zustandslose Transformation) [Beispiel], 10 ms (zustandsbehafteter In-Memory-Vorgang).</block>
  <block id="a1d2bac0d8ed78c0ce6bb941328bc680" category="list-text">100 ms (zustandsbehafteter Netzwerk- oder Festplattenvorgang), 1000 ms (REST-Aufruf eines Drittanbieters).</block>
  <block id="8b74c5757b588cdfea993715c0ce3b58" category="list-text">Ich habe diesen Parameter getestet und weiß genau, wie lange es dauert.</block>
  <block id="df8cd4e4488e4a8198132e46fc2beec9" category="list-text">*Ausgabeaufbewahrung.*  1 Tag (Beispiel).  Ein Stream-Prozessor gibt seine Ausgabe an Apache Kafka zurück.  Wie lange sollen diese Ausgabedaten in Apache Kafka gespeichert werden?  Geben Sie -1 mit einer beliebigen Einheit für eine unendliche Dauer ein.</block>
  <block id="108b072da5b6fab64d55b4f1d69690d4" category="list-text">Aktivieren Sie das Kontrollkästchen „Tiered Storage aktivieren, um die Anzahl der Broker zu verringern und unbegrenzten Speicher zu ermöglichen?“</block>
  <block id="c4462b25651379530a9eea9b2b478755" category="list-text">*Archivspeicherung.*  1 Jahr (zum Beispiel).  Wie lange sollen Ihre Daten im Archivspeicher aufbewahrt werden?  Geben Sie -1 mit einer beliebigen Einheit für eine unendliche Dauer ein.  Der Rechner geht bei unbegrenzter Aufbewahrung von einer Aufbewahrungsdauer von 10 Jahren aus.</block>
  <block id="6507507d73f33bc3d1077b4454d9d3dd" category="list-text">*Prozentsatz der Ausgabeweiterleitung.*  100 (zum Beispiel).  Ein Stream-Prozessor gibt seine Ausgabe an Apache Kafka zurück.  Welcher Prozentsatz des eingehenden Durchsatzes wird zurück an Apache Kafka ausgegeben?  Wenn beispielsweise der eingehende Durchsatz 20 MBps beträgt und dieser Wert 10 ist, beträgt der Ausgangsdurchsatz 2 MBps.</block>
  <block id="aa35062fd231efb888b1d664e6480c1d" category="list-text">Aus welchen Anwendungen wird dies gelesen?  Wählen Sie „Spark“, den Namen, der bei der herstellertypbasierten Größenbestimmung verwendet wird.  Basierend auf den obigen Eingaben können Sie die folgenden Auswirkungen der Größenanpassung auf Stream-Prozessor-Instanzen und Themenpartitionsschätzungen erwarten:</block>
  <block id="bbc0ea8f6decb55572d395615cd02a3b" category="list-text">Diese Stream-Prozessor-Anwendung erfordert die folgende Anzahl von Instanzen.  Die eingehenden Themen erfordern wahrscheinlich auch diese Anzahl an Partitionen.  Wenden Sie sich an Confluent, um diesen Parameter zu bestätigen.</block>
  <block id="0a206846c82be8eef261c4c686599582" category="list-text">1.000 für durchschnittlichen Durchsatz ohne Wachstumsmultiplikator</block>
  <block id="b032c5d1deed2d1b75c4f8019b5155e3" category="list-text">4.000 für Spitzendurchsatz ohne Wachstumsmultiplikator</block>
  <block id="5cbe73cfdf68ec8b04b4506b237d8af9" category="list-text">1.000 für durchschnittlichen Durchsatz mit einem Wachstumsmultiplikator</block>
  <block id="f51843d6cdec756114fb7f153ab79f46" category="list-text">4.000 für Spitzendurchsatz mit Wachstumsmultiplikator</block>
  <block id="1ebe06b1421d14bafea4a4d9a545d956" category="section-title">Verbraucher</block>
  <block id="4d2351cfaa069bdffc56cd73486deacb" category="paragraph">Beschreiben Sie Ihre Anwendungen oder Dienste, die Daten von Apache Kafka nutzen und nicht wieder in Apache Kafka produzieren; beispielsweise ein nativer Client oder Kafka Connector.</block>
  <block id="21af20352468dedb23eb4b6fa7362e32" category="list-text">*Name.*  Spark-Verbraucher.</block>
  <block id="9e3b25cc5e8806da459be0a41ecfce10" category="list-text">*Bearbeitungszeit.*  Wie lange braucht dieser Verbraucher, um eine einzelne Nachricht zu verarbeiten?</block>
  <block id="39ad97382609f7463897aa49624f20d4" category="list-text">1 ms (z. B. eine einfache und zustandslose Aufgabe wie das Protokollieren)</block>
  <block id="3d74518bdd6cfa27a42a16145872cc59" category="list-text">10 ms (schnelles Schreiben in einen Datenspeicher)</block>
  <block id="9f44c2afdbd671220f00e45494646aa6" category="list-text">100 ms (langsames Schreiben in einen Datenspeicher)</block>
  <block id="1284667da9611e925a39eee76e44e565" category="list-text">1000 ms (REST-Aufruf eines Drittanbieters)</block>
  <block id="fff6a4b96ed9fb45c7eab95aeb8eb684" category="list-text">Ein anderer Benchmark-Prozess mit bekannter Dauer.</block>
  <block id="6490501e3342b6bea241de7194a60bba" category="list-text">*Verbrauchertyp.*  Anwendung, Proxy oder Sink zu einem vorhandenen Datenspeicher (RDBMS, NoSQL, andere).</block>
  <block id="23a444b3f78a63619b03bea8301f4edb" category="list-text">Aus welchen Anwendungen wird dies gelesen?  Verbinden Sie diesen Parameter mit der zuvor ermittelten Produzenten- und Streamgröße.</block>
  <block id="2feb2ea8e1991424930eda0c7cdeb393" category="paragraph">Basierend auf den obigen Eingaben müssen Sie die Größe für Verbraucherinstanzen und Themenpartitionsschätzungen bestimmen.  Eine Consumer-Anwendung erfordert die folgende Anzahl von Instanzen.</block>
  <block id="90e1e02e655ca52c281e9b5ac01ca245" category="list-text">2.000 für durchschnittlichen Durchsatz, kein Wachstumsmultiplikator</block>
  <block id="228e2cc32e2eedd0cfaf646cb26ad562" category="list-text">8.000 für Spitzendurchsatz, kein Wachstumsmultiplikator</block>
  <block id="622c202fad5851b4699d8679ec9d3ce4" category="list-text">2.000 für durchschnittlichen Durchsatz, einschließlich Wachstumsmultiplikator</block>
  <block id="da18372dd9e384fd5a4fd97fa6bdb872" category="list-text">8.000 für Spitzendurchsatz, einschließlich Wachstumsmultiplikator</block>
  <block id="5992882fb5e2f68b36cbf47d5ffc182a" category="paragraph">Die eingehenden Themen benötigen wahrscheinlich auch diese Anzahl von Partitionen.  Wenden Sie sich zur Bestätigung an Confluent.</block>
  <block id="152f9b32fca1ce5e9a3fc34e8c9e69c0" category="paragraph">Zusätzlich zu den Anforderungen für Produzenten, Stream-Prozessoren und Konsumenten müssen Sie die folgenden zusätzlichen Anforderungen erfüllen:</block>
  <block id="aea71dcdb94c855eb0655cb615bdcfe2" category="list-text">*Zeit zum Wiederaufbau.*  Zum Beispiel 4 Stunden.  Wenn ein Apache Kafka-Broker-Host ausfällt, seine Daten verloren gehen und ein neuer Host bereitgestellt wird, um den ausgefallenen Host zu ersetzen, wie schnell muss sich dieser neue Host selbst wiederherstellen?  Lassen Sie diesen Parameter leer, wenn der Wert unbekannt ist.</block>
  <block id="3bc49d2594090d023892da5211f6f7a4" category="list-text">*Ressourcennutzungsziel (Prozentsatz).*  Zum Beispiel 60.  Wie ausgelastet sollen Ihre Hosts bei durchschnittlichem Durchsatz sein?  Confluent empfiehlt eine Auslastung von 60 %, es sei denn, Sie verwenden selbstausgleichende Confluent-Cluster. In diesem Fall kann die Auslastung höher sein.</block>
  <block id="9fa691f61c91ce32c6fb2dcc53a9d09c" category="section-title">Beschreiben Sie Ihre Umgebung</block>
  <block id="7e431f8959ae4a79bcfc6e55728ead5a" category="list-text">*In welcher Umgebung wird Ihr Cluster ausgeführt?*  Amazon Web Services, Microsoft Azure, Google Cloud Platform, Bare-Metal vor Ort, VMware vor Ort, OpenStack vor Ort oder Kubernates vor Ort?</block>
  <block id="34946a533795a145eb4c6d66ee12e56b" category="list-text">*Hostdetails.*  Anzahl der Kerne: 48 (zum Beispiel), Netzwerkkartentyp (10GbE, 40GbE, 16GbE, 1GbE oder ein anderer Typ).</block>
  <block id="a50ad1bade1c614aa4ceaa766944b0e1" category="list-text">*Speichervolumes.*  Host: 12 (zum Beispiel).  Wie viele Festplatten oder SSDs werden pro Host unterstützt?  Confluent empfiehlt 12 Festplatten pro Host.</block>
  <block id="bf903fced4e4e598ede3fb2a9dd5427a" category="list-text">*Speicherkapazität/-volumen (in GB).*  1000 (zum Beispiel).  Wie viel Speicherplatz in Gigabyte kann ein einzelnes Volume speichern?  Confluent empfiehlt 1-TB-Festplatten.</block>
  <block id="85a140efdb29007799d7d5e7c16691d5" category="list-text">*Speicherkonfiguration.*  Wie werden Speichervolumes konfiguriert?  Confluent empfiehlt RAID10, um alle Confluent-Funktionen zu nutzen.  JBOD, SAN, RAID 1, RAID 0, RAID 5 und andere Typen werden ebenfalls unterstützt.</block>
  <block id="237d14e07eccd0d6535cf69ee4507805" category="list-text">*Durchsatz einzelner Datenträger (MBps).*  125 (zum Beispiel).  Wie schnell kann ein einzelnes Speichervolumen in Megabyte pro Sekunde lesen oder schreiben?  Confluent empfiehlt Standardfestplatten, die normalerweise einen Durchsatz von 125 MB/s haben.</block>
  <block id="57499d42a69c4ed9f1e7994a0bad7e9f" category="list-text">*Speicherkapazität (GB).*  64 (zum Beispiel).</block>
  <block id="9db0153ae987c66e360fc7027c7819c8" category="paragraph">Nachdem Sie Ihre Umgebungsvariablen ermittelt haben, wählen Sie „Size my Cluster“ (Größe meines Clusters festlegen).  Basierend auf den oben angegebenen Beispielparametern haben wir die folgende Dimensionierung für Confluent Kafka ermittelt:</block>
  <block id="fc644e6661f2118a6b0733f85424f3fa" category="list-text">*Apache Kafka.*  Anzahl der Makler: 22.  Ihr Cluster ist speichergebunden.  Erwägen Sie die Aktivierung von Tiered Storage, um die Anzahl Ihrer Hosts zu verringern und unbegrenzten Speicherplatz zu ermöglichen.</block>
  <block id="689921f4781dfd392aedc0eac4116284" category="list-text">*Apache ZooKeeper.*  Anzahl: 5; Apache Kafka Connect Workers: Anzahl: 2; Schema Registry: Anzahl: 2; REST-Proxy: Anzahl: 2; ksqlDB: Anzahl: 2; Confluent Control Center: Anzahl: 1.</block>
  <block id="df1673ed6a212d182bedbf3a4bdc79a7" category="paragraph">Verwenden Sie den umgekehrten Modus für Plattformteams ohne einen Anwendungsfall im Sinn.  Verwenden Sie den Partitionsmodus, um zu berechnen, wie viele Partitionen ein einzelnes Thema benötigt.  Sehen<block ref="d971ea0f6ada2eeb1a618f5145544e00" category="inline-link-rx"></block> zur Größenbestimmung basierend auf den Reverse- und Partitionsmodi.</block>
  <block id="16d17bd11d09e7ab044f85f158c4ee5c" category="doc">Details zur Lösungsarchitektur</block>
  <block id="096d10f0062b97cca959118975fa506a" category="paragraph">Dieser Abschnitt behandelt die für die Confluent-Verifizierung verwendete Hardware und Software.  Diese Informationen gelten für die Bereitstellung der Confluent Platform mit NetApp -Speicher.  Die folgende Tabelle umfasst die getestete Lösungsarchitektur und die Basiskomponenten.</block>
  <block id="7e897f23ed71aef1c0a8acf1ae54e9e4" category="cell">Lösungskomponenten</block>
  <block id="3ec365dd533ddb7ef3d1c111186ce872" category="cell">Details</block>
  <block id="cd6b218ceb186591718799f941a99fd0" category="cell">Confluent Kafka Version 6.2</block>
  <block id="8a1732b4cde6f106471a0e6dbb186bed" category="list-text">Drei Tierpfleger</block>
  <block id="fde5b2c6fa48108e02c6a3587ce451b4" category="list-text">Fünf Broker-Server</block>
  <block id="cd2e7d4aa00a79a9a92980e984ec50d7" category="list-text">Fünf Tools-Server</block>
  <block id="e9617e461b2b6597095fc0d3c26666c5" category="list-text">Ein Grafana</block>
  <block id="5d96f98a638cf23ac2f3dfe513198e9a" category="list-text">Ein Kontrollzentrum</block>
  <block id="a2a44121136232f1f2dcfb5e5ce5cf22" category="cell">Linux (Ubuntu 18.04)</block>
  <block id="a0681d05c825936a4afc9d89f305934c" category="cell">Alle Server</block>
  <block id="cc3bec1f9974aef63e75985fed9c343e" category="cell">NetApp StorageGRID für Tiered Storage</block>
  <block id="2d4f4568ad652ff08727bc044f1373cc" category="list-text">StorageGRID -Software</block>
  <block id="4ebcee22d98fbad50cf1c7e108dd9541" category="list-text">1 x SG1000 (Lastverteiler)</block>
  <block id="a51cb0f5fd275943954c8d687912e458" category="list-text">4 x SGF6024</block>
  <block id="83cc5cf13ad44caf6aa94887d189cd3a" category="list-text">4 x 24 x 800 SSDs</block>
  <block id="7ccdc7c1d04d9b48b4b016417504685b" category="list-text">S3-Protokoll</block>
  <block id="e185a6ccd16ce2c64c7e948bbc46f45a" category="list-text">4 x 100 GbE (Netzwerkkonnektivität zwischen Broker- und StorageGRID Instanzen)</block>
  <block id="5ecafb7b42f662438e20bd643feb79c9" category="cell">15 Fujitsu PRIMERGY RX2540 Server</block>
  <block id="cdb0680ecb0e0ed91d8293e41334b379" category="cell">Jedes ist ausgestattet mit: * 2 CPUs, insgesamt 16 physischen Kernen * Intel Xeon * 256 GB physischem Speicher * 100 GbE Dual-Port</block>
  <block id="06a768157cb89879ca041da1b730da6e" category="summary">Dieses Dokument enthält Best-Practice-Richtlinien für die Verwendung von Dremio mit NetApp -Speicher, einschließlich TPCDS-Zertifizierungstests, Tuning und Details zu Kundenanwendungsfällen.</block>
  <block id="5539c6da3e2032488a631305f1265434" category="paragraph">Zusammenfassend lässt sich sagen, dass dieser technische Bericht umfassende Bereitstellungsdetails zu q Hybrid Iceberg Lakehouse mit Dremio in Verbindung mit verschiedenen Datenquellen von NetApp -Speichercontrollern, einschließlich ONTAP S3, NAS und StorageGRID, liefert.  Der Bereitstellungsprozess wurde erfolgreich ausgeführt und das TPC-DS-Benchmarking-Tool wurde verwendet, um 99 SQL-Abfragen über die verschiedenen Datenquellen hinweg durchzuführen.  Der Bericht untersuchte außerdem Anwendungsfälle von Kunden innerhalb von NetApp und demonstrierte die Vielseitigkeit und Effektivität von Dremio bei der Erfüllung unterschiedlicher Geschäftsanforderungen.  Darüber hinaus wurde ein spezifischer Anwendungsfall mit einem Kunden aus dem Autoteilehandel untersucht, der die praktische Anwendung und die Vorteile der Nutzung von Dremio für Datenanalysen und -erkenntnisse hervorhob.</block>
  <block id="682cc1e627af4457882db17515ccaf5b" category="paragraph">Insgesamt dient dieses Dokument als wertvolle Ressource zum Verständnis der Bereitstellung und Verwendung von Dremio mit NetApp Speichercontrollern und zeigt seine Fähigkeiten und sein Potenzial für die Förderung datengesteuerter Entscheidungsfindung und Optimierung in verschiedenen Branchen auf.</block>
  <block id="c63354da3a3a21f3ae0083d0a275540c" category="list-text">Zookeeper-Installation</block>
  <block id="661fab58be11f3fe0e5fd03c183c9a3b" category="paragraph"><block ref="661fab58be11f3fe0e5fd03c183c9a3b" category="inline-link-rx"></block></block>
  <block id="288e0e9ab8b8ac8737afefecf16f61fd" category="list-text">Dremio</block>
  <block id="d9f3b0f9c66b1c99f5e01fefb31f3280" category="paragraph"><block ref="d9f3b0f9c66b1c99f5e01fefb31f3280" category="inline-link-rx"></block></block>
  <block id="7d56340ec96dd44dedf67654c4b228a9" category="list-text">Konfigurieren von Dremio mit storageGRID</block>
  <block id="d6a7c21494adf18f10c2f9b2b6da5584" category="paragraph"><block ref="d6a7c21494adf18f10c2f9b2b6da5584" category="inline-link-rx"></block></block>
  <block id="719a5826913817829f2d138a33720835" category="list-text">NetApp Anwendungsfall</block>
  <block id="abd766d13b2562c1684015edb41ddc75" category="paragraph"><block ref="abd766d13b2562c1684015edb41ddc75" category="inline-link-rx"></block></block>
  <block id="108f231402daaaf5b7a58841053615dd" category="summary">Wir haben die Zertifizierung mit der Dremio-Plattform mit Lakehouse-Validierung im NetApp Object Storage durchgeführt.</block>
  <block id="3cd3290a9231e38be51fc2cb3ce01572" category="doc">Bereitstellungsverfahren</block>
  <block id="d44c5f08c906e8f8bc746c8e4083522e" category="inline-image-macro">Abbildung zeigt die Dremio-Architektur mit NetApp -Speichercontroller</block>
  <block id="5e5f3a2661fa2ba525c6c6d493b1058d" category="paragraph">Bei dieser Referenzarchitekturvalidierung verwendeten wir eine Dremio-Konfiguration, die aus einem Koordinator und vier Executoren besteht.<block ref="b76f8c360d80a001aee0571894d68ba2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="07efd46e12f0d695c6aa9e2abf057781" category="section-title">NetApp -Setup</block>
  <block id="82c8a5cee83d98576ecd7fb9135c1b41" category="list-text">Initialisierung des Speichersystems</block>
  <block id="8028442c79907b3f88933ff5c16fac5e" category="list-text">Erstellen einer virtuellen Speichermaschine (SVM)</block>
  <block id="ff602335ea946bbb0494a8ca5aa58bf5" category="list-text">Zuordnung logischer Netzwerkschnittstellen</block>
  <block id="c1d1275f7bc999e53ce84a9b2a48cc7f" category="list-text">NFS, S3-Konfiguration und -Lizenzierung</block>
  <block id="bbc1adf735eb5e7f9c1e5bae1fb2aed8" category="paragraph">Bitte befolgen Sie die folgenden Schritte für NFS (Network File System): 1.  Erstellen Sie ein Flex Group-Volume für NFSv4 oder NFSv3.  In unserem Setup für diese Validierung haben wir 48 SSDs verwendet, 1 SSD für das Root-Volume des Controllers und 47 SSDs, verteilt für NFSv4]].  Stellen Sie sicher, dass die NFS-Exportrichtlinie für das Flex Group-Volume über Lese-/Schreibberechtigungen für das Dremio-Servernetzwerk verfügt.</block>
  <block id="77cf539931cef9f508e194dbd28a0bc0" category="list-text">Erstellen Sie auf allen Dremio-Servern einen Ordner und mounten Sie das Flex Group-Volume über eine logische Schnittstelle (LIF) auf jedem Dremio-Server in diesen Ordner.</block>
  <block id="575afa472f95d77f2af74b7f99bc9d28" category="paragraph">Bitte befolgen Sie die folgenden Schritte für S3 (Simple Storage Service):</block>
  <block id="28863b320894e844cb1d2df9a479aa31" category="list-text">Richten Sie mit dem Befehl „vserver object-store-server create“ einen Object-Store-Server mit aktiviertem HTTP und dem Administratorstatus „up“ ein.  Sie haben die Möglichkeit, HTTPS zu aktivieren und einen benutzerdefinierten Listener-Port festzulegen.</block>
  <block id="993520e0cce3e5f87179d01caa10a746" category="list-text">Erstellen Sie einen Object-Store-Server-Benutzer mit dem Befehl „vserver object-store-server user create -user &lt;Benutzername&gt;“.</block>
  <block id="4c7b617c418e3a5f7073d2d64ba8cb1c" category="list-text">Um den Zugriffsschlüssel und den geheimen Schlüssel zu erhalten, können Sie den folgenden Befehl ausführen: „set diag; vserver object-store-server user show -user &lt;Benutzername&gt;“.  In Zukunft werden diese Schlüssel jedoch während des Benutzererstellungsprozesses bereitgestellt oder können mithilfe von REST-API-Aufrufen abgerufen werden.</block>
  <block id="c3d4f7a6161c482cb921db78c64d1543" category="list-text">Richten Sie mit dem in Schritt 2 erstellten Benutzer eine Object-Store-Server-Gruppe ein und gewähren Sie Zugriff.  In diesem Beispiel haben wir „FullAccess“ bereitgestellt.</block>
  <block id="f346ebaf71f9d3850361e0b732a352f5" category="list-text">Erstellen Sie zwei S3-Buckets, indem Sie ihren Typ auf „S3“ festlegen.  Eine für die Dremio-Konfiguration und eine für Kundendaten.</block>
  <block id="3c29c74ed24f85f4cf464243c6d69bc7" category="section-title">Zookeeper-Setup</block>
  <block id="a284e9d9802d2b863fce5aa237106342" category="paragraph">Sie können die von Dremio bereitgestellte Zookeeper-Konfiguration verwenden.  Bei dieser Validierung haben wir einen separaten Zookeeper verwendet. Wir haben die in diesem Weblink genannten Schritte befolgt<block ref="757110f854f50ea29baeb536bc067417" category="inline-link-rx"></block></block>
  <block id="fb6e0f74d4f2cd819e198308d0e560c8" category="section-title">Dremio-Einrichtung</block>
  <block id="3e793dc4b6b41d43692a24d29150ed55" category="paragraph">Wir sind diesem Weblink gefolgt, um Dremio per Tarball zu installieren.</block>
  <block id="694299a05f621f9d6c47fbc0cdd75cdb" category="list-text">Erstellen Sie eine Dremio-Gruppe.</block>
  <block id="28b115fb542519f28216941113c7fc69" category="list-text">Erstellen Sie einen Dremio-Benutzer.</block>
  <block id="6190c0f96190f68e7387989b98fecd3c" category="list-text">Erstellen Sie Dremio-Verzeichnisse.</block>
  <block id="b8d53340c1af1590a07a31d4782e75c8" category="list-text">Laden Sie die Tar-Datei herunter von<block ref="993599c5d8336ec040e5e84c23246c65" category="inline-link-rx"></block></block>
  <block id="38152bcebb8f6d46160b6d2462ce40a0" category="list-text">Entpacken Sie Dremio in das Verzeichnis /opt/dremio.</block>
  <block id="9af78d03c81be6e6dd350c73be883f9b" category="list-text">Erstellen Sie einen symbolischen Link für den Konfigurationsordner.</block>
  <block id="a16cec17e87f61728dcdd563b7d8ecc7" category="list-text">Richten Sie Ihre Dienstkonfiguration ein (SystemD-Setup).</block>
  <block id="44aba27523001647040cfa3dab851cbb" category="list-text">Kopieren Sie die Unit-Datei für den Dremio-Daemon von /opt/dremio/share/dremio.service nach /etc/systemd/system/dremio.service.</block>
  <block id="617a522470fb25e0b60757c2347779fd" category="list-text">System neu starten</block>
  <block id="b0a645a7658dbbe597c81a61d8095535" category="list-text">Aktivieren Sie Dremio, um beim Booten zu starten.</block>
  <block id="715ae8a49286aaa14659522218602fba" category="list-text">Konfigurieren Sie Dremio auf dem Koordinator.  Weitere Informationen finden Sie unter Dremio-Konfiguration</block>
  <block id="940845b76f9832cb794ce21b8053c3d9" category="list-text">Dremio.conf</block>
  <block id="e49741f6cfbc4fdc21eaf59a034e694c" category="list-text">Core-site.xml</block>
  <block id="157bf0c98c644ad5d09f3dda0843bb8d" category="list-text">Die Dremio-Konfiguration wird im NetApp Objektspeicher gespeichert.  Bei unserer Validierung befindet sich der Bucket „dremioconf“ in einem Ontap S3-Bucket.  Das folgende Bild zeigt einige Details aus den Ordnern „Scratch“ und „Uploads“ des S3-Buckets „dremioconf“.</block>
  <block id="dec65ddc4408a5fd22bf6eef9c5dc2c4" category="inline-image-macro">Abbildung zeigt dremio mit NetApp Objektspeicher</block>
  <block id="3f6534c1dba4ce90c550aec7ec304146" category="paragraph"><block ref="3f6534c1dba4ce90c550aec7ec304146" category="inline-image-macro-rx" type="image"></block></block>
  <block id="536241c2f7d1f3fbe227bc001b56b949" category="list-text">Konfigurieren Sie Dremio auf Executoren.  In unserem Setup haben wir 3 Executoren.</block>
  <block id="98acd539813ecdb677a633c1e8d72ba9" category="list-text">dremio.conf</block>
  <block id="19aac463221a9324b146be45c5f27561" category="list-text">Core-site.xml – dasselbe wie die Koordinatorkonfiguration.</block>
  <block id="9ebe81db6df147f3eea7002c858d2821" category="admonition">NetApp empfiehlt StorageGRID als primäre Objektspeicherlösung für Datalake- und Lakehouse-Umgebungen.  Zusätzlich wird NetApp ONTAP für die Datei-/Objekt-Dualität eingesetzt.  Im Rahmen dieses Dokuments haben wir auf Kundenanfrage Tests mit ONTAP S3 durchgeführt und es funktioniert erfolgreich als Datenquelle.</block>
  <block id="5b8d6104bd7d25e99e47f619fdfd8f81" category="section-title">Einrichtung mehrerer Quellen</block>
  <block id="4ee12bc75bcc4f7fb3bbf527ef1d2720" category="list-text">Konfigurieren Sie ONTAP S3 und storageGRID als S3-Quelle in Dremio.</block>
  <block id="dbd1ae231acf755d63de74b16a8cbeb7" category="list-text">Dremio-Dashboard -&gt; Datensätze -&gt; Quellen -&gt; Quelle hinzufügen.</block>
  <block id="c102e8893995a295f2cc62063b2e0cd5" category="list-text">Aktualisieren Sie im allgemeinen Abschnitt den AWS-Zugriff und den geheimen Schlüssel</block>
  <block id="71a7d593565f192b138481a0e8d335c4" category="list-text">Aktivieren Sie in der erweiterten Option den Kompatibilitätsmodus und aktualisieren Sie die Verbindungseigenschaften mit den folgenden Details.  Die Endpunkt-IP/der Endpunktname vom NetApp -Speichercontroller, entweder von Ontap S3 oder StorageGRID.</block>
  <block id="4f594a255a564afe3df4ac263caedbb5" category="list-text">Aktivieren Sie nach Möglichkeit das lokale Caching. Maximaler Prozentsatz des insgesamt verfügbaren Caches, der nach Möglichkeit verwendet werden soll = 100</block>
  <block id="c71df1ddac771fdc9b484b0ed6f6d9f7" category="inline-image-macro">Abbildung zeigt eine Liste der Dateien aus dem NetApp Objektspeicher</block>
  <block id="a4d1986a0b1a4f12d2237b0963d2e43d" category="list-text">Zeigen Sie dann die Liste der Buckets aus dem NetApp Objektspeicher an.<block ref="3774299f093c28855158f425c629b55d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c80afe9a6ef853e0d394059a332a406d" category="list-text">Beispielansicht der StorageGRID-Bucket-Details<block ref="e0f51eae5ca0e68849adc9661a7def73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18ebb902e9ccb331331d9d1b8b5e0f76" category="list-text">Konfigurieren Sie NAS (insbesondere NFS) als Quelle in Dremio.</block>
  <block id="08a5aec8691cede64f84acb42700e07d" category="list-text">Geben Sie im allgemeinen Abschnitt den Namen und den NFS-Mount-Pfad ein.  Stellen Sie sicher, dass der NFS-Mount-Pfad auf allen Knoten im Dremio-Cluster im selben Ordner gemountet ist.</block>
  <block id="eaa2d3817be8fb7b330c01f9605f0808" category="paragraph"><block ref="eaa2d3817be8fb7b330c01f9605f0808" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26b17225b626fb9238849fd60eabdf60" category="paragraph">+</block>
  <block id="b134468afaa618eaef2e7bfaf5f30da7" category="summary">Dieses Dokument beschreibt die Best-Practice-Richtlinien für die Verwendung von Dremio auf einem NetApp -Speichercontroller.</block>
  <block id="53bd7dac219a2662a137c6de870224d2" category="doc">Die hybride Iceberg Lakehouse-Lösung der nächsten Generation von NetApp und Dremio</block>
  <block id="0c74f27a6d1c41b83e5cc59468f24a0d" category="paragraph">In diesem Dokument besprechen wir die Bereitstellungsdetails von Dremio mit verschiedenen Datenquellen von NetApp Speichercontrollern, einschließlich ONTAP S3, NAS und StorageGRID.  Während der Bereitstellung haben wir das Benchmarking-Tool TPC-DS verwendet, um 99 SQL-Abfragen über verschiedene Quellen hinweg auszuführen.  Das Dokument untersucht außerdem Anwendungsfälle von Kunden innerhalb von NetApp sowie einen Anwendungsfall mit einem Kunden aus dem Autoteileverkauf.</block>
  <block id="d4b28ab5babb078bc6498faee7c53a81" category="summary">Dieser Abschnitt behandelt die für die Dremio-Zertifizierung verwendete Hardware und Software.  Diese Informationen gelten für die Dremio-Bereitstellung mit NetApp Speicher.</block>
  <block id="cb2418c01859c7704da751aa5a7d2421" category="doc">Lösungsübersicht</block>
  <block id="9953e901936889810e67ec0949c6b2fc" category="paragraph">Die Hybrid Iceberg Lakehouse-Lösung bietet einzigartige Vorteile zur Bewältigung der Herausforderungen, mit denen Data Lake-Kunden konfrontiert sind.  Durch die Nutzung der Dremio Unified Lakehouse-Plattform und der NetApp ONTAP, StorageGRID und NetApp Cloud-Lösungen können Unternehmen ihren Geschäftsbetrieb erheblich aufwerten.  Die Lösung bietet nicht nur Zugriff auf mehrere Datenquellen, einschließlich NetApp Quellen, sondern verbessert auch die allgemeine Analyseleistung und hilft Unternehmen dabei, Geschäftseinblicke zu gewinnen, die zu Geschäftswachstum führen.</block>
  <block id="91c847ff0ec1e96ccc74039eaf1b5bf3" category="section-title">NetApp Übersicht</block>
  <block id="b630104207f28e8a0523849fe77c1e9f" category="list-text">Die Angebote von NetApp, wie ONTAP und StorageGRID, ermöglichen die Trennung von Speicher und Computing und ermöglichen so eine optimale Ressourcennutzung basierend auf spezifischen Anforderungen.  Diese Flexibilität ermöglicht es Kunden, ihren Speicher mithilfe von NetApp -Speicherlösungen unabhängig zu skalieren</block>
  <block id="bc213af00312a8c2d752b8b42715eed6" category="list-text">Durch die Nutzung der Speichercontroller von NetApp können Kunden mithilfe der Protokolle NFS und S3 effizient Daten an ihre Vektordatenbank übermitteln.  Diese Protokolle erleichtern die Speicherung von Kundendaten und verwalten den Vektordatenbankindex, sodass nicht mehr mehrere Kopien der Daten benötigt werden, auf die über Datei- und Objektmethoden zugegriffen wird.</block>
  <block id="1557c431be0fea4f212f4006eafc9a8c" category="list-text">NetApp ONTAP bietet native Unterstützung für NAS- und Objektspeicher bei führenden Cloud-Service-Anbietern wie AWS, Azure und Google Cloud.  Diese umfassende Kompatibilität gewährleistet eine nahtlose Integration und ermöglicht Kundendatenmobilität, globale Zugänglichkeit, Notfallwiederherstellung, dynamische Skalierbarkeit und hohe Leistung.</block>
  <block id="392d70ca39f31f10bd637936769788df" category="section-title">StorageGRID</block>
  <block id="9409f64cd9405163cc619bf89c44eaf4" category="paragraph">Unser branchenführender Objektspeicher storageGRID bietet eine leistungsstarke Richtlinien-Engine für die automatisierte Datenplatzierung, flexible Bereitstellungsoptionen und unübertroffene Haltbarkeit mit mehrschichtiger Löschcodierung.  Es verfügt über eine skalierbare Architektur, die Milliarden von Objekten und Petabyte an Daten in einem einzigen Namespace unterstützt.  Die Lösung ermöglicht die Integration einer Hybrid-Cloud und ermöglicht so die Datenaufteilung auf die wichtigsten Cloud-Plattformen.  Es wurde im IDC Marketscape Worldwide Object-Based Vendor Assessment 2019 als führend anerkannt.</block>
  <block id="546a8027b219510c369554288fd7eff4" category="paragraph">Darüber hinaus zeichnet sich storageGRID durch die Verwaltung unstrukturierter Daten im großen Maßstab mit softwaredefiniertem Objektspeicher, Georedundanz und Multi-Site-Funktionen aus.  Es umfasst ein richtlinienbasiertes Informationslebenszyklusmanagement und bietet Cloud-Integrationsfunktionen wie Spiegelung und Suche.  Es verfügt über verschiedene Zertifizierungen, darunter Common Criteria, NF203 Digital Safe Component, ISO/IEC 25051, KPMG und Cohasset Compliance Assessment.</block>
  <block id="030de30483fabd3aca42be7503592961" category="paragraph">Zusammenfassend bietet NetApp storageGRID leistungsstarke Funktionen, Skalierbarkeit, Hybrid-Cloud-Integration und Compliance-Zertifizierungen für die effiziente Verwaltung unstrukturierter Daten im großen Maßstab.</block>
  <block id="7b02ea300aef2e0bff0d7f6111053284" category="section-title">NetApp ONTAP</block>
  <block id="185a43d593912638c2bb37ef99444fc9" category="paragraph">NetApp ONTAP ist eine robuste Speicherlösung, die eine breite Palette an Unternehmensfunktionen bietet.  Es enthält Snapshot, das anwendungskonsistente und manipulationssichere Sofortsicherungen bietet.  SnapRestore ermöglicht die nahezu sofortige Wiederherstellung von Backups auf Anfrage, während SnapMirror integrierte Remote-Backup- und Disaster-Recovery-Funktionen bietet.  Die Lösung umfasst außerdem Autonomous Ransomware Protection (ARP) und gewährleistet Datensicherheit mit Funktionen wie Multi-Administrator-Verifizierung, Data-at-Rest-Verschlüsselung mit FIPS-Zertifizierung, Datenverschlüsselung während der Übertragung, Multifaktor-Authentifizierung (MFA) und rollenbasierter Zugriffskontrolle (RBAC).  Umfassende Protokollierung, Auditierung, integrierte und externe Schlüsselverwaltung, sichere Bereinigung und sichere Verwaltung mehrerer Mandanten verbessern die Datensicherheit und Compliance zusätzlich.</block>
  <block id="48af054a9eb5d217f15aab37f5fe9b91" category="paragraph">NetApp ONTAP verfügt außerdem über SnapLock, das eine gesetzeskonforme Datenaufbewahrung mit einem hohen Maß an Integrität, Leistung und Aufbewahrung bei niedrigen Gesamtbetriebskosten bietet.  Es ist vollständig in NetApp ONTAP 9 integriert und bietet Schutz vor böswilligen Handlungen, betrügerischen Administratoren und Ransomware.</block>
  <block id="afd4da5566327275499951d8db99e683" category="paragraph">Die Lösung umfasst NSE/NVE-Verschlüsselung für die Verschlüsselung von In-Flight- und Data-at-Rest-Daten, Multifaktor-Administratorzugriff und Multi-Admin-Verifizierung.  Active IQ bietet KI-gestützte prädiktive Analysen und Korrekturmaßnahmen, während QoS die Kontrolle der Service-Workload-Qualität gewährleistet.  Die Verwaltungs- und Automatisierungsintegration erfolgt intuitiv über SysMgr/GUI/CLI/API.  FabricPool ermöglicht automatisches Daten-Tiering und die Lösung bietet Effizienz durch Inline-Datenkomprimierung, Deduplizierung und Kompaktierung.  NetApp garantiert die Erreichung der Workload-Effizienzziele ohne Kosten für den Kunden.</block>
  <block id="327b294a4782dbbd617ca02b0227198e" category="paragraph">NetApp ONTAP unterstützt verschiedene Protokolle, darunter NVMe/FC, FC, NVMe/TCP, iSCSI, NFS, SMB und S3, und ist damit eine einheitliche Speicherlösung.  Insgesamt bietet NetApp ONTAP umfangreiche Unternehmensfunktionen, robuste Sicherheit, Compliance, Effizienz und Vielseitigkeit, um den unterschiedlichsten Speicheranforderungen gerecht zu werden.</block>
  <block id="5504df296ab63119754ecfd92e6a07d7" category="section-title">Dremio-Übersicht</block>
  <block id="46664b9047c24c224cf4898236ac4159" category="paragraph">Dremio ist die Unified Lakehouse-Plattform für Self-Service-Analysen und KI.  Die Dremio Unified Analytics Platform bringt Benutzer mit Lakehouse-Flexibilität, Skalierbarkeit und Leistung näher an die Daten heran – und das zu einem Bruchteil der Kosten herkömmlicher Data-Warehouse-Lösungen.  Dremio ermöglicht „Shift-Left“-Analysen, um komplexe und kostspielige Datenintegration und ETL zu eliminieren und nahtlose Analysen im Unternehmensmaßstab ohne Datenbewegung zu ermöglichen.  Dremio bietet außerdem:</block>
  <block id="2f0acfc3dbf17a0571810cc0dedaf64f" category="list-text">Benutzerfreundliche Self-Service-Analysen werden durch eine universelle semantische Ebene und eine eng integrierte, hochleistungsfähige SQL-Abfrage-Engine ermöglicht. Dadurch wird die Verbindung, Verwaltung und Analyse aller Daten sowohl in der Cloud als auch vor Ort vereinfacht.</block>
  <block id="88be140c20067da1baf354c05223a2c6" category="list-text">Die Apache Iceberg-nativen Lakehouse-Verwaltungsfunktionen von Dremio vereinfachen die Datenermittlung und automatisieren die Datenoptimierung, indem sie leistungsstarke Analysen mit Git-inspirierter Datenversionierung liefern.</block>
  <block id="fe08740b7cac34b055da6ec6bfe79c3f" category="list-text">Dremio basiert auf Open Source und offenen Standards und ermöglicht es Unternehmen, Lock-in-Situationen zu vermeiden und für Innovationen gerüstet zu bleiben.  Großunternehmen vertrauen auf Dremio als die benutzerfreundlichste Lakehouse-Plattform mit dem besten Preis-Leistungs-Verhältnis für alle Workloads.</block>
  <block id="e95806f0d7b4743b250387c094acef2b" category="section-title">Welchen Mehrwert bietet die Hybrid Iceberg Lakehouse-Lösung von Dremio und NetApp den Kunden?</block>
  <block id="81c79525dc5cb78051ffe86a4b85377f" category="list-text">*Verbessertes Datenmanagement und -zugänglichkeit*: Dremio ist bekannt für seine Data-Lakehouse-Plattform, die es Unternehmen ermöglicht, Daten mit hoher Geschwindigkeit direkt aus ihren Data Lakes abzufragen.  NetApp hingegen ist ein führender Anbieter von Cloud-Datendiensten und Datenspeicherlösungen.  Das gemeinsame Angebot bietet Kunden eine umfassende Lösung für die effiziente und effiziente Speicherung, Verwaltung, den Zugriff und die Analyse ihrer Unternehmensdaten.</block>
  <block id="4bb8954089d2a9fb6c99825861c39f62" category="list-text">*Leistungsoptimierung*: Mit der Expertise von NetApp im Bereich Datenspeicherung und den Fähigkeiten von Dremio in der Datenverarbeitung und Datenoptimierung bietet die Partnerschaft eine Lösung, die die Leistung von Datenoperationen verbessert, die Latenz reduziert und die Geschwindigkeit der Geschäftserkenntnisse erhöht.  Dremio hat sogar Leistungsvorteile für die interne IT-Analyseinfrastruktur von NetApp gebracht.</block>
  <block id="737f740962d700c8fb65a99e34900bc9" category="list-text">*Skalierbarkeit*: Sowohl Dremio als auch NetApp bieten eine Lösung, die auf Skalierbarkeit ausgelegt ist.  Die gemeinsame Lösung bietet Kunden hochskalierbare Umgebungen für Datenspeicherung, Datenverwaltung und Analysen.  In einer hybriden Iceberg Lakehouse-Umgebung bietet die Dremio SQL-Abfrage-Engine in Kombination mit NetApp StorageGRID beispiellose Skalierbarkeit, Parallelität und Abfrageleistung und ist in der Lage, die Analyseanforderungen jedes Unternehmens zu erfüllen.</block>
  <block id="38eb37e9ecd9ccb05b8fda4a7890c571" category="list-text">*Datensicherheit und -verwaltung*: Beide Unternehmen legen großen Wert auf Datensicherheit und -verwaltung.  Zusammen bieten sie robuste Sicherheits- und Datenverwaltungsfunktionen und gewährleisten so den Schutz der Daten und die Einhaltung der Datenverwaltungsanforderungen.  Funktionen wie rollenbasierte und feinkörnige Zugriffskontrollen, umfassendes Auditing, durchgängige Datenherkunft, einheitliches Identitätsmanagement und SSO mit einem umfassenden Compliance- und Sicherheitsrahmen sorgen dafür, dass die analytischen Datenumgebungen von Unternehmen sicher und kontrolliert sind.</block>
  <block id="b10c860483a8763cd915a0459af4c444" category="list-text">*Kosteneffizienz*: Durch die Integration der Data Lake Engine von Dremio mit den Speicherlösungen von NetApp können Kunden die mit der Datenverwaltung und Datenbewegung verbundenen Kosten senken.  Unternehmen können außerdem von veralteten Data-Lake-Umgebungen auf eine modernere Lakehouse-Lösung aus NetApp und Dremio umsteigen.  Diese Hybrid Iceberg Lakehouse-Lösung bietet eine Hochgeschwindigkeitsabfrageleistung und marktführende Abfrageparallelität, die die Gesamtbetriebskosten senkt und die Zeit bis zur Erlangung geschäftlicher Erkenntnisse verkürzt.</block>
  <block id="55473d705d75e19b6040dbe34242319c" category="summary">In diesem Abschnitt wird die in dieser Lösung verwendete Technologie beschrieben.</block>
  <block id="910af13beca7193218f534b5af1d8881" category="doc">Technologieanforderungen</block>
  <block id="915f99cb757b24fafb485b82cc5fe20e" category="paragraph">Für die in diesem Dokument durchgeführten Validierungen wurden die unten beschriebenen Hardware- und Softwarekonfigurationen verwendet.  Diese Konfigurationen dienen als Richtlinie für die Einrichtung Ihrer Umgebung. Beachten Sie jedoch, dass die spezifischen Komponenten je nach den individuellen Kundenanforderungen variieren können.</block>
  <block id="47dee50ad0138b8f5ca70e40e86e6c04" category="section-title">Hardwareanforderungen</block>
  <block id="3c02a379965ab0dfcd77b1c484450433" category="cell">Hardware</block>
  <block id="74cc4ae913d72260c083ab2b346121ec" category="cell">NetApp AFF Storage-Array HA-Paar</block>
  <block id="e4044b704224bc11ad4a58e92f2131d7" category="list-text">A800</block>
  <block id="8020ad245e7cbc2ac49c84b7f4ace684" category="list-text">ONTAP 9.14.1</block>
  <block id="4c365c4afab33ac328254bd7c2ae19a9" category="list-text">48 x 3,49 TB SSD-NVM</block>
  <block id="fe001f20ed0495ea55b4938631878b7a" category="list-text">Zwei S3-Buckets: Dremio-Metadaten und Kundendaten.</block>
  <block id="637071f2d4a8f15942d2e18657010fa9" category="cell">4 x FUJITSU PRIMERGY RX2540 M4</block>
  <block id="e0c5e2628a6e691fa3fafe35f3bf20c3" category="list-text">64 CPUs</block>
  <block id="319d86787ef65ef260e666cc63f6e1a3" category="list-text">Intel Xeon Gold 6142 CPU @ 2,60 GHz</block>
  <block id="d6b9b9dc5caf5833c325bc02278f4817" category="list-text">256 GM physischer Speicher</block>
  <block id="81555075e106886f4be11de9599425a6" category="list-text">1 x 100GbE-Netzwerkanschluss</block>
  <block id="a5fa5746370b608090b994a97b49e98b" category="cell">Vernetzung</block>
  <block id="edcd3f3adc6d51b309e9115847fa497f" category="list-text">100 GbE</block>
  <block id="9de4526063d2d5dc8600f1abb273fb87" category="cell">* 1 x SG100, 3 x SGF6024 * 3 x 24 x 7,68 TB * Zwei S3-Buckets: Dremio-Metadaten und Kundendaten.</block>
  <block id="500084ff15a1d3831b2b0a0cc8efb3b4" category="list-text">Version - 25.0.3-202405170357270647-d2042e1b</block>
  <block id="b5251cb924b1e27d2fa914e7b3dbd75c" category="list-text">Enterprise Edition</block>
  <block id="cea575677c47839fde1e59dbfc9ad5bb" category="cell">Vor Ort</block>
  <block id="fd50fb0f59921345e87394051ed99e40" category="list-text">Dremio-Cluster mit 5 Knoten</block>
  <block id="743d1e7bf62dfc8a183c666693662dc6" category="list-text">1 Master-Koordinator und 4 Ausführende</block>
  <block id="cce86ec0e697036ce6aa6105904b06de" category="summary">Dieser Abschnitt behandelt die Anwendungsfalldetails von Dremio mit NetApp-Objektspeicher beim Kunden.</block>
  <block id="fe0bd5fc290c9a203c8e8f18a2b6e647" category="doc">Kundenanwendungsfälle</block>
  <block id="46233f9bd0306ff790c810922b25e957" category="section-title">NetApp ActiveIQ Anwendungsfall</block>
  <block id="994534c401b3a0f86cd899f3b7b6ec57" category="inline-image-macro">Alte ActiveIQ-Architektur</block>
  <block id="3002c8327e7407633cb1d61c6e798c05" category="paragraph"><block ref="3002c8327e7407633cb1d61c6e798c05" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e9e9a9c8ceef33ee9b9839f01cdf06a" category="paragraph">*Herausforderung*: NetApps eigene interne Active IQ Lösung, die ursprünglich zur Unterstützung zahlreicher Anwendungsfälle konzipiert wurde, hat sich zu einem umfassenden Angebot sowohl für interne Benutzer als auch für Kunden entwickelt.  Allerdings stellte die zugrunde liegende Hadoop/MapR-basierte Backend-Infrastruktur aufgrund des schnellen Datenwachstums und der Notwendigkeit eines effizienten Datenzugriffs Herausforderungen hinsichtlich Kosten und Leistung dar.  Die Skalierung des Speichers bedeutete das Hinzufügen unnötiger Rechenressourcen, was zu höheren Kosten führte.</block>
  <block id="66c90395e80a7e0f428abf5cf77fa1f4" category="paragraph">Darüber hinaus war die Verwaltung des Hadoop-Clusters zeitaufwändig und erforderte spezielles Fachwissen.  Probleme mit der Datenleistung und -verwaltung erschwerten die Situation zusätzlich: Abfragen dauerten durchschnittlich 45 Minuten und es kam aufgrund von Fehlkonfigurationen zu Ressourcenknappheit.  Um diese Herausforderungen zu bewältigen, suchte NetApp nach einer Alternative zur bestehenden Hadoop-Umgebung und kam zu dem Schluss, dass eine neue, moderne Lösung auf Basis von Dremio die Kosten senken, Speicher und Rechenleistung entkoppeln, die Leistung verbessern, das Datenmanagement vereinfachen, feinkörnige Kontrollen bieten und Disaster-Recovery-Funktionen bereitstellen würde.</block>
  <block id="f4327571cd8b76a68a25a1d8487a0db0" category="inline-image-macro">Neue ActiveIQ-Architektur mit dremio</block>
  <block id="954cc37909c75a2221a99b0c02a26f82" category="paragraph">*Lösung*:<block ref="4a878fba67d10f0324250d8d1dafdcc5" category="inline-image-macro-rx" type="image"></block> Dremio ermöglichte NetApp die schrittweise Modernisierung seiner Hadoop-basierten Dateninfrastruktur und stellte einen Fahrplan für einheitliche Analysen bereit.  Im Gegensatz zu anderen Anbietern, die erhebliche Änderungen an der Datenverarbeitung erforderten, ließ sich Dremio nahtlos in bestehende Pipelines integrieren, was bei der Migration Zeit und Kosten sparte.  Durch die Umstellung auf eine vollständig containerisierte Umgebung konnte NetApp den Verwaltungsaufwand reduzieren, die Sicherheit verbessern und die Ausfallsicherheit erhöhen.  Durch die Übernahme offener Ökosysteme wie Apache Iceberg und Arrow durch Dremio wurde Zukunftssicherheit, Transparenz und Erweiterbarkeit gewährleistet.</block>
  <block id="6f323477260e85221bf9876e157b69d0" category="paragraph">Als Ersatz für die Hadoop/Hive-Infrastruktur bot Dremio über die semantische Ebene Funktionalität für sekundäre Anwendungsfälle.  Während die vorhandenen Spark-basierten ETL- und Datenaufnahmemechanismen erhalten blieben, stellte Dremio eine einheitliche Zugriffsebene für eine einfachere Datenermittlung und -erkundung ohne Duplizierung bereit.  Dieser Ansatz reduzierte die Datenreplikationsfaktoren erheblich und entkoppelte Speicherung und Datenverarbeitung.</block>
  <block id="ef3e4aef01dbcfe8475e127bc34ac240" category="paragraph">*Vorteile*: Mit Dremio konnte NetApp durch die Minimierung des Rechenleistungsverbrauchs und des Speicherplatzbedarfs in seinen Datenumgebungen erhebliche Kostensenkungen erzielen.  Der neue Active IQ Data Lake besteht aus 8.900 Tabellen mit 3 Petabyte an Daten, verglichen mit der vorherigen Infrastruktur mit über 7 Petabyte.  Die Migration zu Dremio umfasste auch den Übergang von 33 Mini-Clustern und 4.000 Kernen zu 16 Executor-Knoten auf Kubernetes-Clustern.  Trotz erheblicher Reduzierung der Rechenressourcen konnte NetApp bemerkenswerte Leistungsverbesserungen erzielen.  Durch den direkten Datenzugriff über Dremio verringerte sich die Abfragelaufzeit von 45 Minuten auf 2 Minuten, was zu einer um 95 % schnelleren Gewinnung von Erkenntnissen für die vorausschauende Wartung und Optimierung führte.  Die Migration führte außerdem zu einer Reduzierung der Rechenkosten um mehr als 60 %, zu mehr als 20-mal schnelleren Abfragen und zu Einsparungen bei den Gesamtbetriebskosten (TCO) um mehr als 30 %.</block>
  <block id="a0c64f41c7126c9e86274e0e58d4bc01" category="section-title">Anwendungsfall für Kunden im Autoteileverkauf.</block>
  <block id="866dec6bda5d640e2bb5d1c8de8d6f67" category="paragraph">*Herausforderungen*: In diesem globalen Autoteilevertriebsunternehmen konnten sich die für die Finanzplanung und -analyse zuständigen Führungs- und Unternehmensgruppen keinen konsolidierten Überblick über die Verkaufsberichte verschaffen und waren gezwungen, die Verkaufskennzahlenberichte der einzelnen Geschäftsbereiche zu lesen und zu versuchen, diese zu konsolidieren.  Dies führte dazu, dass Kunden Entscheidungen auf der Grundlage von Daten trafen, die mindestens einen Tag alt waren.  Die Vorlaufzeiten für neue Analyseerkenntnisse betragen in der Regel mehr als vier Wochen.  Die Fehlerbehebung bei Datenpipelines würde noch mehr Zeit in Anspruch nehmen und den ohnehin schon langen Zeitplan um weitere drei Tage oder mehr verlängern.  Der langsame Berichtsentwicklungsprozess und die langsame Berichtsleistung zwangen die Analysten dazu, ständig auf die Verarbeitung oder das Laden der Daten zu warten, anstatt neue Geschäftseinblicke zu gewinnen und neues Geschäftsverhalten zu fördern.  Diese problematischen Umgebungen bestanden aus zahlreichen unterschiedlichen Datenbanken für unterschiedliche Geschäftsbereiche, was zu zahlreichen Datensilos führte.  Die langsame und fragmentierte Umgebung erschwerte die Datenverwaltung, da es für Analysten zu viele Möglichkeiten gab, ihre eigene Version der Wahrheit zu entwickeln, anstatt nur auf eine einzige Quelle der Wahrheit zurückgreifen zu müssen.  Der Ansatz kostete über 1,9 Millionen US-Dollar an Datenplattform- und Personalkosten.  Für die Wartung der alten Plattform und die Bearbeitung von Datenanfragen waren sieben technische Außendiensttechniker (Vollzeitäquivalente) pro Jahr erforderlich.  Angesichts der zunehmenden Datenanforderungen konnte das Data-Intelligence-Team die bestehende Umgebung nicht skalieren, um zukünftige Anforderungen zu erfüllen.</block>
  <block id="9de1ea6ce232738b38a6f50397411de0" category="paragraph">*Lösung*: Große Iceberg-Tabellen kostengünstig im NetApp Object Store speichern und verwalten.  Erstellen Sie Datendomänen mithilfe der semantischen Ebene von Dremio, sodass Geschäftsbenutzer Datenprodukte einfach erstellen, suchen und freigeben können.</block>
  <block id="859dc66fff375d140e35011f5d94d363" category="paragraph">*Vorteile für den Kunden*: • Verbesserte und optimierte vorhandene Datenarchitektur und Verkürzung der Zeit bis zum Erlangen von Erkenntnissen von vier Wochen auf nur wenige Stunden • Verkürzung der Fehlerbehebungszeit von drei Tagen auf nur wenige Stunden • Senkung der Kosten für Datenplattform und -verwaltung um mehr als 380.000 US-Dollar • (2) Vollzeitäquivalente an Data-Intelligence-Aufwand pro Jahr eingespart</block>
  <block id="4bf80525d5b2bad7362ea2ddc1239135" category="summary">Wir haben den TPC-DS-Test mit fünf Knoten für SQL-Workloads mit dem NetApp Objektspeicher wie in ONTAP und Storagegrid durchgeführt.</block>
  <block id="07c6b8ec7b7d3f9f4e97f8cab49e9952" category="doc">Übersicht zur Lösungsüberprüfung</block>
  <block id="d234b1c706880318f115c69f47d6dfa1" category="paragraph">In diesem Abschnitt haben wir SQL-Testabfragen aus mehreren Quellen ausgeführt, um die Funktionalität zu überprüfen und den Spillover zum NetApp -Speicher zu testen und zu verifizieren.</block>
  <block id="399acee44d644dcec9afa1fb807677db" category="section-title">SQL-Abfrage im Objektspeicher</block>
  <block id="fdbf3a00f4ffd80f1b71f818ac8c17b1" category="list-text">Stellen Sie den Speicher in dremio.env auf 250 GB pro Server ein</block>
  <block id="f01e72d5763f7ff9b6212ae55fe5a618" category="list-text">Überprüfen Sie den Überlaufspeicherort (${DREMIO_HOME}"/dremiocache) in der Datei dremio.conf und den Speicherdetails.</block>
  <block id="c1fd3f5160a9be68b59f1459ab2d43ab" category="list-text">Richten Sie den Dremio-Überlaufspeicherort auf den NetApp NFS-Speicher aus</block>
  <block id="876f04ac63af2ea2d5f8fa3785b310ca" category="list-text">Wählen Sie den Kontext aus.  In unserem Test haben wir den Test mit von TPCDS generierten Parquet-Dateien ausgeführt, die sich in ONTAP S3 befinden.  Dremio Dashboard -&gt; SQL-Runner -&gt; Kontext -&gt; NetAppONTAPS3-&gt;Parquet1TB</block>
  <block id="005d28008e05dae0767805243a8fb4e4" category="inline-image-macro">Legen Sie den Kontext auf den Parquet-Ordner ontaps3 fest</block>
  <block id="1737725edbb24ea279e1a45444de8083" category="paragraph"><block ref="1737725edbb24ea279e1a45444de8083" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d627092b3c15550dd7a319a2762deb9" category="list-text">Führen Sie die TPC-DS-Abfrage67 vom Dremio-Dashboard aus</block>
  <block id="d73e35125ec82123636d65f59cd30912" category="inline-image-macro">Führen Sie Abfrage 67 aus, eine von 99 Abfragen in TPC-DS</block>
  <block id="af576e90e15d8a6ff15105e65b4de6ca" category="paragraph"><block ref="af576e90e15d8a6ff15105e65b4de6ca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2f6a29c6a6cbd53a7eb78e09592b591" category="list-text">Überprüfen Sie, ob der Job auf allen Executoren ausgeführt wird.  Dremio-Dashboard -&gt; Jobs -&gt; &lt;Job-ID&gt; -&gt; Rohprofil -&gt; EXTERNAL_SORT auswählen -&gt; Hostname</block>
  <block id="cc8a9d0051ce4ea66245ee1201332dba" category="inline-image-macro">Liste der Knoten in der Q67-Abfrage</block>
  <block id="de7e26680d69dfee92356b33d4b9e852" category="paragraph"><block ref="de7e26680d69dfee92356b33d4b9e852" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d8ae43960f655adfac548cc72fd74e60" category="list-text">Wenn die SQL-Abfrage ausgeführt wird, können Sie den geteilten Ordner auf Daten-Caching im NetApp -Speichercontroller überprüfen.</block>
  <block id="a6b711eedf77bebde70bdfc6f869c41f" category="inline-image-macro">Überlaufdetails, wenn Abfrage 67 abgeschlossen ist</block>
  <block id="9e9d6f8f3555c800bdfb98b69c82c2df" category="list-text">Die SQL-Abfrage wurde mit Überlauf abgeschlossen<block ref="d1b3ed2b7bf78249ccd584f190063118" category="inline-image-macro-rx" type="image"></block></block>
  <block id="29f8ef4d2e7065fbaf7af29841718352" category="inline-image-macro">Jobzusammenfassung der abgeschlossenen Abfrage 67</block>
  <block id="af756b25baef2ba53e554daaf6f7d4b3" category="list-text">Zusammenfassung der Auftragserledigung.<block ref="91ffddffe841fcfba2fc7aad3683dff3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0de80fdbcc7438b84f536fcf74c03921" category="inline-image-macro">Splleddata-Details aus dem Abfrageergebnis</block>
  <block id="eacfb80ed9b3da589a06f11817a18a8e" category="list-text">Überprüfen Sie die Größe der verschütteten Daten<block ref="c25c4cfe2a16a40eeaf1652c7ba5d9f4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f8d7f6ab5b07156f7006507270c9869" category="paragraph">Das gleiche Verfahren gilt für NAS- und StorageGRID -Objektspeicher.</block>
  <block id="a64b3943d4911d301243b8ac8779ba53" category="summary">Dieser Abschnitt bietet eine Zusammenfassung der Anwendungsfälle und Lösungen von NetApp zur Erfüllung verschiedener Hadoop-Datenschutzanforderungen.</block>
  <block id="ac81718eacd21c51db78a7185a5c0a96" category="paragraph">Dieser Abschnitt bietet eine Zusammenfassung der Anwendungsfälle und Lösungen von NetApp zur Erfüllung verschiedener Hadoop-Datenschutzanforderungen.  Durch die Verwendung der von NetApp bereitgestellten Datenstruktur können Kunden:</block>
  <block id="095ece35729c37846889cf00d16bb141" category="list-text">Profitieren Sie von der Flexibilität, die richtigen Datenschutzlösungen auszuwählen, indem Sie die umfassenden Datenverwaltungsfunktionen von NetApp und die Integration mit nativen Hadoop-Workflows nutzen.</block>
  <block id="925b1719b2db8532854b1de76f928f31" category="list-text">Reduzieren Sie die Zeit des Backup-Fensters Ihres Hadoop-Clusters um fast 70 %.</block>
  <block id="7de96884f777b768ef12e40582f4d816" category="list-text">Beseitigen Sie alle Leistungseinbußen, die durch Hadoop-Cluster-Backups entstehen.</block>
  <block id="d5235d7ce8947322a12272f0c6dc7e24" category="list-text">Bieten Sie Multicloud-Datenschutz und Datenzugriff von verschiedenen Cloud-Anbietern gleichzeitig auf eine einzige Quelle von Analysedaten.</block>
  <block id="61e7eb3536cca4c51ae700159e1d247a" category="list-text">Erstellen Sie mithilfe der FlexClone -Technologie schnelle und platzsparende Hadoop-Clusterkopien.</block>
  <block id="64bb4a6337ad7b2efa8dc5d43d492edf" category="paragraph">Weitere Informationen zu den in diesem Dokument beschriebenen Informationen finden Sie in den folgenden Dokumenten und/oder auf den folgenden Websites:</block>
  <block id="253914d41704f0f326f6595e14005170" category="list-text">NetApp Big Data Analytics-Lösungen</block>
  <block id="85eb07da2e4fd15718f8d05d269a4e30" category="inline-link"><block ref="85eb07da2e4fd15718f8d05d269a4e30" category="inline-link-rx"></block></block>
  <block id="f87d78d98a2357057eba948402e285f0" category="paragraph"><block ref="f87d78d98a2357057eba948402e285f0" category="inline-link-rx"></block></block>
  <block id="b2eb92b872fe536c4a859e695eaf280d" category="list-text">Apache Spark Workload mit NetApp Storage</block>
  <block id="a904c9f7327a2cbf0c9411dd8b7551fa" category="inline-link"><block ref="a904c9f7327a2cbf0c9411dd8b7551fa" category="inline-link-rx"></block></block>
  <block id="3db0ab5f6c6b92b8d32d80cb1a83e214" category="paragraph"><block ref="3db0ab5f6c6b92b8d32d80cb1a83e214" category="inline-link-rx"></block></block>
  <block id="1bff250c7118efa9007019415bb2730d" category="list-text">NetApp Storage-Lösungen für Apache Spark</block>
  <block id="83d445161ea1f91a19d552f783018ea5" category="inline-link"><block ref="83d445161ea1f91a19d552f783018ea5" category="inline-link-rx"></block></block>
  <block id="142c737f7563ed12b8b08b6fc8779b8c" category="paragraph"><block ref="142c737f7563ed12b8b08b6fc8779b8c" category="inline-link-rx"></block></block>
  <block id="df245018c012fa9deefc0e1d65196e46" category="list-text">Apache Hadoop auf Data Fabric, unterstützt von NetApp</block>
  <block id="143ece864a38e1c8267bd8318d458955" category="inline-link"><block ref="143ece864a38e1c8267bd8318d458955" category="inline-link-rx"></block></block>
  <block id="b890b67174812331efb42656a186fa42" category="paragraph"><block ref="b890b67174812331efb42656a186fa42" category="inline-link-rx"></block></block>
  <block id="0407c27180c9b019e644e8ad4c6a9324" category="section-title">Danksagung</block>
  <block id="c4f052e8512b2541f8154dd256a529d6" category="list-text">Paul Burland, Vertriebsmitarbeiter, ANZ Victoria District Sales, NetApp</block>
  <block id="5d14432aa90b3b3ebfa87b98a1844edb" category="list-text">Hoseb Dermanilian, Business Development Manager, NetApp</block>
  <block id="929bdc02c2d9943ae8cb52786476e6c6" category="list-text">Lee Dorrier, Direktor MPSG, NetApp</block>
  <block id="a3ed56594a87e322fbcf5a6e705a4134" category="list-text">David Thiessen, Systemingenieur, ANZ Victoria District SE, NetApp</block>
  <block id="f6a738f75f76f62a241636eca02cd87d" category="section-title">Versionsverlauf</block>
  <block id="44749712dbec183e983dcd78a7736c41" category="cell">Datum</block>
  <block id="8002bc13927c65b5f265b031079ce1d4" category="cell">Dokumentversionsverlauf</block>
  <block id="3798985ee5e15c84c4263815d5a4d0b7" category="cell">Version 1.0</block>
  <block id="effdc6a5d743a9db1cd347a2ac8d6b80" category="cell">Januar 2018</block>
  <block id="dfd02aef9802f4824ead7c08b8f81f1f" category="cell">Erstveröffentlichung</block>
  <block id="304f30474edd152dc34aef7dbb123607" category="cell">Version 2.0</block>
  <block id="a5f3f63c2f6e1d6d4605650633b9ce8a" category="cell">Oktober 2021</block>
  <block id="81d2cd2b484f8c425c2146303b9f1c55" category="cell">Aktualisiert mit Anwendungsfall Nr. 5: Beschleunigen Sie die analytische Arbeitslast</block>
  <block id="46b9839969e4bc429da9cc245c756450" category="cell">Version 3.0</block>
  <block id="fb784db76f57bc935639ba5340089d77" category="cell">November 2023</block>
  <block id="11ec45d75a4ad726423d44fadee3074a" category="cell">NIPAM-Details entfernt</block>
  <block id="5e524f38cae9a99f3ebbaf012df2894e" category="summary">Das von NetApp unterstützte Datengewebe vereinfacht und integriert das Datenmanagement in Cloud- und lokalen Umgebungen, um die digitale Transformation zu beschleunigen.  Das von NetApp unterstützte Data Fabric bietet konsistente und integrierte Datenverwaltungsdienste und -anwendungen (Bausteine) für Datentransparenz und -einblicke, Datenzugriff und -kontrolle sowie Datenschutz und -sicherheit.</block>
  <block id="3c2db15f0fee10b08496ec1701f104d8" category="doc">Data Fabric powered by NetApp für Big Data-Architektur</block>
  <block id="981d357acc471e35d8d150f861ff1828" category="paragraph">Das von NetApp unterstützte Datengewebe vereinfacht und integriert das Datenmanagement in Cloud- und lokalen Umgebungen, um die digitale Transformation zu beschleunigen.</block>
  <block id="d5a64464c1e1f9d8be4cafc8b2325fa6" category="paragraph">Die von NetApp betriebene Datenstruktur bietet konsistente und integrierte Datenverwaltungsdienste und -anwendungen (Bausteine) für Datentransparenz und -einblicke, Datenzugriff und -kontrolle sowie Datenschutz und -sicherheit, wie in der folgenden Abbildung dargestellt.</block>
  <block id="42e5faac50fa6c299b9293560a7e7052" category="paragraph"><block ref="42e5faac50fa6c299b9293560a7e7052" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5083bdadc0fe82e6398670e5dcc6bff9" category="section-title">Bewährte Anwendungsfälle für Data Fabric-Kunden</block>
  <block id="3c1223e53bc7b972a018d3e2597e0bfd" category="paragraph">Das von NetApp unterstützte Data Fabric bietet Kunden die folgenden neun bewährten Anwendungsfälle:</block>
  <block id="a6800f5cacde75e6f1cfb931a6f2dba6" category="list-text">Beschleunigen Sie Analyse-Workloads</block>
  <block id="5b0fa9517345824f19ceddd9d0cd39de" category="list-text">Beschleunigen Sie die DevOps-Transformation</block>
  <block id="90ed50a34505fc6883bd65c36ed8b810" category="list-text">Erstellen Sie eine Cloud-Hosting-Infrastruktur</block>
  <block id="f3933541659deec9d28aa584238f0468" category="list-text">Integrieren Sie Cloud-Datendienste</block>
  <block id="d70909396aef5247a5a1b17dd15cf43d" category="list-text">Schützen und sichern Sie Daten</block>
  <block id="7af5a6e7f241b8d284656f20880db36f" category="list-text">Optimieren Sie unstrukturierte Daten</block>
  <block id="2c63452d476328fa43a39c00bef366f1" category="list-text">Steigern Sie die Effizienz Ihres Rechenzentrums</block>
  <block id="0f72ba4c2b371e4f9f47e7d8c61468a5" category="list-text">Liefern Sie Dateneinblicke und Kontrolle</block>
  <block id="0da79db0a9974fc0002f744165467752" category="list-text">Vereinfachen und automatisieren</block>
  <block id="5d5b69e7e19270db49a42eb4e96be2ee" category="paragraph">Dieses Dokument behandelt zwei der neun Anwendungsfälle (zusammen mit ihren Lösungen):</block>
  <block id="7adb8b5c573e74594feeb2f74e1ffc96" category="section-title">NetApp NFS-Direktzugriff</block>
  <block id="c2915c2b980396a00c86766bff7195e3" category="paragraph">Mit NetApp NFS können Kunden Big Data-Analysejobs auf ihren vorhandenen oder neuen NFSv3- oder NFSv4-Daten ausführen, ohne die Daten zu verschieben oder zu kopieren.  Es verhindert mehrere Kopien der Daten und macht die Synchronisierung der Daten mit einer Quelle überflüssig.  Im Finanzsektor beispielsweise muss die Bewegung von Daten von einem Ort zu einem anderen gesetzlichen Verpflichtungen genügen, was keine leichte Aufgabe ist.  In diesem Szenario analysiert der NetApp NFS-Direktzugriff die Finanzdaten von ihrem ursprünglichen Speicherort.  Ein weiterer wichtiger Vorteil besteht darin, dass die Verwendung des NetApp NFS-Direktzugriffs den Schutz von Hadoop-Daten durch die Verwendung nativer Hadoop-Befehle vereinfacht und Datenschutz-Workflows ermöglicht, die das umfangreiche Datenmanagement-Portfolio von NetApp nutzen.</block>
  <block id="1e72dcaa767fcc4be580ce5e9e1b52ea" category="paragraph"><block ref="1e72dcaa767fcc4be580ce5e9e1b52ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aa47c768dc0f007b4606d394be4330c3" category="paragraph">Der NetApp NFS-Direktzugriff bietet zwei Arten von Bereitstellungsoptionen für Hadoop/Spark-Cluster:</block>
  <block id="cc7514a5b2b35641026a81211ae7fe9a" category="list-text">Standardmäßig verwenden die Hadoop/Spark-Cluster das Hadoop Distributed File System (HDFS) zur Datenspeicherung und als Standarddateisystem.  Der NetApp NFS-Direktzugriff kann das Standard-HDFS durch NFS-Speicher als Standarddateisystem ersetzen und ermöglicht so direkte Analysevorgänge auf NFS-Daten.</block>
  <block id="5a5dace50e75999dec9323da42fe5410" category="list-text">In einer anderen Bereitstellungsoption unterstützt der NetApp NFS-Direktzugriff die Konfiguration von NFS als zusätzlichen Speicher zusammen mit HDFS in einem einzelnen Hadoop/Spark-Cluster.  In diesem Fall kann der Kunde Daten über NFS-Exporte freigeben und zusammen mit HDFS-Daten vom selben Cluster aus darauf zugreifen.</block>
  <block id="933871f01596456078e75585ab9480ae" category="paragraph">Zu den wichtigsten Vorteilen der Verwendung des NetApp NFS-Direktzugriffs gehören:</block>
  <block id="bc3221e251e23e5ee9782e37b0337c38" category="list-text">Analysiert die Daten von ihrem aktuellen Standort aus, wodurch die zeit- und leistungsintensive Aufgabe des Verschiebens von Analysedaten in eine Hadoop-Infrastruktur wie HDFS vermieden wird.</block>
  <block id="fe5efea0cd6733d158bfb04016f055f0" category="list-text">Reduziert die Anzahl der Replikate von drei auf eins.</block>
  <block id="21b00f92397ca3c72f6407dd3a873e23" category="list-text">Ermöglicht Benutzern, Rechenleistung und Speicher zu entkoppeln, um sie unabhängig voneinander zu skalieren.</block>
  <block id="be7e2eb6e940a1e798db3abedc75b7a8" category="list-text">Bietet Unternehmensdatenschutz durch Nutzung der umfassenden Datenverwaltungsfunktionen von ONTAP.</block>
  <block id="acc50ec5f7ffe1b08ee357afcb502a0f" category="list-text">Ist mit der Hortonworks-Datenplattform zertifiziert.</block>
  <block id="be5acbdc2ea462a8345ea92d4c42511c" category="list-text">Ermöglicht die Bereitstellung hybrider Datenanalysen.</block>
  <block id="227afbdb4ab9214131d6ca5ca3df3cd6" category="list-text">Reduziert die Sicherungszeit durch Nutzung der dynamischen Multithread-Funktion.</block>
  <block id="787364630dc10cfc2657bc82f289a9fb" category="section-title">Bausteine für Big Data</block>
  <block id="7698deb733ad601844c58f0102d0470c" category="paragraph">Das von NetApp betriebene Datengewebe integriert Datenverwaltungsdienste und Anwendungen (Bausteine) für Datenzugriff, -kontrolle, -schutz und -sicherheit, wie in der folgenden Abbildung dargestellt.</block>
  <block id="daa25861e76d8b4617b478f8cd89c0b2" category="paragraph"><block ref="daa25861e76d8b4617b478f8cd89c0b2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="162f2b2249f4b8bda40b0c01043779b3" category="paragraph">Zu den Bausteinen in der obigen Abbildung gehören:</block>
  <block id="e64f250539a531b81423d6f3f4729665" category="list-text">* NetApp NFS-Direktzugriff.*  Bietet den neuesten Hadoop- und Spark-Clustern direkten Zugriff auf NetApp NFS-Volumes ohne zusätzliche Software- oder Treiberanforderungen.</block>
  <block id="f79865a14977797753199d8c238eade6" category="list-text">* NetApp Cloud Volumes ONTAP und Google Cloud NetApp Volumes.*  Softwaredefinierter verbundener Speicher basierend auf ONTAP , der in Amazon Web Services (AWS) oder Azure NetApp Files (ANF) in Microsoft Azure-Clouddiensten ausgeführt wird.</block>
  <block id="5d382bdcedb0a9c7aa214b09e129e5e7" category="list-text">* NetApp SnapMirror -Technologie*.  Bietet Datenschutzfunktionen zwischen lokalen und ONTAP Cloud- oder NPS-Instanzen.</block>
  <block id="e2d911047fad9851fae1d7c4e71b2fab" category="list-text">*Cloud-Dienstanbieter.*  Zu diesen Anbietern gehören AWS, Microsoft Azure, Google Cloud und IBM Cloud.</block>
  <block id="486add91df5cb94a1fee5fccffe4f39b" category="list-text">*PaaS.*  Cloudbasierte Analysedienste wie Amazon Elastic MapReduce (EMR) und Databricks in AWS sowie Microsoft Azure HDInsight und Azure Databricks.</block>
  <block id="df343d31543826a7505d157cf243c96a" category="summary">Hadoop DistCp ist ein natives Tool zum Kopieren großer Datenmengen zwischen und innerhalb von Clustern.  Der grundlegende Hadoop DistCp-Prozess ist ein typischer Sicherungsworkflow, bei dem Hadoop-native Tools wie MapReduce verwendet werden, um Hadoop-Daten von einer HDFS-Quelle auf ein entsprechendes Ziel zu kopieren.</block>
  <block id="2a377dc939cca8cab65101c1869d628d" category="doc">Hadoop-Datenschutz und NetApp</block>
  <block id="1d766990d66db8e06b462398928288cd" category="paragraph">Hadoop DistCp ist ein natives Tool zum Kopieren großer Datenmengen zwischen und innerhalb von Clustern.  Der in der folgenden Abbildung dargestellte grundlegende Hadoop DistCp-Prozess ist ein typischer Sicherungsworkflow, bei dem native Hadoop-Tools wie MapReduce verwendet werden, um Hadoop-Daten von einer HDFS-Quelle auf ein entsprechendes Ziel zu kopieren.</block>
  <block id="7cded69de10ed23fb288e8f481913718" category="paragraph">Der NetApp NFS-Direktzugriff ermöglicht es Kunden, NFS als Ziel für das Hadoop DistCp-Tool festzulegen, um die Daten über MapReduce von der HDFS-Quelle in eine NFS-Freigabe zu kopieren.  Der NetApp NFS-Direktzugriff fungiert als NFS-Treiber für das DistCp-Tool.</block>
  <block id="3225c81e14f83a90295391be9d81302a" category="paragraph"><block ref="3225c81e14f83a90295391be9d81302a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cedd54d52b90b58fb9615e956db81629" category="summary">Dieses Dokument beschreibt Hybrid-Cloud-Datenlösungen mit NetApp AFF und FAS Speichersystemen, NetApp Cloud Volumes ONTAP, NetApp Connected Storage und NetApp FlexClone -Technologie für Spark und Hadoop.  Diese Lösungsarchitekturen ermöglichen es Kunden, eine geeignete Datenschutzlösung für ihre Umgebung auszuwählen.  NetApp hat diese Lösungen auf der Grundlage der Interaktion mit Kunden und ihren geschäftlichen Anwendungsfällen entwickelt.</block>
  <block id="71932d00608c3a9fe13a866ab35227f6" category="paragraph">Karthikeyan Nagalingam und Sathish Thyagarajan, NetApp</block>
  <block id="8b6b60ca3f35331d22d686d9c4e12871" category="paragraph">Dieses Dokument beschreibt Hybrid-Cloud-Datenlösungen mit NetApp AFF und FAS Speichersystemen, NetApp Cloud Volumes ONTAP, NetApp Connected Storage und NetApp FlexClone -Technologie für Spark und Hadoop.  Diese Lösungsarchitekturen ermöglichen es Kunden, eine geeignete Datenschutzlösung für ihre Umgebung auszuwählen.  NetApp hat diese Lösungen auf der Grundlage der Interaktion mit Kunden und ihren geschäftlichen Anwendungsfällen entwickelt.  Dieses Dokument enthält die folgenden detaillierten Informationen:</block>
  <block id="d928ac205302ed3d60386e2a4759c6d6" category="list-text">Warum wir Datenschutz für Spark- und Hadoop-Umgebungen und Kundenherausforderungen benötigen.</block>
  <block id="4444991e618ed955b12fdbcf746ad762" category="list-text">Das Data Fabric basiert auf NetApp Vision und seinen Bausteinen und Services.</block>
  <block id="018b3e5bb8ca92450618b4f5ff9719f7" category="list-text">Wie diese Bausteine zum Entwerfen flexibler Datenschutz-Workflows verwendet werden können.</block>
  <block id="30b68051de2b69f7d6ab186bed865f7c" category="list-text">Die Vor- und Nachteile mehrerer Architekturen basierend auf realen Anwendungsfällen von Kunden.  Jeder Anwendungsfall stellt die folgenden Komponenten bereit:</block>
  <block id="acf055fa7efae33ce06471f448ae1267" category="list-text">Kundenszenarien</block>
  <block id="5f5e12d29ffccf33e8cb5a30f4d2fe8c" category="list-text">Anforderungen und Herausforderungen</block>
  <block id="2a9dbfa4b74c53d7304fc8b79a1874d3" category="list-text">Lösungen</block>
  <block id="cb9825c3c7619f7000c8452d9005aa5b" category="list-text">Zusammenfassung der Lösungen</block>
  <block id="40300466f60ef41f731d7fd45a1024e2" category="section-title">Warum Hadoop-Datenschutz?</block>
  <block id="d54234515a0cb2905eb88ccb03d85491" category="paragraph">In einer Hadoop- und Spark-Umgebung müssen die folgenden Aspekte berücksichtigt werden:</block>
  <block id="9ed257b8e8a9504946fcf430ea2e12e3" category="list-text">*Software- oder menschliches Versagen.*  Menschliche Fehler bei Software-Updates während der Durchführung von Hadoop-Datenoperationen können zu fehlerhaftem Verhalten führen, das unerwartete Ergebnisse des Auftrags zur Folge haben kann.  In einem solchen Fall müssen wir die Daten schützen, um Fehler oder unangemessene Ergebnisse zu vermeiden.  Beispielsweise kann aufgrund eines schlecht ausgeführten Software-Updates einer Anwendung zur Verkehrssignalanalyse eine neue Funktion die im Klartext vorliegenden Verkehrssignaldaten nicht richtig analysieren.  Die Software analysiert weiterhin JSON und andere Nicht-Text-Dateiformate, was dazu führt, dass das Echtzeit-Verkehrskontrollanalysesystem Vorhersageergebnisse erzeugt, bei denen Datenpunkte fehlen.  Diese Situation kann zu fehlerhaften Ausgaben führen, die zu Unfällen an der Ampel führen können.  Der Datenschutz kann dieses Problem lösen, indem er die Möglichkeit bietet, schnell zur vorherigen funktionierenden Anwendungsversion zurückzukehren.</block>
  <block id="38b145294d087c4d733df994e6a7b6c1" category="list-text">*Größe und Maßstab.*  Aufgrund der ständig zunehmenden Anzahl von Datenquellen und Datenvolumina wächst der Umfang der Analysedaten täglich.  Soziale Medien, mobile Apps, Datenanalysen und Cloud-Computing-Plattformen sind die wichtigsten Datenquellen im aktuellen Big-Data-Markt, der sehr schnell wächst. Daher müssen die Daten geschützt werden, um einen genauen Datenbetrieb zu gewährleisten.</block>
  <block id="612be5fe1026c2566014b79f77403701" category="list-text">*Hadoops nativer Datenschutz.*  Hadoop verfügt über einen nativen Befehl zum Schutz der Daten, dieser Befehl gewährleistet jedoch keine Datenkonsistenz während der Sicherung.  Es unterstützt nur die Sicherung auf Verzeichnisebene.  Die von Hadoop erstellten Snapshots sind schreibgeschützt und können nicht zur direkten Wiederverwendung der Sicherungsdaten verwendet werden.</block>
  <block id="e664ca405ed3e90fecf2e085985fe24c" category="section-title">Datenschutzherausforderungen für Hadoop- und Spark-Kunden</block>
  <block id="c2d49a2ee903d6d86976c3618079a61d" category="paragraph">Eine häufige Herausforderung für Hadoop- und Spark-Kunden besteht darin, die Sicherungszeit zu verkürzen und die Zuverlässigkeit der Sicherung zu erhöhen, ohne die Leistung des Produktionsclusters während der Datensicherung negativ zu beeinflussen.</block>
  <block id="8d54bea5cb89e665d1a703529f703765" category="paragraph">Kunden müssen außerdem die Ausfallzeiten im Hinblick auf Recovery Point Objective (RPO) und Recovery Time Objective (RTO) minimieren und ihre lokalen und Cloud-basierten Disaster-Recovery-Sites für optimale Geschäftskontinuität kontrollieren.  Diese Kontrolle wird in der Regel durch den Einsatz von Managementtools auf Unternehmensebene erreicht.</block>
  <block id="042be4d2813fd31d6b49e6eeaa1a42c3" category="paragraph">Die Hadoop- und Spark-Umgebungen sind kompliziert, da nicht nur das Datenvolumen riesig ist und wächst, sondern auch die Geschwindigkeit, mit der diese Daten eintreffen, zunimmt.  Dieses Szenario erschwert die schnelle Erstellung effizienter und aktueller DevTest- und QA-Umgebungen aus den Quelldaten.  NetApp ist sich dieser Herausforderungen bewusst und bietet die in diesem Dokument vorgestellten Lösungen an.</block>
  <block id="7d617748001976c06ae87f824ca77b2d" category="summary">In diesem Szenario wurde die Analyseplattform einer großen Finanzdienstleistungs- und Investmentbank mithilfe der NetApp NFS-Speicherlösung modernisiert, um eine deutliche Verbesserung bei der Analyse von Anlagerisiken und Derivaten für ihre Vermögensverwaltungs- und quantitative Geschäftseinheit zu erreichen.</block>
  <block id="0158648474e8dffab94ca58af2257b92" category="doc">Anwendungsfall 5: Beschleunigen analytischer Workloads</block>
  <block id="54861efdd06fc309e1c9a420feff98eb" category="section-title">Szenario</block>
  <block id="f3274c43bc916b05ebe766167f47a1ad" category="paragraph">In der bestehenden Umgebung des Kunden nutzte die für die Analyseplattform verwendete Hadoop-Infrastruktur den internen Speicher der Hadoop-Server.  Aufgrund der proprietären Natur der JBOD-Umgebung konnten viele interne Kunden innerhalb der Organisation ihr quantitatives Monte-Carlo-Modell nicht nutzen, eine Simulation, die auf wiederkehrenden Stichproben von Echtzeitdaten basiert.  Die unzureichende Fähigkeit, die Auswirkungen der Unsicherheit bei Marktbewegungen zu verstehen, wirkte sich nachteilig auf die Geschäftseinheit für quantitatives Asset Management aus.</block>
  <block id="788ab145281501314f18747a0ab1eaea" category="paragraph">Die quantitative Geschäftseinheit der Bank wollte eine effiziente Prognosemethode, um genaue und zeitnahe Vorhersagen zu erzielen.  Um dies zu erreichen, erkannte das Team die Notwendigkeit, die Infrastruktur zu modernisieren, die bestehende E/A-Wartezeit zu reduzieren und die Leistung der Analyseanwendungen wie Hadoop und Spark zu verbessern, um Investitionsmodelle effizient zu simulieren, potenzielle Gewinne zu messen und Risiken zu analysieren.</block>
  <block id="49b21ad0d38942f635877e7bbc5d7a1e" category="section-title">Lösung</block>
  <block id="43b3ece7a28edcf11ee066112179b834" category="paragraph">Der Kunde hatte JBOD für seine bestehende Spark-Lösung.  NetApp ONTAP, NetApp StorageGRID und MinIO Gateway to NFS wurden dann genutzt, um die E/A-Wartezeit für die quantitative Finanzgruppe der Bank zu reduzieren, die Simulationen und Analysen von Investitionsmodellen durchführt, um potenzielle Gewinne und Risiken zu bewerten.  Dieses Bild zeigt die Spark-Lösung mit NetApp -Speicher.</block>
  <block id="d9e962022f714fc5ed8bccce82c920ac" category="paragraph"><block ref="d9e962022f714fc5ed8bccce82c920ac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3a052314babbb25c995c7b6b2b18d04" category="paragraph">Wie in der Abbildung oben gezeigt, wurden AFF A800 und A700-Systeme sowie StorageGRID bereitgestellt, um über NFS- und S3-Protokolle in einem Hadoop-Cluster mit sechs Knoten mit Spark sowie YARN- und Hive-Metadatendiensten für Datenanalysevorgänge auf Parquet-Dateien zuzugreifen.</block>
  <block id="473d88a5512cc81d2571425bbea591d2" category="paragraph">Eine Direct-Attached-Storage-Lösung (DAS) in der alten Umgebung des Kunden hatte den Nachteil, dass Rechenleistung und Speicher unabhängig voneinander skaliert werden mussten.  Mit der NetApp ONTAP -Lösung für Spark konnte die Geschäftseinheit für Finanzanalysen der Bank Speicher und Rechenleistung entkoppeln und Infrastrukturressourcen bei Bedarf nahtlos und effektiver bereitstellen.</block>
  <block id="fceb3129a02a41b3231baa9b6f633217" category="paragraph">Durch die Verwendung von ONTAP mit NFS wurden die CPUs des Compute-Servers für Spark SQL-Jobs fast vollständig genutzt und die E/A-Wartezeit um fast 70 % reduziert, was zu einer besseren Rechenleistung und Leistungssteigerung für Spark-Workloads führte.  Durch die anschließende Erhöhung der CPU-Auslastung konnte der Kunde auch GPUs wie GPUDirect für eine weitere Modernisierung der Plattform nutzen.  Darüber hinaus bietet StorageGRID eine kostengünstige Speicheroption für Spark-Workloads und MinIO Gateway bietet sicheren Zugriff auf NFS-Daten über das S3-Protokoll.  Für Daten in der Cloud empfiehlt NetApp Cloud Volumes ONTAP, Azure NetApp Files und Google Cloud NetApp Volumes.</block>
  <block id="9d9b3c1914053d9ff102d01b77ab40a9" category="summary">Dieser Anwendungsfall basiert auf einem Rundfunkkunden, der Cloud-basierte Analysedaten in seinem lokalen Rechenzentrum sichern muss.</block>
  <block id="0abf694ae9fa8ac43b805ba39a10d143" category="doc">Anwendungsfall 2: Backup und Disaster Recovery von der Cloud in die lokale Umgebung</block>
  <block id="733d8d14fe9ffb98d02b33079e3d3db2" category="paragraph">Dieser Anwendungsfall basiert auf einem Rundfunkkunden, der Cloud-basierte Analysedaten in seinem lokalen Rechenzentrum sichern muss, wie in der folgenden Abbildung dargestellt.</block>
  <block id="56f5fb8db5f5326b20e3fe17ce11efa4" category="paragraph"><block ref="56f5fb8db5f5326b20e3fe17ce11efa4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26fea23389e404e4cb8cf9be2c100cbd" category="paragraph">In diesem Szenario werden die IoT-Sensordaten in die Cloud eingespeist und mithilfe eines Open-Source-Apache-Spark-Clusters innerhalb von AWS analysiert.  Voraussetzung ist, dass die verarbeiteten Daten aus der Cloud vor Ort gesichert werden.</block>
  <block id="c04f16bb8233216a472d30b6c509b230" category="paragraph">Zu den wichtigsten Anforderungen und Herausforderungen für diesen Anwendungsfall gehören:</block>
  <block id="bb446485afc21a80bc5f26a9131de160" category="list-text">Das Aktivieren des Datenschutzes sollte keine Auswirkungen auf die Leistung des Spark/Hadoop-Produktionsclusters in der Cloud haben.</block>
  <block id="dbb6231aec34eed7c53cff2d4a2d43ef" category="list-text">Cloud-Sensordaten müssen effizient und sicher vor Ort verschoben und geschützt werden.</block>
  <block id="848b66ad8aca524142404de79ce64c73" category="list-text">Flexibilität bei der Datenübertragung von der Cloud zu lokalen Standorten unter verschiedenen Bedingungen, z. B. bei Bedarf, sofort und bei geringer Cluster-Auslastung.</block>
  <block id="4d8011e28e4ef4359ca7c169e7797091" category="paragraph">Der Kunde verwendet AWS Elastic Block Store (EBS) für seinen Spark-Cluster-HDFS-Speicher, um Daten von Remote-Sensoren über Kafka zu empfangen und aufzunehmen.  Folglich fungiert der HDFS-Speicher als Quelle für die Sicherungsdaten.</block>
  <block id="e55d60f6f17896ce9b53a0ef23e23413" category="paragraph">Um diese Anforderungen zu erfüllen, wird NetApp ONTAP Cloud in AWS bereitgestellt und eine NFS-Freigabe erstellt, die als Sicherungsziel für den Spark/Hadoop-Cluster fungiert.</block>
  <block id="3c0f76e2d6fa82b2004270ec86f39aa7" category="paragraph">Nachdem die NFS-Freigabe erstellt wurde, kopieren Sie die Daten aus dem HDFS-EBS-Speicher in die ONTAP -NFS-Freigabe.  Nachdem die Daten in NFS in ONTAP Cloud gespeichert wurden, können die Daten mithilfe der SnapMirror -Technologie bei Bedarf sicher und effizient aus der Cloud in den lokalen Speicher gespiegelt werden.</block>
  <block id="aecad7c5bdfba92aa6cd945a9045c37f" category="paragraph">Dieses Bild zeigt die Backup- und Disaster-Recovery-Lösung von der Cloud zur lokalen Lösung.</block>
  <block id="6d742f93cf04e332b07c93ce2bc96163" category="paragraph"><block ref="6d742f93cf04e332b07c93ce2bc96163" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1dca3067f5c6c2fa6b32ef683fcab56f" category="summary">In diesem Szenario verfügt der Kunde über ein großes lokales Hadoop-Repository und möchte es für die Notfallwiederherstellung sichern.  Die aktuelle Backup-Lösung des Kunden ist jedoch kostspielig und leidet unter einem langen Backup-Fenster von mehr als 24 Stunden.</block>
  <block id="817ac2975197bd6c376a7918a798981f" category="doc">Anwendungsfall 1: Sichern von Hadoop-Daten</block>
  <block id="7ffe71c29f8ea391bbd80c1e8441af9a" category="list-text">Software-Abwärtskompatibilität:</block>
  <block id="d96828d85e8cc053407a391bee52257f" category="list-text">Die vorgeschlagene alternative Sicherungslösung sollte mit den aktuell im Produktions-Hadoop-Cluster verwendeten Softwareversionen kompatibel sein.</block>
  <block id="dd5bb530e532c011487ffc3a69e56f57" category="list-text">Um die vereinbarten SLAs einzuhalten, sollte die vorgeschlagene Alternativlösung sehr niedrige RPOs und RTOs erreichen.</block>
  <block id="4783ab1f0401dc9c24cc9afa6dc5823e" category="list-text">Das von der NetApp Backup-Lösung erstellte Backup kann sowohl im lokal im Rechenzentrum erstellten Hadoop-Cluster als auch im Hadoop-Cluster verwendet werden, der am Disaster-Recovery-Standort am Remote-Standort ausgeführt wird.</block>
  <block id="1dbc869d2df036d4d6e732e9c680ab6b" category="list-text">Die vorgeschlagene Lösung muss kosteneffizient sein.</block>
  <block id="7405e6ba4b630f11b88a7976325a95e4" category="list-text">Die vorgeschlagene Lösung muss die Leistungseinbußen bei den aktuell laufenden, produktiven Analysejobs während der Sicherungszeiten reduzieren.</block>
  <block id="265e759e2a3b4c55776e0de53887b3b4" category="section-title">Vorhandene Backup-Lösung des Kundenx</block>
  <block id="f350f804f84a5bf788cd78cd4aae7eab" category="paragraph">Die folgende Abbildung zeigt die ursprüngliche native Hadoop-Backup-Lösung.</block>
  <block id="f9efb12aa8582a65d79ac1fcd7574665" category="paragraph"><block ref="f9efb12aa8582a65d79ac1fcd7574665" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76b8e496c38192b97fdfa6cae2ba2bb4" category="paragraph">Die Produktionsdaten werden über den Zwischensicherungscluster auf Band gesichert:</block>
  <block id="d07ca391addc59b7408fb88541552b43" category="list-text">HDFS1-Daten werden nach HDFS2 kopiert, indem der<block ref="56eafdf3e9748260b9403493314dc20d" prefix=" " category="inline-code"></block> Befehl.</block>
  <block id="2c4cadbb7f122d1d0cd988a11681248a" category="list-text">Der Backup-Cluster fungiert als NFS-Gateway und die Daten werden manuell über das Linux-System auf Band kopiert.<block ref="9c95319bf274672d6eae7eb97c3dfda5" prefix=" " category="inline-code"></block> Befehl durch die Bandbibliothek.</block>
  <block id="b73035943c8623cbdb7bd67992201012" category="paragraph">Zu den Vorteilen der ursprünglichen nativen Hadoop-Backup-Lösung gehören:</block>
  <block id="5bdb90a1352ca42ab8dde5b9ab7ffac3" category="list-text">Die Lösung basiert auf nativen Hadoop-Befehlen, sodass der Benutzer keine neuen Verfahren erlernen muss.</block>
  <block id="f581d1b5f93adda1865bad95e215a7b9" category="list-text">Die Lösung nutzt eine dem Industriestandard entsprechende Architektur und Hardware.</block>
  <block id="ddd131647a4d5e1b5bcb983ec8872ff9" category="paragraph">Zu den Nachteilen der ursprünglichen nativen Hadoop-Backup-Lösung gehören:</block>
  <block id="2cd5e9eae715f3bb0475ed032bf56190" category="list-text">Das lange Backup-Fenster beträgt mehr als 24 Stunden, wodurch die Produktionsdaten gefährdet sind.</block>
  <block id="b22d500a5624a2c57ec5bda86aa57011" category="list-text">Erhebliche Leistungseinbußen des Clusters während der Sicherungszeiten.</block>
  <block id="69bfe7f4231b0c1d65247d0abfc89cb3" category="list-text">Das Kopieren auf Band ist ein manueller Vorgang.</block>
  <block id="6ef8e4ec49425ac5ded9c6cc599c17d2" category="list-text">Die Backup-Lösung ist hinsichtlich der erforderlichen Hardware und der für manuelle Prozesse erforderlichen Arbeitsstunden teuer.</block>
  <block id="1b4d2bf420e7f05ecb82ecf2197ab810" category="section-title">Backup-Lösungen</block>
  <block id="6d977e36854ae6439cbc4fe8e0c1b227" category="paragraph">Basierend auf diesen Herausforderungen und Anforderungen und unter Berücksichtigung des vorhandenen Backup-Systems wurden drei mögliche Backup-Lösungen vorgeschlagen.  In den folgenden Unterabschnitten werden die drei verschiedenen Sicherungslösungen mit den Bezeichnungen Lösung A bis Lösung C beschrieben.</block>
  <block id="c5a6c012dc14dc7f9d2fa0df0ccb0cdf" category="section-title">Lösung A</block>
  <block id="bc98837ed486c01d428d23d0c3a83d6a" category="paragraph">In Lösung A sendet der Hadoop-Backup-Cluster die sekundären Backups an NetApp NFS-Speichersysteme, wodurch die Bandanforderung entfällt, wie in der folgenden Abbildung dargestellt.</block>
  <block id="c7446a7fd101a1f229e62b8dfc3f2627" category="paragraph"><block ref="c7446a7fd101a1f229e62b8dfc3f2627" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2813f022c034c63ad3d6efeeb503eb70" category="paragraph">Die detaillierten Aufgaben für Lösung A umfassen:</block>
  <block id="0406c5ca05cfb5f7a0c02971c3962460" category="list-text">Der Produktions-Hadoop-Cluster verfügt über die Analysedaten des Kunden im HDFS, die geschützt werden müssen.</block>
  <block id="feb7749ff700168c127dfbd8376b35f7" category="list-text">Der Backup-Hadoop-Cluster mit HDFS fungiert als Zwischenspeicherort für die Daten.  Nur eine Reihe von Festplatten (JBOD) stellt den Speicher für HDFS sowohl in den Produktions- als auch in den Backup-Hadoop-Clustern bereit.</block>
  <block id="b3f54540429c806b8cf0080fd78b34bc" category="list-text">Schützen Sie die Hadoop-Produktionsdaten vom Produktionscluster HDFS zum Backup-Cluster HDFS, indem Sie Folgendes ausführen:<block ref="900bb9daf20a55f63530a23a8ff21d21" prefix=" " category="inline-code"></block> Befehl.</block>
  <block id="2de4833848a0b94bd672bdf9bc60d4aa" category="admonition">Der Hadoop-Snapshot wird verwendet, um die Daten vor der Produktion im Hadoop-Backup-Cluster zu schützen.</block>
  <block id="79ef8fc2c565c69b33f5918c3a0bdd9a" category="list-text">Der NetApp ONTAP Speichercontroller stellt ein per NFS exportiertes Volume bereit, das für den Backup-Hadoop-Cluster bereitgestellt wird.</block>
  <block id="1b449b0ea4a324dc81f41259db2c13e9" category="list-text">Durch Ausführen des<block ref="e23fdb1dae75e2830274d92fdf2535ed" prefix=" " category="inline-code"></block> Durch den Einsatz von MapReduce und mehreren Mappern werden die Analysedaten vom Backup-Hadoop-Cluster auf NFS geschützt.</block>
  <block id="738997de22c6371f563f69e1bb57b6e5" category="paragraph">Nachdem die Daten in NFS auf dem NetApp -Speichersystem gespeichert wurden, werden die Technologien NetApp Snapshot, SnapRestore und FlexClone verwendet, um die Hadoop-Daten nach Bedarf zu sichern, wiederherzustellen und zu duplizieren.</block>
  <block id="0bd252182290e872b264ad65d369637f" category="admonition">Hadoop-Daten können mithilfe der SnapMirror -Technologie sowohl in der Cloud als auch an Disaster-Recovery-Standorten geschützt werden.</block>
  <block id="4a1b9aaeaa6487c6df7072326cf3798e" category="paragraph">Zu den Vorteilen von Lösung A gehören:</block>
  <block id="0843e6a882cae98851adbefb52d05827" category="list-text">Hadoop-Produktionsdaten werden vor dem Backup-Cluster geschützt.</block>
  <block id="522d0cf303cbf1b16ea5cc33480ce02f" category="list-text">HDFS-Daten werden durch NFS geschützt und ermöglichen so den Schutz von Cloud- und Notfallwiederherstellungsstandorten.</block>
  <block id="298d20d1ae9110668e52c07776f62948" category="list-text">Verbessert die Leistung durch Auslagerung von Sicherungsvorgängen auf den Sicherungscluster.</block>
  <block id="4c10451e9e5bf987bc3ab16a9fce3966" category="list-text">Eliminiert manuelle Bandvorgänge</block>
  <block id="0ff20f264e79e773549ded37f50f4b3b" category="list-text">Ermöglicht Unternehmensverwaltungsfunktionen über NetApp -Tools.</block>
  <block id="4c84f95e2dad9b5385151a736e89f0c3" category="list-text">Erfordert nur minimale Änderungen an der vorhandenen Umgebung.</block>
  <block id="66f3b3a8c99e03a363a88a58fabe03cc" category="list-text">Ist eine kostengünstige Lösung.</block>
  <block id="4e941dea7920913a2c3a6d2a11a0936f" category="paragraph">Der Nachteil dieser Lösung besteht darin, dass sie einen Backup-Cluster und zusätzliche Mapper zur Leistungsverbesserung erfordert.</block>
  <block id="0628ac302dce6afb9d95a6b8ebd0d013" category="paragraph">Der Kunde hat vor Kurzem Lösung A aufgrund ihrer Einfachheit, Kosten und Gesamtleistung implementiert.</block>
  <block id="7a3ba8b554aec9832f399bff2ba17c74" category="paragraph">Bei dieser Lösung können SAN-Festplatten von ONTAP anstelle von JBOD verwendet werden.  Diese Option verlagert die Speicherlast des Backup-Clusters auf ONTAP. Der Nachteil besteht jedoch darin, dass SAN-Fabric-Switches erforderlich sind.</block>
  <block id="501a1b4ce382e8e2da0089aded30d11e" category="section-title">Lösung B</block>
  <block id="099eafc2208317136c2902383d7b0755" category="paragraph">Lösung B fügt dem Produktions-Hadoop-Cluster ein NFS-Volume hinzu, wodurch der Backup-Hadoop-Cluster überflüssig wird, wie in der folgenden Abbildung gezeigt.</block>
  <block id="5b70fb212e3f22443316e06668fb7eaf" category="paragraph"><block ref="5b70fb212e3f22443316e06668fb7eaf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8ca30c628556726e2038c5df9689fd91" category="paragraph">Die detaillierten Aufgaben für Lösung B umfassen:</block>
  <block id="e493f6dc701d2253466d5705af2e5bb1" category="list-text">Der NetApp ONTAP Speichercontroller stellt den NFS-Export zum Produktions-Hadoop-Cluster bereit.</block>
  <block id="b8c0e409f361575b0a2787968f3e6737" category="paragraph">Der Hadoop-Native<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> Der Befehl schützt die Hadoop-Daten vom Produktionscluster HDFS auf NFS.</block>
  <block id="665cfb3949b836c368d9be47d34bcbba" category="list-text">Nachdem die Daten in NFS auf dem NetApp -Speichersystem gespeichert wurden, werden die Technologien Snapshot, SnapRestore und FlexClone verwendet, um die Hadoop-Daten nach Bedarf zu sichern, wiederherzustellen und zu duplizieren.</block>
  <block id="4f1aeb2a94e89562b7bef27c368ed9cc" category="paragraph">Zu den Vorteilen der Lösung B gehören:</block>
  <block id="748dc25f775dc78e1da24328f753d1e1" category="list-text">Der Produktionscluster wird für die Backup-Lösung leicht modifiziert, was die Implementierung vereinfacht und zusätzliche Infrastrukturkosten reduziert.</block>
  <block id="a565a40a6656693466a7da18be6d44ca" category="list-text">Ein Backup-Cluster für den Backup-Vorgang ist nicht erforderlich.</block>
  <block id="fa6ae9dfac02b933ef93450603114fce" category="list-text">HDFS-Produktionsdaten werden bei der Konvertierung in NFS-Daten geschützt.</block>
  <block id="cf7952142a1253af6b9394a3f01408b3" category="list-text">Die Lösung ermöglicht Unternehmensverwaltungsfunktionen über NetApp -Tools.</block>
  <block id="f4ffcfc00594c5a445a43499130eb8d3" category="paragraph">Der Nachteil dieser Lösung besteht darin, dass sie im Produktionscluster implementiert wird, was zu zusätzlichen Administratoraufgaben im Produktionscluster führen kann.</block>
  <block id="0a3b8c5fab2a32545423ade2927b1185" category="section-title">Lösung C</block>
  <block id="6c176725a15c1c609d24387ddf6600da" category="paragraph">In Lösung C werden die NetApp SAN-Volumes direkt für den Hadoop-Produktionscluster zur HDFS-Speicherung bereitgestellt, wie in der folgenden Abbildung dargestellt.</block>
  <block id="016077aafc394500fb21c4f233724258" category="paragraph"><block ref="016077aafc394500fb21c4f233724258" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c0d09b63c2b939de22a3b5d0f4cb3c87" category="paragraph">Die detaillierten Schritte für Lösung C umfassen:</block>
  <block id="35edf0b5a2042b4561d4d499298010e6" category="list-text">NetApp ONTAP SAN-Speicher wird im Produktions-Hadoop-Cluster für die HDFS-Datenspeicherung bereitgestellt.</block>
  <block id="3b694951a08990d1243da1dd36e6cd07" category="list-text">Zum Sichern der HDFS-Daten aus dem Produktions-Hadoop-Cluster werden die Technologien NetApp Snapshot und SnapMirror verwendet.</block>
  <block id="c32b4eb407751e515d7d037629b66dfb" category="list-text">Während des Snapshot-Kopiersicherungsprozesses kommt es zu keinen Leistungseinbußen bei der Produktion des Hadoop/Spark-Clusters, da die Sicherung auf der Speicherebene erfolgt.</block>
  <block id="ef54974b65426daa87a86290447ed9a6" category="admonition">Die Snapshot-Technologie ermöglicht Backups, die unabhängig von der Datengröße in Sekundenschnelle abgeschlossen sind.</block>
  <block id="f499d7fd731eb2bb1efe6c4069efcb47" category="paragraph">Zu den Vorteilen der Lösung C gehören:</block>
  <block id="abe0be0b8deb695793caa75a1dcfc4b3" category="list-text">Mithilfe der Snapshot-Technologie können platzsparende Backups erstellt werden.</block>
  <block id="2c755351ada495582a6d9015943de077" category="summary">In diesem Anwendungsfall besteht die Anforderung des Kunden darin, schnell und effizient neue Hadoop/Spark-Cluster auf der Grundlage eines vorhandenen Hadoop-Clusters zu erstellen, der eine große Menge an Analysedaten für DevTest- und Berichtszwecke im selben Rechenzentrum sowie an Remote-Standorten enthält.</block>
  <block id="acb2dd720b2161405c8cb1ca6035618b" category="doc">Anwendungsfall 3: DevTest für vorhandene Hadoop-Daten aktivieren</block>
  <block id="4e19c1aafa6d3711ae619f7e1621a61e" category="paragraph">In diesem Szenario werden mehrere Spark/Hadoop-Cluster aus einer großen Hadoop-Data-Lake-Implementierung vor Ort sowie an Disaster-Recovery-Standorten erstellt.</block>
  <block id="5768edca640abf2b08dd5ba0e593dcc7" category="list-text">Erstellen Sie mehrere Hadoop-Cluster für DevTest, Qualitätssicherung oder andere Zwecke, die Zugriff auf dieselben Produktionsdaten erfordern.  Die Herausforderung besteht darin, einen sehr großen Hadoop-Cluster mehrere Male gleichzeitig und auf sehr platzsparende Weise zu klonen.</block>
  <block id="529c78f9988d342b33707ecaae7d2576" category="list-text">Synchronisieren Sie die Hadoop-Daten mit DevTest- und Berichtsteams, um die betriebliche Effizienz zu steigern.</block>
  <block id="07178cfd87815398d5079e55c257f96c" category="list-text">Verteilen Sie die Hadoop-Daten, indem Sie dieselben Anmeldeinformationen in der Produktion und in neuen Clustern verwenden.</block>
  <block id="b26eaa756d7ec14dcec5c25d7d9ad6b6" category="list-text">Verwenden Sie geplante Richtlinien, um QA-Cluster effizient zu erstellen, ohne den Produktionscluster zu beeinträchtigen.</block>
  <block id="6442ec446d11bbd47497299e0ffceed5" category="paragraph">Um die gerade beschriebenen Anforderungen zu erfüllen, wird die FlexClone -Technologie verwendet.  Die FlexClone -Technologie ist die Lese-/Schreibkopie einer Snapshot-Kopie.  Es liest die Daten aus den übergeordneten Snapshot-Kopiedaten und verbraucht nur zusätzlichen Speicherplatz für neue/geänderte Blöcke.  Es ist schnell und platzsparend.</block>
  <block id="51a22383ed7ac5a70a455d81a9bad789" category="paragraph">Zunächst wurde mithilfe einer NetApp Konsistenzgruppe eine Snapshot-Kopie des vorhandenen Clusters erstellt.</block>
  <block id="ff0e15997f709c232408a5055738df05" category="paragraph">Snapshot-Kopien im NetApp System Manager oder in der Storage-Admin-Eingabeaufforderung.  Bei den Snapshot-Kopien der Konsistenzgruppe handelt es sich um anwendungskonsistente Snapshot-Kopien der Gruppe, und das FlexClone -Volume wird basierend auf Snapshot-Kopien der Konsistenzgruppe erstellt.  Es ist erwähnenswert, dass ein FlexClone -Volume die NFS-Exportrichtlinie des übergeordneten Volumes erbt.  Nachdem die Snapshot-Kopie erstellt wurde, muss ein neuer Hadoop-Cluster für DevTest- und Berichtszwecke installiert werden, wie in der folgenden Abbildung dargestellt.  Das geklonte NFS-Volume aus dem neuen Hadoop-Cluster greift auf die NFS-Daten zu.</block>
  <block id="6ee7e035a9c46bb26ee76c40aa671148" category="paragraph">Dieses Bild zeigt den Hadoop-Cluster für DevTest.</block>
  <block id="abc9a1c20fcf276389f79d3093665e5c" category="paragraph"><block ref="abc9a1c20fcf276389f79d3093665e5c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fa7dcae8e4f7d8ecc191c3ce8547a53a" category="summary">Dieser Anwendungsfall ist für einen Cloud-Service-Partner relevant, der die Aufgabe hat, Multicloud-Konnektivität für die Big-Data-Analysedaten von Kunden bereitzustellen.</block>
  <block id="2268700ee8bd2216d594273e566b0cc9" category="doc">Anwendungsfall 4: Datenschutz und Multicloud-Konnektivität</block>
  <block id="3cec8f6cf1ce867e7f73dd5132b7fbf3" category="paragraph">In diesem Szenario werden IoT-Daten, die in AWS aus verschiedenen Quellen empfangen werden, an einem zentralen Ort in NPS gespeichert.  Der NPS-Speicher ist mit Spark/Hadoop-Clustern in AWS und Azure verbunden, sodass Big Data-Analyseanwendungen in mehreren Clouds ausgeführt werden können und auf dieselben Daten zugreifen.</block>
  <block id="bed6436414550585ccb4ac4c67a449a3" category="list-text">Kunden möchten Analyseaufträge mit denselben Daten über mehrere Clouds ausführen.</block>
  <block id="6af3e1f448b2a56e9bd0fbbd43b31bc8" category="list-text">Daten müssen aus verschiedenen Quellen, beispielsweise vor Ort und aus der Cloud, über verschiedene Sensoren und Hubs empfangen werden.</block>
  <block id="e3c7f1ced05166adfc90c26337389e3e" category="list-text">Die Lösung muss effizient und kostengünstig sein.</block>
  <block id="b320f1b1ab6d0a21e40ee3d444669645" category="list-text">Die größte Herausforderung besteht darin, eine kostengünstige und effiziente Lösung zu entwickeln, die hybride Analysedienste zwischen lokalen Standorten und verschiedenen Clouds bereitstellt.</block>
  <block id="0d4b3cfa555ff36cd92fb4e36fb69fbf" category="paragraph">Dieses Bild veranschaulicht die Lösung für Datenschutz und Multicloud-Konnektivität.</block>
  <block id="5308dad4844e43fdad02844ec50752c0" category="paragraph"><block ref="5308dad4844e43fdad02844ec50752c0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4ea48e5206de42785842cb864377766c" category="paragraph">Wie in der obigen Abbildung gezeigt, werden Daten von Sensoren gestreamt und über Kafka in den AWS Spark-Cluster aufgenommen.  Die Daten werden in einer NFS-Freigabe gespeichert, die sich in NPS befindet, das sich außerhalb des Cloud-Anbieters in einem Equinix-Rechenzentrum befindet.  Da NetApp NPS über Direct Connect- bzw. Express Route-Verbindungen mit Amazon AWS und Microsoft Azure verbunden ist, können Kunden auf die NFS-Daten sowohl von Amazon- als auch von AWS-Analyseclustern zugreifen.  Dieser Ansatz löst das Problem, Cloud-Analysen über mehrere Hyperscaler hinweg durchzuführen.</block>
  <block id="4089db0b43263b1f59a9c2db909edf6e" category="paragraph">Da sowohl der lokale als auch der NPS-Speicher mit ONTAP -Software laufen, kann SnapMirror die NPS-Daten in den lokalen Cluster spiegeln und so Hybrid-Cloud-Analysen über lokale und mehrere Clouds hinweg bereitstellen.</block>
  <block id="d446808fb03b5fae4f2e518cbc7d767f" category="paragraph">Für eine optimale Leistung empfiehlt NetApp normalerweise die Verwendung mehrerer Netzwerkschnittstellen und Direktverbindungen/Expressrouten für den Zugriff auf die Daten von Cloud-Instanzen.</block>
  <block id="f9fe6a27dc7f13d26e9416153b950597" category="summary">Dieser Abschnitt bietet eine allgemeine Beschreibung der Anwendungsfälle zum Datenschutz, die den Schwerpunkt dieses Dokuments bilden.  Die verbleibenden Abschnitte enthalten weitere Details zu jedem Anwendungsfall, beispielsweise zum Kundenproblem (Szenario), zu Anforderungen und Herausforderungen sowie zu Lösungen.</block>
  <block id="6a15e1dac7cc5c330a1da84c32b3ff2e" category="doc">Übersicht über Anwendungsfälle für den Hadoop-Datenschutz</block>
  <block id="6f2c5dcd0294b9c34430b1de4713c06d" category="paragraph">In diesem Anwendungsfall konnte ein großes Finanzinstitut mithilfe des NetApp NFS-Volumes die lange Backup-Zeit von über 24 Stunden auf knapp ein paar Stunden reduzieren.</block>
  <block id="06b83cb579d9aaf1f26d8c4284a5a42e" category="paragraph">Durch die Verwendung der von NetApp bereitgestellten Datenstruktur als Bausteine konnte ein großes Rundfunkunternehmen seine Anforderung erfüllen, Cloud-Daten in seinem Rechenzentrum vor Ort zu sichern, und zwar abhängig von den verschiedenen Datenübertragungsmodi, beispielsweise auf Abruf, sofort oder basierend auf der Hadoop/Spark-Clusterlast.</block>
  <block id="da17b6db6e3e50f66b5bcaee1d74f8b1" category="paragraph">Mithilfe von NetApp -Lösungen konnte ein Online-Musikvertrieb schnell mehrere platzsparende Hadoop-Cluster in verschiedenen Zweigstellen erstellen, um mithilfe geplanter Richtlinien Berichte zu erstellen und tägliche DevTest-Aufgaben auszuführen.</block>
  <block id="90fc62f886a8c33032d4db8b79ec5814" category="paragraph">Ein großer Dienstanbieter nutzte das von NetApp betriebene Daten-Fabric, um seinen Kunden Multicloud-Analysen aus verschiedenen Cloud-Instanzen bereitzustellen.</block>
  <block id="67f07a55567ecfc26b3c7b54823a43ee" category="paragraph">Eine der größten Finanzdienstleistungs- und Investmentbanken nutzte die Network Attached Storage-Lösung von NetApp , um die I/O-Wartezeit zu reduzieren und ihre Plattform für quantitative Finanzanalysen zu beschleunigen.</block>
  <block id="139709c8a32ed1bcce233da863c5efda" category="summary">In diesem Abschnitt werden die Erkenntnisse aus dieser Zertifizierung vorgestellt.</block>
  <block id="eab9ac0f00ca7c338d71f9acf8885092" category="doc">Best Practice-Richtlinien</block>
  <block id="1bd6648fc95556a0a0fde4774f780085" category="list-text">Basierend auf unserer Validierung ist der S3-Objektspeicher für Confluent am besten geeignet, um Daten aufzubewahren.</block>
  <block id="18f3dd1f96633e1c3f4b4473c8f63239" category="list-text">Wir können ein Hochdurchsatz-SAN (insbesondere FC) verwenden, um die Hot Data des Brokers oder die lokale Festplatte aufzubewahren, da in der mehrstufigen Speicherkonfiguration von Confluent die Größe der im Datenverzeichnis des Brokers gespeicherten Daten auf der Segmentgröße und der Aufbewahrungszeit basiert, wenn die Daten in den Objektspeicher verschoben werden.</block>
  <block id="992e82f9c5ce28bbe0068e8ff7ea8a09" category="list-text">Objektspeicher bieten eine bessere Leistung, wenn segment.bytes höher ist; wir haben 512 MB getestet.</block>
  <block id="f165ec9e9849281afaf2162f6396907c" category="list-text">In Kafka wird die Länge des Schlüssels oder Wertes (in Bytes) für jeden zum Thema erstellten Datensatz durch die<block ref="89a621c030df783ee8eee89dd8f42cb9" prefix=" " category="inline-code"></block> Parameter.  Für StorageGRID wurde die Leistung beim Aufnehmen und Abrufen von S3-Objekten auf höhere Werte erhöht.  Beispielsweise ermöglichten 512 Bytes einen Abruf von 5,8 GBps, 1024 Bytes einen S3-Abruf von 7,5 GBps und 2048 Bytes fast 10 GBps.</block>
  <block id="92a9c9d4753636cd8ef8008380f5de9b" category="paragraph">Die folgende Abbildung zeigt die Aufnahme und den Abruf von S3-Objekten basierend auf<block ref="89a621c030df783ee8eee89dd8f42cb9" prefix=" " category="inline-code"></block> .</block>
  <block id="88108446d5ab5e54118010ab8c716e93" category="paragraph"><block ref="88108446d5ab5e54118010ab8c716e93" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9432e98ec213778ab349305141050c42" category="list-text">*Kafka-Tuning.*  Um die Leistung des mehrstufigen Speichers zu verbessern, können Sie TierFetcherNumThreads und TierArchiverNumThreads erhöhen.  Als allgemeine Richtlinie sollten Sie TierFetcherNumThreads erhöhen, um es an die Anzahl der physischen CPU-Kerne anzupassen, und TierArchiverNumThreads auf die Hälfte der Anzahl der CPU-Kerne erhöhen.  Wenn Sie beispielsweise über eine Maschine mit acht physischen Kernen verfügen, legen Sie in den Servereigenschaften confluent.tier.fetcher.num.threads = 8 und confluent.tier.archiver.num.threads = 4 fest.</block>
  <block id="ed3ecb8a7183dd06de652f3dc38b1037" category="list-text">*Zeitintervall für Themenlöschungen.*  Wenn ein Thema gelöscht wird, beginnt das Löschen der Protokollsegmentdateien im Objektspeicher nicht sofort.  Vielmehr gibt es ein Zeitintervall mit einem Standardwert von 3 Stunden, bevor die Löschung dieser Dateien erfolgt.  Sie können die Konfiguration confluent.tier.topic.delete.check.interval.ms ändern, um den Wert dieses Intervalls zu ändern.  Wenn Sie ein Thema oder einen Cluster löschen, können Sie die Objekte im jeweiligen Bucket auch manuell löschen.</block>
  <block id="3833b7b3d2c8a15e32f72248bab1add9" category="list-text">*ACLs zu internen Themen des Tiered Storage.*  Eine empfohlene Best Practice für lokale Bereitstellungen besteht darin, einen ACL-Autorisierer für die internen Themen zu aktivieren, die für mehrstufigen Speicher verwendet werden.  Legen Sie ACL-Regeln fest, um den Zugriff auf diese Daten auf den Broker-Benutzer zu beschränken.  Dies sichert die internen Themen und verhindert den unbefugten Zugriff auf Tiered-Storage-Daten und Metadaten.</block>
  <block id="ebcb583d4445a2a39076c7fa4627f79a" category="admonition">Ersetzen Sie den Benutzer<block ref="a802c5bf62b7c5970725474468cf46f4" prefix=" " category="inline-code"></block> mit dem tatsächlichen Broker-Prinzipal in Ihrer Bereitstellung.</block>
  <block id="0ca954cd7923be900c49b3b807caf2b6" category="paragraph">Beispielsweise der Befehl<block ref="bccf46e0861de44696513d6cbea91e4c" prefix=" " category="inline-code"></block> legt ACLs für das interne Thema für mehrstufigen Speicher fest.  Derzeit gibt es nur ein einziges internes Thema zum Thema Tiered Storage.  Das Beispiel erstellt eine ACL, die dem Kafka-Prinzip die Berechtigung für alle Vorgänge am internen Thema erteilt.</block>
  <block id="663d826f2d39c93c218bb619244537b3" category="summary">Wir haben die Zertifizierung mit Confluent Platform mit Kafka für Tiered Storage in NetApp StorageGRID durchgeführt.</block>
  <block id="5436c2a5438619c1dbe68551a8297494" category="doc">Konfluente Überprüfung</block>
  <block id="0c112d1616223eaa5f0484a9499d587f" category="paragraph">Wir haben die Überprüfung mit Confluent Platform 6.2 Tiered Storage in NetApp StorageGRID durchgeführt.  Die Teams von NetApp und Confluent arbeiteten gemeinsam an dieser Verifizierung und führten die für die Verifizierung erforderlichen Testfälle aus.</block>
  <block id="ba5b5ff137c16b8859e6ac90b55d071c" category="section-title">Einrichtung der Confluent-Plattform</block>
  <block id="d8802fa9749bdc5ddc844a1f86c9461d" category="paragraph">Zur Überprüfung haben wir das folgende Setup verwendet.</block>
  <block id="7b5948d7f6534813c3989b6697841566" category="paragraph">Zur Überprüfung verwendeten wir drei Zookeeper, fünf Broker, fünf Testskript-Ausführungsserver, benannte Tool-Server mit 256 GB RAM und 16 CPUs.  Für den NetApp -Speicher haben wir StorageGRID mit einem SG1000-Load Balancer mit vier SGF6024 verwendet.  Die Speicher und Broker wurden über 100GbE-Verbindungen verbunden.</block>
  <block id="e9f968cb8cc147519310d7290c28f99d" category="paragraph">Die folgende Abbildung zeigt die Netzwerktopologie der für die Confluent-Verifizierung verwendeten Konfiguration.</block>
  <block id="275745d9c13bf80b7275e6f8633d15e4" category="paragraph"><block ref="275745d9c13bf80b7275e6f8633d15e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8a85abadadde0e32bd269b5667b6226" category="paragraph">Die Tool-Server fungieren als Anwendungsclients, die Anfragen an Confluent-Knoten senden.</block>
  <block id="a0b3c1e592076debe73b163734ed8e2b" category="section-title">Confluent-Tiered-Storage-Konfiguration</block>
  <block id="81082f7982ae1144f7662efde7446f1f" category="paragraph">Die mehrstufige Speicherkonfiguration erfordert die folgenden Parameter in Kafka:</block>
  <block id="c78850251892556ff1c48a03b16cf1bf" category="paragraph">Zur Überprüfung haben wir StorageGRID mit dem HTTP-Protokoll verwendet, aber auch HTTPS funktioniert.  Der Zugriffsschlüssel und der geheime Schlüssel werden in der Datei mit dem angegebenen Namen gespeichert.<block ref="f5bafadf6000aaed6c910fea0a85f4f3" prefix=" " category="inline-code"></block> Parameter.</block>
  <block id="4e19f24a6f1bb774911253be7f9d487f" category="section-title">NetApp Objektspeicher – StorageGRID</block>
  <block id="2d5dff5c754356b277b47604fee26e79" category="paragraph">Zur Überprüfung haben wir die Single-Site-Konfiguration in StorageGRID konfiguriert.</block>
  <block id="dddbd2d03db81f9c6cb7d2dc1329df76" category="paragraph"><block ref="dddbd2d03db81f9c6cb7d2dc1329df76" category="inline-image-macro-rx" type="image"></block></block>
  <block id="829026ce89cdb29d9f59599cb2244752" category="section-title">Verifizierungstests</block>
  <block id="f97246b7185276a5fe91aba0dd7311ae" category="paragraph">Zur Verifizierung haben wir die folgenden fünf Testfälle durchgeführt.  Diese Tests werden auf dem Trogdor-Framework ausgeführt.  Bei den ersten beiden handelte es sich um Funktionstests und bei den restlichen drei um Leistungstests.</block>
  <block id="4c5791ce7d906a384ff35dab9f635d41" category="section-title">Korrektheitstest des Objektspeichers</block>
  <block id="a0a36b11d315565a64a50eb2a0ed8c35" category="paragraph">Dieser Test ermittelt, ob alle grundlegenden Vorgänge (z. B. Get/Put/Delete) der Objektspeicher-API entsprechend den Anforderungen des mehrstufigen Speichers gut funktionieren.  Es handelt sich um einen grundlegenden Test, den jeder Objektspeicherdienst vor den folgenden Tests bestehen sollte.  Es handelt sich um einen Aussagetest, der entweder bestanden oder nicht bestanden wird.</block>
  <block id="7cf5be835d50b9e5b598a4363e5a1310" category="section-title">Korrektheitstest der Tiering-Funktionalität</block>
  <block id="afca9446d059f239c7c73699ec215b35" category="paragraph">Dieser Test ermittelt mit einem Assertivtest, der entweder erfolgreich ist oder fehlschlägt, ob die End-to-End-Tiered-Storage-Funktionalität gut funktioniert.  Der Test erstellt ein Testthema, das standardmäßig mit aktiviertem Tiering und stark reduzierter Hotset-Größe konfiguriert ist.  Es erzeugt einen Ereignisstrom zum neu erstellten Testthema, wartet darauf, dass die Broker die Segmente im Objektspeicher archivieren, verbraucht dann den Ereignisstrom und überprüft, ob der verbrauchte Strom mit dem erzeugten Strom übereinstimmt.  Die Anzahl der an den Ereignisstrom gesendeten Nachrichten ist konfigurierbar, sodass der Benutzer je nach Testbedarf eine ausreichend große Arbeitslast generieren kann.  Die reduzierte Hotset-Größe stellt sicher, dass die Abrufe des Verbrauchers außerhalb des aktiven Segments nur aus dem Objektspeicher erfolgen. Dies hilft beim Testen der Richtigkeit des Objektspeichers für Lesevorgänge.  Wir haben diesen Test mit und ohne Fehlerinjektion im Objektspeicher durchgeführt.  Wir haben einen Knotenausfall simuliert, indem wir den Service Manager-Dienst in einem der Knoten in StorageGRID gestoppt und überprüft haben, ob die End-to-End-Funktionalität mit dem Objektspeicher funktioniert.</block>
  <block id="88960bc44aa73a667c97d6168a27332a" category="section-title">Benchmark für den Tier-Abruf</block>
  <block id="777c3235446f781652127bde532a7d6e" category="paragraph">Dieser Test validierte die Leseleistung des mehrstufigen Objektspeichers und überprüfte die Range-Fetch-Leseanforderungen unter hoher Last von Segmenten, die durch den Benchmark generiert wurden.  In diesem Benchmark hat Confluent benutzerdefinierte Clients entwickelt, um die Tier-Fetch-Anfragen zu erfüllen.</block>
  <block id="07b15abc12bd3f43d57ebd95fce23917" category="section-title">Benchmark für die Arbeitslast „Produzieren und Konsumieren“</block>
  <block id="82ac7c284d524e3dba7699721633a674" category="paragraph">Dieser Test erzeugte durch die Archivierung von Segmenten indirekt eine Schreiblast im Objektspeicher.  Die Lesearbeitslast (gelesene Segmente) wurde aus dem Objektspeicher generiert, als Verbrauchergruppen die Segmente abgerufen haben.  Diese Arbeitslast wurde durch das Testskript generiert.  Dieser Test überprüfte die Leistung beim Lesen und Schreiben im Objektspeicher in parallelen Threads.  Wir haben mit und ohne Fehlerinjektion im Objektspeicher getestet, wie wir es für den Korrektheitstest der Tiering-Funktionalität getan haben.</block>
  <block id="fc8cd6782366e38a4c0191fff79825b0" category="section-title">Benchmark für die Aufbewahrungsarbeitslast</block>
  <block id="c51c74edfaecd19ad2258d1dd18ba5d5" category="paragraph">Dieser Test prüfte die Löschleistung eines Objektspeichers unter einer hohen Themenaufbewahrungslast.  Der Aufbewahrungsaufwand wurde mithilfe eines Testskripts generiert, das viele Nachrichten parallel zu einem Testthema produziert.  Das Testthema war die Konfiguration mit einer aggressiven größen- und zeitbasierten Aufbewahrungseinstellung, die dazu führte, dass der Ereignisstrom kontinuierlich aus dem Objektspeicher gelöscht wurde.  Anschließend wurden die Segmente archiviert.  Dies führte zu einer großen Anzahl von Löschungen im Objektspeicher durch den Broker und zur Erfassung der Leistung der Löschvorgänge im Objektspeicher.</block>
  <block id="996099c5b9fa96634feb727528db335e" category="list-text">Was ist Apache Kafka?</block>
  <block id="64512a184434b7e7734cf3c0a7283f2a" category="list-text">Was ist eine dumme Umbenennung?</block>
  <block id="c4fe8f5f0b73bc80c0f8289fac9a6123" category="inline-link"><block ref="c4fe8f5f0b73bc80c0f8289fac9a6123" category="inline-link-rx"></block></block>
  <block id="0bf644a00aca415462aeb30f96e502cf" category="paragraph"><block ref="0bf644a00aca415462aeb30f96e502cf" category="inline-link-rx"></block></block>
  <block id="4a15e598cdac14bbb90bb0e4020f4a79" category="list-text">ONATP wird für Streaming-Anwendungen gelesen.</block>
  <block id="90bd054ee4c47533d08a6c79bd89dc5a" category="inline-link"><block ref="90bd054ee4c47533d08a6c79bd89dc5a" category="inline-link-rx"></block></block>
  <block id="05c0a7e8a1aa7fd9f25faae2cfd814e9" category="paragraph"><block ref="05c0a7e8a1aa7fd9f25faae2cfd814e9" category="inline-link-rx"></block></block>
  <block id="02aed7d7f25878a636d26b696ed151bb" category="list-text">NetApp Produktdokumentation</block>
  <block id="e861ab8ac55c9110672ee8b4ba3c5990" category="list-text">Was ist NFS?</block>
  <block id="bbdb25bd27a345174d3b4ea622b9ec26" category="inline-link"><block ref="bbdb25bd27a345174d3b4ea622b9ec26" category="inline-link-rx"></block></block>
  <block id="6b6d6a7e1bfbb25506c4af7f443a7b25" category="paragraph"><block ref="6b6d6a7e1bfbb25506c4af7f443a7b25" category="inline-link-rx"></block></block>
  <block id="9fee8c35c177577e85d941aa2c9dedc4" category="list-text">Was ist eine Kafka-Partitionsneuzuweisung?</block>
  <block id="2363cdcf0f5fc9a387ed87b925979747" category="inline-link"><block ref="2363cdcf0f5fc9a387ed87b925979747" category="inline-link-rx"></block></block>
  <block id="12b4d09f121a118c1b63eba5f3523fa2" category="paragraph"><block ref="12b4d09f121a118c1b63eba5f3523fa2" category="inline-link-rx"></block></block>
  <block id="f06a814ac7d838a2d019219102377120" category="list-text">Was ist der OpenMessaging-Benchmark?</block>
  <block id="9466397f90b4d13297982537f7f1f157" category="inline-link"><block ref="9466397f90b4d13297982537f7f1f157" category="inline-link-rx"></block></block>
  <block id="f42769fbe9abef93dd4da40d8f886c4a" category="paragraph"><block ref="f42769fbe9abef93dd4da40d8f886c4a" category="inline-link-rx"></block></block>
  <block id="bcc483eab76f7252a6d3060ae223f024" category="list-text">Wie migriert man einen Kafka-Broker?</block>
  <block id="7702dea2646d94249d97c22a4dcb6f96" category="inline-link"><block ref="7702dea2646d94249d97c22a4dcb6f96" category="inline-link-rx"></block></block>
  <block id="ebdd7bc6eaa2157f5f400c61c1826417" category="paragraph"><block ref="ebdd7bc6eaa2157f5f400c61c1826417" category="inline-link-rx"></block></block>
  <block id="3f7e227a8b3d0fc0cdcbf84e2bc565ac" category="list-text">Wie überwachen Sie den Kafka-Broker mit Prometheus?</block>
  <block id="2d2cb8fe8b8d32b7fb984622e41036f1" category="paragraph"><block ref="2d2cb8fe8b8d32b7fb984622e41036f1" category="inline-link-rx"></block></block>
  <block id="c8219112931de58f84e7a14a0d24d1ce" category="list-text">Verwaltete Plattform für Apache Kafka</block>
  <block id="a96e98488edf9123c2fb5281e71c6ec2" category="paragraph"><block ref="a96e98488edf9123c2fb5281e71c6ec2" category="inline-link-rx"></block></block>
  <block id="0cb1f340d12ba20e283d00e1e0823526" category="list-text">Unterstützung für Apache Kafka</block>
  <block id="14bb5ca8b6287991417f8f43b4d9eb0c" category="paragraph"><block ref="14bb5ca8b6287991417f8f43b4d9eb0c" category="inline-link-rx"></block></block>
  <block id="9d5591555b2fbddd314212720dc97729" category="list-text">Beratungsleistungen für Apache Kafka</block>
  <block id="583ea5ea8c7ad81fed86a1925483124c" category="paragraph"><block ref="583ea5ea8c7ad81fed86a1925483124c" category="inline-link-rx"></block></block>
  <block id="bf06620c2cdf1b79a1673e62b409eae0" category="summary">Die NetApp -Lösung für das Silly-Rename-Problem bietet eine einfache, kostengünstige und zentral verwaltete Speicherform für Workloads, die zuvor mit NFS nicht kompatibel waren.</block>
  <block id="5fe141c77d102adcaccfa6da33564741" category="paragraph">Dieses neue Paradigma ermöglicht es Kunden, besser verwaltbare Kafka-Cluster zu erstellen, die sich zum Zweck der Notfallwiederherstellung und des Datenschutzes einfacher migrieren und spiegeln lassen.  Wir haben außerdem festgestellt, dass NFS zusätzliche Vorteile bietet, wie etwa eine geringere CPU-Auslastung und eine schnellere Wiederherstellungszeit, eine deutlich verbesserte Speichereffizienz und eine bessere Leistung durch NetApp ONTAP.</block>
  <block id="34ea6423c17a78bdf284132538078bac" category="summary">In diesem Dokument werden die folgenden Themen beschrieben: das Silly-Rename-Problem und die Lösungsvalidierung, die Reduzierung der CPU-Auslastung zur Verkürzung der E/A-Wartezeit, eine schnellere Wiederherstellungszeit des Kafka-Brokers sowie die Leistung in der Cloud und vor Ort.</block>
  <block id="47e33b895b285760d0d1bcb64e42e5d0" category="doc">TR-4947: Apache Kafka-Workload mit NetApp NFS-Speicher – Funktionale Validierung und Leistung</block>
  <block id="62233ad21bd81bbbff938616c0106477" category="paragraph">Shantanu Chakole, Karthikeyan Nagalingam und Joe Scott, NetApp</block>
  <block id="8150fcf9bdcb89b4901e10f34571667e" category="paragraph">Kafka ist ein verteiltes Publish-Subscribe-Messaging-System mit einer robusten Warteschlange, die große Mengen an Nachrichtendaten aufnehmen kann.  Mit Kafka können Anwendungen Daten sehr schnell in Themen schreiben und daraus lesen.  Aufgrund seiner Fehlertoleranz und Skalierbarkeit wird Kafka im Big Data-Bereich häufig als zuverlässige Methode zum schnellen Aufnehmen und Verschieben vieler Datenströme verwendet.  Zu den Anwendungsfällen gehören Stream-Verarbeitung, Website-Aktivitätsverfolgung, Erfassung und Überwachung von Metriken, Protokollaggregation, Echtzeitanalysen usw.</block>
  <block id="6c92285fa6d3e827b198d120ea3ac674" category="inline-link">hier,</block>
  <block id="e1304dc2c6d37619b73112fae0bd8411" category="paragraph">Obwohl normale Kafka-Operationen auf NFS gut funktionieren, führt das dumme Umbenennungsproblem beim Ändern der Größe oder Neupartitionieren eines auf NFS laufenden Kafka-Clusters zum Absturz der Anwendung.  Dies ist ein erhebliches Problem, da die Größe eines Kafka-Clusters zum Lastenausgleich oder zu Wartungszwecken geändert oder neu partitioniert werden muss.  Weitere Details finden Sie<block ref="eff8c14b44ddf611b2ff09607d7665a2" category="inline-link-rx"></block> .</block>
  <block id="229b214236b3c346dc9f6c75d096604b" category="paragraph">In diesem Dokument werden die folgenden Themen beschrieben:</block>
  <block id="995fd45f2f5174bc9a5d8029655c1b88" category="list-text">Das alberne Umbenennungsproblem und die Lösungsvalidierung</block>
  <block id="7c9e8a4fdb767e60565e9c4b4d95eed2" category="list-text">Reduzierung der CPU-Auslastung zur Verkürzung der E/A-Wartezeit</block>
  <block id="915a1ce7d578786f5aa93e503452d2b9" category="list-text">Schnellere Wiederherstellungszeit des Kafka-Brokers</block>
  <block id="5810e3ce10e4e8edfee5f25cae3459c1" category="list-text">Leistung in der Cloud und vor Ort</block>
  <block id="7910f734d679965fb4e725f87dcb3c61" category="section-title">Warum NFS-Speicher für Kafka-Workloads verwenden?</block>
  <block id="932e5edaa1f66c6b109d045d3c7ba0bc" category="paragraph">Kafka-Workloads in Produktionsanwendungen können riesige Datenmengen zwischen Anwendungen streamen.  Diese Daten werden in den Kafka-Broker-Knoten im Kafka-Cluster gehalten und gespeichert.  Kafka ist außerdem für seine Verfügbarkeit und Parallelität bekannt, die es durch die Aufteilung von Themen in Partitionen und die anschließende Replikation dieser Partitionen im gesamten Cluster erreicht.  Dies bedeutet letztendlich, dass sich die enorme Datenmenge, die durch einen Kafka-Cluster fließt, im Allgemeinen vervielfacht.  NFS ermöglicht eine Neugewichtung der Daten bei Änderungen der Anzahl der Broker sehr schnell und einfach.  Bei großen Umgebungen ist die Neuverteilung der Daten über DAS bei einer Änderung der Brokeranzahl sehr zeitaufwändig, und in den meisten Kafka-Umgebungen ändert sich die Anzahl der Broker häufig.</block>
  <block id="a49afd0b2827b8f1d1b83a36f75d3efc" category="paragraph">Zu den weiteren Vorteilen zählen:</block>
  <block id="889d2761ec65245a621931da633b8cfe" category="list-text">*Reife.*  NFS ist ein ausgereiftes Protokoll, was bedeutet, dass die meisten Aspekte seiner Implementierung, Sicherung und Verwendung gut verstanden sind.</block>
  <block id="c231daeb716325a2bca62a5e30431c8d" category="list-text">*Offen.*  NFS ist ein offenes Protokoll und seine Weiterentwicklung ist in Internetspezifikationen als freies und offenes Netzwerkprotokoll dokumentiert.</block>
  <block id="6526aeb62806bf842c7ab66949c2de0c" category="list-text">*Kostengünstig.*  NFS ist eine kostengünstige Lösung für die gemeinsame Nutzung von Netzwerkdateien, die einfach einzurichten ist, da sie die vorhandene Netzwerkinfrastruktur nutzt.</block>
  <block id="8c70ad2ab84f33f7d462109fc8edc329" category="list-text">*Zentral verwaltet.*  Durch die zentrale Verwaltung von NFS verringert sich der Bedarf an zusätzlicher Software und Speicherplatz auf den Systemen einzelner Benutzer.</block>
  <block id="dbb4f7d4eb0147816ffd5d84e4a79e19" category="list-text">*Verteilt.*  NFS kann als verteiltes Dateisystem verwendet werden, wodurch der Bedarf an Wechselmedienspeichergeräten reduziert wird.</block>
  <block id="37377984e38462f1628867b8e7a1e772" category="section-title">Warum NetApp für Kafka-Workloads?</block>
  <block id="300fdb82e8f9a8b6ebb6d42a92483544" category="paragraph">Die NetApp NFS-Implementierung gilt als Goldstandard für das Protokoll und wird in zahllosen Enterprise-NAS-Umgebungen verwendet. Neben der Glaubwürdigkeit von NetApp bietet es auch die folgenden Vorteile:</block>
  <block id="f7e7d6aebe6163c0f639238b2e1a0333" category="list-text">Zuverlässigkeit und Effizienz</block>
  <block id="735980c2ea138788423c50ba2ef7c6c5" category="list-text">Skalierbarkeit und Leistung</block>
  <block id="a8fbd78750bfdd72ecb8371fa5fa9648" category="list-text">Hohe Verfügbarkeit (HA-Partner in einem NetApp ONTAP Cluster)</block>
  <block id="7e7397a7b79323762c61941fc0e6b5f9" category="list-text">Datenschutz</block>
  <block id="e005f1a13de2a01927e39ecb29ff1a7c" category="list-text">*Notfallwiederherstellung (NetApp SnapMirror).*  Ihre Site ist ausgefallen oder Sie möchten auf einer anderen Site weitermachen und dort fortfahren, wo Sie aufgehört haben.</block>
  <block id="81757222cee28779fe25327e8ef3f5a2" category="list-text">Verwaltbarkeit Ihres Speichersystems (Administration und Management mit NetApp OnCommand).</block>
  <block id="7d411cbcfa7cf122ac8423795b89a4b8" category="list-text">*Lastausgleich.*  Der Cluster ermöglicht Ihnen den Zugriff auf verschiedene Volumes von Daten-LIFs, die auf verschiedenen Knoten gehostet werden.</block>
  <block id="6c38013b179499c32ccf05a98b927de6" category="list-text">*Unterbrechungsfreier Betrieb.*  LIFs oder Volume-Verschiebungen sind für die NFS-Clients transparent.</block>
  <block id="d4baa2e552beefa00e93883ed51f3ba2" category="summary">Vor Ort haben wir den NetApp AFF A900 Speichercontroller mit ONTAP 9.12.1RC1 verwendet, um die Leistung und Skalierung eines Kafka-Clusters zu validieren.  Wir haben dasselbe Testbed wie bei unseren vorherigen Best Practices für Tiered Storage mit ONTAP und AFF verwendet.</block>
  <block id="1e753c720a0b773dd9d69024ca734577" category="doc">Leistungsübersicht und Validierung mit AFF A900 vor Ort</block>
  <block id="94391d4f56386aadb6f39e1a596f2427" category="paragraph">Vor Ort haben wir den NetApp AFF A900 Speichercontroller mit ONTAP 9.12.1RC1 verwendet, um die Leistung und Skalierung eines Kafka-Clusters zu validieren.  Wir haben dasselbe Testbed wie bei unseren vorherigen Best Practices für Tiered Storage mit ONTAP und AFF verwendet.</block>
  <block id="b1e7584c9874b52caeb25c3646e8f273" category="paragraph">Zur Evaluierung des AFF A900 haben wir Confluent Kafka 6.2.0 verwendet.  Der Cluster verfügt über acht Broker-Knoten und drei Zookeeper-Knoten.  Für Leistungstests haben wir fünf OMB-Workerknoten verwendet.</block>
  <block id="7d23a6a699d760fc27aa7ce39406c010" category="paragraph"><block ref="7d23a6a699d760fc27aa7ce39406c010" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e8775bd755a8835ce86806d669677ea" category="section-title">Storage-Konfiguration</block>
  <block id="637d24b49cc32320a5e44ea905f65d10" category="paragraph">Wir haben NetApp FlexGroups-Instanzen verwendet, um einen einzigen Namespace für Protokollverzeichnisse bereitzustellen und so die Wiederherstellung und Konfiguration zu vereinfachen.  Wir haben NFSv4.1 und pNFS verwendet, um einen direkten Pfadzugriff auf die Daten des Protokollsegments zu ermöglichen.</block>
  <block id="50ff5e789ae0742f2485b5147c072643" category="section-title">Client-Tuning</block>
  <block id="fc3a7751877b7f4e9a71c82ad3da7e44" category="paragraph">Jeder Client hat die FlexGroup -Instanz mit dem folgenden Befehl gemountet.</block>
  <block id="a5b2794b174e20f0b6dd9350cba3df82" category="paragraph">Darüber hinaus erhöhten wir die<block ref="44d907b0e69e5aa31320f9e86a7ef440" prefix=" " category="inline-code"></block> von der Standardeinstellung<block ref="ea5d2f1c4608232e07d3aa3d998e5135" prefix=" " category="inline-code"></block> Zu<block ref="045117b0e0a11a242b9765e79cbf113f" prefix=" " category="inline-code"></block> .  Dies entspricht dem Standardlimit für Sitzungsslots in ONTAP.</block>
  <block id="31305973da10c7b492918a2ad2b3deee" category="section-title">Kafka-Broker-Tuning</block>
  <block id="4ed38f0369b8bb562a96594ca860ab81" category="paragraph">Um den Durchsatz im Testsystem zu maximieren, haben wir die Standardparameter für bestimmte wichtige Thread-Pools deutlich erhöht.  Wir empfehlen, für die meisten Konfigurationen die Best Practices von Confluent Kafka zu befolgen.  Diese Optimierung wurde verwendet, um die Parallelität ausstehender E/A-Vorgänge zum Speicher zu maximieren.  Diese Parameter können angepasst werden, um den Rechenressourcen und Speicherattributen Ihres Brokers zu entsprechen.</block>
  <block id="0e80721091b1e58209e2877462ebbd21" category="section-title">Testmethodik für Workload-Generatoren</block>
  <block id="9707ee58e22a2478985c56025e656cad" category="paragraph">Wir haben für den Durchsatztreiber und die Themenkonfiguration dieselben OMB-Konfigurationen wie für Cloud-Tests verwendet.</block>
  <block id="dbdfae7d08a693255815e0890397b78f" category="list-text">Eine FlexGroup -Instanz wurde mit Ansible auf einem AFF Cluster bereitgestellt.</block>
  <block id="6c2577e00543c33096c33e1b2e79742d" category="list-text">pNFS wurde auf dem ONTAP SVM aktiviert.</block>
  <block id="62313ead30e5ae09df5e2329bfe44784" category="list-text">Die Arbeitslast wurde mit dem Throughput-Treiber ausgelöst, wobei dieselbe Arbeitslastkonfiguration wie für Cloud Volumes ONTAP verwendet wurde.  Siehe Abschnitt "<block ref="f628eac6c1ff8c1b0462e81ea7b2efc1" category="inline-xref-macro-rx"></block> " unten.  Die Arbeitslast verwendete einen Replikationsfaktor von 3, was bedeutet, dass drei Kopien der Protokollsegmente in NFS verwaltet wurden.</block>
  <block id="823002616491cde5a10847131e46b9a6" category="list-text">Abschließend haben wir Messungen mithilfe eines Rückstands durchgeführt, um die Fähigkeit der Verbraucher zu messen, die neuesten Nachrichten nachzuholen.  OMB baut einen Rückstand auf, indem es Verbraucher zu Beginn einer Messung anhält.  Dadurch entstehen drei verschiedene Phasen: die Erstellung eines Rückstands (Verkehr nur für Produzenten), der Abbau des Rückstands (eine Phase mit vielen Konsumenten, in der Konsumenten verpasste Ereignisse zu einem Thema nachholen) und der stationäre Zustand. Siehe Abschnitt "<block ref="67d9096f7dc6dfc3943f178b4a30cff8" category="inline-xref-macro-rx"></block> " für weitere Informationen.</block>
  <block id="158bb82f009332b2fe16aba7bebc0c15" category="section-title">Steady-State-Leistung</block>
  <block id="216824b7a5a0da585075bc35333402f6" category="paragraph">Wir haben die AFF A900 mithilfe des OpenMessaging Benchmarks bewertet, um einen ähnlichen Vergleich wie für Cloud Volumes ONTAP in AWS und DAS in AWS zu ermöglichen.  Alle Leistungswerte stellen den Durchsatz des Kafka-Clusters auf Produzenten- und Verbraucherebene dar.</block>
  <block id="34121e3b81b5330bbb499603af5609e6" category="paragraph">Die konstante Leistung mit Confluent Kafka und dem AFF A900 erreichte einen durchschnittlichen Durchsatz von über 3,4 GBps für Produzenten und Verbraucher.  Das sind über 3,4 Millionen Nachrichten im gesamten Kafka-Cluster.  Durch die Visualisierung des anhaltenden Durchsatzes in Bytes pro Sekunde für BrokerTopicMetrics sehen wir die hervorragende Dauerleistung und den Datenverkehr, die vom AFF A900 unterstützt werden.</block>
  <block id="c99b1e0f8a1447330448c8c7dc3df6b6" category="inline-image-macro">Dieses Diagramm zeigt den Broker-Netzwerkdurchsatz.</block>
  <block id="7965f443cb0aaaa8c5c51bc5dec6bed3" category="paragraph"><block ref="7965f443cb0aaaa8c5c51bc5dec6bed3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9877d3e22635e0b37f0b74ab2d832d05" category="paragraph">Dies passt gut zur Ansicht der pro Thema übermittelten Nachrichten.  Das folgende Diagramm bietet eine Aufschlüsselung nach Themen.  In der getesteten Konfiguration haben wir fast 900.000 Nachrichten pro Thema in vier Themenbereichen gesehen.</block>
  <block id="a6f05b2032cdce5554a9058f33e2d728" category="paragraph"><block ref="a6f05b2032cdce5554a9058f33e2d728" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc35bf5a15bb7c42ab972c7038f773f5" category="section-title">Extreme Leistung und Ausloten der Speichergrenzen</block>
  <block id="58b4fe8d21ee892b9633349960eaa7ab" category="paragraph">Für AFF haben wir auch mit OMB unter Verwendung der Backlog-Funktion getestet.  Die Backlog-Funktion pausiert Verbraucherabonnements, während sich im Kafka-Cluster ein Rückstand an Ereignissen aufbaut.  Während dieser Phase tritt nur Produzentenverkehr auf, der Ereignisse generiert, die in Protokollen festgehalten werden.  Dies emuliert am ehesten die Stapelverarbeitung oder Offline-Analyse-Workflows. In diesen Workflows werden Verbraucherabonnements gestartet und müssen historische Daten lesen, die bereits aus dem Broker-Cache entfernt wurden.</block>
  <block id="2aeeb1b752e68f3fabc8026c34af1e23" category="paragraph">Um die Speicherbeschränkungen für den Verbraucherdurchsatz in dieser Konfiguration zu verstehen, haben wir die reine Produzentenphase gemessen, um zu verstehen, wie viel Schreibverkehr der A900 aufnehmen kann.  Siehe den nächsten Abschnitt "<block ref="dbf93a9130703fe2432219c42c2bf311" category="inline-xref-macro-rx"></block> ", um zu verstehen, wie diese Daten genutzt werden können.</block>
  <block id="feec11a45c1fd079250c6f3603d708cd" category="paragraph">Während des Nur-Produzenten-Teils dieser Messung sahen wir einen hohen Spitzendurchsatz, der die Grenzen der A900-Leistung ausreizte (wenn andere Broker-Ressourcen nicht durch die Bedienung des Produzenten- und Verbraucherverkehrs ausgelastet waren).</block>
  <block id="bab88ff8b10be68a7d1ab6839852ce6b" category="paragraph"><block ref="bab88ff8b10be68a7d1ab6839852ce6b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f237b36d09d10702066fb620cf352dcf" category="admonition">Wir haben die Nachrichtengröße für diese Messung auf 16 KB erhöht, um den Overhead pro Nachricht zu begrenzen und den Speicherdurchsatz zu NFS-Mountpunkten zu maximieren.</block>
  <block id="9e1dbe9319ed19b15341f3000f56398a" category="paragraph">Der Confluent Kafka-Cluster erreichte einen Spitzenproduzentendurchsatz von 4,03 GBps.</block>
  <block id="3355268f822f520fe03b272691c2e428" category="paragraph">Nachdem OMB das Auffüllen des Eventbacklogs abgeschlossen hatte, wurde der Verbraucherverkehr neu gestartet.  Bei Messungen mit Backlog-Drainage konnten wir einen Spitzendurchsatz der Verbraucher von über 20 GBits/s bei allen Themen feststellen.  Der kombinierte Durchsatz zum NFS-Volume, auf dem die OMB-Protokolldaten gespeichert sind, lag bei etwa 30 GBits/s.</block>
  <block id="157a25969caf77d231e319ce70f0b637" category="section-title">Größenberatung</block>
  <block id="2e4bacad236b9e36d868b929042e2bad" category="inline-link">Größentabelle</block>
  <block id="eec877a6f9c2530996fae2423259c2c6" category="paragraph">Amazon Web Services bietet eine<block ref="e9ae0e8f89540055129f0fae422bdb9a" category="inline-link-rx"></block> zur Größenbestimmung und Skalierung von Kafka-Clustern.</block>
  <block id="cc4abcaa3ba3e4f795b82759d3dcd056" category="paragraph">Diese Größenbestimmung bietet eine nützliche Formel zur Bestimmung des Speicherdurchsatzbedarfs für Ihren Kafka-Cluster:</block>
  <block id="f2fb73fb163775775c1145d28c68ad20" category="paragraph">Bei einem aggregierten Durchsatz, der mit einem Replikationsfaktor von r in den Cluster von tcluster erzeugt wird, beträgt der vom Broker-Speicher empfangene Durchsatz:</block>
  <block id="0acbbdd0cc159664d8baab43c6d168bd" category="paragraph">Dies lässt sich noch weiter vereinfachen:</block>
  <block id="28c949d6bdead032a1410c176cbf74cb" category="paragraph">Mithilfe dieser Formel können Sie die geeignete ONTAP Plattform für Ihre Kafka-Hot-Tier-Anforderungen auswählen.</block>
  <block id="df3f8ed04b35156def4360bb05a77cc1" category="paragraph">Die folgende Tabelle erläutert den erwarteten Herstellerdurchsatz für den A900 mit unterschiedlichen Replikationsfaktoren:</block>
  <block id="329589e3ff014cb50ee2238aecc6a867" category="cell">Replikationsfaktor</block>
  <block id="75ec49708cc8881a7762e3740e342ca3" category="cell">Produzentendurchsatz (GPps)</block>
  <block id="c2b3050f7fde2050bb86e4e9ef0f7567" category="cell">3 (gemessen)</block>
  <block id="31053ad0506e935470ca21b43cae98cf" category="cell">3,4</block>
  <block id="c81e728d9d4c2f636f067f89cc14862c" category="cell">2</block>
  <block id="43ff194f410f3e93a8680bef5ba51e50" category="cell">5,1</block>
  <block id="a9d9d1b0257dda96d595bd00149cccdb" category="cell">10,2</block>
  <block id="bc0316be7ba1d2f8b53c282f09f9b532" category="summary">Ein Kafka-Cluster mit der auf NetApp NFS montierten Speicherschicht wurde hinsichtlich seiner Leistung in der AWS-Cloud getestet.  Die Benchmarking-Beispiele werden in den folgenden Abschnitten beschrieben.</block>
  <block id="bf57de8e029ea3108f102be3202cff5f" category="doc">Leistungsübersicht und -validierung in AWS FSx ONTAP</block>
  <block id="71db594c48140b244b2b54ff2bdedb71" category="paragraph">Ein Kafka-Cluster mit der auf NetApp NFS montierten Speicherschicht wurde hinsichtlich seiner Leistung im AWS FSx ONTAP getestet.  Die Benchmarking-Beispiele werden in den folgenden Abschnitten beschrieben.</block>
  <block id="1c036e91476215fff31a2c45fdf276f9" category="section-title">Apache Kafka in AWS FSx ONTAP</block>
  <block id="29144a8d530212e5210d98eceae62106" category="paragraph">Network File System (NFS) ist ein weit verbreitetes Netzwerkdateisystem zum Speichern großer Datenmengen.  In den meisten Organisationen werden Daten zunehmend durch Streaming-Anwendungen wie Apache Kafka generiert.  Diese Workloads erfordern Skalierbarkeit, geringe Latenz und eine robuste Datenaufnahmearchitektur mit modernen Speicherfunktionen.  Um Echtzeitanalysen zu ermöglichen und umsetzbare Erkenntnisse zu liefern, ist eine gut konzipierte und hochleistungsfähige Infrastruktur erforderlich.</block>
  <block id="3c10ee4415fe854b95a1b3d124b0f0ea" category="paragraph">Kafka arbeitet konstruktionsbedingt mit POSIX-kompatiblen Dateisystemen und verlässt sich bei der Verarbeitung von Dateivorgängen auf das Dateisystem. Beim Speichern von Daten auf einem NFSv3-Dateisystem kann der NFS-Client des Kafka-Brokers Dateivorgänge jedoch anders interpretieren als ein lokales Dateisystem wie XFS oder Ext4.  Ein häufiges Beispiel ist die NFS Silly-Umbenennung, die zum Ausfall von Kafka-Brokern beim Erweitern von Clustern und Neuzuordnen von Partitionen führte.  Um diese Herausforderung zu bewältigen, hat NetApp den Open-Source-Linux-NFS-Client mit Änderungen aktualisiert, die jetzt allgemein in RHEL8.7 und RHEL9.1 verfügbar sind und ab der aktuellen FSx ONTAP Version ONTAP 9.12.1 unterstützt werden.</block>
  <block id="2c69958ee453c213417e415ee57b1690" category="paragraph">Amazon FSx ONTAP bietet ein vollständig verwaltetes, skalierbares und leistungsstarkes NFS-Dateisystem in der Cloud.  Kafka-Daten auf FSx ONTAP können skaliert werden, um große Datenmengen zu verarbeiten und Fehlertoleranz zu gewährleisten.  NFS bietet zentrales Speichermanagement und Datenschutz für kritische und sensible Datensätze.</block>
  <block id="542c651fdfac42519bffb9b7ebf01539" category="paragraph">Diese Verbesserungen ermöglichen es AWS-Kunden, die Vorteile von FSx ONTAP zu nutzen, wenn sie Kafka-Workloads auf AWS-Rechendiensten ausführen.  Diese Vorteile sind: * Reduzierung der CPU-Auslastung zur Verkürzung der E/A-Wartezeit * Schnellere Wiederherstellungszeit des Kafka-Brokers.  * Zuverlässigkeit und Effizienz.  * Skalierbarkeit und Leistung.  * Verfügbarkeit in mehreren Verfügbarkeitszonen.  * Datenschutz.</block>
  <block id="cafd94f15e4ecd146a2af6ea620cc490" category="section-title">Kafka in AWS FSx ONTAP</block>
  <block id="7e3b8d1a53f4bf4f127be8ea0fda504d" category="paragraph">Ein Kafka-Cluster mit AWS FSx ONTAP wurde hinsichtlich seiner Leistung in der AWS-Cloud getestet.  Dieses Benchmarking wird in den folgenden Abschnitten beschrieben.</block>
  <block id="029bc8dc2b20f11a166635df18b0a419" category="section-title">Architektonischer Aufbau</block>
  <block id="6d14883a196c6b234f62d60a400fe708" category="paragraph">Die folgende Tabelle zeigt die Umgebungskonfiguration für einen Kafka-Cluster mit AWS FSx ONTAP.</block>
  <block id="7a785978a6b38bb45ae8786c30a1781e" category="cell">Plattformkomponente</block>
  <block id="c704d8c873b1a8d5d0243075656aa1f5" category="cell">Umgebungskonfiguration</block>
  <block id="f874b8bfe50ce846d8156aabe96e5a34" category="cell">Kafka 3.2.3</block>
  <block id="e2322efe17a0927e7f855686b9597301" category="list-text">3 x Tierpfleger – t2.small</block>
  <block id="ea55ea3b374458b5777457efaf0db679" category="list-text">3 x Broker-Server – i3en.2xlarge</block>
  <block id="d521f24278937c9ada520622e97168d8" category="list-text">1 x Grafana – c5n.2xlarge</block>
  <block id="747684069b5286f0282d40e544a04812" category="list-text">4 x Produzent/Verbraucher -- c5n.2xlarge *</block>
  <block id="29c331c65dbb1c85faa29881b295fbfc" category="cell">Betriebssystem auf allen Knoten</block>
  <block id="a0d574b61a80df70bd921b269853cc18" category="cell">RHEL8.6</block>
  <block id="9e813193a6755822d3c1628326e814e6" category="cell">Multi-AZ mit 4 GB/Sek. Durchsatz und 160.000 IOPS</block>
  <block id="8eb6827eb8f798501ab14f58155a9982" category="section-title">NetApp FSx ONTAP Setup</block>
  <block id="eb1e12842ba64aa1b662a4e95a406d45" category="list-text">Für unsere ersten Tests haben wir ein FSx ONTAP Dateisystem mit 2 TB Kapazität und 40.000 IOPs für einen Durchsatz von 2 GB/s erstellt.</block>
  <block id="7ce8d5b94f98d9eb7023e64b4f92f5fd" category="paragraph">In unserem Beispiel stellen wir FSx ONTAP über die AWS CLI bereit.  Sie müssen den Befehl in Ihrer Umgebung nach Bedarf weiter anpassen.  FSx ONTAP kann zusätzlich über die AWS-Konsole bereitgestellt und verwaltet werden, um eine einfachere und optimierte Bereitstellung mit weniger Befehlszeileneingaben zu ermöglichen.</block>
  <block id="81656db36243146de24c60a68b7b395c" category="paragraph">Dokumentation: In FSx ONTAP beträgt der maximal erreichbare IOPS-Wert für ein Dateisystem mit 2 GB/s Durchsatz in unserer Testregion (US-Ost-1) 80.000 IOPS.  Die maximalen Gesamt-IOPS für ein FSx ONTAP -Dateisystem betragen 160.000 IOPS. Um dies zu erreichen, ist eine Bereitstellung mit einem Durchsatz von 4 GB/s erforderlich, was wir später in diesem Dokument demonstrieren werden.</block>
  <block id="3c50ca3005ca0da0071db25317a45f47" category="paragraph">Weitere Informationen zu den Leistungsspezifikationen von FSx ONTAP finden Sie hier in der AWS FSx ONTAP -Dokumentation:<block ref="f270bb91d9718c264ef59ceaf9562990" category="inline-link-rx"></block> .</block>
  <block id="ac3f15100beedf3665df00f75c6a126e" category="paragraph">Eine detaillierte Befehlszeilensyntax für FSx „create-file-system“ finden Sie hier:<block ref="6dfaa72a4db79e3cd69acb6bd09e3928" category="inline-link-rx"></block></block>
  <block id="4510c1fa7d54bc22137fc99fdee7ec14" category="paragraph">Sie können beispielsweise einen bestimmten KMS-Schlüssel angeben, im Gegensatz zum standardmäßigen AWS FSx-Hauptschlüssel, der verwendet wird, wenn kein KMS-Schlüssel angegeben ist.</block>
  <block id="b2d4bc4b14215051ed2eea3eff254d84" category="list-text">Warten Sie beim Erstellen des FSx ONTAP Dateisystems, bis sich der Status „LifeCycle“ in Ihrer JSON-Rückgabe in „AVAILABLE“ ändert, nachdem Sie Ihr Dateisystem wie folgt beschrieben haben:</block>
  <block id="fcd00639267fd24b3c25a30b3abcd5b0" category="list-text">Bestätigen Sie die Anmeldeinformationen, indem Sie sich mit dem Benutzer fsxadmin bei FSx ONTAP SSH anmelden: Fsxadmin ist das Standardadministratorkonto für FSx ONTAP Dateisysteme bei der Erstellung.  Das Kennwort für fsxadmin ist das Kennwort, das beim ersten Erstellen des Dateisystems entweder in der AWS-Konsole oder mit der AWS CLI konfiguriert wurde, wie wir es in Schritt 1 abgeschlossen haben.</block>
  <block id="89fd702da938a0842ce8bbbd1978c407" category="list-text">Sobald Ihre Anmeldeinformationen validiert wurden, erstellen Sie die virtuelle Speichermaschine auf dem FSx ONTAP Dateisystem</block>
  <block id="52140a6ade484065f20232f9d150ea61" category="paragraph">Eine Storage Virtual Machine (SVM) ist ein isolierter Dateiserver mit eigenen Administratoranmeldeinformationen und Endpunkten zum Verwalten und Zugreifen auf Daten in FSx ONTAP Volumes und bietet FSx ONTAP Multi-Tenancy.</block>
  <block id="e05c7d2454cf3006c8871c25085ec858" category="list-text">Nachdem Sie Ihre primäre Storage Virtual Machine konfiguriert haben, greifen Sie per SSH auf das neu erstellte FSx ONTAP Dateisystem zu und erstellen Sie Volumes in der Storage Virtual Machine mit dem folgenden Beispielbefehl. Auf ähnliche Weise erstellen wir 6 Volumes für diese Validierung.  Behalten Sie basierend auf unserer Validierung die Standardkomponente (8) oder weniger Komponenten bei, was zu einer besseren Leistung von Kafka führt.</block>
  <block id="f82c8c9ef7e5f94bfc60abe80b30a2c1" category="list-text">Für unsere Tests benötigen wir zusätzliche Kapazitäten in unseren Volumina.  Erweitern Sie die Größe des Volumes auf 2 TB und mounten Sie es auf dem Verbindungspfad.</block>
  <block id="401223c85704727381abb64f33f1e700" category="paragraph">In FSx ONTAP können Volumes per Thin Provisioning bereitgestellt werden.  In unserem Beispiel übersteigt die Gesamtkapazität des erweiterten Volumes die Gesamtkapazität des Dateisystems. Daher müssen wir die Gesamtkapazität des Dateisystems erweitern, um zusätzliche bereitgestellte Volumekapazität freizugeben, was wir im nächsten Schritt demonstrieren werden.</block>
  <block id="980bf78b74033a80493ead9ead18533e" category="list-text">Als nächstes erweitern wir für zusätzliche Leistung und Kapazität die FSx ONTAP Durchsatzkapazität von 2 GB/Sek. auf 4 GB/Sek. und IOPS auf 160000 und die Kapazität auf 5 TB</block>
  <block id="cfd6d8adc21dc264014c117cc1a95fda" category="paragraph">Eine detaillierte Befehlszeilensyntax für FSx „update-file-system“ finden Sie hier:<block ref="f3196344ef0cf3de8d956a0736aba68b" category="inline-link-rx"></block></block>
  <block id="d067a587144a5c3f420cd628e1e5e9ae" category="list-text">Die FSx ONTAP -Volumes werden mit nconnect und Standardoptionen in Kafka-Brokern gemountet</block>
  <block id="fe25ee0c1614b7db9e4a6cec9f2cd488" category="paragraph">Das folgende Bild zeigt unsere endgültige Architektur eines auf FSx ONTAP basierenden Kafka-Clusters:</block>
  <block id="a09d4eb20485c4e2d2f9ed81274d727a" category="inline-image-macro">Dieses Bild zeigt die Architektur eines FSx ONTAP-basierten Kafka-Clusters.</block>
  <block id="f230dbbbd1d967f5675641bd1e9ff03e" category="paragraph"><block ref="f230dbbbd1d967f5675641bd1e9ff03e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a205c51d74e59d28030cda2886e41130" category="list-text">Berechnen.  Wir haben einen Kafka-Cluster mit drei Knoten und einem Zookeeper-Ensemble mit drei Knoten verwendet, das auf dedizierten Servern ausgeführt wird.  Jeder Broker hatte sechs NFS-Mount-Punkte für sechs Volumes auf der FSx ONTAP Instanz.</block>
  <block id="447931d0542671d1817df0b8bdc35ff4" category="list-text">Überwachung.  Wir haben zwei Knoten für eine Prometheus-Grafana-Kombination verwendet.  Zum Generieren von Workloads haben wir einen separaten Cluster mit drei Knoten verwendet, der für diesen Kafka-Cluster produzieren und verbrauchen konnte.</block>
  <block id="35f0ed4ee5bc59733f7cd41a36cf4721" category="list-text">Lagerung.  Wir haben ein FSx ONTAP mit sechs gemounteten 2-TB-Volumes verwendet.  Das Volume wurde dann mit einem NFS-Mount zum Kafka-Broker exportiert. Die FSx ONTAP Volumes werden mit 16 Nconnect-Sitzungen und Standardoptionen in Kafka-Brokern gemountet.</block>
  <block id="c06018aab55e4fa9ef871b34b2cf7897" category="section-title">OpenMessage-Benchmarking-Konfigurationen.</block>
  <block id="9300a7a969a31b3c5371c03474456ec3" category="paragraph">Wir haben dieselbe Konfiguration verwendet, die für die NetApp Cloud Volumes ONTAP verwendet wurde. Die Details dazu finden Sie hier: Link:kafka-nfs-performance-overview-and-validation-in-aws.html#architectural-setup</block>
  <block id="91c26176df142d17ab999313541632c5" category="section-title">Testmethodik</block>
  <block id="79f0e8e2c892a7ffb6c02f9be47fd6f5" category="list-text">Ein Kafka-Cluster wurde gemäß der oben beschriebenen Spezifikation mithilfe von Terraform und Ansible bereitgestellt.  Terraform wird verwendet, um die Infrastruktur mithilfe von AWS-Instanzen für den Kafka-Cluster aufzubauen, und Ansible erstellt den Kafka-Cluster darauf.</block>
  <block id="d9a3b4ca51b8378374ab25c3f90ec2a2" category="list-text">Mit der oben beschriebenen Workload-Konfiguration und dem Sync-Treiber wurde eine OMB-Workload ausgelöst.</block>
  <block id="3f6a85702112dff5bcd0970b7ceb3f02" category="list-text">Mit dem Throughput-Treiber wurde eine weitere Workload mit derselben Workload-Konfiguration ausgelöst.</block>
  <block id="c680d437163cc6bab4f9bdb35c3073d0" category="section-title">Beobachtung</block>
  <block id="5f2da6c069f19294c52f39a18639f0d2" category="paragraph">Zum Generieren von Workloads wurden zwei verschiedene Treibertypen verwendet, um die Leistung einer auf NFS laufenden Kafka-Instanz zu vergleichen.  Der Unterschied zwischen den Treibern liegt in der Log-Flush-Eigenschaft.</block>
  <block id="6e3e5905f95f1d3670a864fd2b1e1855" category="paragraph">Für einen Kafka-Replikationsfaktor 1 und den FSx ONTAP:</block>
  <block id="477397883986e4a6ef0944db3f171a9a" category="list-text">Gesamtdurchsatz, der durchgängig vom Sync-Treiber generiert wird: ~ 3218 MBps und Spitzenleistung bei ~ 3652 MBps.</block>
  <block id="526cf61e40ed54cf3e36bc48e608fe6a" category="list-text">Gesamtdurchsatz, der durchgängig vom Durchsatztreiber generiert wird: ~ 3679 MBps und Spitzenleistung bei ~ 3908 MBps.</block>
  <block id="5c677e3834aab5345e650615a307b653" category="paragraph">Für Kafka mit Replikationsfaktor 3 und FSx ONTAP :</block>
  <block id="1d0957e5fc4340aeed631639b2076501" category="list-text">Gesamtdurchsatz, der durchgängig vom Sync-Treiber generiert wird: ~ 1252 MBps und Spitzenleistung bei ~ 1382 MBps.</block>
  <block id="e18b6be6753e1c55e4474648e1073e75" category="list-text">Gesamtdurchsatz, der durch den Durchsatztreiber konstant generiert wird: ~ 1218 MBps und Spitzenleistung bei ~ 1328 MBps.</block>
  <block id="9e99c55380b9b536ec73cd9bdfbad865" category="paragraph">Beim Kafka-Replikationsfaktor 3 erfolgte der Lese- und Schreibvorgang dreimal auf dem FSx ONTAP. Beim Kafka-Replikationsfaktor 1 erfolgt der Lese- und Schreibvorgang einmal auf dem FSx ONTAP, sodass wir bei beiden Validierungen den maximalen Durchsatz von 4 GB/s erreichen konnten.</block>
  <block id="4bb1ab47e2a029960970bd2e246f9a57" category="paragraph">Der Sync-Treiber kann einen konsistenten Durchsatz generieren, da Protokolle sofort auf die Festplatte geschrieben werden, während der Throughput-Treiber Durchsatzschübe generiert, da Protokolle in großen Mengen auf die Festplatte geschrieben werden.</block>
  <block id="920a7d00fe9032493a9a70c1e6c8972a" category="paragraph">Diese Durchsatzzahlen werden für die jeweilige AWS-Konfiguration generiert.  Bei höheren Leistungsanforderungen können die Instanztypen hochskaliert und für bessere Durchsatzzahlen weiter optimiert werden.  Der Gesamtdurchsatz oder die Gesamtrate ist die Kombination aus Produzenten- und Verbraucherrate.</block>
  <block id="5d4902b750979a6daa75a334daf3b4dd" category="inline-image-macro">Dieses Bild zeigt die Leistung von Kafka mit RF1 und RF3</block>
  <block id="67731dd79a61f656bfde458fade09eb2" category="paragraph"><block ref="67731dd79a61f656bfde458fade09eb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3293059261e00d42aa4678d1677be1b1" category="paragraph">Das folgende Diagramm zeigt die Leistung von 2 GB/s für FSx ONTAP und 4 GB/s für den Kafka-Replikationsfaktor 3.  Der Replikationsfaktor 3 führt den Lese- und Schreibvorgang dreimal auf dem FSx ONTAP Speicher aus.  Die Gesamtrate für den Durchsatztreiber beträgt 881 MB/s, was Lese- und Schreibvorgänge für Kafka mit ungefähr 2,64 GB/s auf dem FSx ONTAP Dateisystem mit 2 GB/s ausführt, und die Gesamtrate für den Durchsatztreiber beträgt 1328 MB/s, was Lese- und Schreibvorgänge für Kafka mit ungefähr 3,98 GB/s ausführt.  Die Kafka-Leistung ist linear und basierend auf dem FSx ONTAP Durchsatz skalierbar.</block>
  <block id="a7ddac9765853f96e59270871b8a3925" category="inline-image-macro">Dieses Bild zeigt die Scale-Out-Leistung von 2 GB/s und 4 GB/s.</block>
  <block id="94043e4666620e8e09ceedcb705c7951" category="paragraph"><block ref="94043e4666620e8e09ceedcb705c7951" category="inline-image-macro-rx" type="image"></block></block>
  <block id="61f2d83a3758c796ac8892836cada117" category="paragraph">Das folgende Diagramm zeigt die Leistung zwischen EC2-Instanz und FSx ONTAP (Kafka-Replikationsfaktor: 3).</block>
  <block id="b891a78e120a481bc23346cb210b2fa2" category="inline-image-macro">Dieses Bild zeigt den Leistungsvergleich von EC2 und FSx ONTAP in RF3.</block>
  <block id="59b617ab46ce09f11c02ed94c18645e4" category="paragraph"><block ref="59b617ab46ce09f11c02ed94c18645e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02b742a6a1f227191aecb81d8822d2ee" category="doc">Leistungsübersicht und -validierung in AWS</block>
  <block id="28e2dfa4242e2b504727dab8605d1432" category="section-title">Kafka in der AWS-Cloud mit NetApp Cloud Volumes ONTAP (Hochverfügbarkeitspaar und Einzelknoten)</block>
  <block id="1dc7a426b0cbf7d35c5edda73f68403d" category="paragraph">Ein Kafka-Cluster mit NetApp Cloud Volumes ONTAP (HA-Paar) wurde hinsichtlich seiner Leistung in der AWS-Cloud getestet.  Dieses Benchmarking wird in den folgenden Abschnitten beschrieben.</block>
  <block id="61c964c4267b0fa60eeaa1a7ccdf706e" category="paragraph">Die folgende Tabelle zeigt die Umgebungskonfiguration für einen Kafka-Cluster mit NAS.</block>
  <block id="4f04a8a7e04e79aafa7150a5ae2bab1b" category="cell">NetApp Cloud Volumes ONTAP Instanz</block>
  <block id="462fed98d4e5a4d1be4d08b1fdd3f0df" category="cell">HA-Paarinstanz – m5dn.12xLarge x 2 Knoten Einzelknoteninstanz – m5dn.12xLarge x 1 Knoten</block>
  <block id="29e8b4fdf26266c94b184b76858f935e" category="section-title">NetApp Cluster Volume ONTAP Setup</block>
  <block id="febbbf2a22b781c8cb2d828a8cbf52d6" category="list-text">Für das Cloud Volumes ONTAP HA-Paar haben wir zwei Aggregate mit jeweils drei Volumes auf jedem Aggregat auf jedem Speichercontroller erstellt.  Für den einzelnen Cloud Volumes ONTAP -Knoten erstellen wir sechs Volumes in einem Aggregat.</block>
  <block id="72bcc37cf8850d4e74a6305d71727956" category="inline-image-macro">Dieses Bild zeigt die Eigenschaften von aggr3 und aggr22.</block>
  <block id="cc5972f21a1c1b3f25fd1c54ca580885" category="paragraph"><block ref="cc5972f21a1c1b3f25fd1c54ca580885" category="inline-image-macro-rx" type="image"></block></block>
  <block id="518fcf406a83698c4ba5d2f41cafab41" category="inline-image-macro">Dieses Bild zeigt die Eigenschaften von aggr2.</block>
  <block id="7bf987d778dee1c98d1b0b2d5fb00a9c" category="paragraph"><block ref="7bf987d778dee1c98d1b0b2d5fb00a9c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a6501fcefae41cda9ecf425cdc1ef15" category="list-text">Um eine bessere Netzwerkleistung zu erzielen, haben wir Hochgeschwindigkeitsnetzwerke sowohl für das HA-Paar als auch für den einzelnen Knoten aktiviert.</block>
  <block id="a4de9e1c332b656e2e19024cce28f939" category="inline-image-macro">Dieses Bild zeigt, wie Hochgeschwindigkeitsnetzwerke aktiviert werden.</block>
  <block id="49c32669e9d6be5a2b08ff5d8eb59127" category="paragraph"><block ref="49c32669e9d6be5a2b08ff5d8eb59127" category="inline-image-macro-rx" type="image"></block></block>
  <block id="678217b29dc6cbf917f08c79a1819f92" category="list-text">Wir haben festgestellt, dass der ONTAP NVRAM mehr IOPS hatte, also haben wir die IOPS für das Cloud Volumes ONTAP Stammvolume auf 2350 geändert.  Die Root-Volume-Festplatte in Cloud Volumes ONTAP hatte eine Größe von 47 GB.  Der folgende ONTAP -Befehl gilt für das HA-Paar und der gleiche Schritt ist für den einzelnen Knoten anwendbar.</block>
  <block id="71ac6dbf3d671b6b9db5497aad37fc67" category="inline-image-macro">Dieses Bild zeigt, wie die Volume-Eigenschaften geändert werden.</block>
  <block id="044b1cecac787ba4da45dc749881f5a1" category="paragraph"><block ref="044b1cecac787ba4da45dc749881f5a1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6c2cacbcd5f4927358fee9d8a0b60252" category="paragraph">Die folgende Abbildung zeigt die Architektur eines NAS-basierten Kafka-Clusters.</block>
  <block id="a5f2ebf87b5aa37d2e02d041ede98e4f" category="list-text">*Berechnen.*  Wir haben einen Kafka-Cluster mit drei Knoten und einem Zookeeper-Ensemble mit drei Knoten verwendet, das auf dedizierten Servern ausgeführt wird.  Jeder Broker verfügte über zwei NFS-Mount-Punkte zu einem einzelnen Volume auf der Cloud Volumes ONTAP Instanz über ein dediziertes LIF.</block>
  <block id="493b3bd02a683f505d957bb27957e1b6" category="list-text">*Überwachung.*  Wir haben zwei Knoten für eine Prometheus-Grafana-Kombination verwendet.  Zum Generieren von Workloads haben wir einen separaten Cluster mit drei Knoten verwendet, der für diesen Kafka-Cluster produzieren und konsumieren konnte.</block>
  <block id="dcb39d8372b01f5eb051372b3d943fbd" category="list-text">*Lagerung.*  Wir haben eine HA-Pair-Cloud-Volumes ONTAP Instanz mit einem auf der Instanz gemounteten 6-TB-GP3-AWS-EBS-Volume verwendet.  Anschließend wurde das Volume mit einem NFS-Mount zum Kafka-Broker exportiert.</block>
  <block id="78f0f1d311c4aae35de324851ecea08a" category="inline-image-macro">Diese Abbildung zeigt die Architektur eines NAS-basierten Kafka-Clusters.</block>
  <block id="474d97e74219f2fc9511f3691ed0ae94" category="paragraph"><block ref="474d97e74219f2fc9511f3691ed0ae94" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cce0ad6ab772599285bd32c539025c1f" category="section-title">OpenMessage Benchmarking-Konfigurationen</block>
  <block id="6a1fe63829e046313e1b3073459bf538" category="list-text">Für eine bessere NFS-Leistung benötigen wir mehr Netzwerkverbindungen zwischen dem NFS-Server und dem NFS-Client, die mit nconnect erstellt werden können.  Mounten Sie die NFS-Volumes auf den Broker-Knoten mit der Option „nconnect“, indem Sie den folgenden Befehl ausführen:</block>
  <block id="a973eefced896f4a698ed64af6dc0199" category="list-text">Überprüfen Sie die Netzwerkverbindungen in Cloud Volumes ONTAP.  Der folgende ONTAP -Befehl wird vom einzelnen Cloud Volumes ONTAP Knoten verwendet.  Derselbe Schritt gilt für das Cloud Volumes ONTAP HA-Paar.</block>
  <block id="828ed34406e4dab30166070e0af1f142" category="list-text">Wir verwenden folgende Kafka<block ref="05cc8f97f27bba0114c55d20c80d4fe7" prefix=" " category="inline-code"></block> in allen Kafka-Brokern für das Cloud Volumes ONTAP HA-Paar.  Der<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> Die Eigenschaft ist für jeden Broker unterschiedlich und die übrigen Eigenschaften sind für alle Broker gleich.  Für Broker1 ist die<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> Der Wert lautet wie folgt:</block>
  <block id="66ddebf2d4ab98ff8682a008dc466ce6" category="list-text">Für Broker2 ist die<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> Der Eigenschaftswert lautet wie folgt:</block>
  <block id="fcfc381980a9ed554f51cbfd5b77616a" category="list-text">Für Broker3 ist die<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> Der Eigenschaftswert lautet wie folgt:</block>
  <block id="00d57462d7009374713be86d6c491d89" category="list-text">Für den einzelnen Cloud Volumes ONTAP -Knoten: Der Kafka<block ref="21d5034d4d99d6ca0da314367f1cccd6" prefix=" " category="inline-code"></block> ist das gleiche wie für das Cloud Volumes ONTAP HA-Paar, außer der<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> Eigentum.</block>
  <block id="cf168cce281f1eccdc9f9fb55c933d29" category="list-text">Für Broker1 ist die<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> Der Wert lautet wie folgt:</block>
  <block id="1692ac5191f19e15cf0e3a8af0820752" category="list-text">Für Broker2 ist die<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> Der Wert lautet wie folgt:</block>
  <block id="4b0728fa62359454465b3a26a608d83c" category="list-text">Die Arbeitslast im OMB ist mit den folgenden Eigenschaften konfiguriert:<block ref="9a97642a426510e31f49e0a98ed35e46" prefix=" " category="inline-code"></block> .</block>
  <block id="433b44cf3e6084d97e5162a06d481873" category="paragraph">Der<block ref="f21d26061df60c086aedb156e38f66b5" prefix=" " category="inline-code"></block> kann je nach Anwendungsfall unterschiedlich sein.  In unserem Leistungstest haben wir 3K verwendet.</block>
  <block id="bd9348653b0cfa7f0962b694fa058428" category="paragraph">Wir haben zwei verschiedene Treiber, Sync oder Throughput, von OMB verwendet, um die Arbeitslast auf dem Kafka-Cluster zu generieren.</block>
  <block id="50e5861dab89d00bf88787e044b2c24f" category="list-text">Die für die Sync-Treibereigenschaften verwendete YAML-Datei lautet wie folgt<block ref="46c2adf6b9dc6e5883c47b1d76feb008" prefix=" " category="inline-code"></block> :</block>
  <block id="9ae100f8fb1875133a485c355266af55" category="list-text">Die für die Durchsatztreibereigenschaften verwendete YAML-Datei lautet wie folgt<block ref="658e4b47fcd8812e9b0b2886af867717" prefix=" " category="inline-code"></block> :</block>
  <block id="a887b430cb278fa8f52827a223308324" category="list-text">Ein Kafka-Cluster wurde gemäß der oben beschriebenen Spezifikation mit Terraform und Ansible bereitgestellt.  Terraform wird verwendet, um die Infrastruktur mithilfe von AWS-Instanzen für den Kafka-Cluster aufzubauen, und Ansible baut den Kafka-Cluster darauf auf.</block>
  <block id="59f70e2d523801f5ede7c9bb7b48cc76" category="paragraph">Für ein Cloud Volumes ONTAP HA-Paar:</block>
  <block id="ffb03fd768825b381d478b114716f8cf" category="list-text">Gesamtdurchsatz, der durchgängig vom Sync-Treiber generiert wird: ~1236 MBps.</block>
  <block id="84c96e7c92d1f10aac5f3600c7df9299" category="list-text">Gesamtdurchsatz, der für den Durchsatztreiber generiert wurde: Spitze ~1412 MBps.</block>
  <block id="5896e2cd1e01fb8ef69cdf280a9a38e3" category="paragraph">Für einen einzelnen Cloud Volumes ONTAP Knoten:</block>
  <block id="d3c9dedf3eb9fce5e9a983948c3cef0e" category="list-text">Gesamtdurchsatz, der durchgängig vom Sync-Treiber generiert wird: ~ 1962 MBps.</block>
  <block id="86acf2bdaf8de60bbc77d3dc8f0e1b12" category="list-text">Gesamtdurchsatz, der vom Durchsatztreiber generiert wird: Spitze ~1660 MBps</block>
  <block id="c5616509b949bfcdee10d7e87918ec9d" category="inline-image-macro">Hier werden vier verschiedene Diagramme präsentiert.  CVO-HA-Paar-Durchsatztreiber.  CVO-HA-Paar-Sync-Treiber.  CVO-Einzelknoten-Durchsatztreiber.  CVO-Einzelknoten-Sync-Treiber.</block>
  <block id="d2fc51602d60125ca82c279f8a8e03af" category="paragraph"><block ref="d2fc51602d60125ca82c279f8a8e03af" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8c6ad6fcb6db991d86273d33ed35d3c9" category="paragraph">Überprüfen Sie unbedingt den Speicherdurchsatz, wenn Sie ein Durchsatz- oder Synchronisierungstreiber-Benchmarking durchführen.</block>
  <block id="22156e4cc2df3388f0f9dfe0c178db37" category="inline-image-macro">Dieses Diagramm zeigt die Leistung in Bezug auf Latenz, IOPS und Durchsatz.</block>
  <block id="e34c5c483b0b104d0cc1453f3be5f6b4" category="paragraph"><block ref="e34c5c483b0b104d0cc1453f3be5f6b4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc2e9a005ff6b9d50a1fca9914e8eac0" category="summary">In diesem Abschnitt wird das Problem der dummen Umbenennung und die erforderlichen Änderungen am NFS-Server und NFS-Client beschrieben, um das Problem zu beheben.</block>
  <block id="0d5e61a5d0c056718a15d6df7037a50c" category="doc">NetApp -Lösung für das dumme Umbenennungsproblem für NFS-zu-Kafka-Workloads</block>
  <block id="e5ee0fc73f4f4f38e75acb2c0b2343be" category="paragraph">Kafka wird unter der Annahme erstellt, dass das zugrunde liegende Dateisystem POSIX-kompatibel ist: beispielsweise XFS oder Ext4.  Durch die Neuverteilung der Kafka-Ressourcen werden Dateien entfernt, während die Anwendung sie noch verwendet.  Ein POSIX-kompatibles Dateisystem ermöglicht die Fortsetzung der Verknüpfungsaufhebung.  Die Datei wird jedoch erst entfernt, wenn alle Verweise auf die Datei verschwunden sind.  Wenn das zugrunde liegende Dateisystem an das Netzwerk angeschlossen ist, fängt der NFS-Client die Unlink-Aufrufe ab und verwaltet den Workflow.  Da für die Datei, deren Verknüpfung aufgehoben wird, noch Öffnungsvorgänge ausstehen, sendet der NFS-Client eine Umbenennungsanforderung an den NFS-Server und führt beim letzten Schließen der aufgehobenen Datei einen Entfernungsvorgang für die umbenannte Datei aus.  Dieses Verhalten wird allgemein als „NFS Silly Rename“ bezeichnet und wird vom NFS-Client orchestriert.</block>
  <block id="f17efbdff90d69935a8d84a6215665a5" category="paragraph">Jeder Kafka-Broker, der Speicher von einem NFSv3-Server verwendet, stößt aufgrund dieses Verhaltens auf Probleme.  Das NFSv4.x-Protokoll verfügt jedoch über Funktionen zur Behebung dieses Problems, indem es dem Server ermöglicht, die Verantwortung für die geöffneten, nicht verknüpften Dateien zu übernehmen.  NFS-Server, die diese optionale Funktion unterstützen, teilen dem NFS-Client beim Öffnen der Datei die Eigentumsrechte mit.  Der NFS-Client beendet dann die Verwaltung der Verknüpfungsaufhebung, wenn noch Öffnungen ausstehen, und überlässt dem Server die Verwaltung des Datenflusses.  Obwohl die NFSv4-Spezifikation Richtlinien für die Implementierung bereitstellt, gab es bisher keine bekannten NFS-Serverimplementierungen, die diese optionale Funktion unterstützten.</block>
  <block id="219af746424bba4643138d0820ab40b5" category="paragraph">Um das Problem der dummen Umbenennung zu beheben, sind für den NFS-Server und den NFS-Client die folgenden Änderungen erforderlich:</block>
  <block id="36efd47a4ba95b58e3b2a0f2ed7420ad" category="list-text">*Änderungen am NFS-Client (Linux).*  Beim Öffnen der Datei antwortet der NFS-Server mit einem Flag, das die Fähigkeit anzeigt, die Verknüpfung geöffneter Dateien aufzuheben.  Durch Änderungen auf der NFS-Clientseite kann der NFS-Server die Aufhebung der Verknüpfung bei Vorhandensein des Flags handhaben.  NetApp hat den Open-Source-Linux-NFS-Client mit diesen Änderungen aktualisiert.  Der aktualisierte NFS-Client ist jetzt allgemein in RHEL8.7 und RHEL9.1 verfügbar.</block>
  <block id="f400588f268c9f90112ff6290a81575a" category="list-text">*Änderungen am NFS-Server.*  Der NFS-Server verfolgt die Öffnungen.  Das Aufheben der Verknüpfung einer vorhandenen geöffneten Datei wird jetzt vom Server verwaltet, um der POSIX-Semantik zu entsprechen.  Wenn die letzte Öffnung geschlossen ist, leitet der NFS-Server das eigentliche Entfernen der Datei ein und vermeidet so den albernen Umbenennungsprozess.  Der ONTAP NFS-Server hat diese Funktion in seiner neuesten Version, ONTAP 9.12.1, implementiert.</block>
  <block id="21a87b96dd7bfc9863d6bca5fc12f005" category="paragraph">Mit den oben genannten Änderungen am NFS-Client und -Server kann Kafka alle Vorteile des netzwerkgebundenen NFS-Speichers sicher nutzen.</block>
  <block id="8a1762b0db0285b0ca6661669e3a9aec" category="summary">Zur Funktionsvalidierung haben wir gezeigt, dass ein Kafka-Cluster mit einer NFSv3-Einbindung für den Speicher keine Kafka-Operationen wie die Partitionsumverteilung durchführen kann, während ein anderer, mit dem Fix auf NFSv4 eingebundener Cluster dieselben Operationen ohne Unterbrechungen durchführen kann.</block>
  <block id="2b1635c7ae2a72d0b26454157a03e197" category="doc">Funktionale Validierung – Dumme Umbenennungskorrektur</block>
  <block id="a8ead7a6a54d47ea0a38e64908ab321f" category="section-title">Validierungs-Setup</block>
  <block id="e087dbbdc5792f1e574cdf41c135d858" category="paragraph">Das Setup wird auf AWS ausgeführt.  Die folgende Tabelle zeigt die verschiedenen Plattformkomponenten und Umgebungskonfigurationen, die für die Validierung verwendet wurden.</block>
  <block id="cccdd75af54f32ac7f570bbcca39f516" category="cell">Confluent Platform Version 7.2.1</block>
  <block id="185b9d1a84206af090c5f70ac68f24ad" category="list-text">3 x Tierpfleger – t3.xlarge</block>
  <block id="6677060ff0c6c4620e427121a576713c" category="list-text">4 x Broker-Server – r3.xlarge</block>
  <block id="61e62294effd3d2046982e7d5a22b824" category="list-text">1 x Grafana – t3.xlarge</block>
  <block id="1e2657a43dca2051e4684eb73c2a856c" category="list-text">1 x Kontrollzentrum – t3.xlarge</block>
  <block id="2dcca349e332f9e312cebc29485dadf0" category="list-text">3 x Produzent/Konsument</block>
  <block id="00ecb59dfdd1b1378b38c6b7bf8e91dc" category="cell">RHEL8.7 oder höher</block>
  <block id="d09d15c71c68b596f76c57a87a19e0e5" category="cell">Einzelknoteninstanz – M5.2xLarge</block>
  <block id="3ba4ec8d167c12be652d6829ce6e51d8" category="paragraph">Die folgende Abbildung zeigt die Architekturkonfiguration für diese Lösung.</block>
  <block id="b3c6c8984f5671892932b2a7eacc5bf4" category="inline-image-macro">Dieses Bild zeigt die AWS-Topologie mit einem VPC, das drei private Subnetze mit einem Produzentenschwarm, dem Kafka-Cluster und einer CVO-Instanz enthält.</block>
  <block id="2046377162498de9fec810aafa41c2b3" category="paragraph"><block ref="2046377162498de9fec810aafa41c2b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7d580bb4c55b441a712ec6c9dc12d38b" category="section-title">Architektonischer Fluss</block>
  <block id="82c8c0c94e152cc00496c6c5a1fa76b0" category="list-text">*Berechnen.*  Wir haben einen Kafka-Cluster mit vier Knoten und einem Zookeeper-Ensemble mit drei Knoten verwendet, das auf dedizierten Servern ausgeführt wird.</block>
  <block id="e236bd14d5d59a952978645a606dd7f9" category="list-text">*Überwachung.*  Wir haben zwei Knoten für eine Prometheus-Grafana-Kombination verwendet.</block>
  <block id="c375f003dbf6b1accc45fd3811ce2b82" category="list-text">*Arbeitsbelastung.*  Zum Generieren von Workloads haben wir einen separaten Cluster mit drei Knoten verwendet, der für diesen Kafka-Cluster produzieren und von diesem konsumieren kann.</block>
  <block id="ada284cbb65ff7bad5814ecb0c6ecb2f" category="list-text">*Lagerung.*  Wir haben eine NetApp Cloud Volumes ONTAP Instanz mit einem Knoten verwendet, an die zwei 500 GB große GP2 AWS-EBS-Volumes angeschlossen waren.  Diese Volumes wurden dann über ein LIF als einzelnes NFSv4.1-Volume dem Kafka-Cluster zugänglich gemacht.</block>
  <block id="e86dc7584f98dc172fd46661ef8b935a" category="paragraph">Für alle Server wurden die Standardeigenschaften von Kafka gewählt.  Dasselbe wurde für den Zoowärterschwarm getan.</block>
  <block id="c31fea06105fe5260bb879284c6181e0" category="list-text">Aktualisieren<block ref="9733772c7c0780d4ef7a6a8d6a9dbd7d" prefix=" " category="inline-code"></block> zum Kafka-Band, wie folgt:</block>
  <block id="5ca41832794ba1f8118f718465d6ffe4" category="list-text">Es wurden zwei ähnliche Kafka-Cluster mit folgendem Unterschied erstellt:</block>
  <block id="fc1a46a26a283c18443e516b58cb0a58" category="list-text">*Cluster 1.*  Der Backend-NFS v4.1-Server mit der produktionsbereiten ONTAP Version 9.12.1 wurde von einer NetApp CVO-Instanz gehostet.  Auf den Brokern wurden RHEL 8.7/RHEL 9.1 installiert.</block>
  <block id="183a9a6c4f97a876554696844cf5cd19" category="list-text">*Cluster 2.*  Der Backend-NFS-Server war ein manuell erstellter generischer Linux-NFSv3-Server.</block>
  <block id="8dac413f2b3b7fdfc73d642ae6e79a33" category="list-text">Auf beiden Kafka-Clustern wurde ein Demothema erstellt.</block>
  <block id="dc30a10b7f3dac3bcce7b54e12502e89" category="paragraph">Cluster 1:</block>
  <block id="0cdb385ae4a7f7449cf10919962c71c8" category="inline-image-macro">Dieser Screenshot zeigt das auf Cluster 1 erstellte Demothema.</block>
  <block id="23e2fb3a3a7caf11826a6ddc3650812b" category="paragraph"><block ref="23e2fb3a3a7caf11826a6ddc3650812b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="83655cf6beab33b344c9ae17bec532d0" category="paragraph">Cluster 2:</block>
  <block id="772ab3218dd37dea5c304575fe358498" category="inline-image-macro">Dieser Screenshot zeigt das auf Cluster 2 erstellte Demothema.</block>
  <block id="2d82e26036412c43987356c7c8ca8fb3" category="paragraph"><block ref="2d82e26036412c43987356c7c8ca8fb3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bb392c27040a7eb25cfeb1d96323917e" category="list-text">In diese neu erstellten Themen wurden für beide Cluster Daten geladen.  Dies wurde mithilfe des Producer-Perf-Test-Toolkits durchgeführt, das im Standardpaket von Kafka enthalten ist:</block>
  <block id="bd5bb4c79c0fd5aea6e14277bbd9c5fe" category="list-text">Für Broker-1 wurde für jeden der Cluster per Telnet eine Integritätsprüfung durchgeführt:</block>
  <block id="ec97e8f78ae99ff145018ede90a47c77" category="list-text">Telnet<block ref="da440d4c50d5bbb0ffa4021d6db8332c" prefix=" " category="inline-code"></block></block>
  <block id="a93dad1338160e3b828529ad6a585d13" category="list-text">Telnet<block ref="2a3da46f5894b7e15be0ea3be46975cc" prefix=" " category="inline-code"></block></block>
  <block id="a7892fb38856d45eb1f6cd89d3118830" category="paragraph">Eine erfolgreiche Integritätsprüfung für Broker auf beiden Clustern wird im nächsten Screenshot angezeigt:</block>
  <block id="855ba5b1fb4b822400c8e412d08df6e4" category="inline-image-macro">Dieser Screenshot zeigt die Ausgabe für einen erfolgreichen Integritätscheck beider Broker.</block>
  <block id="abe3c89cfc6f09b3a5f31df9bcf7ac04" category="paragraph"><block ref="abe3c89cfc6f09b3a5f31df9bcf7ac04" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a63ad47b1692dcaccf39fb2a5c42e393" category="list-text">Um den Fehlerzustand auszulösen, der zum Absturz von Kafka-Clustern mit NFSv3-Speichervolumes führt, haben wir den Prozess zur Neuzuweisung der Partitionen auf beiden Clustern eingeleitet.  Die Neuzuweisung der Partitionen erfolgte mit<block ref="5cbd65bd2e4824bbb4876b792e513e10" prefix=" " category="inline-code"></block> .  Der detaillierte Ablauf ist wie folgt:</block>
  <block id="9ea6b7d5de4fbe3c468699ad3c8bb6ef" category="list-text">Um die Partitionen für ein Thema in einem Kafka-Cluster neu zuzuweisen, haben wir die vorgeschlagene JSON-Konfiguration für die Neuzuweisung generiert (dies wurde für beide Cluster durchgeführt).</block>
  <block id="c4c8306a70b22c96715a3f79fe60eca9" category="list-text">Das generierte Neuzuweisungs-JSON wurde dann gespeichert in<block ref="d773b1c180323b61e54dc5acaa6fb66f" prefix=" " category="inline-code"></block> .</block>
  <block id="05e65fb821eccc3b4cb26cc7285d75f8" category="list-text">Der eigentliche Partitionsneuzuweisungsprozess wurde durch den folgenden Befehl ausgelöst:</block>
  <block id="83c299e30316ef5659e9b3bbd34b40ad" category="list-text">Einige Minuten nach Abschluss der Neuzuweisung zeigte eine weitere Integritätsprüfung der Broker, dass bei Clustern mit NFSv3-Speichervolumes ein dummes Umbenennungsproblem aufgetreten war und diese abgestürzt waren, während Cluster 1 mit NetApp ONTAP NFSv4.1-Speichervolumes und dem Fix den Betrieb ohne Unterbrechungen fortsetzte.</block>
  <block id="197bc98012d3a74f45e086c86b7237bc" category="inline-image-macro">Dieser Screenshot zeigt die Ausgabe eines abgestürzten Brokers.</block>
  <block id="3a51f6a0340d9026c9fc6619a6584b83" category="paragraph"><block ref="3a51f6a0340d9026c9fc6619a6584b83" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7796cd6b11de5af34093097d2db9b94f" category="list-text">Cluster1-Broker-1 ist aktiv.</block>
  <block id="fef78f6445fec5a3c0d0cb2008e6c34e" category="list-text">Cluster2-Broker-1 ist tot.</block>
  <block id="e413a6c934b14b11c478c905d8c0489b" category="list-text">Beim Überprüfen der Kafka-Protokollverzeichnisse war klar, dass Cluster 1, der NetApp ONTAP NFSv4.1-Speichervolumes mit dem Fix verwendet, über eine saubere Partitionszuweisung verfügte, während dies bei Cluster 2, der generischen NFSv3-Speicher verwendet, aufgrund von dummen Umbenennungsproblemen, die zum Absturz führten, nicht der Fall war.  Das folgende Bild zeigt die Neuverteilung der Partitionen von Cluster 2, die zu einem dummen Umbenennungsproblem im NFSv3-Speicher führte.</block>
  <block id="1c2cca9f5ca8cce4b11ebdc970e4a78c" category="inline-image-macro">Dieser Screenshot zeigt die Protokollausgabe für den Absturz von Cluster 2.</block>
  <block id="587e107619187efb07b3bd05f8bcf7f9" category="paragraph"><block ref="587e107619187efb07b3bd05f8bcf7f9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43fea21bb45bdea6ebc007efbf3c0053" category="paragraph">Das folgende Bild zeigt eine saubere Neuverteilung der Partitionen von Cluster 1 unter Verwendung von NetApp NFSv4.1-Speicher.</block>
  <block id="1ac73d9186e013f2157d22422bc044ff" category="inline-image-macro">Dieser Screenshot zeigt die Protokollausgabe für eine erfolgreiche saubere Partitionszuweisung für Cluster 1, während</block>
  <block id="f3d0f09c5b4a3c2f532881572a744b6c" category="paragraph"><block ref="f3d0f09c5b4a3c2f532881572a744b6c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8eac57fa6403d9c896c24cb94767e954" category="summary">Da es jetzt eine Lösung für das alberne Umbenennungsproblem im NFS-Speicher mit Kafka gibt, können Sie robuste Bereitstellungen erstellen, die NetApp ONTAP -Speicher für Ihre Kafka-Workload nutzen.  Dies reduziert nicht nur den Betriebsaufwand erheblich, sondern bringt Ihren Kafka-Clustern auch die folgenden Vorteile.</block>
  <block id="76827cff700415303c6b7420a1869192" category="doc">Warum NetApp NFS für Kafka-Workloads?</block>
  <block id="984b2b530f32710e640393a80677e426" category="paragraph">Da es jetzt eine Lösung für das alberne Umbenennungsproblem im NFS-Speicher mit Kafka gibt, können Sie robuste Bereitstellungen erstellen, die NetApp ONTAP -Speicher für Ihre Kafka-Workload nutzen.  Dies reduziert nicht nur den Betriebsaufwand erheblich, sondern bringt Ihren Kafka-Clustern auch die folgenden Vorteile:</block>
  <block id="2dbec01439aed1c5b5fbe8a521623f2d" category="list-text">*Reduzierte CPU-Auslastung bei Kafka-Brokern.*  Durch die Verwendung disaggregierter NetApp ONTAP -Speicher werden Festplatten-E/A-Vorgänge vom Broker getrennt und so dessen CPU-Bedarf reduziert.</block>
  <block id="24c6011da569f3cc3fede5c4eafff91e" category="list-text">*Schnellere Wiederherstellungszeit des Brokers.*  Da der disaggregierte NetApp ONTAP Speicher über alle Kafka-Broker-Knoten hinweg gemeinsam genutzt wird, kann eine neue Compute-Instanz einen fehlerhaften Broker jederzeit in einem Bruchteil der Zeit ersetzen, die bei herkömmlichen Kafka-Bereitstellungen benötigt wird, ohne dass die Daten neu erstellt werden müssen.</block>
  <block id="04615fed33ad7a5a209c685460f2c557" category="list-text">*Speichereffizienz.* Da die Speicherebene der Anwendung jetzt über NetApp ONTAP bereitgestellt wird, können Kunden alle Vorteile der Speichereffizienz von ONTAP nutzen, wie beispielsweise Inline-Datenkomprimierung, Deduplizierung und Kompaktierung.</block>
  <block id="c7444ea1ca211e0d3dd1b89c4f792d00" category="paragraph">Diese Vorteile wurden in Testfällen getestet und validiert, die wir in diesem Abschnitt ausführlich besprechen.</block>
  <block id="454cd026e1a6a7761ee25bf6682aeb2b" category="section-title">Reduzierte CPU-Auslastung auf dem Kafka-Broker</block>
  <block id="70c59ac3ed6ee89fe977676b2dba2f05" category="paragraph">Wir haben festgestellt, dass die allgemeine CPU-Auslastung niedriger ist als beim DAS-Gegenstück, als wir ähnliche Workloads auf zwei separaten Kafka-Clustern ausführten, die in ihren technischen Spezifikationen identisch waren, sich aber in ihren Speichertechnologien unterschieden.  Wenn der Kafka-Cluster ONTAP Speicher verwendet, ist nicht nur die allgemeine CPU-Auslastung geringer, sondern auch der Anstieg der CPU-Auslastung weist einen sanfteren Verlauf auf als in einem DAS-basierten Kafka-Cluster.</block>
  <block id="c9d177e7e6018d464567bf6a8f9773e7" category="paragraph">Die folgende Tabelle zeigt die Umgebungskonfiguration, die verwendet wurde, um eine reduzierte CPU-Auslastung zu demonstrieren.</block>
  <block id="5ed4a4dbe122b39d7103642bff11de54" category="cell">Kafka 3.2.3 Benchmarking-Tool: OpenMessaging</block>
  <block id="3cb61b8b67329a8a20d9128458cf6633" category="list-text">4 x Produzent/Verbraucher -- c5n.2xlarge</block>
  <block id="d34010cfee0f2a6d774e450acd135088" category="cell">RHEL 8.7 oder höher</block>
  <block id="bce5fbe7fa89f635a887c6af2f95a9be" category="cell">Einzelknoteninstanz – M5.2xLarge</block>
  <block id="a27bb92a9fdd5b8b4c084b824b810232" category="section-title">Benchmarking-Tool</block>
  <block id="d483516be45a355eab4c7f9b129540c9" category="inline-link">OpenMessaging</block>
  <block id="0a48e066bcee681066419fb01ccd9f16" category="paragraph">Das in diesem Testfall verwendete Benchmarking-Tool ist das<block ref="3990ab384d3299fd4c655b02444eb5d6" category="inline-link-rx"></block> Rahmen.  OpenMessaging ist anbieter- und sprachunabhängig; es bietet Branchenrichtlinien für Finanzen, E-Commerce, IoT und Big Data und unterstützt die Entwicklung von Messaging- und Streaming-Anwendungen über heterogene Systeme und Plattformen hinweg.  Die folgende Abbildung zeigt die Interaktion von OpenMessaging-Clients mit einem Kafka-Cluster.</block>
  <block id="ac6d62ee86368b8c24366434f9b5d5a1" category="inline-image-macro">Dieses Bild zeigt die Interaktion von OpenMessaging-Clients mit einem Kafka-Cluster.</block>
  <block id="9cb3e560e852dc92918678c092a4105e" category="paragraph"><block ref="9cb3e560e852dc92918678c092a4105e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6250495e61aa2eb3c47f71d21f58c6f8" category="list-text">*Berechnen.*  Wir haben einen Kafka-Cluster mit drei Knoten und einem Zookeeper-Ensemble mit drei Knoten verwendet, das auf dedizierten Servern ausgeführt wird.  Jeder Broker verfügte über zwei NFSv4.1-Mount-Punkte zu einem einzelnen Volume auf der NetApp CVO-Instanz über ein dediziertes LIF.</block>
  <block id="f91ee5c5359f2260d72c50f2c8009925" category="list-text">*Überwachung.*  Wir haben zwei Knoten für eine Prometheus-Grafana-Kombination verwendet.  Zum Generieren von Workloads verfügen wir über einen separaten Cluster mit drei Knoten, der für diesen Kafka-Cluster produzieren und von diesem konsumieren kann.</block>
  <block id="e2b1493c4214be739b2c9349a2c481ef" category="list-text">*Lagerung.*  Wir haben eine NetApp Cloud Volumes ONTAP Instanz mit einem Knoten und sechs auf der Instanz gemounteten 250 GB GP2 AWS-EBS-Volumes verwendet.  Diese Volumes wurden dann dem Kafka-Cluster als sechs NFSv4.1-Volumes über dedizierte LIFs zugänglich gemacht.</block>
  <block id="ede634748bd4515e69245593cfc4478c" category="list-text">*Konfiguration.*  Die beiden konfigurierbaren Elemente in diesem Testfall waren Kafka-Broker und OpenMessaging-Workloads.</block>
  <block id="b053d1656e3b9dcaa2b4834fbdc4fb86" category="list-text">*Broker-Konfiguration.*  Für die Kafka-Broker wurden folgende Spezifikationen gewählt.  Wir haben für alle Messungen einen Replikationsfaktor von 3 verwendet, wie unten hervorgehoben.</block>
  <block id="d5ee20b40da2061d10bff33a6f13467a" category="inline-image-macro">Dieses Bild zeigt die für die Kafka-Broker ausgewählten Spezifikationen.</block>
  <block id="41b835894ba02ffb1ba3f3fdae71877c" category="paragraph"><block ref="41b835894ba02ffb1ba3f3fdae71877c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82f54619faeaa86063f362102c160601" category="list-text">*OpenMessaging-Benchmark (OMB)-Workload-Konfiguration.*  Die folgenden Spezifikationen wurden bereitgestellt.  Wir haben eine Zielproduzentenrate festgelegt, die unten hervorgehoben ist.</block>
  <block id="da43f96a4bfe17af8039df6b15f4f6da" category="inline-image-macro">Dieses Bild zeigt die für die OpenMessaging-Benchmark-Workload-Konfiguration ausgewählten Spezifikationen.</block>
  <block id="41106ec7ad546fdd6a08b370c8093ab9" category="paragraph"><block ref="41106ec7ad546fdd6a08b370c8093ab9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc6067cc387407f4d8dc9d623c770cfd" category="list-text">Es wurden zwei ähnliche Cluster erstellt, die jeweils über einen eigenen Satz von Benchmarking-Cluster-Schwärmen verfügten.</block>
  <block id="c85bb905404dda665035e21b11ab1a58" category="list-text">*Cluster 1.*  NFS-basierter Kafka-Cluster.</block>
  <block id="9ed0b3eccef17299a0119b0f28568e78" category="list-text">*Cluster 2.*  DAS-basierter Kafka-Cluster.</block>
  <block id="a38c46362b3feb9b3bb5f53b1957d50f" category="list-text">Mithilfe eines OpenMessaging-Befehls wurden auf jedem Cluster ähnliche Workloads ausgelöst.</block>
  <block id="c18ed3feb8720fe4fc76d90a9fa6a6e3" category="list-text">Die Produktionsratenkonfiguration wurde in vier Iterationen erhöht und die CPU-Auslastung mit Grafana aufgezeichnet.  Die Produktionsrate wurde auf folgende Stufen festgelegt:</block>
  <block id="04207e7bb62b9b5d14bdb603f74e683c" category="list-text">10.000</block>
  <block id="e19784a5420512b2876c7b24680652b5" category="list-text">40.000</block>
  <block id="e57650a6c15f273334d41da58fa72111" category="list-text">80.000</block>
  <block id="ee70718f6a92d6c1b099a6942f594963" category="list-text">100.000</block>
  <block id="524fdb84d137ea63c19f5efab343f82b" category="paragraph">Die Verwendung von NetApp NFS-Speicher mit Kafka bietet zwei Hauptvorteile:</block>
  <block id="612e27ad9fd383437f1445cf80d554b1" category="list-text">*Sie können die CPU-Auslastung um fast ein Drittel reduzieren.*  Die allgemeine CPU-Auslastung war bei ähnlichen Arbeitslasten bei NFS niedriger als bei DAS-SSDs; die Einsparungen reichen von 5 % bei niedrigeren Produktionsraten bis zu 32 % bei höheren Produktionsraten.</block>
  <block id="bc31b9852409e970a3a4659fef4b4f93" category="list-text">*Eine dreifache Reduzierung der CPU-Auslastungsabweichung bei höheren Produktionsraten.*  Wie erwartet gab es mit der Erhöhung der Produktionsraten einen Aufwärtstrend bei der Erhöhung der CPU-Auslastung.  Allerdings stieg die CPU-Auslastung bei Kafka-Brokern, die DAS verwenden, von 31 % bei der niedrigeren Produktionsrate auf 70 % bei der höheren Produktionsrate, also um 39 %.  Mit einem NFS-Speicher-Backend stieg die CPU-Auslastung jedoch von 26 % auf 38 %, eine Steigerung um 12 %.</block>
  <block id="6299b9c8f7a14a0a0ca7407cbb9a187a" category="inline-image-macro">Dieses Diagramm zeigt das Verhalten eines DAS-basierten Clusters.</block>
  <block id="9630ee6aa29406a977bc5179849d2639" category="paragraph"><block ref="9630ee6aa29406a977bc5179849d2639" category="inline-image-macro-rx" type="image"></block></block>
  <block id="60e393621d29424b529201d4bc48e3b4" category="inline-image-macro">Dieses Diagramm zeigt das Verhalten eines NFS-basierten Clusters.</block>
  <block id="74336896d4b61e55ed364028f046f35b" category="paragraph"><block ref="74336896d4b61e55ed364028f046f35b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03d4293a3bcf73010216e2f0399fd571" category="paragraph">Außerdem weist DAS bei 100.000 Nachrichten eine höhere CPU-Auslastung auf als ein NFS-Cluster.</block>
  <block id="a0e6052c526d2d343fa217b609c943a6" category="inline-image-macro">Dieses Diagramm zeigt das Verhalten eines DAS-basierten Clusters bei 100.000 Nachrichten.</block>
  <block id="73c360518d32a693e133ab63604b2ab4" category="paragraph"><block ref="73c360518d32a693e133ab63604b2ab4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9d76c4aeb68cf4d7ef9bf3ce121bdd2" category="inline-image-macro">Dieses Diagramm zeigt das Verhalten eines NFS-basierten Clusters bei 100.000 Nachrichten.</block>
  <block id="be31c668debc31c9573036c63b1b4f49" category="paragraph"><block ref="be31c668debc31c9573036c63b1b4f49" category="inline-image-macro-rx" type="image"></block></block>
  <block id="60a5caa55d79e52e0af298cf19b5c73d" category="section-title">Schnellere Broker-Wiederherstellung</block>
  <block id="bc0ed21388f4042414a88362de068e14" category="paragraph">Wir haben festgestellt, dass Kafka-Broker schneller wiederhergestellt werden, wenn sie gemeinsam genutzten NetApp NFS-Speicher verwenden.  Wenn ein Broker in einem Kafka-Cluster abstürzt, kann dieser Broker durch einen fehlerfreien Broker mit derselben Broker-ID ersetzt werden.  Bei der Durchführung dieses Testfalls stellten wir fest, dass im Fall eines DAS-basierten Kafka-Clusters der Cluster die Daten auf einem neu hinzugefügten, fehlerfreien Broker neu aufbaut, was zeitaufwändig ist.  Im Fall eines NetApp NFS-basierten Kafka-Clusters liest der ersetzende Broker weiterhin Daten aus dem vorherigen Protokollverzeichnis und stellt die Daten viel schneller wieder her.</block>
  <block id="687972ccb765e5204fa2220ba3dff130" category="list-text">4 x Produzent/Verbraucher – c5n.2xlarge</block>
  <block id="31638173210d76d464e93c8f3f53711c" category="list-text">1 x Backup-Kafka-Knoten – i3en.2xlarge</block>
  <block id="5d27021addda02398c54d28a4ceee767" category="cell">RHEL8.7 oder höher</block>
  <block id="477284b661c88fdd810eb7273729b5ed" category="paragraph"><block ref="477284b661c88fdd810eb7273729b5ed" category="inline-image-macro-rx" type="image"></block></block>
  <block id="64898c42d1ced91d44ff2e383b066de3" category="list-text">*Berechnen.*  Ein Kafka-Cluster mit drei Knoten und einem Zookeeper-Ensemble mit drei Knoten, das auf dedizierten Servern ausgeführt wird.  Jeder Broker verfügt über zwei NFS-Mount-Punkte zu einem einzelnen Volume auf der NetApp CVO-Instanz über ein dediziertes LIF.</block>
  <block id="06e870f499bc90bbe828323be8625621" category="list-text">*Überwachung.*  Zwei Knoten für eine Prometheus-Grafana-Kombination.  Zum Generieren von Workloads verwenden wir einen separaten Cluster mit drei Knoten, der für diesen Kafka-Cluster produzieren und konsumieren kann.</block>
  <block id="1a5c8241b05feb71d0733c2cc2f073c2" category="list-text">*Lagerung.*  Eine NetApp Cloud Volumes ONTAP Instanz mit einem Knoten und sechs auf der Instanz gemounteten 250 GB GP2 AWS-EBS-Volumes.  Diese Volumes werden dann dem Kafka-Cluster über dedizierte LIFs als sechs NFS-Volumes zur Verfügung gestellt.</block>
  <block id="7a4e5e874bf6fcf8217de7f8f0af5acb" category="list-text">*Broker-Konfiguration.*  Das einzige konfigurierbare Element in diesem Testfall sind Kafka-Broker.  Für die Kafka-Broker wurden folgende Spezifikationen gewählt.  Der<block ref="2aa7cd054835892b354c130576c17b61" prefix=" " category="inline-code"></block> wird auf einen hohen Wert eingestellt, da dieser bestimmt, wie schnell ein bestimmter Knoten aus der ISR-Liste entfernt wird.  Wenn Sie zwischen fehlerhaften und fehlerfreien Knoten wechseln, möchten Sie nicht, dass diese Broker-ID von der ISR-Liste ausgeschlossen wird.</block>
  <block id="d6068b616491b51ff179d0138965bba4" category="inline-image-macro">Dieses Bild zeigt die für die Kafka-Broker gewählten Spezifikationen.</block>
  <block id="ce565ed35fddb2c8191f4b8496e98245" category="paragraph"><block ref="ce565ed35fddb2c8191f4b8496e98245" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7f6ea5961f5640ce4fa828022abc91c1" category="list-text">Es wurden zwei ähnliche Cluster erstellt:</block>
  <block id="71754d8c640cd0a117a3c82af0bd3646" category="list-text">Ein EC2-basierter konfluenter Cluster.</block>
  <block id="c4b4e0617e4a38a83a00fc9bd8083465" category="list-text">Ein NetApp NFS-basierter Confluent-Cluster.</block>
  <block id="fbbf8c78f6f01371b1caa7b79bfa91b9" category="list-text">Es wurde ein Standby-Kafka-Knoten mit einer Konfiguration erstellt, die mit den Knoten des ursprünglichen Kafka-Clusters identisch ist.</block>
  <block id="b2d04ce59538c1ba125aa91697b3854f" category="list-text">Auf jedem der Cluster wurde ein Beispielthema erstellt und auf jedem der Broker wurden ungefähr 110 GB Daten gespeichert.</block>
  <block id="25bb70a763a5456f70f68d98646ecbd6" category="list-text">*EC2-basierter Cluster.*  Ein Kafka-Broker-Datenverzeichnis ist abgebildet auf<block ref="8463a3643fa4431218a88d6e1e85f064" prefix=" " category="inline-code"></block> (In der folgenden Abbildung Broker-1 von Cluster1 [linkes Terminal]).</block>
  <block id="bbec1799f53d01620bdd78881b0f0310" category="list-text">* NetApp NFS-basierter Cluster.*  Ein Kafka-Broker-Datenverzeichnis ist auf einem NFS-Punkt gemountet<block ref="ecabd55f704fe0f0dcc41be6e7e7ab83" prefix=" " category="inline-code"></block> (In der folgenden Abbildung Broker-1 von Cluster2 [rechtes Terminal]).</block>
  <block id="86f85a2a5eed8a784f9a06a8fe205c9a" category="inline-image-macro">Dieses Bild zeigt zwei Terminalbildschirme.</block>
  <block id="3a534dc7ed1f2e8444c4b278dd70aa7e" category="paragraph"><block ref="3a534dc7ed1f2e8444c4b278dd70aa7e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02296aafa9e3a6424418dd97a673e931" category="list-text">In jedem der Cluster wurde Broker-1 beendet, um einen fehlgeschlagenen Broker-Wiederherstellungsprozess auszulösen.</block>
  <block id="fe4c3f604a59eb786f64f0fc5a7cfa01" category="list-text">Nachdem der Broker beendet wurde, wurde die Broker-IP-Adresse dem Standby-Broker als sekundäre IP zugewiesen.  Dies war notwendig, da ein Broker in einem Kafka-Cluster durch Folgendes identifiziert wird:</block>
  <block id="597bfb23e3e10c354a661882e4728565" category="list-text">*IP-Adresse.*  Zugewiesen durch Neuzuweisung der ausgefallenen Broker-IP an den Standby-Broker.</block>
  <block id="d86a6ec6cd64cd7365ad5d46f7c32d85" category="list-text">*Broker-ID.*  Dies wurde im Standby-Broker konfiguriert<block ref="05cc8f97f27bba0114c55d20c80d4fe7" prefix=" " category="inline-code"></block> .</block>
  <block id="c71af5d75ff28fc80b8aa2c6c6832c39" category="list-text">Bei der IP-Zuweisung wurde der Kafka-Dienst auf dem Standby-Broker gestartet.</block>
  <block id="e6f0e1804a85ff41f08342fa0cd0e8c5" category="list-text">Nach einer Weile wurden die Serverprotokolle abgerufen, um die zum Erstellen der Daten auf dem Ersatzknoten im Cluster benötigte Zeit zu überprüfen.</block>
  <block id="b4e6de827ba8af76c3d7cf0e11dee63e" category="paragraph">Die Wiederherstellung des Kafka-Brokers war fast neunmal schneller.  Die zur Wiederherstellung eines ausgefallenen Broker-Knotens benötigte Zeit war bei Verwendung des gemeinsam genutzten NetApp NFS-Speichers deutlich kürzer als bei Verwendung von DAS-SSDs in einem Kafka-Cluster.  Bei 1 TB Themendaten betrug die Wiederherstellungszeit für einen DAS-basierten Cluster 48 Minuten, verglichen mit weniger als 5 Minuten für einen NetApp-NFS-basierten Kafka-Cluster.</block>
  <block id="fcd5351f741ba27a03aeaa4aff141fde" category="paragraph">Wir haben festgestellt, dass der EC2-basierte Cluster 10 Minuten benötigte, um die 110 GB Daten auf dem neuen Broker-Knoten wiederherzustellen, während der NFS-basierte Cluster die Wiederherstellung in 3 Minuten abschloss.  Wir haben in den Protokollen auch festgestellt, dass die Consumer-Offsets für die Partitionen für EC2 0 waren, während im NFS-Cluster die Consumer-Offsets vom vorherigen Broker übernommen wurden.</block>
  <block id="01a0d5c558a836a74adf3dc3fe1de25d" category="section-title">DAS-basierter Cluster</block>
  <block id="542ac5d9dd4769eb5fb4a8a7da3aa594" category="list-text">Der Sicherungsknoten wurde um 08:55:53.730 gestartet.</block>
  <block id="b5f0acf8be0dd329b7dae7c96c9b3dc8" category="inline-image-macro">Dieses Bild zeigt die Protokollausgabe für einen DAS-basierten Cluster.</block>
  <block id="91569a3f4fee956cd801e625cc8eb34f" category="paragraph"><block ref="91569a3f4fee956cd801e625cc8eb34f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d48d1996a0b89fc5aa313e48f1c2c149" category="list-text">Der Datenwiederherstellungsprozess endete um 09:05:24.860.  Die Verarbeitung von 110 GB Daten dauerte ungefähr 10 Minuten.</block>
  <block id="d598dda290e226574121bf65a66222c1" category="paragraph"><block ref="d598dda290e226574121bf65a66222c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d10d1e0d7dc7546ca2ee585553c90f24" category="section-title">NFS-basierter Cluster</block>
  <block id="e163d6812be40c2618b43cc9d2ed21a1" category="list-text">Der Backup-Knoten wurde um 09:39:17,213 gestartet.  Der Startprotokolleintrag ist unten hervorgehoben.</block>
  <block id="1af763f7fe72be73a16f6a9010023e1f" category="inline-image-macro">Dieses Bild zeigt die Protokollausgabe für einen NFS-basierten Cluster.</block>
  <block id="bbb8038819966fa92b04b31dfe935e66" category="paragraph"><block ref="bbb8038819966fa92b04b31dfe935e66" category="inline-image-macro-rx" type="image"></block></block>
  <block id="459f0a82f7fc8505de6db94698f5e9c8" category="list-text">Der Datenwiederherstellungsprozess endete um 09:42:29,115.  Die Verarbeitung von 110 GB Daten dauerte ungefähr 3 Minuten.</block>
  <block id="bb69fdfb2a75f135682b3880999f8c2e" category="paragraph"><block ref="bb69fdfb2a75f135682b3880999f8c2e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="24c9b21a2ca87ae467a56b044593521b" category="paragraph">Der Test wurde für Broker mit etwa 1 TB Daten wiederholt, was für das DAS ungefähr 48 Minuten und für NFS 3 Minuten dauerte.  Die Ergebnisse sind in der folgenden Grafik dargestellt.</block>
  <block id="6994918ac91afbe69dd9a20ab257afa1" category="inline-image-macro">Dieses Diagramm zeigt die für die Broker-Wiederherstellung benötigte Zeit in Abhängigkeit von der auf den Broker geladenen Datenmenge für einen DAS-basierten Cluster oder einen NFS-basierten Cluster.</block>
  <block id="fcc7c3e745c4c2ba0f4fe48c8d589122" category="paragraph"><block ref="fcc7c3e745c4c2ba0f4fe48c8d589122" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fd18465573ec21a6218982055981f6b1" category="section-title">Speichereffizienz</block>
  <block id="f94ef2603834178da773ec5ccd97683b" category="paragraph">Da die Speicherschicht des Kafka-Clusters über NetApp ONTAP bereitgestellt wurde, konnten wir alle Speichereffizienzfunktionen von ONTAP nutzen.  Dies wurde getestet, indem eine erhebliche Datenmenge auf einem Kafka-Cluster mit NFS-Speicher generiert wurde, der auf Cloud Volumes ONTAP bereitgestellt wurde.  Wir konnten feststellen, dass es aufgrund der ONTAP -Funktionen zu einer erheblichen Platzreduzierung kam.</block>
  <block id="d1030267f4090d953bd3cabbb565b51b" category="cell">Einzelknoteninstanz – M5.2xLarge</block>
  <block id="717373873e977ccdc16d9a371e92b55b" category="list-text">*Berechnen.*  Wir haben einen Kafka-Cluster mit drei Knoten und einem Zookeeper-Ensemble mit drei Knoten verwendet, das auf dedizierten Servern ausgeführt wird.  Jeder Broker verfügte über zwei NFS-Mount-Punkte zu einem einzelnen Volume auf der NetApp CVO-Instanz über ein dediziertes LIF.</block>
  <block id="cce21f164c30f5ce10f914c4542e252f" category="list-text">*Lagerung.*  Wir haben eine NetApp Cloud Volumes ONTAP Instanz mit einem Knoten und sechs auf der Instanz gemounteten 250 GB GP2 AWS-EBS-Volumes verwendet.  Diese Volumes wurden dann über dedizierte LIFs als sechs NFS-Volumes dem Kafka-Cluster zugänglich gemacht.</block>
  <block id="68f29d01fbebb4ad998127522e13950b" category="list-text">*Konfiguration.*  Die konfigurierbaren Elemente in diesem Testfall waren die Kafka-Broker.</block>
  <block id="8e44bdd37fc66a06e9780582642d0c37" category="paragraph">Die Komprimierung wurde auf der Produzentenseite abgeschaltet, wodurch die Produzenten einen hohen Durchsatz erzielen konnten.  Die Speichereffizienz wurde stattdessen von der Rechenschicht übernommen.</block>
  <block id="7da10cbdbba2e826cd4954054b5c1843" category="list-text">Ein Kafka-Cluster wurde mit den oben genannten Spezifikationen bereitgestellt.</block>
  <block id="e857c1394ce43b04a9548d5a3dec0ee5" category="list-text">Auf dem Cluster wurden mithilfe des OpenMessaging Benchmarking-Tools etwa 350 GB Daten erstellt.</block>
  <block id="efc4a3d9bfed3a9a80b0caea9016ca6c" category="list-text">Nachdem die Arbeitslast abgeschlossen war, wurden die Statistiken zur Speichereffizienz mithilfe von ONTAP System Manager und der CLI erfasst.</block>
  <block id="9c9850d81b369454a9610d48c5bfe8a0" category="paragraph">Bei Daten, die mit dem OMB-Tool generiert wurden, konnten wir eine Platzersparnis von ca. 33 % bei einem Speichereffizienzverhältnis von 1,70:1 feststellen.  Wie aus den folgenden Abbildungen hervorgeht, betrug der von den erzeugten Daten verwendete logische Speicherplatz 420,3 GB und der zum Speichern der Daten verwendete physische Speicherplatz 281,7 GB.</block>
  <block id="f11c8594ca77ceb3e0ab124768dd061d" category="inline-image-macro">Dieses Bild zeigt die Platzeinsparungen in VMDISK.</block>
  <block id="565d9cbc0c15374b9bdebe62dd5efe32" category="paragraph"><block ref="565d9cbc0c15374b9bdebe62dd5efe32" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3afbd9828e011526955ca93b48b57524" category="inline-image-macro">Screenshot</block>
  <block id="50abdfc5295b4aedbb53a46e0bd7512b" category="paragraph"><block ref="50abdfc5295b4aedbb53a46e0bd7512b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c6c6f7c15f1d0324567be0828cb855f7" category="paragraph"><block ref="c6c6f7c15f1d0324567be0828cb855f7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c9fee86e220b694a9ca26cb5d3943276" category="summary">Dieses Dokument beschreibt Leistungsbenchmarks für die Confluent-Plattform auf NetApp ONTAP unter Verwendung eines Tiered Storage-Benchmarking-Kits.</block>
  <block id="5514e652e396365ccb56f1b2b5371569" category="doc">TR-4941: Konfluent mit NetApp ONTAP -Speichercontrollern</block>
  <block id="1e0e02def11263577d232ee8ce69c727" category="paragraph">Karthikeyan Nagalingam, Joe Scott, NetApp Rankesh Kumar, Confluent</block>
  <block id="30f774bc5050b82b9a42fe5d8f4bc99f" category="paragraph">Um die Confluent-Plattform skalierbarer und elastischer zu machen, muss sie in der Lage sein, Arbeitslasten sehr schnell zu skalieren und auszugleichen.  Durch die Reduzierung dieses Betriebsaufwands wird die Speicherung großer Datenmengen in Confluent durch mehrstufige Speicherung handhabbar.</block>
  <block id="981ac9f1443bdd13b0920d6ca1ee4eb3" category="paragraph">Die Grundidee besteht darin, die Datenspeicherung von der Datenverarbeitung zu trennen, wodurch eine unabhängige Skalierung beider Bereiche wesentlich einfacher wird.</block>
  <block id="44f523cee834fac14fc6966d940c5e92" category="paragraph">Die mit branchenführenden Innovationen ausgestattete NetApp ONTAP Datenverwaltungssoftware bietet Confluent viele Vorteile, egal wo sich die Daten befinden.</block>
  <block id="7e936a7640e03dad09e0b76d68277d56" category="summary">Wir haben die Tiered-Storage-Tests mit drei bis vier Knoten für Produktions- und Verbraucher-Workloads mit dem NetApp StorageGRID Setup durchgeführt.</block>
  <block id="3c2fe55c24192bbec6d6d3aede570213" category="doc">Leistungstests mit Skalierbarkeit</block>
  <block id="7d962aad50ee059cfbd23de23ab5a916" category="paragraph">Wir haben die Tiered-Storage-Tests mit drei bis vier Knoten für Producer- und Consumer-Workloads mit dem NetApp StorageGRID Setup durchgeführt.  Unseren Tests zufolge waren die Zeit bis zur Fertigstellung und die Leistungsergebnisse direkt proportional zur Anzahl der StorageGRID Knoten.  Für die Einrichtung von StorageGRID waren mindestens drei Knoten erforderlich.</block>
  <block id="4e6097966a711c7acf606365a2925b64" category="list-text">Die Zeit zum Abschließen des Produktions- und Verbrauchervorgangs verringerte sich linear, wenn die Anzahl der Speicherknoten zunahm.</block>
  <block id="5393f806598ea16510805a4ab3b20623" category="paragraph"><block ref="5393f806598ea16510805a4ab3b20623" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d098e780afaaad433dd6982bbc5af988" category="list-text">Die Leistung für den S3-Abrufvorgang stieg linear basierend auf der Anzahl der StorageGRID Knoten.  StorageGRID unterstützt bis zu 200 StorgeGRID-Knoten.</block>
  <block id="d73d827635c7a6fcfa52120cc6f3b96d" category="paragraph"><block ref="d73d827635c7a6fcfa52120cc6f3b96d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43f0735f931622d61f6837a0eb61f87e" category="summary">Dieser Test basiert auf der Funktion für selbstausgleichende Cluster, die den Neuausgleich basierend auf Änderungen der Clustertopologie oder ungleichmäßiger Last automatisiert.</block>
  <block id="565b2f1bfcd6857afba2efa000b83759" category="doc">Konfluente, selbstausgleichende Cluster</block>
  <block id="d3975bd93d0a2c24b382774d34b5a963" category="paragraph">Wenn Sie bereits einen Kafka-Cluster verwaltet haben, sind Sie wahrscheinlich mit den Herausforderungen vertraut, die mit der manuellen Neuzuweisung von Partitionen an verschiedene Broker einhergehen, um sicherzustellen, dass die Arbeitslast im gesamten Cluster ausgeglichen ist.  Für Organisationen mit großen Kafka-Bereitstellungen kann die Neuordnung großer Datenmengen entmutigend, mühsam und riskant sein, insbesondere wenn unternehmenskritische Anwendungen auf dem Cluster erstellt werden.  Allerdings ist der Prozess selbst bei den kleinsten Kafka-Anwendungsfällen zeitaufwändig und anfällig für menschliche Fehler.</block>
  <block id="3c404a9102e2cb3ac7b75fa7ff7a2cb2" category="paragraph">In unserem Labor haben wir die Funktion zum selbstausgleichenden Cluster von Confluent getestet, die den Neuausgleich basierend auf Änderungen der Clustertopologie oder ungleichmäßiger Last automatisiert.  Der Confluent-Neuausgleichstest hilft dabei, die Zeit zu messen, die zum Hinzufügen eines neuen Brokers benötigt wird, wenn ein Knotenausfall vorliegt oder der Skalierungsknoten einen Neuausgleich der Daten zwischen den Brokern erfordert.  In klassischen Kafka-Konfigurationen wächst die Menge der neu auszugleichenden Daten mit dem Wachstum des Clusters, bei mehrstufigem Speicher ist die Neuausgleichung jedoch auf eine kleine Datenmenge beschränkt.  Basierend auf unserer Validierung dauert die Neuausrichtung im mehrstufigen Speicher in einer klassischen Kafka-Architektur Sekunden oder Minuten und wächst linear mit dem Wachstum des Clusters.</block>
  <block id="829c663686b68c76ea97bd7a23d534b6" category="paragraph">In selbstausgleichenden Clustern werden Partitionsneuausgleiche vollständig automatisiert, um den Durchsatz von Kafka zu optimieren, die Broker-Skalierung zu beschleunigen und den Betriebsaufwand für den Betrieb eines großen Clusters zu reduzieren.  Im stationären Zustand überwachen selbstausgleichende Cluster die Datenabweichung zwischen den Brokern und weisen Partitionen kontinuierlich neu zu, um die Clusterleistung zu optimieren.  Beim Hoch- oder Herunterskalieren der Plattform erkennen selbstausgleichende Cluster automatisch das Vorhandensein neuer Broker oder das Entfernen alter Broker und lösen eine anschließende Neuzuweisung der Partition aus.  Dadurch können Sie Broker einfach hinzufügen und außer Betrieb nehmen, wodurch Ihre Kafka-Cluster wesentlich elastischer werden.  Diese Vorteile ergeben sich ohne manuelle Eingriffe, komplexe Berechnungen oder das Risiko menschlicher Fehler, das bei Partitionsneuzuweisungen normalerweise auftritt.  Dadurch werden Datenneuausrichtungen in wesentlich kürzerer Zeit abgeschlossen und Sie können sich auf höherwertige Event-Streaming-Projekte konzentrieren, anstatt Ihre Cluster ständig überwachen zu müssen.</block>
  <block id="bc15ae13f16a39532174d0aec78a6432" category="summary">In diesem Setup zeigen wir Ihnen, wie Sie Themen im Objektspeicher von Kafka direkt mithilfe des Kafka s3-Sink-Connectors lesen und schreiben.  Für diesen Test haben wir einen eigenständigen Confluent-Cluster verwendet, dieses Setup ist jedoch auch auf einen verteilten Cluster anwendbar.</block>
  <block id="8b7e627b574df4c4813de77ed2896ad8" category="doc">Confluent S3-Anschluss</block>
  <block id="524b95dc71b518ce734757656cf9594c" category="paragraph">Der Amazon S3 Sink-Connector exportiert Daten aus Apache Kafka-Themen in S3-Objekte im Avro-, JSON- oder Bytes-Format.  Der Amazon S3-Sink-Connector fragt regelmäßig Daten von Kafka ab und lädt sie wiederum zu S3 hoch.  Ein Partitionierer wird verwendet, um die Daten jeder Kafka-Partition in Blöcke aufzuteilen.  Jeder Datenblock wird als S3-Objekt dargestellt.  Der Schlüsselname kodiert das Thema, die Kafka-Partition und den Start-Offset dieses Datenblocks.</block>
  <block id="b5829317a86f448ffca89934abe420d3" category="list-text">Laden Sie Confluent Kafka von der Confluent-Website herunter.</block>
  <block id="99eec7bbd3416776cb76d9d8f52bfddc" category="list-text">Entpacken Sie das Paket in einen Ordner auf Ihrem Server.</block>
  <block id="2d025d1c11796b49f323ce393e802635" category="list-text">Exportieren Sie zwei Variablen.</block>
  <block id="e238a3352503bcd61be91778a307f02e" category="list-text">Für ein eigenständiges Confluent Kafka-Setup erstellt der Cluster einen temporären Stammordner in<block ref="d42b9c57d24cf5db3bd8d332dc35437f" prefix=" " category="inline-code"></block> . Es erstellt außerdem Zookeeper, Kafka, ein Schema-Registry, Connect, einen KSQL-Server und Control-Center-Ordner und kopiert die jeweiligen Konfigurationsdateien von<block ref="5f8dd6e4b96ae5c78585ed0293d4338d" prefix=" " category="inline-code"></block> .  Siehe das folgende Beispiel:</block>
  <block id="ed529b17b192b6bcfa1fb220aa0f37e4" category="list-text">Konfigurieren Sie Zookeeper.  Wenn Sie die Standardparameter verwenden, müssen Sie nichts ändern.</block>
  <block id="ad2d4e5ed593359b5d1fe13997541e6f" category="paragraph">In der obigen Konfiguration haben wir die<block ref="2f11dbffae155119df4dc4d60229477e" prefix=" " category="inline-code"></block> Eigentum.  Standardmäßig benötigen Sie drei Zookeeper für die Kafka-Leader-Auswahl.</block>
  <block id="b7eb15647b54e1bfd5b79f04012f19ce" category="list-text">Wir haben eine Myid-Datei erstellt in<block ref="417022983f4126687b04c2a16a36183c" prefix=" " category="inline-code"></block> mit einer eindeutigen ID:</block>
  <block id="78f7f3d70d7fc386cde6a61b7d08bc07" category="paragraph">Wir haben die letzte Nummer der IP-Adressen für die MyID-Datei verwendet.  Wir haben Standardwerte für die Konfigurationen Kafka, Connect, Control-Center, Kafka, Kafka-Rest, KSQL-Server und Schema-Registry verwendet.</block>
  <block id="5ad6084775d1229b3edcbda0f353315c" category="list-text">Starten Sie die Kafka-Dienste.</block>
  <block id="67228b3b71aba311ab74c0946efe35e8" category="paragraph">Für jede Konfiguration gibt es einen Protokollordner, der bei der Fehlerbehebung hilft.  In einigen Fällen dauert der Start der Dienste länger.  Stellen Sie sicher, dass alle Dienste aktiv sind und ausgeführt werden.</block>
  <block id="65272a6acb72513d0bfa2bdd8b0c6d1b" category="list-text">Installieren Sie Kafka Connect mit<block ref="dcd3bd9446852f6dec3cf416e98154dc" prefix=" " category="inline-code"></block> .</block>
  <block id="4bdaf464a75dbea14d9240c6722a822a" category="paragraph">Sie können auch eine bestimmte Version installieren, indem Sie<block ref="edb107f75d4831212ad61dd615bc468f" prefix=" " category="inline-code"></block> .</block>
  <block id="004220cf4b170d47a455040fde149eaf" category="list-text">Standardmäßig<block ref="4ccf7940f1e125b6b7fb994629fe7c02" prefix=" " category="inline-code"></block> ist installiert in<block ref="6ae652b878f3c54eeaed9d623a1a8c82" prefix=" " category="inline-code"></block> .</block>
  <block id="fe4b44765b8ad323e0d6a2e6b7325246" category="list-text">Aktualisieren Sie den Plug-In-Pfad mit dem neuen<block ref="4ccf7940f1e125b6b7fb994629fe7c02" prefix=" " category="inline-code"></block> .</block>
  <block id="331885900730ee061e0f6b4f55e62ece" category="list-text">Stoppen Sie die Confluent-Dienste und starten Sie sie neu.</block>
  <block id="7fe69cf1bb033725fdeb56839e70fe4e" category="list-text">Konfigurieren Sie die Zugriffs-ID und den geheimen Schlüssel im<block ref="40f203cedcd08f7589920d1a469a96d9" prefix=" " category="inline-code"></block> Datei.</block>
  <block id="fac7d16b475df7919931f2de707a4a45" category="list-text">Überprüfen Sie, ob der Bucket erreichbar ist.</block>
  <block id="369f5700a42f83495e179b9e947587fb" category="list-text">Konfigurieren Sie die S3-Sink-Eigenschaftendatei für die S3- und Bucket-Konfiguration.</block>
  <block id="3d3c898205223806be88ccecb8f0598c" category="list-text">Importieren Sie einige Datensätze in den S3-Bucket.</block>
  <block id="50b781543cad31f75eed99b8efb20e79" category="list-text">Laden Sie den S3-Sink-Connector.</block>
  <block id="6e773b2ab9703d3433d0ebfb5a45a3a1" category="list-text">Überprüfen Sie den S3-Sink-Status.</block>
  <block id="b533fadf7b5ac18085d65eb6814528cf" category="list-text">Überprüfen Sie das Protokoll, um sicherzustellen, dass s3-sink bereit ist, Themen anzunehmen.</block>
  <block id="613093505fc60a58e7893af8aee3b7b8" category="list-text">Sehen Sie sich die Themen in Kafka an.</block>
  <block id="38f7472ee233ba1cc1a7d724a0ca6542" category="list-text">Überprüfen Sie die Objekte im S3-Bucket.</block>
  <block id="09fa6729fb808be555e2da157c07e47e" category="list-text">Um den Inhalt zu überprüfen, kopieren Sie jede Datei von S3 in Ihr lokales Dateisystem, indem Sie den folgenden Befehl ausführen:</block>
  <block id="e8eeb400cc1af7c80b7561572c879a12" category="inline-link">Apache-Archive</block>
  <block id="7d059565bbab6abb5da76e3abcfe6f90" category="list-text">Um die Datensätze auszudrucken, verwenden Sie avro-tools-1.11.0.1.jar (verfügbar im<block ref="55ee52f435d2dbbc99b651e203ff837e" category="inline-link-rx"></block> ).</block>
  <block id="331c0d2ba7a09b3ae7f6fac4652625da" category="summary">Auf dieser Seite werden die Best Practices zur Verbesserung der Leistung dieser Lösung beschrieben.</block>
  <block id="69cefd131c612b28f058caddd20f5cac" category="doc">Richtlinien für bewährte Methoden zur Leistung</block>
  <block id="21414169b395738292b2ac2fd8ca50a9" category="list-text">Verwenden Sie für ONTAP nach Möglichkeit eine GET-Größe &gt;=1 MB.</block>
  <block id="ce2e9b8aaceb2d2993c90188d874af95" category="list-text">Zunehmend<block ref="0a6a261ab97b8f0aa88765065fded320" prefix=" " category="inline-code"></block> Und<block ref="f05155cb2203ab2a3da64642aea51bd0" prefix=" " category="inline-code"></block> In<block ref="05cc8f97f27bba0114c55d20c80d4fe7" prefix=" " category="inline-code"></block> auf Brokerknoten können Sie erhöhte Tiering-Aktivitäten auf die S3-Ebene übertragen.  Diese Ergebnisse sind mit<block ref="0a6a261ab97b8f0aa88765065fded320" prefix=" " category="inline-code"></block> Und<block ref="f05155cb2203ab2a3da64642aea51bd0" prefix=" " category="inline-code"></block> auf 32 eingestellt.</block>
  <block id="1a48e01d01924d18e32943982eb6d924" category="list-text">S3-Buckets sollten auf acht Bestandteile pro Mitgliedsaggregat abzielen.</block>
  <block id="b5a9dc3c7ec54467d103e00eaa0efb21" category="list-text">Ethernet-Verbindungen, die S3-Verkehr steuern, sollten nach Möglichkeit sowohl auf dem Speicher als auch auf dem Client eine MTU von 9.000 verwenden.</block>
  <block id="4ea8220421596c898f8150bfebdf4ccb" category="summary">Dieser Verifizierungstest erreichte einen Tiering-Durchsatz von 31,74 GBps auf Confluent mit einem NetApp ONTAP Speichercontroller.</block>
  <block id="93a10982e8e304323ad8af9a9387d775" category="paragraph">Dieser Verifizierungstest erreichte einen Tiering-Durchsatz von 31,74 GBps auf Confluent mit NetApp ONTAP Storage Controller.</block>
  <block id="0f2f674cce6910ae97ee7ecc7bd9de18" category="list-text">Was ist Confluent?</block>
  <block id="e6deab0ab2821160c056af4c7766624c" category="inline-link"><block ref="e6deab0ab2821160c056af4c7766624c" category="inline-link-rx"></block></block>
  <block id="ce3026317a00b57c81627bd64a1b3311" category="paragraph"><block ref="ce3026317a00b57c81627bd64a1b3311" category="inline-link-rx"></block></block>
  <block id="58a229be829dc9196abdaff6a4a26864" category="list-text">S3 in ONTAP – Best Practices</block>
  <block id="f47b79954bb4ad3165d7f99db02fe933" category="inline-link"><block ref="f47b79954bb4ad3165d7f99db02fe933" category="inline-link-rx"></block></block>
  <block id="e98b34b649783312d3b317c7441a20a5" category="paragraph"><block ref="e98b34b649783312d3b317c7441a20a5" category="inline-link-rx"></block></block>
  <block id="3075344c29b864c90ae1411c1db26e87" category="list-text">S3-Objektspeicherverwaltung</block>
  <block id="cdc54c0262b6c0a6146ee416a9ca2113" category="inline-link"><block ref="cdc54c0262b6c0a6146ee416a9ca2113" category="inline-link-rx"></block></block>
  <block id="8a93310a8dd4b405a8711f82adeb3c23" category="paragraph"><block ref="8a93310a8dd4b405a8711f82adeb3c23" category="inline-link-rx"></block></block>
  <block id="614eb548d72efbb3690b5c131745db1b" category="summary">Auf dieser Seite wird die Leistungsvalidierung von Confluent innerhalb der Parameter dieser Lösung beschrieben.</block>
  <block id="28052d386826afbb88768d0629570b19" category="doc">Confluent-Leistungsvalidierung</block>
  <block id="3ec7b1ca1aaf25c9bbca707f1ca8e466" category="paragraph">Wir haben die Überprüfung mit Confluent Platform für Tiered Storage auf NetApp ONTAP durchgeführt.  Die Teams von NetApp und Confluent haben gemeinsam an dieser Verifizierung gearbeitet und die dafür erforderlichen Testfälle ausgeführt.</block>
  <block id="1f567e45477749710cbc14cf6b10afc4" category="section-title">Confluent-Setup</block>
  <block id="99b45ae42dbbf816c910ba27197525dc" category="paragraph">Für das Setup haben wir drei Zookeeper, fünf Broker und fünf Testserver mit 256 GB RAM und 16 CPUs verwendet.  Für den NetApp -Speicher haben wir ONTAP mit einem AFF A900 HA-Paar verwendet.  Der Speicher und die Broker wurden über 100-GbE-Verbindungen verbunden.</block>
  <block id="77727c2ca2ac5beb0de2853929b43367" category="paragraph">Die folgende Abbildung zeigt die Netzwerktopologie der Konfiguration, die für die Überprüfung des mehrstufigen Speichers verwendet wird.</block>
  <block id="57e8d3257fec5774d2e8d38588771a69" category="inline-image-macro">Diese Grafik zeigt die Netzwerktopologie der Konfiguration, die für die Überprüfung des mehrstufigen Speichers verwendet wird.</block>
  <block id="b460294b1898fd26dfbb545338caacee" category="paragraph"><block ref="b460294b1898fd26dfbb545338caacee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d9b75f4efe285b9777255f14c81323b" category="paragraph">Die Tool-Server fungieren als Anwendungsclients, die Ereignisse an Confluent-Knoten senden oder von diesen empfangen.</block>
  <block id="1068af448bd05a968329fd2341036bfb" category="paragraph">Wir haben die folgenden Testparameter verwendet:</block>
  <block id="3bfb3f2755d25ed45d39dad8b3ed3008" category="paragraph">Zur Überprüfung haben wir ONTAP mit dem HTTP-Protokoll verwendet, aber auch HTTPS funktionierte.  Der Zugriffsschlüssel und der geheime Schlüssel werden in der Datei mit dem angegebenen Namen gespeichert.<block ref="f5bafadf6000aaed6c910fea0a85f4f3" prefix=" " category="inline-code"></block> Parameter.</block>
  <block id="86d7ae5e1e87e4958b4fafcbca603956" category="section-title">NetApp Speichercontroller – ONTAP</block>
  <block id="b915ce35d395a0d68a794b87705f95fa" category="paragraph">Zur Überprüfung haben wir eine einzelne HA-Paarkonfiguration in ONTAP konfiguriert.</block>
  <block id="b9d2b35b3cfffa153fd4ed3401cb9dd9" category="inline-image-macro">Diese Grafik zeigt, wie die Umgebung zur Überprüfung als einzelnes HA-Paar konfiguriert wurde.</block>
  <block id="267b459a69088e0dc82f7fe972205f92" category="paragraph"><block ref="267b459a69088e0dc82f7fe972205f92" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7069b530e46a91698a16159b7d083019" category="section-title">Verifizierungsergebnisse</block>
  <block id="3af1efc909fae49a716fe2d22ba24290" category="paragraph">Zur Verifizierung haben wir die folgenden fünf Testfälle durchgeführt.  Bei den ersten beiden handelte es sich um Funktionstests und bei den restlichen drei um Leistungstests.</block>
  <block id="09da8339466c8b6111e4f310f1b78cb5" category="paragraph">Dieser Test führt mithilfe von API-Aufrufen grundlegende Vorgänge wie „Get“, „Put“ und „Delete“ im Objektspeicher aus, der für den mehrstufigen Speicher verwendet wird.</block>
  <block id="622ce818e2b8228cee071a827a43e1b2" category="paragraph">Dieser Test überprüft die End-to-End-Funktionalität des Objektspeichers.  Es erstellt ein Thema, erzeugt einen Ereignisstrom zum neu erstellten Thema, wartet darauf, dass die Broker die Segmente im Objektspeicher archivieren, verbraucht den Ereignisstrom und überprüft, ob der verbrauchte Strom mit dem erzeugten Strom übereinstimmt.  Wir haben diesen Test mit und ohne Fehlerinjektion im Objektspeicher durchgeführt.  Wir haben einen Knotenausfall simuliert, indem wir den Service Manager-Dienst in einem der Knoten in ONTAP gestoppt und überprüft haben, ob die End-to-End-Funktionalität mit dem Objektspeicher funktioniert.</block>
  <block id="2712a580ff4c3586c7ba3534b78aad18" category="section-title">Arbeitslastgenerator zum Produzieren und Konsumieren</block>
  <block id="0c22172129c2d0d58a5685fa1094fca0" category="paragraph">Dieser Test erzeugt durch die Archivierung von Segmenten indirekt Schreibarbeitslast im Objektspeicher.  Die Lesearbeitslast (gelesene Segmente) wurde aus dem Objektspeicher generiert, als Verbrauchergruppen die Segmente abgerufen haben.  Diese Arbeitslast wurde durch ein TOCC-Skript generiert.  Dieser Test überprüfte die Leistung beim Lesen und Schreiben im Objektspeicher in parallelen Threads.  Wir haben mit und ohne Fehlerinjektion im Objektspeicher getestet, wie wir es für den Korrektheitstest der Tiering-Funktionalität getan haben.</block>
  <block id="2a7273e52c0214e6f0b27bf1e870960e" category="section-title">Generator für die Aufbewahrungsarbeitslast</block>
  <block id="48771387cb6a84889bc1db951598f78c" category="paragraph">Dieser Test prüfte die Löschleistung eines Objektspeichers unter einer hohen Themenaufbewahrungsarbeitslast.  Der Aufbewahrungsaufwand wurde mithilfe eines TOCC-Skripts generiert, das viele Nachrichten parallel zu einem Testthema produziert.  Das Testthema war die Konfiguration mit einer aggressiven größen- und zeitbasierten Aufbewahrungseinstellung, die dazu führte, dass der Ereignisstrom kontinuierlich aus dem Objektspeicher gelöscht wurde.  Anschließend wurden die Segmente archiviert.  Dies führte zu zahlreichen Löschungen im Objektspeicher durch den Broker und zur Erfassung der Leistung der Löschvorgänge im Objektspeicher.</block>
  <block id="a03d0d99a3287875dda3d19daa736d0c" category="inline-link">Zusammenfließend</block>
  <block id="047fb529cf71ef63efe04d4185302684" category="paragraph">Einzelheiten zur Überprüfung finden Sie im<block ref="86830f666762f920df1dddf1c71e6509" category="inline-link-rx"></block> Webseite.</block>
  <block id="dbb940c31f0b7d7563745993661f70d4" category="summary">Wir haben Tiered-Storage-Tests mit entweder fünf oder acht Broker-Knoten während einer Produce-Consume-Workload mit dem einen AFF A900 HA-Paar NetApp -Storage-Controller durchgeführt.  Unseren Tests zufolge skalierten die Zeit bis zur Fertigstellung und die Leistungsergebnisse mit der Anzahl der Brokerknoten, bis die Ressourcenauslastung von AFF A900 hundert Prozent erreichte.  Für die Einrichtung des ONTAP Speichercontrollers war mindestens ein HA-Paar erforderlich.</block>
  <block id="91e1cb9730965860cb465802520e6a45" category="doc">Leistungstests mit dem Produce-Consume-Workload-Generator</block>
  <block id="b15c40872cdd0b1e0a152907f2194e69" category="paragraph">Die Leistung für den S3-Abrufvorgang stieg linear basierend auf der Anzahl der Confluent-Broker-Knoten.  Der ONTAP Speichercontroller unterstützt bis zu 12 HA-Paare in einer einzigen Bereitstellung.</block>
  <block id="ec043d5e2714e1035038cbeb1aa3cba8" category="paragraph">Das folgende Diagramm zeigt den kombinierten S3-Tiering-Verkehr mit fünf oder acht Broker-Knoten.  Wir haben die Leistung des einzelnen HA-Paares des AFF A900 maximiert.</block>
  <block id="ffff2891cfdd07445c4e1e5261739c68" category="inline-image-macro">Dieses Datendiagramm zeigt den kombinierten S3-Tiering-Verkehr mit fünf oder acht Broker-Knoten.</block>
  <block id="d1912fadda4ef80cc1a01c7f3f919602" category="paragraph"><block ref="d1912fadda4ef80cc1a01c7f3f919602" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1efe906cedfd00618bda4d39b41a52fd" category="paragraph">Das folgende Diagramm zeigt den Kafka-Durchsatz von ungefähr 31,74 GBps.</block>
  <block id="e7aff80741661a5eb60f57649077f9c5" category="inline-image-macro">Dieses Datendiagramm zeigt einen Kafka-Durchsatz von ungefähr 31,74 GBps.</block>
  <block id="a9504735d0b0cbb3b424919bb1328a7d" category="paragraph"><block ref="a9504735d0b0cbb3b424919bb1328a7d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc6821411dfc3b7f483da21b37082dfc" category="paragraph">Wir haben auch einen ähnlichen Durchsatz im ONTAP Speichercontroller beobachtet<block ref="d40e53103e181690f77a04eadc8aa6cc" prefix=" " category="inline-code"></block> Bericht.</block>
  <block id="b0c400a1c1ac5de2cbdc877645b349a0" category="summary">Dieser Abschnitt behandelt die Hardware und Software, die zur Leistungsüberprüfung bei der Bereitstellung der Confluent Platform mit NetApp ONTAP für mehrstufigen Speicher verwendet wird.  Die folgende Tabelle behandelt die Lösungsarchitektur und die Basiskomponenten.</block>
  <block id="5197b1c9433e86b5ed33786625f77786" category="paragraph">Confluent und der NetApp AFF A900 Speichercontroller mit ONTAP Unterstützung sind verteilte Systeme, die für Datenströme konzipiert sind.  Beide sind horizontal skalierbar, fehlertolerant und bieten eine hervorragende Leistung unter Last.  Sie ergänzen sich beim verteilten Datenstreaming und der Streamverarbeitung mit geringeren Speicherkosten und Datenreduktionstechnologien, die den Datenbedarf minimieren.  Der AFF A900 Speichercontroller bietet eine hervorragende Leistung und ermöglicht gleichzeitig die Entkopplung von Rechen- und Datenspeicherressourcen.  Dies vereinfacht die Systemadministration und ermöglicht eine unabhängige Skalierung der Ressourcen.</block>
  <block id="8ebef54f33ae0fdc7c4dcb83539b6eac" category="inline-image-macro">Bild, das die Lösungsübersicht zeigt.</block>
  <block id="c7c06ecce0e6f1e46fab6853d4d45058" category="paragraph"><block ref="c7c06ecce0e6f1e46fab6853d4d45058" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f75094292f4afb812bc29237348d9948" category="cell">Confluent Platform Version 6.2</block>
  <block id="5cc4fd015c7740c575d319eefacbce83" category="list-text">3 x Tierpfleger</block>
  <block id="8f6a506566bd03a47cafb69561bafe0f" category="list-text">8 x Broker-Server</block>
  <block id="aa76981d988c82fc8b387682968887e6" category="list-text">5 x Werkzeugserver</block>
  <block id="b56d58a9a181bae1fa65f36407ea002c" category="list-text">1 x Grafana</block>
  <block id="4af3adf9207f6f8d2d6d9edda08f0638" category="list-text">1 x Kontrollzentrum</block>
  <block id="de4d788671df5cf79fda01236d8fc9a6" category="cell">NetApp ONTAP für Warm Buckets</block>
  <block id="37e0c77638b1388d83b997c8dffdb6d3" category="list-text">1 x AFF A900 Hochverfügbarkeitspaar (HA)</block>
  <block id="2e1c9b5ce764f890af0aebf38f1a500a" category="list-text">100GbE</block>
  <block id="983e16c42b860c2511053f17d60918c8" category="list-text">2 CPUs; insgesamt 16 physische Kerne</block>
  <block id="ce4750dd79017960eed95bd3b2677eb4" category="list-text">Intel Xeon</block>
  <block id="01dcc4e221fc9ff7472c5102b082eaf4" category="list-text">256 GB physischer Speicher</block>
  <block id="433304c312dd41f05955324749c0a47f" category="list-text">100GbE Dual-Port</block>
  <block id="b7d338a537a3a1d0186080c4c4ba47eb" category="summary">Auf dieser Seite wird die in dieser Lösung verwendete Technologie beschrieben.</block>
  <block id="a1f13b9a0674cc0beb81e208dfb68d05" category="doc">Technologieübersicht</block>
  <block id="7f1512274139985d5f21a72e13808522" category="section-title">NetApp ONTAP Speichercontroller</block>
  <block id="b691cb82ce5ecb3d94f82b73ef3c2219" category="paragraph">NetApp ONTAP ist ein leistungsstarkes Speicherbetriebssystem der Enterprise-Klasse.</block>
  <block id="f8b80927eb906c831742041c4c139be1" category="paragraph">NetApp ONTAP 9.8 führt Unterstützung für Amazon Simple Storage Service (S3)-APIs ein.  ONTAP unterstützt eine Teilmenge der S3-API-Aktionen von Amazon Web Services (AWS) und ermöglicht die Darstellung von Daten als Objekte in ONTAP-basierten Systemen bei Cloud-Anbietern (AWS, Azure und GCP) und vor Ort.</block>
  <block id="9496ba5a97ab04d734dc449f86646ffe" category="paragraph">Die NetApp StorageGRID -Software ist die Flaggschiff-Lösung von NetApp für Objektspeicher.  ONTAP ergänzt StorageGRID , indem es einen Aufnahme- und Vorverarbeitungspunkt am Rand bereitstellt, das von NetApp betriebene Datengewebe für Objektdaten erweitert und den Wert des NetApp -Produktportfolios steigert.</block>
  <block id="d6e8f345bdd21d285f35171c2da8cd3a" category="paragraph">Der Zugriff auf einen S3-Bucket wird über autorisierte Benutzer- und Clientanwendungen bereitgestellt.  Das folgende Diagramm zeigt die Anwendung beim Zugriff auf einen S3-Bucket.</block>
  <block id="a38dfb3b286ff4854c6f5d67ebc15e13" category="inline-image-macro">Diese Grafik zeigt die Anwendung beim Zugriff auf einen S3-Bucket.</block>
  <block id="185bab9f8946071e86896c051a520617" category="paragraph"><block ref="185bab9f8946071e86896c051a520617" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5088428c842a8d5e45f2e6597af4138" category="section-title">Primäre Anwendungsfälle</block>
  <block id="5c2f4a513e63ae351e5dc0b7412a43c2" category="paragraph">Der Hauptzweck der Unterstützung von S3-APIs besteht darin, Objektzugriff auf ONTAP bereitzustellen.  Die einheitliche Speicherarchitektur von ONTAP unterstützt jetzt Dateien (NFS und SMB), Blöcke (FC und iSCSI) und Objekte (S3).</block>
  <block id="1af2e65957e458000d1181bb9eba2517" category="section-title">Native S3-Anwendungen</block>
  <block id="c0889d6b193afe7d0069e3d99bc5f310" category="paragraph">Immer mehr Anwendungen können die ONTAP Unterstützung für den Objektzugriff mit S3 nutzen.  Obwohl sie für Archivierungs-Workloads mit hoher Kapazität gut geeignet sind, wächst der Bedarf an hoher Leistung in nativen S3-Anwendungen schnell und umfasst:</block>
  <block id="a768caa988605a2846599cf7e2d0c26a" category="list-text">Analyse</block>
  <block id="9d0996a44c6d51cf223e833dceecb286" category="list-text">Künstliche Intelligenz</block>
  <block id="1669cbc398e4228e7e05d6b2e030cbe7" category="list-text">Edge-to-Core-Aufnahme</block>
  <block id="bd1a4166acf45c62946d7592a64ad52d" category="paragraph">Kunden können jetzt vertraute Verwaltungstools wie ONTAP System Manager verwenden, um schnell leistungsstarken Objektspeicher für Entwicklung und Betrieb in ONTAP bereitzustellen und dabei die Effizienz und Sicherheit des ONTAP Speichers zu nutzen.</block>
  <block id="50472ac5cace1b7798b3f92db5c3049e" category="section-title">FabricPool -Endpunkte</block>
  <block id="5050f2389b47df5462550d8e11451e9d" category="paragraph">Ab ONTAP 9.8 unterstützt FabricPool die Tiering-Funktion für Buckets in ONTAP und ermöglicht so ONTAP-zu- ONTAP -Tiering.  Dies ist eine hervorragende Option für Kunden, die ihre vorhandene FAS Infrastruktur als Objektspeicher-Endpunkt umfunktionieren möchten.</block>
  <block id="10beb552e5ed01d5c890a260a1d6af16" category="paragraph">FabricPool unterstützt das Tiering zu ONTAP auf zwei Arten:</block>
  <block id="1e53159984d41f5ea848cdf412430a06" category="list-text">*Lokale Cluster-Tiering.*  Inaktive Daten werden mithilfe von Cluster-LIFs in einen Bucket auf dem lokalen Cluster verschoben.</block>
  <block id="08be0ca0511f2294cbbaf9d92327996b" category="list-text">*Remote-Cluster-Tiering.*  Inaktive Daten werden in einem Bucket auf einem Remote-Cluster abgelegt, und zwar auf ähnliche Weise wie bei einer herkömmlichen FabricPool Cloud-Ebene, wobei IC-LIFs auf dem FabricPool Client und Daten-LIFs auf dem ONTAP Objektspeicher verwendet werden.</block>
  <block id="bda29d8d2c5de29e5ec15858a0f72c79" category="paragraph">ONTAP S3 ist geeignet, wenn Sie S3-Funktionen auf vorhandenen Clustern ohne zusätzliche Hardware und Verwaltung wünschen.  Für Bereitstellungen mit mehr als 300 TB ist die NetApp StorageGRID -Software weiterhin die führende NetApp -Lösung für Objektspeicher.  Bei Verwendung von ONTAP oder StorageGRID als Cloud-Ebene ist keine FabricPool -Lizenz erforderlich.</block>
  <block id="5a7adb78ef640711a870d82123f00775" category="section-title">NetApp ONTAP für Confluent Tiered Storage</block>
  <block id="9a5bc88300f877a695de175398887e0e" category="paragraph">In jedem Rechenzentrum müssen geschäftskritische Anwendungen ausgeführt werden und wichtige Daten verfügbar und sicher sein.  Das neue NetApp AFF A900 -System basiert auf der Software ONTAP Enterprise Edition und verfügt über ein hoch belastbares Design.  Unser neues blitzschnelles NVMe-Speichersystem verhindert Störungen unternehmenskritischer Vorgänge, minimiert die Leistungsoptimierung und schützt Ihre Daten vor Ransomware-Angriffen.</block>
  <block id="42dfa85904e1fd1b7fb41d4278c38047" category="paragraph">Von der ersten Bereitstellung bis zur Skalierung Ihres Confluent-Clusters erfordert Ihre Umgebung eine schnelle Anpassung an Änderungen, die Ihre geschäftskritischen Anwendungen nicht beeinträchtigen.  ONTAP Enterprise-Datenmanagement, Quality of Service (QoS) und Leistung ermöglichen Ihnen die Planung und Anpassung an Ihre Umgebung.</block>
  <block id="36509bd95b243830a012c72c8a2d5844" category="paragraph">Die gemeinsame Verwendung von NetApp ONTAP und Confluent Tiered Storage vereinfacht die Verwaltung von Apache Kafka-Clustern, indem ONTAP als Scale-Out-Speicherziel genutzt wird und eine unabhängige Skalierung der Rechen- und Speicherressourcen für Confluent ermöglicht wird.</block>
  <block id="e09818a7d7d98185cdb0309cf3aca8f5" category="paragraph">Ein ONTAP S3-Server basiert auf den ausgereiften Scale-Out-Speicherfunktionen von ONTAP.  Die Skalierung Ihres ONTAP Clusters kann nahtlos erfolgen, indem Sie Ihre S3-Buckets erweitern, um neu hinzugefügte Knoten zum ONTAP Cluster zu verwenden.</block>
  <block id="1ccfe00aee80492f09968d6b208801d5" category="section-title">Einfache Verwaltung mit ONTAP System Manager</block>
  <block id="4fdad8328864e9de2db5338bb25291fc" category="paragraph">ONTAP System Manager ist eine browserbasierte grafische Benutzeroberfläche, mit der Sie Ihren ONTAP -Speichercontroller an weltweit verteilten Standorten in einer einzigen Konsole konfigurieren, verwalten und überwachen können.</block>
  <block id="c99eb67a4e6cbe9ba119a72c95161fab" category="inline-image-macro">Diese Grafik zeigt den Arbeitsbereich des ONTAP System Manager.</block>
  <block id="db8cf11125f7909f889c4894d1b8c042" category="paragraph"><block ref="db8cf11125f7909f889c4894d1b8c042" category="inline-image-macro-rx" type="image"></block></block>
  <block id="783157c9c38b4e88d7eefffe21cd97d3" category="paragraph">Sie können ONTAP S3 mit System Manager und der ONTAP CLI konfigurieren und verwalten.  Wenn Sie S3 aktivieren und Buckets mit System Manager erstellen, bietet ONTAP Best-Practice-Standards für eine vereinfachte Konfiguration.  Wenn Sie den S3-Server und die Buckets über die CLI konfigurieren, können Sie sie bei Bedarf weiterhin mit System Manager verwalten und umgekehrt.</block>
  <block id="d1623a9fec2de2642847391236e62e9b" category="paragraph">Wenn Sie mit System Manager einen S3-Bucket erstellen, konfiguriert ONTAP ein standardmäßiges Leistungsservicelevel, das dem höchsten auf Ihrem System verfügbaren entspricht.  Bei einem AFF -System wäre die Standardeinstellung beispielsweise „Extrem“.  Leistungsdienstebenen sind vordefinierte adaptive QoS-Richtliniengruppen.  Anstelle einer der Standard-Serviceebenen können Sie eine benutzerdefinierte QoS-Richtliniengruppe oder keine Richtliniengruppe angeben.</block>
  <block id="bbcb9e2700fba39c3b7b7fd438155100" category="paragraph">Zu den vordefinierten adaptiven QoS-Richtliniengruppen gehören die folgenden:</block>
  <block id="f1ec0b0c482a42bad395f01e7f2b6c1d" category="list-text">*Extrem.*  Wird für Anwendungen verwendet, die die geringste Latenz und höchste Leistung erfordern.</block>
  <block id="06e90efc82fff7e3090ba9ff1a3bd2a3" category="list-text">*Leistung.*  Wird für Anwendungen mit mäßigem Leistungsbedarf und geringer Latenz verwendet.</block>
  <block id="7aa0f5702784b1be0a3c5ed9e6f3df8e" category="list-text">*Wert.*  Wird für Anwendungen verwendet, bei denen Durchsatz und Kapazität wichtiger sind als Latenz.</block>
  <block id="113d20f8cc4d864cdfea1b0f611cbb0a" category="list-text">*Brauch.*  Geben Sie eine benutzerdefinierte QoS-Richtlinie oder keine QoS-Richtlinie an.</block>
  <block id="42cc32e2c7857ba980019c70438e92ed" category="paragraph">Wenn Sie *Für Tiering verwenden* auswählen, werden keine Leistungsservicelevel ausgewählt und das System versucht, kostengünstige Medien mit optimaler Leistung für die gestaffelten Daten auszuwählen.</block>
  <block id="5cc287af927b81043d030fc6a1ece879" category="paragraph">ONTAP versucht, diesen Bucket auf lokalen Ebenen bereitzustellen, die über die am besten geeigneten Festplatten verfügen und so das gewählte Servicelevel erfüllen.  Wenn Sie jedoch angeben müssen, welche Datenträger in den Bucket aufgenommen werden sollen, sollten Sie den S3-Objektspeicher über die CLI konfigurieren, indem Sie die lokalen Ebenen (Aggregat) angeben.  Wenn Sie den S3-Server über die CLI konfigurieren, können Sie ihn bei Bedarf weiterhin mit System Manager verwalten.</block>
  <block id="74869eb3dfe4756dab5491da2a3de2ad" category="paragraph">Wenn Sie angeben möchten, welche Aggregate für Buckets verwendet werden, können Sie dies nur über die CLI tun.</block>
  <block id="0c0e3a803cf68a8772ebf58a68b20124" category="paragraph">Confluent Platform ist eine umfassende Daten-Streaming-Plattform, die Ihnen den einfachen Zugriff auf Daten sowie deren Speicherung und Verwaltung als kontinuierliche Echtzeit-Streams ermöglicht.  Confluent wurde von den ursprünglichen Entwicklern von Apache Kafka entwickelt und erweitert die Vorteile von Kafka um Funktionen auf Unternehmensniveau, während es gleichzeitig den Aufwand für die Verwaltung oder Überwachung von Kafka verringert.  Heute nutzen über 80 % der Fortune 100-Unternehmen Datenstreaming-Technologie und die meisten davon verwenden Confluent.</block>
  <block id="3bcbf4072ba1e23a48434530e19a485d" category="section-title">Warum Confluent?</block>
  <block id="0fcb60f8560b74a641f556dbf96faf91" category="paragraph">Durch die Integration historischer und Echtzeitdaten in eine einzige, zentrale Quelle der Wahrheit erleichtert Confluent den Aufbau einer völlig neuen Kategorie moderner, ereignisgesteuerter Anwendungen, den Aufbau einer universellen Datenpipeline und die Erschließung leistungsstarker neuer Anwendungsfälle mit voller Skalierbarkeit, Leistung und Zuverlässigkeit.</block>
  <block id="f781b7a8a0d145997db9cf8449512bb8" category="section-title">Wofür wird Confluent verwendet?</block>
  <block id="d3c11d67f567698de4c90210b84c554d" category="paragraph">Mit der Confluent Platform können Sie sich darauf konzentrieren, wie Sie aus Ihren Daten geschäftlichen Nutzen ziehen, anstatt sich um die zugrunde liegenden Mechanismen zu kümmern, beispielsweise darum, wie Daten zwischen unterschiedlichen Systemen transportiert oder integriert werden.  Insbesondere vereinfacht die Confluent Platform die Verbindung von Datenquellen mit Kafka, die Erstellung von Streaming-Anwendungen sowie die Sicherung, Überwachung und Verwaltung Ihrer Kafka-Infrastruktur.  Heute wird die Confluent Platform für eine breite Palette von Anwendungsfällen in zahlreichen Branchen eingesetzt, von Finanzdienstleistungen, Omnichannel-Einzelhandel und autonomen Autos bis hin zu Betrugserkennung, Microservices und IoT.</block>
  <block id="870b2318ccfd123ac0f7e9ef1396d49d" category="paragraph">Die folgende Abbildung zeigt die Komponenten der Confluent-Plattform.</block>
  <block id="9d880468cb22c04bd894fc612814dbab" category="inline-image-macro">Diese Grafik zeigt die Komponenten der Confluent Platform.</block>
  <block id="e21a51ac4ed645780def5d56f85ac9a8" category="paragraph"><block ref="e21a51ac4ed645780def5d56f85ac9a8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="05fafb4336e843d4634bd9ac122177c8" category="section-title">Übersicht über die Confluent Event-Streaming-Technologie</block>
  <block id="51be25b0145a0beca811de24a62b5cb4" category="inline-link">Kafka</block>
  <block id="0139d991fe55319f2e19e039da969fcf" category="paragraph">Der Kern der Confluent Platform ist<block ref="66a1a9ec54e6ef0a1c109ad94b972ac9" category="inline-link-rx"></block> , die beliebteste Open-Source-Plattform für verteiltes Streaming.  Zu den wichtigsten Funktionen von Kafka gehören die folgenden:</block>
  <block id="f630f472aeeab8697846e0f1f2f730aa" category="list-text">Veröffentlichen und abonnieren Sie Datensatz-Streams.</block>
  <block id="176fc2b349b906f6eb7a8f49c7ce9780" category="list-text">Speichern Sie Datensatzströme fehlertolerant.</block>
  <block id="6026e29e86fd0ddcb6cba3908f85691f" category="list-text">Verarbeiten Sie Datensatzströme.</block>
  <block id="f7ec60663c6d3ee6fd5abe343b34f2b4" category="paragraph">Die Confluent Platform umfasst standardmäßig auch Schema Registry, REST Proxy, insgesamt über 100 vorgefertigte Kafka-Konnektoren und ksqlDB.</block>
  <block id="82ff0b3d0476bb8ca2283ff06c017658" category="section-title">Übersicht über die Enterprise-Funktionen der Confluent-Plattform</block>
  <block id="ed2c640e88db15d474de830703c8783b" category="list-text">*Confluent-Kontrollzentrum.*  Ein UI-basiertes System zur Verwaltung und Überwachung von Kafka.  Es ermöglicht Ihnen die einfache Verwaltung von Kafka Connect und das Erstellen, Bearbeiten und Verwalten von Verbindungen zu anderen Systemen.</block>
  <block id="da2f1a857a79ec960671ee4c735cc96e" category="list-text">*Confluent für Kubernetes.*  Confluent für Kubernetes ist ein Kubernetes-Operator.  Kubernetes-Operatoren erweitern die Orchestrierungsfunktionen von Kubernetes, indem sie die einzigartigen Funktionen und Anforderungen für eine bestimmte Plattformanwendung bereitstellen.  Für die Confluent Platform bedeutet dies eine erhebliche Vereinfachung des Bereitstellungsprozesses von Kafka auf Kubernetes und die Automatisierung typischer Aufgaben im Lebenszyklus der Infrastruktur.</block>
  <block id="d63f46631d40c1c76b1a1a46445584aa" category="list-text">*Kafka Connect-Konnektoren.*  Konnektoren verwenden die Kafka Connect-API, um Kafka mit anderen Systemen wie Datenbanken, Schlüssel-Wert-Speichern, Suchindizes und Dateisystemen zu verbinden.  Confluent Hub verfügt über herunterladbare Konnektoren für die gängigsten Datenquellen und -senken, einschließlich vollständig getesteter und unterstützter Versionen dieser Konnektoren mit Confluent Platform.  Weitere Details finden Sie<block ref="2f0cdf69523bef6b3b17324f38f83353" category="inline-link-rx"></block> .</block>
  <block id="9103a2961d6b4c593517d3d641763e5c" category="list-text">*Selbstausgleichende Cluster.*  Bietet automatisierten Lastausgleich, Fehlererkennung und Selbstheilung.  Es bietet außerdem Unterstützung für das Hinzufügen oder Außerbetriebnehmen von Brokern nach Bedarf, ohne dass eine manuelle Anpassung erforderlich ist.</block>
  <block id="776a13408286748f8c985c409604e8b6" category="list-text">*Konfluente Clusterverknüpfung.*  Verbindet Cluster direkt miteinander und spiegelt Themen von einem Cluster zum anderen über eine Linkbrücke.  Die Clusterverknüpfung vereinfacht die Einrichtung von Multi-Datacenter-, Multi-Cluster- und Hybrid-Cloud-Bereitstellungen.</block>
  <block id="c1712fa040f6accce664a82ba6d58b94" category="list-text">*Confluent automatischer Datenausgleich.*  Überwacht Ihren Cluster hinsichtlich der Anzahl der Broker, der Größe der Partitionen, der Anzahl der Partitionen und der Anzahl der Leader innerhalb des Clusters.  Sie können Daten verschieben, um eine gleichmäßige Arbeitslast in Ihrem Cluster zu erreichen, und gleichzeitig den Datenverkehr drosseln, um die Auswirkungen auf die Produktionsarbeitslasten während der Neuverteilung zu minimieren.</block>
  <block id="0f97179e1bb10c15685ca78b035b4956" category="list-text">*Konfluenter Replikator.*  Macht es einfacher als je zuvor, mehrere Kafka-Cluster in mehreren Rechenzentren zu verwalten.</block>
  <block id="a409602cf12dbcb436352a95146b6407" category="list-text">*Stufenspeicher.*  Bietet Optionen zum Speichern großer Mengen von Kafka-Daten bei Ihrem bevorzugten Cloud-Anbieter und reduziert so den Betriebsaufwand und die Kosten.  Mit Tiered Storage können Sie Daten auf kostengünstigem Objektspeicher aufbewahren und Broker nur dann skalieren, wenn Sie mehr Rechenressourcen benötigen.</block>
  <block id="ce61411f1780c30f58dd5aed90a77ad3" category="list-text">*Confluent JMS-Client.*  Confluent Platform enthält einen JMS-kompatiblen Client für Kafka.  Dieser Kafka-Client implementiert die JMS 1.1-Standard-API und verwendet Kafka-Broker als Backend.  Dies ist nützlich, wenn Sie über ältere Anwendungen verfügen, die JMS verwenden, und Sie den vorhandenen JMS-Nachrichtenbroker durch Kafka ersetzen möchten.</block>
  <block id="b38f5ff9be3975e499ba273a01035420" category="list-text">*Confluent MQTT-Proxy.*  Bietet eine Möglichkeit, Daten von MQTT-Geräten und -Gateways direkt an Kafka zu veröffentlichen, ohne dass ein MQTT-Broker dazwischengeschaltet werden muss.</block>
  <block id="ab05a802c02076dd0f0b419529e71ccd" category="list-text">*Confluent-Sicherheits-Plugins.*  Confluent-Sicherheits-Plugins werden verwendet, um verschiedenen Tools und Produkten der Confluent-Plattform Sicherheitsfunktionen hinzuzufügen.  Derzeit ist ein Plug-In für den Confluent REST-Proxy verfügbar, das bei der Authentifizierung eingehender Anfragen hilft und den authentifizierten Auftraggeber an Anfragen an Kafka weitergibt.  Dadurch können Confluent REST-Proxy-Clients die Multitenant-Sicherheitsfunktionen des Kafka-Brokers nutzen.</block>
  <block id="55cf1a0f0fce69fd543500e5761dd26d" category="section-title">NetApp StorageGRID</block>
  <block id="d82d42ad0a2161d02e1d8ce74ffcf0ab" category="paragraph">NetApp StorageGRID ist eine leistungsstarke und kostengünstige Objektspeicherplattform.  Durch die Verwendung von mehrstufigem Speicher werden die meisten Daten auf Confluent Kafka, die im lokalen Speicher oder im SAN-Speicher des Brokers gespeichert sind, in den Remote-Objektspeicher ausgelagert.  Diese Konfiguration führt zu erheblichen Betriebsverbesserungen, da Zeit und Kosten für die Neuausrichtung, Erweiterung oder Verkleinerung von Clustern oder den Austausch eines ausgefallenen Brokers reduziert werden.  Der Objektspeicher spielt eine wichtige Rolle bei der Verwaltung von Daten, die sich auf der Objektspeicherebene befinden. Deshalb ist die Auswahl des richtigen Objektspeichers wichtig.</block>
  <block id="3fa5e29e13fc3b3448ca388750ef38f0" category="paragraph">StorageGRID bietet intelligentes, richtliniengesteuertes globales Datenmanagement mithilfe einer verteilten, knotenbasierten Grid-Architektur.  Es vereinfacht die Verwaltung von Petabytes unstrukturierter Daten und Milliarden von Objekten durch seinen allgegenwärtigen globalen Objekt-Namespace in Kombination mit ausgefeilten Datenverwaltungsfunktionen.  Der Objektzugriff per Einzelaufruf erstreckt sich über mehrere Standorte und vereinfacht Hochverfügbarkeitsarchitekturen, während gleichzeitig ein kontinuierlicher Objektzugriff unabhängig von Standort- oder Infrastrukturausfällen gewährleistet wird.</block>
  <block id="30f28784f61df7a2f8e7069cefea91eb" category="paragraph">Durch die Mandantenfähigkeit können mehrere unstrukturierte Cloud- und Unternehmensdatenanwendungen sicher im selben Grid verwaltet werden, wodurch sich der ROI und die Anwendungsfälle für NetApp StorageGRID erhöhen.  Sie können mehrere Service-Levels mit metadatengesteuerten Objekt-Lebenszyklusrichtlinien erstellen und so Haltbarkeit, Schutz, Leistung und Lokalität über mehrere geografische Regionen hinweg optimieren.  Benutzer können Datenverwaltungsrichtlinien anpassen und Verkehrsbeschränkungen überwachen und anwenden, um sich unterbrechungsfrei an die Datenlandschaft anzupassen, wenn sich ihre Anforderungen in sich ständig verändernden IT-Umgebungen ändern.</block>
  <block id="dc10add739549f11a9f3d6ac44bf7fcc" category="section-title">Einfache Verwaltung mit Grid Manager</block>
  <block id="494ed2651e6b5b87a49cfe7ab40d5253" category="paragraph">Der StorageGRID Grid Manager ist eine browserbasierte grafische Benutzeroberfläche, mit der Sie Ihr StorageGRID -System an weltweit verteilten Standorten in einer einzigen Fensteransicht konfigurieren, verwalten und überwachen können.</block>
  <block id="772a64d9b71789d3f7910c440c370541" category="paragraph"><block ref="772a64d9b71789d3f7910c440c370541" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3784ac64ff307aaceedbc4045a0d047c" category="paragraph">Mit der StorageGRID Grid Manager-Schnittstelle können Sie die folgenden Aufgaben ausführen:</block>
  <block id="57d56613e28a4b5b4e9f351d17e228f7" category="list-text">Verwalten Sie global verteilte Repositories im Petabyte-Bereich mit Objekten wie Bildern, Videos und Aufzeichnungen.</block>
  <block id="5865c6ada208cf4e21f121f0d367b25a" category="list-text">Überwachen Sie Grid-Knoten und -Dienste, um die Objektverfügbarkeit sicherzustellen.</block>
  <block id="e21286be18c417a3042cb53e1dd1e8da" category="list-text">Verwalten Sie die Platzierung von Objektdaten im Laufe der Zeit mithilfe von Regeln für das Information Lifecycle Management (ILM).  Diese Regeln legen fest, was mit den Daten eines Objekts nach der Aufnahme geschieht, wie sie vor Verlust geschützt werden, wo und wie lange die Objektdaten gespeichert werden.</block>
  <block id="5c578eee23496659cea7dda27021c318" category="list-text">Überwachen Sie Transaktionen, Leistung und Vorgänge innerhalb des Systems.</block>
  <block id="c91fcac1d7192250f9c73d72ad06e051" category="section-title">Richtlinien für das Information Lifecycle Management</block>
  <block id="0550f1f7df7311673165b9915b4d10b2" category="paragraph">StorageGRID verfügt über flexible Datenverwaltungsrichtlinien, die das Aufbewahren von Replikatkopien Ihrer Objekte und die Verwendung von EC-Schemata (Erasure Coding) wie 2+1 und 4+2 (unter anderem) zum Speichern Ihrer Objekte umfassen, abhängig von spezifischen Leistungs- und Datenschutzanforderungen.  Da sich Arbeitslasten und Anforderungen im Laufe der Zeit ändern, ist es üblich, dass sich auch die ILM-Richtlinien im Laufe der Zeit ändern müssen.  Das Ändern von ILM-Richtlinien ist eine Kernfunktion, die es StorageGRID Kunden ermöglicht, sich schnell und einfach an ihre sich ständig ändernde Umgebung anzupassen.</block>
  <block id="9446a98ad14416153cc4d45ab8b531bf" category="section-title">Performance</block>
  <block id="356760a65d5411f2c9f8647f90e50978" category="inline-link-macro">SG5712, SG5760, SG6060 oder SGF6024</block>
  <block id="2ec930774314e7709987603c82825f4b" category="paragraph">StorageGRID skaliert die Leistung durch Hinzufügen weiterer Speicherknoten, die VMs, Bare Metal oder speziell entwickelte Geräte wie die<block ref="585d6d5337b82c3c73a6c04b53fcdd23" category="inline-link-macro-rx"></block> .  In unseren Tests haben wir die wichtigsten Leistungsanforderungen von Apache Kafka mit einem Drei-Knoten-Raster der Mindestgröße unter Verwendung des SGF6024-Geräts übertroffen.  Wenn Kunden ihren Kafka-Cluster mit zusätzlichen Brokern skalieren, können sie weitere Speicherknoten hinzufügen, um Leistung und Kapazität zu erhöhen.</block>
  <block id="3eee81ca69cbbee2bec24db63e4dea0d" category="section-title">Load Balancer und Endpunktkonfiguration</block>
  <block id="5b42fd120a40ecd7cc8ac5cdedde8ceb" category="paragraph">Admin-Knoten in StorageGRID bieten die Grid Manager-Benutzeroberfläche (Benutzeroberfläche) und den REST-API-Endpunkt zum Anzeigen, Konfigurieren und Verwalten Ihres StorageGRID -Systems sowie Prüfprotokolle zum Verfolgen der Systemaktivität.  Um einen hochverfügbaren S3-Endpunkt für den mehrstufigen Confluent Kafka-Speicher bereitzustellen, haben wir den StorageGRID Load Balancer implementiert, der als Dienst auf Admin-Knoten und Gateway-Knoten ausgeführt wird.  Darüber hinaus verwaltet der Load Balancer auch den lokalen Datenverkehr und kommuniziert mit dem GSLB (Global Server Load Balancing), um bei der Notfallwiederherstellung zu helfen.</block>
  <block id="95ae2f11a98975eca88411c818226d25" category="paragraph">Um die Endpunktkonfiguration weiter zu verbessern, bietet StorageGRID im Admin-Knoten integrierte Richtlinien zur Verkehrsklassifizierung, ermöglicht Ihnen die Überwachung Ihres Workload-Verkehrs und wendet verschiedene Quality-of-Service-Grenzwerte (QoS) auf Ihre Workloads an.  Richtlinien zur Verkehrsklassifizierung werden auf Endpunkte des StorageGRID Load Balancer-Dienstes für Gateway-Knoten und Admin-Knoten angewendet.  Diese Richtlinien können bei der Verkehrsgestaltung und -überwachung helfen.</block>
  <block id="dca5165744ce2dbf5825f022349ee941" category="section-title">Verkehrsklassifizierung in StorageGRID</block>
  <block id="588db6e460515c5268204303c93a770b" category="paragraph">StorageGRID verfügt über eine integrierte QoS-Funktionalität.  Richtlinien zur Verkehrsklassifizierung können dabei helfen, verschiedene Arten von S3-Verkehr zu überwachen, der von einer Clientanwendung kommt.  Sie können dann Richtlinien erstellen und anwenden, um diesen Datenverkehr basierend auf der Eingangs-/Ausgangsbandbreite, der Anzahl gleichzeitiger Lese-/Schreibanforderungen oder der Lese-/Schreibanforderungsrate zu begrenzen.</block>
  <block id="75dab812558989436263375877a82fb6" category="paragraph">Apache Kafka ist eine Framework-Implementierung eines Softwarebusses mit Stream-Verarbeitung, geschrieben in Java und Scala.  Ziel ist es, eine einheitliche Plattform mit hohem Durchsatz und geringer Latenz für die Verarbeitung von Echtzeit-Datenfeeds bereitzustellen.  Kafka kann über Kafka Connect eine Verbindung zu einem externen System zum Datenexport und -import herstellen und bietet Kafka Streams, eine Java-Stream-Verarbeitungsbibliothek.  Kafka verwendet ein binäres, TCP-basiertes Protokoll, das auf Effizienz optimiert ist und auf einer „Nachrichtensatz“-Abstraktion basiert, die Nachrichten auf natürliche Weise gruppiert, um den Overhead des Netzwerk-Roundtrips zu reduzieren.  Dies ermöglicht größere sequenzielle Festplattenvorgänge, größere Netzwerkpakete und zusammenhängende Speicherblöcke, wodurch Kafka einen stoßweisen Strom zufälliger Nachrichtenschreibvorgänge in lineare Schreibvorgänge umwandeln kann.  Die folgende Abbildung zeigt den grundlegenden Datenfluss von Apache Kafka.</block>
  <block id="3c061e9fbf92872063da256279195fbb" category="paragraph"><block ref="3c061e9fbf92872063da256279195fbb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c50889322e9d7d913a4218be06b94d9d" category="paragraph">Kafka speichert Schlüssel-Wert-Nachrichten, die von einer beliebigen Anzahl von Prozessen, sogenannten Produzenten, stammen.  Die Daten können innerhalb verschiedener Themen in verschiedene Partitionen aufgeteilt werden.  Innerhalb einer Partition werden Nachrichten streng nach ihren Offsets (der Position einer Nachricht innerhalb einer Partition) geordnet und zusammen mit einem Zeitstempel indiziert und gespeichert.  Andere Prozesse, sogenannte Verbraucher, können Nachrichten aus Partitionen lesen.  Für die Stream-Verarbeitung bietet Kafka die Streams-API, die das Schreiben von Java-Anwendungen ermöglicht, die Daten von Kafka nutzen und Ergebnisse zurück an Kafka schreiben.  Apache Kafka funktioniert auch mit externen Stream-Verarbeitungssystemen wie Apache Apex, Apache Flink, Apache Spark, Apache Storm und Apache NiFi.</block>
  <block id="0f13dfad626acfc5a84f5c6d8127cb93" category="paragraph">Kafka läuft auf einem Cluster aus einem oder mehreren Servern (Brokern genannt) und die Partitionen aller Themen werden auf die Clusterknoten verteilt.  Darüber hinaus werden Partitionen auf mehrere Broker repliziert.  Diese Architektur ermöglicht es Kafka, riesige Nachrichtenströme fehlertolerant zu übermitteln und einige der herkömmlichen Nachrichtensysteme wie Java Message Service (JMS), Advanced Message Queuing Protocol (AMQP) usw. zu ersetzen.  Seit der Version 0.11.0.0 bietet Kafka transaktionale Schreibvorgänge, die mithilfe der Streams-API eine exakt einmalige Stream-Verarbeitung ermöglichen.</block>
  <block id="a05ab89a0e70d8932f92ff5626b80205" category="paragraph">Kafka unterstützt zwei Arten von Themen: regulär und kompakt.  Reguläre Themen können mit einer Aufbewahrungsdauer oder einer Platzbegrenzung konfiguriert werden.  Wenn Datensätze vorhanden sind, die älter als die angegebene Aufbewahrungszeit sind, oder wenn die Speicherplatzgrenze für eine Partition überschritten wird, darf Kafka alte Daten löschen, um Speicherplatz freizugeben.  Standardmäßig sind Themen mit einer Aufbewahrungszeit von 7 Tagen konfiguriert, es ist jedoch auch möglich, Daten unbegrenzt zu speichern.  Bei komprimierten Themen verfallen Datensätze nicht aufgrund von Zeit- oder Speicherplatzbeschränkungen.  Stattdessen behandelt Kafka spätere Nachrichten als Aktualisierungen älterer Nachrichten mit demselben Schlüssel und garantiert, dass die neueste Nachricht pro Schlüssel niemals gelöscht wird.  Benutzer können Nachrichten vollständig löschen, indem sie eine sogenannte Tombstone-Nachricht mit dem Nullwert für einen bestimmten Schlüssel schreiben.</block>
  <block id="67510baee28b6897f23f317ea0eec6cd" category="paragraph">Es gibt fünf wichtige APIs in Kafka:</block>
  <block id="43437be1fd3e6788160e377194164ab4" category="list-text">*Produzenten-API.*  Ermöglicht einer Anwendung, Datensatzströme zu veröffentlichen.</block>
  <block id="d4814db3c767fa7cb8ef858faeb32012" category="list-text">*Consumer-API.*  Ermöglicht einer Anwendung, Themen zu abonnieren und Datensatzströme zu verarbeiten.</block>
  <block id="8e4e76f717f8e282710dbe0549551bbc" category="list-text">*Connector-API.*  Führt die wiederverwendbaren Producer- und Consumer-APIs aus, die die Themen mit den vorhandenen Anwendungen verknüpfen können.</block>
  <block id="32a74767220f0fd870d75199524522d5" category="list-text">*Streams-API.*  Diese API konvertiert die Eingabeströme in Ausgaben und erzeugt das Ergebnis.</block>
  <block id="4bb47a81bc800e1fb57bdde2d0945599" category="list-text">*Admin-API.*  Wird zum Verwalten von Kafka-Themen, Brokern und anderen Kafka-Objekten verwendet.</block>
  <block id="610121f784783393f66b6624cf93dafb" category="paragraph">Die Consumer- und Producer-APIs bauen auf dem Kafka-Messaging-Protokoll auf und bieten eine Referenzimplementierung für Kafka-Consumer- und Producer-Clients in Java.  Das zugrunde liegende Nachrichtenprotokoll ist ein Binärprotokoll, das Entwickler verwenden können, um ihre eigenen Consumer- oder Producer-Clients in jeder beliebigen Programmiersprache zu schreiben.  Dadurch wird Kafka aus dem Ökosystem der Java Virtual Machine (JVM) entsperrt.  Eine Liste der verfügbaren Nicht-Java-Clients wird im Apache Kafka-Wiki verwaltet.</block>
  <block id="3b85a5b4b78ed5de8ac5389862ce3d3f" category="section-title">Apache Kafka-Anwendungsfälle</block>
  <block id="21f595a264810e4537696c1280efad57" category="paragraph">Apache Kafka wird am häufigsten für Messaging, Website-Aktivitätsverfolgung, Metriken, Protokollaggregation, Stream-Verarbeitung, Event Sourcing und Commit-Protokollierung verwendet.</block>
  <block id="60f50b920903b4049f776062aa5e6cdc" category="list-text">Kafka verfügt über einen verbesserten Durchsatz, integrierte Partitionierung, Replikation und Fehlertoleranz, was es zu einer guten Lösung für groß angelegte Nachrichtenverarbeitungsanwendungen macht.</block>
  <block id="0ae69072c472e595412163a07084932c" category="list-text">Kafka kann die Aktivitäten eines Benutzers (Seitenaufrufe, Suchvorgänge) in einer Tracking-Pipeline als eine Reihe von Publish-Subscribe-Feeds in Echtzeit wiederherstellen.</block>
  <block id="6d9673a2fe148c529c3b2051cfe93896" category="list-text">Kafka wird häufig für Betriebsüberwachungsdaten verwendet.  Dabei werden Statistiken aus verteilten Anwendungen aggregiert, um zentralisierte Feeds mit Betriebsdaten zu erstellen.</block>
  <block id="8b8951c427cfdc3f095bb9d556dce00e" category="list-text">Viele Leute verwenden Kafka als Ersatz für eine Protokollaggregationslösung.  Bei der Protokollaggregation werden in der Regel physische Protokolldateien von Servern gesammelt und zur Verarbeitung an einem zentralen Ort (z. B. einem Dateiserver oder HDFS) abgelegt.  Kafka abstrahiert Dateidetails und bietet eine sauberere Abstraktion von Protokoll- oder Ereignisdaten als Nachrichtenstrom.  Dies ermöglicht eine Verarbeitung mit geringerer Latenz und eine einfachere Unterstützung mehrerer Datenquellen und einer verteilten Datennutzung.</block>
  <block id="e9b95314420c3704f19bfa0e922f51d1" category="list-text">Viele Kafka-Benutzer verarbeiten Daten in Verarbeitungspipelines, die aus mehreren Phasen bestehen, in denen Roheingabedaten aus Kafka-Themen verwendet und dann aggregiert, angereichert oder anderweitig in neue Themen zur weiteren Verwendung oder Weiterverarbeitung umgewandelt werden.  Beispielsweise könnte eine Verarbeitungspipeline zum Empfehlen von Nachrichtenartikeln Artikelinhalte aus RSS-Feeds crawlen und in einem „Artikel“-Thema veröffentlichen.  Bei der weiteren Verarbeitung kann dieser Inhalt normalisiert oder dedupliziert und der bereinigte Artikelinhalt in einem neuen Thema veröffentlicht werden. In einer letzten Verarbeitungsphase kann versucht werden, den Benutzern diesen Inhalt zu empfehlen.  Solche Verarbeitungspipelines erstellen Diagramme von Echtzeit-Datenflüssen basierend auf den einzelnen Themen.</block>
  <block id="f2bf506d0e67708783f1bc5c0b518527" category="list-text">Event Sourcing ist ein Anwendungsdesignstil, bei dem Statusänderungen als zeitlich geordnete Abfolge von Datensätzen protokolliert werden.  Die Unterstützung von Kafka für sehr große gespeicherte Protokolldaten macht es zu einem hervorragenden Backend für eine in diesem Stil erstellte Anwendung.</block>
  <block id="6a4fef92874e37e1418ff91ed4fda9cd" category="list-text">Kafka kann als eine Art externes Commit-Log für ein verteiltes System dienen.  Das Protokoll hilft bei der Replikation von Daten zwischen Knoten und fungiert als Neusynchronisierungsmechanismus für ausgefallene Knoten, um ihre Daten wiederherzustellen.  Die Protokollkomprimierungsfunktion in Kafka unterstützt diesen Anwendungsfall.</block>
  <block id="ca010f92402f8d9066224231329f1128" category="paragraph">Confluent Platform ist eine unternehmensreife Plattform, die Kafka um erweiterte Funktionen ergänzt, die die Anwendungsentwicklung und Konnektivität beschleunigen, Transformationen durch Stream-Verarbeitung ermöglichen, Unternehmensabläufe im großen Maßstab vereinfachen und strenge Architekturanforderungen erfüllen sollen.  Confluent wurde von den ursprünglichen Entwicklern von Apache Kafka entwickelt und erweitert die Vorteile von Kafka um Funktionen auf Unternehmensniveau, während es gleichzeitig den Aufwand für die Verwaltung oder Überwachung von Kafka verringert.  Heute nutzen über 80 % der Fortune 100-Unternehmen Datenstreaming-Technologie – und die meisten von ihnen verwenden Confluent.</block>
  <block id="6b41836f6be8bfff401751859b6f5561" category="paragraph">Mit der Confluent Platform können Sie sich darauf konzentrieren, wie Sie aus Ihren Daten geschäftlichen Nutzen ziehen, anstatt sich um die zugrunde liegenden Mechanismen zu kümmern, beispielsweise darum, wie Daten zwischen unterschiedlichen Systemen transportiert oder integriert werden.  Insbesondere vereinfacht die Confluent Platform die Verbindung von Datenquellen mit Kafka, die Erstellung von Streaming-Anwendungen sowie die Sicherung, Überwachung und Verwaltung Ihrer Kafka-Infrastruktur.  Heute wird die Confluent Platform für eine breite Palette von Anwendungsfällen in zahlreichen Branchen eingesetzt, von Finanzdienstleistungen, Omnichannel-Einzelhandel und autonomen Autos bis hin zu Betrugserkennung, Microservices und IoT.</block>
  <block id="774f9746d58ac38abf733a92e4720365" category="paragraph">Die folgende Abbildung zeigt die Komponenten der Confluent Kafka-Plattform.</block>
  <block id="4f93c36b7d83350cef38a27356c0d5c9" category="paragraph"><block ref="4f93c36b7d83350cef38a27356c0d5c9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="95577831087dbd899deb60b296f64a9c" category="section-title">Überblick über die Event-Streaming-Technologie von Confluent</block>
  <block id="f6d3df755e538ab85e1dffe4e2ef9966" category="paragraph">Der Kern der Confluent Platform ist<block ref="67718c59f00d7d04e4868dff5b37db2b" category="inline-link-rx"></block> , die beliebteste Open-Source-Plattform für verteiltes Streaming.  Die wichtigsten Funktionen von Kafka sind:</block>
  <block id="8da3f3354457b244e53f1423a77e8944" category="section-title">Übersicht über die Enterprise-Funktionen der Confluent-Plattform</block>
  <block id="c7d070206c9b11b02bee9b591736971c" category="list-text">*Confluent-Kontrollzentrum.*  Ein GUI-basiertes System zur Verwaltung und Überwachung von Kafka.  Es ermöglicht Ihnen die einfache Verwaltung von Kafka Connect und das Erstellen, Bearbeiten und Verwalten von Verbindungen zu anderen Systemen.</block>
  <block id="5488a6660d4f7d32995b983624c2e915" category="list-text">*Konfluente Konnektoren zu Kafka.*  Konnektoren verwenden die Kafka Connect-API, um Kafka mit anderen Systemen wie Datenbanken, Schlüssel-Wert-Speichern, Suchindizes und Dateisystemen zu verbinden.  Confluent Hub verfügt über herunterladbare Konnektoren für die gängigsten Datenquellen und -senken, einschließlich vollständig getesteter und unterstützter Versionen dieser Konnektoren mit Confluent Platform.  Weitere Details finden Sie<block ref="2f0cdf69523bef6b3b17324f38f83353" category="inline-link-rx"></block> .</block>
  <block id="b47dc18271c0f29d64ce1f45f12a053c" category="list-text">*Selbstausgleichende Cluster.*  Bietet automatisierten Lastausgleich, Fehlererkennung und Selbstheilung.  Es bietet Unterstützung für das Hinzufügen oder Außerbetriebnehmen von Brokern nach Bedarf, ohne dass eine manuelle Anpassung erforderlich ist.</block>
  <block id="1e5c2c1a7b1c3f9809e2b97438773325" category="list-text">*Confluent automatischer Datenausgleich.*  Überwacht Ihren Cluster hinsichtlich der Anzahl der Broker, der Größe der Partitionen, der Anzahl der Partitionen und der Anzahl der Leader innerhalb des Clusters.  Sie können Daten verschieben, um eine gleichmäßige Arbeitslast in Ihrem Cluster zu erreichen, und gleichzeitig den Datenverkehr drosseln, um die Auswirkungen auf die Produktionsarbeitslasten während der Neuverteilung zu minimieren.</block>
  <block id="e2e44d09263d2131a3697ad71cadb51b" category="doc">NVA-1157-DEPLOY: Apache Spark-Workload mit NetApp Speicherlösung</block>
  <block id="ddf79baf38c476a90774aad122f73cb5" category="paragraph">NVA-1157-DEPLOY beschreibt die Leistungs- und Funktionsvalidierung von Apache Spark SQL auf NetApp NFS AFF Speichersystemen.  Es werden Konfiguration, Architektur und Leistungstests anhand verschiedener Szenarien überprüft und Empfehlungen zur Verwendung von Spark mit der NetApp ONTAP Datenverwaltungssoftware gegeben.  Es umfasst auch Testergebnisse, die auf nur einer Reihe von Festplatten (JBOD) im Vergleich zum NetApp AFF A800 Speichercontroller basieren.</block>
  <block id="39234cd00ad225afa457b33c5b2c5957" category="paragraph"><block ref="39234cd00ad225afa457b33c5b2c5957" category="inline-link-macro-rx"></block></block>
  <block id="6a67053961e2b9d7e16bf757a5bea347" category="doc">Moderne Datenanalyse – Verschiedene Lösungen für unterschiedliche Analysestrategien</block>
  <block id="139dc952e7e6df2bb7d8000f47a42232" category="paragraph">Dieses Whitepaper beschreibt die modernen Lösungsstrategien für die Datenanalyse von NetApp .  Es enthält Einzelheiten zu Geschäftsergebnissen, Kundenherausforderungen, Technologietrends, Legacy-Architekturen der Konkurrenz, modernen Workflows, Anwendungsfällen, Branchen, Cloud, Technologiepartnern, Datenverschiebern, NetApp Active IQ Digital Advisor (auch bekannt als Digital Advisor), NetApp DataOps Toolkit, Hadoop to Spark, softwaredefiniertem Speicher mit NetApp Trident Protect, Containern, Enterprise-Datenmanagement, Archivierung und Tiering zur Erreichung der Ziele von KI und Analytik und dazu, wie NetApp und Kunden gemeinsam ihre Datenarchitektur modernisieren.</block>
  <block id="9a13b1875b1cf906383834093477aa0b" category="paragraph"><block ref="9a13b1875b1cf906383834093477aa0b" category="inline-link-macro-rx"></block></block>
  <block id="b5062caa115b4047ecd2ef0d7177923b" category="paragraph">Die folgenden Referenzen wurden in diesem TR verwendet:</block>
  <block id="7a5b516d0c7b523466aabf4d65c5920e" category="list-text">Apache Spark-Architektur und -Komponenten</block>
  <block id="71792c2d1ea80e0e082f8dc3cbdabfdd" category="inline-link"><block ref="71792c2d1ea80e0e082f8dc3cbdabfdd" category="inline-link-rx"></block></block>
  <block id="e37c2ea27f7286c4bd6a5fda415b8de8" category="paragraph"><block ref="e37c2ea27f7286c4bd6a5fda415b8de8" category="inline-link-rx"></block></block>
  <block id="63e2d6091a94e7952a98f50aab0149ce" category="list-text">Anwendungsfälle für Apache Spark</block>
  <block id="f2b9f91de80e495bcbc6169f57a4bd2d" category="inline-link"><block ref="f2b9f91de80e495bcbc6169f57a4bd2d" category="inline-link-rx"></block></block>
  <block id="7bc4162d3088ec5f539bb8bccd911d30" category="paragraph"><block ref="7bc4162d3088ec5f539bb8bccd911d30" category="inline-link-rx"></block></block>
  <block id="164b938eda63c6ce2631a3fcf3f37e5f" category="inline-link"><block ref="164b938eda63c6ce2631a3fcf3f37e5f" category="inline-link-rx"></block></block>
  <block id="4f2faa20c7d825b4d0501e1086305aac" category="paragraph"><block ref="4f2faa20c7d825b4d0501e1086305aac" category="inline-link-rx"></block></block>
  <block id="221c3eff38f8ab54d359694f9da63c6e" category="list-text">BERT</block>
  <block id="94f39b7b282094c13473d8b26a45d1f1" category="inline-link"><block ref="94f39b7b282094c13473d8b26a45d1f1" category="inline-link-rx"></block></block>
  <block id="aff4ff24147d7c4a2645c7781e081f7f" category="paragraph"><block ref="aff4ff24147d7c4a2645c7781e081f7f" category="inline-link-rx"></block></block>
  <block id="b507f78e88e67a8302f19d731bc75b06" category="list-text">Tiefes und netzwerkübergreifendes Netzwerk für Anzeigenklickvorhersagen</block>
  <block id="8ebbe970a3e3c77f7c8e00655ce2e505" category="inline-link"><block ref="8ebbe970a3e3c77f7c8e00655ce2e505" category="inline-link-rx"></block></block>
  <block id="ae454d032cd3c53237c03ee439566905" category="paragraph"><block ref="ae454d032cd3c53237c03ee439566905" category="inline-link-rx"></block></block>
  <block id="54452390cac5f65f3bcec580ba079531" category="list-text">FlexGroup</block>
  <block id="63e6562f5c9bc7c86f115b960762e586" category="paragraph"><block ref="63e6562f5c9bc7c86f115b960762e586" category="inline-link-rx"></block></block>
  <block id="becd6832ca6f3b6680d480b5802d1435" category="list-text">Streaming-ETL</block>
  <block id="b5924cfbbd0aa8b99cd3b6953ae625a3" category="inline-link"><block ref="b5924cfbbd0aa8b99cd3b6953ae625a3" category="inline-link-rx"></block></block>
  <block id="8d325f57229e685a7ad47c71dd567604" category="paragraph"><block ref="8d325f57229e685a7ad47c71dd567604" category="inline-link-rx"></block></block>
  <block id="31a31ad34b829349beab62dc154bb53c" category="list-text">NetApp E-Series-Lösungen für Hadoop</block>
  <block id="7cc9f35180bb40054e46d3046347f4fd" category="inline-link"><block ref="7cc9f35180bb40054e46d3046347f4fd" category="inline-link-rx"></block></block>
  <block id="ea07fc98557e1b8c5b675972fe1621da" category="paragraph"><block ref="ea07fc98557e1b8c5b675972fe1621da" category="inline-link-rx"></block></block>
  <block id="3f7d09efe0b4d4a65add41ac272194fd" category="list-text">Moderne Datenanalyselösungen von NetApp</block>
  <block id="105db1e1e5e90ed75dc22390638d6b74" category="inline-link-macro">Datenanalyselösungen</block>
  <block id="a1acc25bb8d463a22c069a9ae3d7a581" category="paragraph"><block ref="a1acc25bb8d463a22c069a9ae3d7a581" category="inline-link-macro-rx"></block></block>
  <block id="794cb725c5631ad99b5b7c000307f0df" category="list-text">SnapMirror</block>
  <block id="c932e562e101240deed6e4be0656dfd6" category="inline-link"><block ref="c932e562e101240deed6e4be0656dfd6" category="inline-link-rx"></block></block>
  <block id="750daab11890513d7529766b651ae531" category="paragraph"><block ref="750daab11890513d7529766b651ae531" category="inline-link-rx"></block></block>
  <block id="a7ac1d2e69b9bbb9a2accb2ec30a1d69" category="list-text">XCP</block>
  <block id="e7d54d48522774aa8774f3733414d084" category="inline-link"><block ref="f575d0e12f7a285daadcaf60a35e305e" category="inline-link-rx"></block></block>
  <block id="a0b810672fcf48d5064bdbf73f520d55" category="paragraph"><block ref="d41dfcb87efb2171f45941c801c9f5cc" category="inline-link-rx"></block></block>
  <block id="1ae50adfec05c416d0398e26bea5fc01" category="list-text">BlueXP Kopieren und Synchronisieren</block>
  <block id="90a11f9647f9e3f6cfead9fdd4f0789d" category="inline-link"><block ref="90a11f9647f9e3f6cfead9fdd4f0789d" category="inline-link-rx"></block></block>
  <block id="b8cfbcc5c9748a8f12142a1b9aae0e67" category="paragraph"><block ref="b8cfbcc5c9748a8f12142a1b9aae0e67" category="inline-link-rx"></block></block>
  <block id="ce9b5cd96205262213c417b501e9ed55" category="list-text">DataOps-Toolkit</block>
  <block id="eb87ce8a565e070f3b8c09faa4e840c1" category="inline-link"><block ref="eb87ce8a565e070f3b8c09faa4e840c1" category="inline-link-rx"></block></block>
  <block id="20a0f3ab42054c3aa4add8c8901b4aa9" category="paragraph"><block ref="20a0f3ab42054c3aa4add8c8901b4aa9" category="inline-link-rx"></block></block>
  <block id="fd79b6614eaf33c0131b98cf6d33aef4" category="summary">Auf dieser Seite werden die wichtigsten Anwendungsfälle und Architekturen für KI, ML und DL ausführlicher beschrieben.</block>
  <block id="029e93fe56123e362c90a853d36c91c9" category="doc">Wichtige Anwendungsfälle und Architekturen für KI, ML und DL</block>
  <block id="38fe3ee7a8452539638ebb43094bf303" category="paragraph">Die wichtigsten Anwendungsfälle und Methoden für KI, ML und DL können in die folgenden Abschnitte unterteilt werden:</block>
  <block id="28ab286fd15a84ffcfa82ffe262b2d07" category="section-title">Spark NLP-Pipelines und verteilte TensorFlow-Inferenz</block>
  <block id="b66d8859b0ca8adab0c5459ef44ed90c" category="paragraph">Die folgende Liste enthält die beliebtesten Open-Source-NLP-Bibliotheken, die von der Data-Science-Community in unterschiedlichen Entwicklungsstufen übernommen wurden:</block>
  <block id="357d19386660ae0694f2fa195678b61a" category="inline-link">Toolkit für natürliche Sprache (NLTK)</block>
  <block id="b7c0dd146600af70e881dce2c233cdb9" category="list-text"><block ref="202d1986e5208977bf54b6b767767c39" category="inline-link-rx"></block> . Das komplette Toolkit für alle NLP-Techniken.  Es wird seit Anfang der 2000er Jahre gepflegt.</block>
  <block id="76e3c26aea345cd63928dae30c7683b8" category="inline-link">TextBlob</block>
  <block id="9733a294c2e8cbac3f50f2b1c6165ac9" category="list-text"><block ref="29dbbb204c6bb7c5433e577a001773ba" category="inline-link-rx"></block> . Eine benutzerfreundliche Python-API für NLP-Tools, die auf NLTK und Pattern basiert.</block>
  <block id="b8dc45aaa0db9ddabebf51171beed13a" category="inline-link">Stanford Core NLP</block>
  <block id="e566a3c30415cf2003b1ae965e897b0c" category="list-text"><block ref="3aea58940b1efe70ecaf2254ccc89f1e" category="inline-link-rx"></block> . NLP-Dienste und -Pakete in Java, entwickelt von der Stanford NLP Group.</block>
  <block id="7013def92af3dd7db98d1285170b5c5a" category="inline-link">Gensim</block>
  <block id="f669b3f1322541dcae0edc94f45435ac" category="list-text"><block ref="7b679f834cae0cff7425a8dc62e2ec2e" category="inline-link-rx"></block> . „Topic Modelling for Humans“ begann als Sammlung von Python-Skripten für das Projekt „Czech Digital Mathematics Library“.</block>
  <block id="2840ef6b507856e3306a32ffe28a8886" category="inline-link">SpaCy</block>
  <block id="418cc23cee80079d8aa2ccd37169bfc0" category="list-text"><block ref="bc5121a0541ff390725a7d480b19b87f" category="inline-link-rx"></block> . End-to-End-NLP-Workflows für die Industrie mit Python und Cython mit GPU-Beschleunigung für Transformatoren.</block>
  <block id="e0b205fce51b69be7136044a22a371ab" category="inline-link">Fasttext</block>
  <block id="c3ad48f357ddb1f4eb538b483e904fbe" category="list-text"><block ref="53fd0bea11d98e3b7893bc4fbf501c85" category="inline-link-rx"></block> . Eine kostenlose, leichtgewichtige Open-Source-NLP-Bibliothek zum Lernen von Wort-Embeddings und zur Satzklassifizierung, die vom AI Research (FAIR)-Labor von Facebook erstellt wurde.</block>
  <block id="12680128425c827ef65d76f354329e97" category="inline-link">Spark ML</block>
  <block id="16cbab2d9cd08ef0822a3f68f3792982" category="paragraph">Spark NLP ist eine einzige, einheitliche Lösung für alle NLP-Aufgaben und -Anforderungen, die skalierbare, leistungsstarke und hochpräzise NLP-basierte Software für echte Produktionsanwendungsfälle ermöglicht.  Es nutzt Transferlernen und implementiert die neuesten hochmodernen Algorithmen und Modelle in der Forschung und branchenübergreifend.  Aufgrund der fehlenden vollständigen Unterstützung durch Spark für die oben genannten Bibliotheken wurde Spark NLP auf Basis von<block ref="3b3cfa486b6d50798f20e9b1ded08f31" category="inline-link-rx"></block> um die Vorteile der universellen verteilten In-Memory-Datenverarbeitungs-Engine von Spark als NLP-Bibliothek der Enterprise-Klasse für unternehmenskritische Produktionsabläufe zu nutzen.  Seine Annotatoren nutzen regelbasierte Algorithmen, maschinelles Lernen und TensorFlow, um Deep-Learning-Implementierungen zu unterstützen.  Dies umfasst gängige NLP-Aufgaben, einschließlich, aber nicht beschränkt auf Tokenisierung, Lemmatisierung, Stemming, Part-of-Speech-Tagging, Named-Entity-Erkennung, Rechtschreibprüfung und Stimmungsanalyse.</block>
  <block id="5f29df192bff436cf72d454f30a968c1" category="paragraph">Bidirectional Encoder Representations from Transformers (BERT) ist eine transformerbasierte maschinelle Lerntechnik für NLP.  Es machte das Konzept des Vortrainings und der Feinabstimmung populär.  Die Transformer-Architektur in BERT stammt aus der maschinellen Übersetzung, die langfristige Abhängigkeiten besser modelliert als auf rekurrenten neuronalen Netzwerken (RNN) basierende Sprachmodelle.  Außerdem wurde die Masked Language Modelling (MLM)-Aufgabe eingeführt, bei der zufällig 15 % aller Token maskiert werden und das Modell sie vorhersagt, wodurch echte Bidirektionalität ermöglicht wird.</block>
  <block id="f12fa7d8a39cc8394ad5dfb1afe14bee" category="inline-link">Reuters TRC2</block>
  <block id="3795ebdf5b8232c65a11ceced659b1d5" category="inline-link">Finanzielle PhraseBank</block>
  <block id="189f0cc22e5920c5fbe48e7f7a384fa4" category="inline-link">Dokument DL erklären</block>
  <block id="75396b8f8501a234110f5c2b41e8f2c1" category="paragraph">Aufgrund der Fachsprache und des Mangels an gekennzeichneten Daten in diesem Bereich ist die Analyse der Finanzstimmung eine Herausforderung.  FinBERT, ein Sprachmodell basierend auf vortrainiertem BERT, wurde domänenangepasst auf<block ref="a21d1b93ad8a312fcc9c56c81567ecca" category="inline-link-rx"></block> , ein Finanzkorpus, und mit gekennzeichneten Daten fein abgestimmt (<block ref="14fa31c8eadcc29b01046706cfe3add5" category="inline-link-rx"></block> ) zur Klassifizierung der Finanzstimmung.  Forscher extrahierten 4.500 Sätze aus Nachrichtenartikeln mit Finanzbegriffen.  Anschließend bewerteten 16 Experten und Masterstudenten mit Finanzhintergrund die Sätze als positiv, neutral und negativ.  Wir haben einen End-to-End-Spark-Workflow erstellt, um die Stimmung für die Transkripte der Telefonkonferenzen zu den Top-10-Gewinnzahlen der NASDAQ-Unternehmen von 2016 bis 2020 mithilfe von FinBERT und zwei weiteren vortrainierten Pipelines zu analysieren.<block ref="520f5e4ba9970dad735654cb1f0d1138" category="inline-link-rx"></block> ) von Spark NLP.</block>
  <block id="026dcbbbfad27f6209a41e9dab2f3aed" category="paragraph">Die zugrunde liegende Deep-Learning-Engine für Spark NLP ist TensorFlow, eine durchgängige Open-Source-Plattform für maschinelles Lernen, die eine einfache Modellerstellung, eine robuste ML-Produktion überall und leistungsstarke Experimente für die Forschung ermöglicht.  Daher, wenn wir unsere Pipelines in Spark ausführen<block ref="cbfea9758df7100c6471e30d3f36d3e1" prefix=" " category="inline-code"></block> Im Modus führten wir im Wesentlichen verteiltes TensorFlow mit Daten- und Modellparallelisierung über einen Master- und mehrere Worker-Knoten sowie über einen auf dem Cluster montierten Netzwerkspeicher aus.</block>
  <block id="159bdf3f5d37e56033c6c1736f86b085" category="section-title">Horovod verteiltes Training</block>
  <block id="7a2c7ce5896a9e74083af4e2048bb5a8" category="inline-link">NetApp E-Series-Lösung für Hadoop</block>
  <block id="bd3eac2bb98f840c3e8ec0d92eb9a66f" category="paragraph">Die zentrale Hadoop-Validierung für die MapReduce-bezogene Leistung wird mit TeraGen, TeraSort, TeraValidate und DFSIO (Lesen und Schreiben) durchgeführt.  Die Validierungsergebnisse von TeraGen und TeraSort werden in<block ref="c276ecb51e19896948b1464a39a504e4" category="inline-link-rx"></block> und im Abschnitt „Storage Tiering“ für AFF.</block>
  <block id="2c41734dc7928bdea8c2eab845ad7074" category="inline-link">Hovorod auf Spark</block>
  <block id="7509c08cb8b336b99de5f0cd33f545fd" category="paragraph">Aufgrund von Kundenanfragen betrachten wir das verteilte Training mit Spark als einen der wichtigsten der verschiedenen Anwendungsfälle.  In diesem Dokument haben wir die<block ref="e46884ff7ae14dc4a4c2907aa0145199" category="inline-link-rx"></block> um die Spark-Leistung mit lokalen, Cloud-nativen und Hybrid-Cloud-Lösungen von NetApp unter Verwendung von NetApp All Flash FAS (AFF)-Speichercontrollern, Azure NetApp Files und StorageGRID zu validieren.</block>
  <block id="57b5eacba6da62ec21ea18f95421ef6b" category="paragraph">Das Horovod on Spark-Paket bietet einen praktischen Wrapper um Horovod, der die Ausführung verteilter Trainings-Workloads in Spark-Clustern vereinfacht und eine enge Modelldesignschleife ermöglicht, in der Datenverarbeitung, Modelltraining und Modellbewertung alle in Spark erfolgen, wo sich die Trainings- und Inferenzdaten befinden.</block>
  <block id="e556cc2b256f6dd2bbe1cdfdb528c858" category="inline-link">Kaggle Rossmann Store Sales</block>
  <block id="f2280eb8ac361218b35f9fc97d4027b4" category="paragraph">Es gibt zwei APIs zum Ausführen von Horovod auf Spark: eine Estimator-API auf hoher Ebene und eine Run-API auf niedrigerer Ebene.  Obwohl beide denselben zugrunde liegenden Mechanismus zum Starten von Horovod auf Spark-Executoren verwenden, abstrahiert die Estimator-API die Datenverarbeitung, die Modelltrainingsschleife, die Modellprüfpunkte, die Metrikerfassung und das verteilte Training.  Wir verwendeten Horovod Spark Estimators, TensorFlow und Keras für eine End-to-End-Datenaufbereitung und einen verteilten Trainings-Workflow basierend auf dem<block ref="d30b6f4a07a765f48b43dd15bf3bc8ea" category="inline-link-rx"></block> Wettbewerb.</block>
  <block id="85cbe9ee50d80a624a5aacb533195f44" category="paragraph">Das Drehbuch<block ref="b502aa50c7ae6d7ea7adaf15de40ffe5" prefix=" " category="inline-code"></block> finden Sie im Abschnitt<block ref="b6cb6fe53e443d0379ed59c804a7a30d" category="inline-link-macro-rx"></block> Es besteht aus drei Teilen:</block>
  <block id="1e0ac520c0a0627793f8b0ca3703e8e1" category="list-text">Der erste Teil führt verschiedene Schritte zur Datenvorverarbeitung für einen ersten Satz von CSV-Dateien durch, die von Kaggle bereitgestellt und von der Community gesammelt wurden.  Die Eingabedaten werden in einen Trainingssatz mit einem<block ref="13148717f8faa9037f37d28971dfc219" prefix=" " category="inline-code"></block> Teilmenge und ein Testdatensatz.</block>
  <block id="80ee77d4db5b8f731e911e7c47803afa" category="list-text">Der zweite Teil definiert ein Keras Deep Neural Network (DNN)-Modell mit logarithmischer Sigmoid-Aktivierungsfunktion und einem Adam-Optimierer und führt ein verteiltes Training des Modells mit Horovod auf Spark durch.</block>
  <block id="6c32e5a10a8b9f7e225e92b30c4eb494" category="list-text">Der dritte Teil führt eine Vorhersage für den Testdatensatz durch, wobei das beste Modell verwendet wird, das den mittleren absoluten Gesamtfehler des Validierungssatzes minimiert.  Anschließend wird eine CSV-Ausgabedatei erstellt.</block>
  <block id="091fa9121c047db1dd48c3e2ab5f3c91" category="inline-link-macro">Maschinelles Lernen</block>
  <block id="4f57ef43a107778b9d34e7c8fabafb09" category="paragraph">Siehe den Abschnitt<block ref="c54562cdac0f1ff9f8a09a53f27a34da" category="inline-link-macro-rx"></block> für verschiedene Laufzeitvergleichsergebnisse.</block>
  <block id="840da3122eba37f84480a8dc769a8cc3" category="section-title">Multi-Worker-Deep-Learning mit Keras zur CTR-Vorhersage</block>
  <block id="d003b4f5bf1fc42082f5817cb6e961dc" category="paragraph">Angesichts der jüngsten Fortschritte bei ML-Plattformen und -Anwendungen richtet sich der Fokus nun stark auf das Lernen im großen Maßstab.  Die Klickrate (Click-Through-Rate, CTR) ist definiert als die durchschnittliche Anzahl von Klicks pro hundert Online-Anzeigenimpressionen (ausgedrückt als Prozentsatz).  Es wird in zahlreichen Branchen und Anwendungsfällen, darunter digitales Marketing, Einzelhandel, E-Commerce und Dienstleister, als Schlüsselkennzahl eingesetzt.  Weitere Einzelheiten zu den Anwendungen von CTR und verteilten Trainingsleistungsergebnissen finden Sie im<block ref="7cd04747490b9545ba139688b057ed31" category="inline-link-macro-rx"></block> Abschnitt.</block>
  <block id="45c832c8d01426bfb65d74b7c547ad0c" category="inline-link">Criteo Terabyte Click Logs-Datensatz</block>
  <block id="be1115ec919e48805da898209ea2c15a" category="paragraph">In diesem technischen Bericht verwendeten wir eine Variante des<block ref="1a19f40e7660b78c77663f74c89e1e7b" category="inline-link-rx"></block> (siehe TR-4904) für verteiltes Deep Learning mit mehreren Workern unter Verwendung von Keras zum Erstellen eines Spark-Workflows mit Deep- und Cross-Network-Modellen (DCN), wobei die Leistung hinsichtlich der Log-Loss-Fehlerfunktion mit einem Basismodell der logistischen Regression von Spark ML verglichen wird.  DCN erfasst effizient effektive Merkmalsinteraktionen begrenzten Grades, lernt hochgradig nichtlineare Interaktionen, erfordert keine manuelle Merkmalsentwicklung oder umfassende Suche und weist einen geringen Rechenaufwand auf.</block>
  <block id="71b755d753dcdba2aeca91b65c167330" category="paragraph">Daten für Empfehlungssysteme im Webmaßstab sind größtenteils diskret und kategorisch, was zu einem großen und spärlichen Merkmalsraum führt, der die Merkmalserkundung erschwert.  Dies hat die meisten groß angelegten Systeme auf lineare Modelle wie die logistische Regression beschränkt.  Der Schlüssel zu guten Vorhersagen liegt jedoch darin, häufig vorhersagbare Merkmale zu identifizieren und gleichzeitig ungesehene oder seltene Kreuzmerkmale zu untersuchen.  Lineare Modelle sind einfach, interpretierbar und leicht skalierbar, ihre Ausdruckskraft ist jedoch begrenzt.</block>
  <block id="b5353aa08a1306ca5da9e3faacc66b15" category="paragraph">Andererseits hat sich gezeigt, dass Kreuzmerkmale für die Verbesserung der Ausdruckskraft der Modelle von Bedeutung sind.  Leider ist zur Identifizierung solcher Features häufig eine manuelle Feature-Entwicklung oder eine umfassende Suche erforderlich.  Die Verallgemeinerung auf unsichtbare Funktionsinteraktionen ist oft schwierig.  Durch die Verwendung eines gekreuzten neuronalen Netzwerks wie DCN wird aufgabenspezifisches Feature Engineering vermieden, indem Feature-Crossing explizit und automatisch angewendet wird.  Das Kreuznetzwerk besteht aus mehreren Schichten, wobei der höchste Grad an Interaktionen nachweislich durch die Schichttiefe bestimmt wird.  Jede Schicht erzeugt Interaktionen höherer Ordnung auf der Grundlage bestehender Interaktionen und behält die Interaktionen der vorherigen Schichten bei.</block>
  <block id="70725839e7d887ef6f8c815f325d4592" category="paragraph">Ein tiefes neuronales Netzwerk (DNN) verspricht, sehr komplexe Interaktionen zwischen Features zu erfassen.  Im Vergleich zu DCN erfordert es jedoch fast eine Größenordnung mehr Parameter, kann keine Kreuzmerkmale explizit bilden und kann einige Arten von Merkmalsinteraktionen möglicherweise nicht effizient erlernen.  Das Cross-Network ist speichereffizient und einfach zu implementieren.  Durch das gemeinsame Training der Cross- und DNN-Komponenten werden prädiktive Feature-Interaktionen effizient erfasst und eine hochmoderne Leistung im Criteo CTR-Datensatz erzielt.</block>
  <block id="2c9e5f067c0c14c56aa757d792108648" category="inline-link">DeepCTR</block>
  <block id="c024a57f5a6b531b69123f5c78627fb9" category="paragraph">Ein DCN-Modell beginnt mit einer Einbettungs- und Stapelschicht, gefolgt von einem Quernetzwerk und einem tiefen Netzwerk parallel.  Darauf folgt wiederum eine letzte Kombinationsschicht, die die Ausgaben der beiden Netzwerke kombiniert.  Ihre Eingabedaten können ein Vektor mit spärlichen und dichten Merkmalen sein.  In Spark enthalten die Bibliotheken den Typ<block ref="4fe0a291146b8f5681b4e75f2031c1b1" prefix=" " category="inline-code"></block> .  Daher ist es für Benutzer wichtig, zwischen den beiden zu unterscheiden und beim Aufrufen der jeweiligen Funktionen und Methoden vorsichtig zu sein.  In webbasierten Empfehlungssystemen wie der CTR-Vorhersage sind die Eingaben meist kategorische Merkmale, zum Beispiel<block ref="f296a99dd35f7e3e83183f98a62982bf" prefix=" " category="inline-code"></block> .  Solche Merkmale werden oft als One-Hot-Vektoren kodiert, zum Beispiel:<block ref="05b38799fb2e84c83a72d68e1cb6ff67" prefix=" " category="inline-code"></block> .  One-Hot-Encoding (OHE) mit<block ref="4fe0a291146b8f5681b4e75f2031c1b1" prefix=" " category="inline-code"></block> ist nützlich, wenn Sie mit realen Datensätzen mit sich ständig änderndem und wachsendem Vokabular arbeiten.  Wir haben Beispiele in<block ref="0be922124247f224cab64b030781eed7" category="inline-link-rx"></block> um große Vokabulare zu verarbeiten und Einbettungsvektoren in der Einbettungs- und Stapelschicht unseres DCN zu erstellen.</block>
  <block id="565d2d07d9c220babb78adab27c2243a" category="inline-link">Criteo Display Ads-Datensatz</block>
  <block id="75253ebc28edb897ef33f95dd995dd58" category="paragraph">Der<block ref="8cb83117ecfa6e6678785dbda34d1999" category="inline-link-rx"></block> sagt die Klickrate der Anzeigen voraus.  Es verfügt über 13 ganzzahlige Merkmale und 26 kategorische Merkmale, wobei jede Kategorie eine hohe Kardinalität aufweist.  Für diesen Datensatz ist aufgrund der großen Eingabegröße eine Verbesserung des Logverlusts um 0,001 praktisch signifikant.  Eine kleine Verbesserung der Vorhersagegenauigkeit für eine große Benutzerbasis kann möglicherweise zu einer erheblichen Steigerung des Umsatzes eines Unternehmens führen.  Der Datensatz enthält 11 GB Benutzerprotokolle aus einem Zeitraum von 7 Tagen, was etwa 41 Millionen Datensätzen entspricht.  Wir haben Spark verwendet<block ref="26ef62452ce5167b94d9bf8e4552df44" prefix=" " category="inline-code"></block> die Daten nach dem Zufallsprinzip für das Training (80 %), die Kreuzvalidierung (10 %) und die restlichen 10 % für Tests aufzuteilen.</block>
  <block id="e871e132ed2e9c6d6213da57972adec1" category="paragraph">DCN wurde auf TensorFlow mit Keras implementiert.  Bei der Implementierung des Modelltrainingsprozesses mit DCN gibt es vier Hauptkomponenten:</block>
  <block id="18aca2eb061782e34fcc772d780e4327" category="list-text">*Datenverarbeitung und -einbettung.*  Realwertige Merkmale werden durch Anwenden einer Log-Transformation normalisiert.  Für kategorische Merkmale betten wir die Merkmale in dichte Vektoren der Dimension 6 × (Kategoriekardinalität) 1/4 ein.  Durch Verketten aller Einbettungen entsteht ein Vektor der Dimension 1026.</block>
  <block id="190befa8188b0e07126d23d7488e79e7" category="list-text">*Optimierung.*  Wir haben eine stochastische Mini-Batch-Optimierung mit dem Adam-Optimierer angewendet.  Die Batchgröße wurde auf 512 festgelegt.  Auf das tiefe Netzwerk wurde eine Batch-Normalisierung angewendet und die Gradienten-Clip-Norm auf 100 festgelegt.</block>
  <block id="023b8b252258fa415118862dec994bbf" category="list-text">*Regularisierung.*  Wir haben ein frühes Stoppen verwendet, da sich die L2-Regularisierung oder das Dropout als nicht wirksam erwiesen haben.</block>
  <block id="5f7ce3c44b690052b88504fd4c0ff7bb" category="list-text">*Hyperparameter.*  Wir berichten über Ergebnisse, die auf einer Rastersuche über die Anzahl der verborgenen Schichten, die Größe der verborgenen Schichten, die anfängliche Lernrate und die Anzahl der Kreuzschichten basieren.  Die Anzahl der verborgenen Schichten lag zwischen 2 und 5, wobei die Größe der verborgenen Schichten zwischen 32 und 1024 lag.  Bei DCN lag die Anzahl der Querschichten zwischen 1 und 6.  Die anfängliche Lernrate wurde in Schritten von 0,0001 von 0,0001 auf 0,001 eingestellt.  Bei allen Experimenten wurde ein frühzeitiger Stopp bei Trainingsschritt 150.000 angewendet, da ab diesem Zeitpunkt eine Überanpassung eintrat.</block>
  <block id="a5203fd5d2ee4a156e177b2b5b5ecb45" category="inline-link">DeepFM</block>
  <block id="43d5f147547ecf24ebc038feb06a8312" category="inline-link">AutoInt</block>
  <block id="79249d5f44965bf593f3105190bac784" category="inline-link">DCN v2</block>
  <block id="edddedbe12bade5d0d47c6600aa7fc40" category="paragraph">Zusätzlich zu DCN haben wir auch andere beliebte Deep-Learning-Modelle zur CTR-Vorhersage getestet, darunter<block ref="256b68047e4850e72fc6a1a263d88e86" category="inline-link-rx"></block> ,<block ref="a61c3ddacc920697ed1145d7ed359d25" category="inline-link-rx"></block> , Und<block ref="8b59d0e884bf752e43135b866516c089" category="inline-link-rx"></block> .</block>
  <block id="408be753ce98edae615db82036085d63" category="section-title">Zur Validierung verwendete Architekturen</block>
  <block id="2150013c97241fde077622292dd996b4" category="paragraph">Für diese Validierung haben wir vier Worker-Knoten und einen Master-Knoten mit einem AFF-A800-HA-Paar verwendet.  Alle Clustermitglieder waren über 10GbE-Netzwerk-Switches verbunden.</block>
  <block id="de404d7688ac5c78348bfea711a12792" category="paragraph">Für diese Validierung der NetApp Spark-Lösung haben wir drei verschiedene Speichercontroller verwendet: den E5760, den E5724 und den AFF-A800.  Die Speichercontroller der E-Serie wurden mit 12-Gbit/s-SAS-Verbindungen an fünf Datenknoten angeschlossen.  Der AFF HA-Paar-Speichercontroller stellt exportierte NFS-Volumes über 10-GbE-Verbindungen für Hadoop-Workerknoten bereit.  Die Hadoop-Clustermitglieder wurden über 10-GbE-Verbindungen in den Hadoop-Lösungen E-Series, AFF und StorageGRID verbunden.</block>
  <block id="f3952bdea9a512245a3b2e368bdd17a4" category="inline-image-macro">Zur Validierung verwendete Architekturen.</block>
  <block id="dbb9fda021247ba28b40c95fcf20d529" category="paragraph"><block ref="dbb9fda021247ba28b40c95fcf20d529" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dce4db89f623baec1071c07c6784f4b1" category="summary">Ein modernes Unternehmensrechenzentrum ist eine Hybrid-Cloud, die mehrere verteilte Infrastrukturumgebungen über eine kontinuierliche Datenverwaltungsebene mit einem konsistenten Betriebsmodell vor Ort und/oder in mehreren öffentlichen Clouds verbindet.  Um das Beste aus einer Hybrid Cloud herauszuholen, müssen Sie in der Lage sein, Daten nahtlos zwischen Ihren lokalen und Multi-Cloud-Umgebungen zu verschieben, ohne dass Datenkonvertierungen oder Anwendungs-Refactoring erforderlich sind.</block>
  <block id="e27d277adca53504bfe79d8a5e7c2084" category="doc">Hybrid-Cloud-Lösung</block>
  <block id="9cf7905c60934870d86a546076b272e4" category="paragraph">Kunden haben angegeben, dass sie ihre Reise in die Hybrid Cloud entweder mit der Verlagerung von Sekundärspeichern in die Cloud für Anwendungsfälle wie Datenschutz oder mit der Verlagerung weniger geschäftskritischer Workloads wie Anwendungsentwicklung und DevOps in die Cloud beginnen.  Anschließend wenden sie sich kritischeren Arbeitslasten zu.  Zu den beliebtesten Hybrid-Cloud-Workloads gehören Web- und Content-Hosting, DevOps und Anwendungsentwicklung, Datenbanken, Analysen und containerisierte Apps.  Die Komplexität, die Kosten und die Risiken von KI-Projekten in Unternehmen haben in der Vergangenheit die Einführung von KI von der experimentellen Phase bis zur Produktion behindert.</block>
  <block id="38ddba87301d0e027f020fd24b8a5ade" category="paragraph">Mit einer NetApp Hybrid-Cloud-Lösung profitieren Kunden von integrierten Tools für Sicherheit, Datenverwaltung und Compliance mit einem einzigen Control Panel für das Daten- und Workflow-Management in verteilten Umgebungen und optimieren gleichzeitig die Gesamtbetriebskosten basierend auf ihrem Verbrauch.  Die folgende Abbildung zeigt eine Beispiellösung eines Cloud-Service-Partners, der die Aufgabe hat, Multi-Cloud-Konnektivität für die Big-Data-Analysedaten der Kunden bereitzustellen.</block>
  <block id="10ebc90118ac5ab60f289bf34b75d978" category="inline-image-macro">Beispiellösung eines Cloud-Service-Partners.</block>
  <block id="f6eb8b15960b6dcbfd7e927644b45d94" category="paragraph"><block ref="f6eb8b15960b6dcbfd7e927644b45d94" category="inline-image-macro-rx" type="image"></block></block>
  <block id="207f35bf95973770d860aeee0abe32a2" category="paragraph">In diesem Szenario werden IoT-Daten, die in AWS aus verschiedenen Quellen empfangen werden, an einem zentralen Ort im NetApp Private Storage (NPS) gespeichert.  Der NPS-Speicher ist mit Spark- oder Hadoop-Clustern in AWS und Azure verbunden, sodass Big-Data-Analyseanwendungen in mehreren Clouds ausgeführt werden können und auf dieselben Daten zugreifen.  Zu den wichtigsten Anforderungen und Herausforderungen für diesen Anwendungsfall zählen die folgenden:</block>
  <block id="bf871745f8e53cd8c13aca4c2ae67522" category="list-text">Daten müssen aus verschiedenen Quellen, beispielsweise lokalen und Cloud-Umgebungen, über verschiedene Sensoren und Hubs empfangen werden.</block>
  <block id="cb1726ae6d68d40c3bc9861c2b26a1a0" category="list-text">Die Lösung muss effizient und kostengünstig sein.</block>
  <block id="6dc7db5e9c1da14f7d61e2a7f4428219" category="list-text">Die größte Herausforderung besteht darin, eine kostengünstige und effiziente Lösung zu entwickeln, die hybride Analysedienste zwischen verschiedenen lokalen und Cloud-Umgebungen bereitstellt.</block>
  <block id="cc4772ffa75dd53e0fb87df4b15528cd" category="paragraph">Unsere Lösung für Datenschutz und Multicloud-Konnektivität löst das Problem, das entsteht, wenn Cloud-Analyseanwendungen über mehrere Hyperscaler verteilt sind.  Wie in der obigen Abbildung gezeigt, werden Daten von Sensoren gestreamt und über Kafka in den AWS Spark-Cluster aufgenommen.  Die Daten werden in einer NFS-Freigabe gespeichert, die sich in NPS befindet, das sich außerhalb des Cloud-Anbieters in einem Equinix-Rechenzentrum befindet.</block>
  <block id="88971c24837a2734fa58ba8805336328" category="paragraph">Da NetApp NPS über Direct Connect- bzw. Express Route-Verbindungen mit Amazon AWS und Microsoft Azure verbunden ist, können Kunden das In-Place Analytics-Modul nutzen, um auf die Daten von Amazon- und AWS-Analyseclustern zuzugreifen.  Da sowohl der lokale als auch der NPS-Speicher mit ONTAP -Software läuft,<block ref="fcca72a796080b3a5e2b7b1394bd00ad" category="inline-link-rx"></block> kann die NPS-Daten in den lokalen Cluster spiegeln und so Hybrid-Cloud-Analysen über lokale und mehrere Clouds hinweg bereitstellen.</block>
  <block id="bc35f58684dbedfb73dd7ff64a4bd5a8" category="paragraph">Für eine optimale Leistung empfiehlt NetApp normalerweise die Verwendung mehrerer Netzwerkschnittstellen und Direktverbindungen oder Expressrouten für den Zugriff auf die Daten von Cloud-Instanzen.  Wir haben andere Data Mover-Lösungen, darunter<block ref="0adb843c17d646acd72646e9688dde2b" category="inline-link-rx"></block> Und<block ref="079cab06c3947ff50532e4e825fc7b2c" category="inline-link-rx"></block> um Kunden beim Aufbau anwendungsbewusster, sicherer und kostengünstiger Hybrid-Cloud-Spark-Cluster zu unterstützen.</block>
  <block id="cfb5f1c014066f18d7979fa1d35a934d" category="paragraph">Die folgenden drei Python-Skripte entsprechen den drei getesteten Hauptanwendungsfällen.  Erstens ist<block ref="b01d528ada3b5a6e0e9094642b727562" prefix=" " category="inline-code"></block> .</block>
  <block id="d3abf6f12cafa2cc1b795b31cd547c75" category="paragraph">Das zweite Skript ist<block ref="b502aa50c7ae6d7ea7adaf15de40ffe5" prefix=" " category="inline-code"></block> .</block>
  <block id="6e9120b39f924b2eed528e3bcdd009ac" category="paragraph">Das dritte Skript ist<block ref="5e1386bf4aaea9725a3cc5bc8e2bc9f4" prefix=" " category="inline-code"></block> .</block>
  <block id="90f0f970ed32524c528ba2778079d485" category="summary">NetApp verfügt über drei Speicherportfolios: FAS/ AFF, E-Series und Cloud Volumes ONTAP.  Wir haben AFF und die E-Serie mit ONTAP Speichersystem für Hadoop-Lösungen mit Apache Spark validiert.  Das von NetApp betriebene Data Fabric integriert Datenverwaltungsdienste und Anwendungen (Bausteine) für Datenzugriff, -kontrolle, -schutz und -sicherheit.</block>
  <block id="12a9f57585cd6b3b985dd451bf552845" category="doc">Übersicht über die NetApp Spark-Lösungen</block>
  <block id="c7516072fbed3396e6f4c39a5f2356a6" category="paragraph">NetApp verfügt über drei Speicherportfolios: FAS/ AFF, E-Serie und Cloud Volumes ONTAP.  Wir haben AFF und die E-Serie mit ONTAP Speichersystem für Hadoop-Lösungen mit Apache Spark validiert.</block>
  <block id="710b54a5dd637d8e21574c4fb3eea545" category="inline-image-macro">Das Datengewebe bietet Datenverwaltungsdienste und -anwendungen.</block>
  <block id="6370a459d17d7eda9502b6008ad71b4a" category="paragraph"><block ref="6370a459d17d7eda9502b6008ad71b4a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="829a597c83ae2b02e991f062bb891ace" category="list-text">* NetApp NFS-Direktzugriff.*  Bietet den neuesten Hadoop- und Spark-Clustern direkten Zugriff auf NetApp NFS-Volumes ohne zusätzliche Software- oder Treiberanforderungen.</block>
  <block id="d075304bce816c2722d405cac9bf4877" category="list-text">* NetApp SnapMirror Technologie.*  Bietet Datenschutzfunktionen zwischen lokalen und ONTAP Cloud- oder NPS-Instanzen.</block>
  <block id="bd162abba0390e6a6e2e2581d449bf77" category="paragraph">Die folgende Abbildung zeigt die Spark-Lösung mit NetApp Speicher.</block>
  <block id="0ec1ecf37e474c5f4116ab4ae95e84d9" category="inline-image-macro">Spark-Lösung mit NetApp -Speicher.</block>
  <block id="2c73cc344c9ea7b4fbe0e5179bb17d5a" category="paragraph"><block ref="2c73cc344c9ea7b4fbe0e5179bb17d5a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e58a24b49fbb76272d712aaabf465bf7" category="paragraph">Die ONTAP Spark-Lösung verwendet das NetApp NFS-Direktzugriffsprotokoll für In-Place-Analysen und KI-, ML- und DL-Workflows unter Zugriff auf vorhandene Produktionsdaten.  Für Hadoop-Knoten verfügbare Produktionsdaten werden exportiert, um vor Ort analytische sowie KI-, ML- und DL-Jobs auszuführen.  Sie können auf die zu verarbeitenden Daten in Hadoop-Knoten entweder mit oder ohne direkten NetApp NFS-Zugriff zugreifen.  In Spark mit dem Standalone- oder<block ref="bb3462b62cd8db3f9ba007d86f8d1c6d" prefix=" " category="inline-code"></block> Cluster-Manager können Sie ein NFS-Volume konfigurieren, indem Sie<block ref="806400a5eefaa4811c63e2b45a736984" prefix=" " category="inline-code"></block> .  Wir haben drei Anwendungsfälle mit unterschiedlichen Datensätzen validiert.  Die Einzelheiten dieser Validierungen werden im Abschnitt „Testergebnisse“ vorgestellt.  (xref)</block>
  <block id="955ae639ea2500f38215e8263610b119" category="paragraph">Die folgende Abbildung zeigt die Speicherpositionierung von NetApp Apache Spark/Hadoop.</block>
  <block id="78157b6c5aece6e0b7b7ea998dce3a8a" category="inline-image-macro">NetApp Apache Spark/Hadoop-Speicherpositionierung.</block>
  <block id="8e32cf48ce4f12a61f456b3ec41a7e21" category="paragraph"><block ref="8e32cf48ce4f12a61f456b3ec41a7e21" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3cf3adbf38f17f8e0c86c8531fc379b7" category="paragraph">Wir haben die einzigartigen Funktionen der E-Series Spark-Lösung, der AFF/ FAS ONTAP Spark-Lösung und der StorageGRID Spark-Lösung identifiziert und detaillierte Validierungen und Tests durchgeführt.  Basierend auf unseren Beobachtungen empfiehlt NetApp die E-Series-Lösung für Greenfield-Installationen und neue skalierbare Bereitstellungen sowie die AFF/ FAS -Lösung für In-Place-Analysen, KI-, ML- und DL-Workloads unter Verwendung vorhandener NFS-Daten und StorageGRID für KI-, ML- und DL- und moderne Datenanalysen, wenn Objektspeicher erforderlich ist.</block>
  <block id="675ed5324aa6eda280e015498c583161" category="inline-image-macro">Empfohlene NetApp -Lösungen für Spark.</block>
  <block id="32530ebcaeef5cc30a605229e26ea933" category="paragraph"><block ref="32530ebcaeef5cc30a605229e26ea933" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aa7b20f32446fa30f765cd0b1ca93739" category="paragraph">Ein Data Lake ist ein Speicherrepository für große Datensätze in nativer Form, das für Analyse-, KI-, ML- und DL-Aufgaben verwendet werden kann.  Wir haben ein Data Lake-Repository für die Spark-Lösungen E-Series, AFF/ FAS und StorageGRID SG6060 erstellt.  Das E-Series-System bietet HDFS-Zugriff auf den Hadoop Spark-Cluster, während auf vorhandene Produktionsdaten über das NFS-Direktzugriffsprotokoll auf den Hadoop-Cluster zugegriffen wird.  Für Datensätze, die sich im Objektspeicher befinden, bietet NetApp StorageGRID sicheren S3- und S3a-Zugriff.</block>
  <block id="881214767967db331c99550277ceb793" category="summary">Auf dieser Seite wird die Splunk-Architektur beschrieben, einschließlich wichtiger Definitionen, verteilter Splunk-Bereitstellungen, Splunk SmartStore, Datenfluss, Hardware- und Softwareanforderungen, Anforderungen für Einzel- und Multisite-Umgebungen usw.</block>
  <block id="1e6ade59f7284c0bca28eaeeeeed0a30" category="doc">Splunk-Architektur</block>
  <block id="3924240363e47a4a292119abc4a993a1" category="paragraph">In diesem Abschnitt wird die Splunk-Architektur beschrieben, einschließlich wichtiger Definitionen, verteilter Splunk-Bereitstellungen, Splunk SmartStore, Datenfluss, Hardware- und Softwareanforderungen, Anforderungen für Einzel- und Multisite-Umgebungen usw.</block>
  <block id="a8449bda57f23b9282f766113987bdf2" category="section-title">Wichtige Definitionen</block>
  <block id="56eee8e9cc278d0a414a6d5697a4675f" category="paragraph">In den nächsten beiden Tabellen sind die Splunk- und NetApp Komponenten aufgeführt, die in der verteilten Splunk-Bereitstellung verwendet werden.</block>
  <block id="5078bea36734bcaa4a0c1e3a0e6e4606" category="paragraph">Diese Tabelle listet die Splunk-Hardwarekomponenten für die verteilte Splunk Enterprise-Konfiguration auf.</block>
  <block id="5e536c35aec296fa99efa02703d1eb07" category="cell">Splunk-Komponente</block>
  <block id="eaeb30f9f18e0c50b178676f3eaef45f" category="cell">Aufgabe</block>
  <block id="84f200201a8fe699d8d701c940bade8e" category="cell">Indexer</block>
  <block id="a5aa1df4c3c47c407c84c66303cf0ece" category="cell">Repository für Splunk Enterprise-Daten</block>
  <block id="872c8a2437dfbfa5be0882eabc86bcd3" category="cell">Universal-Spediteur</block>
  <block id="66d25b75f626d8f6c535a4b4d25c9906" category="cell">Verantwortlich für die Aufnahme und Weiterleitung von Daten an die Indexer</block>
  <block id="c91b59f2eae5ebf309d600609f87a36f" category="cell">Suchkopf</block>
  <block id="5873147385b9bd833ffd9a046374c97b" category="cell">Das Benutzer-Frontend, das zum Suchen von Daten in Indexern verwendet wird</block>
  <block id="a6230a0628a31d41191b4ef7800745ed" category="cell">Cluster-Master</block>
  <block id="e4ae9d4eb2313305a17cde160f405a17" category="cell">Verwaltet die Splunk-Installation von Indexern und Suchköpfen</block>
  <block id="805ac84d9852820feaf2e2b643a07efb" category="cell">Überwachungskonsole</block>
  <block id="5cf5006c1d7fdc954614a4e4185a2c62" category="cell">Zentralisiertes Überwachungstool für die gesamte Bereitstellung</block>
  <block id="fdccec582408614d1e2f7428910b1c8f" category="cell">Lizenzmaster</block>
  <block id="7c3b9b8892864eb6fa5cb2a32b85cc93" category="cell">License Master kümmert sich um die Splunk Enterprise-Lizenzierung</block>
  <block id="06262b5ad14fe5851defa5b0b70c86c6" category="cell">Bereitstellungsserver</block>
  <block id="ebe1fa5d8a359a6db13876ab1142fa50" category="cell">Aktualisiert Konfigurationen und verteilt Apps an die Verarbeitungskomponente</block>
  <block id="4fabea287d13a082b71f046f9d8be91d" category="cell">Speicherkomponente</block>
  <block id="8bf5bd6530ea430a8edac8a795165179" category="cell">NetApp AFF</block>
  <block id="b1edd0b37872fd00feb3bb2738987b41" category="cell">Zur Verwaltung von Hot-Tier-Daten wird ein vollständiger Flash-Speicher verwendet.  Auch als lokaler Speicher bekannt.</block>
  <block id="518d90155e7eb8bf96c6b7852ba519a6" category="cell">S3-Objektspeicher zur Verwaltung von Warm-Tier-Daten.  Wird von SmartStore verwendet, um Daten zwischen der heißen und warmen Ebene zu verschieben.  Auch als Remote-Speicher bekannt.</block>
  <block id="310a27e25811a8eca9b6e5edd921a267" category="paragraph">Diese Tabelle listet die Komponenten der Splunk-Speicherarchitektur auf.</block>
  <block id="40f14800d20c9cecbec85dbb2cf35592" category="cell">Verantwortliche Komponente</block>
  <block id="a5847d984bf6ac525e00b95b93be4e94" category="cell">SmartStore</block>
  <block id="6b64d740ca8627e515d54827d95bc7cb" category="cell">Bietet Indexern die Möglichkeit, Daten vom lokalen Speicher in den Objektspeicher zu verschieben.</block>
  <block id="2f9304fe9b427489507405bef9a0bb9f" category="cell">Splunk</block>
  <block id="4194726ee334e1085d93e002837b73f0" category="cell">Heiß</block>
  <block id="cc42c7d2fb33f9ccc06f2e23486a9b0e" category="cell">Der Landeplatz, an dem Universal Forwarder neu geschriebene Daten platzieren.  Der Speicher ist beschreibbar und die Daten sind durchsuchbar.  Diese Datenebene besteht normalerweise aus SSDs oder schnellen HDDs.</block>
  <block id="253b40ae359ba25b56231803430c4873" category="cell">ONTAP</block>
  <block id="f156996831cd546988bf05451ede7b02" category="cell">Cache-Manager</block>
  <block id="52520fc1f4cef574661d086d8efcb1f8" category="cell">Verwaltet den lokalen Cache der indizierten Daten, ruft bei einer Suche warme Daten aus dem Remote-Speicher ab und entfernt am wenigsten häufig verwendete Daten aus dem Cache.</block>
  <block id="18297117d3d251afceed9ecbe797c849" category="cell">Warm</block>
  <block id="810be2ef6ffed5e543f948bf5984d544" category="cell">Die Daten werden logisch in den Bucket gerollt und zunächst vom Hot-Tier in den Warm-Tier umbenannt.  Die Daten innerhalb dieser Ebene sind geschützt und können, wie die Hot-Tier-Ebene, aus SSDs oder HDDs mit größerer Kapazität bestehen.  Sowohl inkrementelle als auch vollständige Backups werden mithilfe gängiger Datenschutzlösungen unterstützt.</block>
  <block id="7cf9c58117f9052c5d5a43b3add7f6a4" category="section-title">Verteilte Splunk-Bereitstellungen</block>
  <block id="11c2b5859cb0c1d37b40f8df716542e2" category="paragraph">Um größere Umgebungen zu unterstützen, in denen die Daten von vielen Maschinen stammen, müssen Sie große Datenmengen verarbeiten.  Wenn viele Benutzer die Daten durchsuchen müssen, können Sie die Bereitstellung skalieren, indem Sie Splunk Enterprise-Instanzen auf mehrere Maschinen verteilen.  Dies wird als verteilte Bereitstellung bezeichnet.</block>
  <block id="113f0bd975880424e2c87874233b2afb" category="paragraph">In einer typischen verteilten Bereitstellung führt jede Splunk Enterprise-Instanz eine spezielle Aufgabe aus und befindet sich auf einer von drei Verarbeitungsebenen, die den Hauptverarbeitungsfunktionen entsprechen.</block>
  <block id="ac31b29e5bbd68654aeb200e66227fb8" category="paragraph">In der folgenden Tabelle sind die Verarbeitungsebenen von Splunk Enterprise aufgeführt.</block>
  <block id="9483f17a69bd0b52dbc44f9106718634" category="cell">Stufe</block>
  <block id="2cb05e4bb7830be982f0922fed86b4cd" category="cell">Komponente</block>
  <block id="b5a7adde1af5c87d7fd797b6245c2a39" category="cell">Beschreibung</block>
  <block id="7d38267cdf833b2983d3487954ebf88e" category="cell">Dateneingabe</block>
  <block id="2d361d5fe6d74b7550e0aa35d94342ec" category="cell">Spediteur</block>
  <block id="b2eebf5023a2a2ba3b35711069723656" category="cell">Ein Forwarder verbraucht Daten und leitet die Daten dann an eine Gruppe von Indexern weiter.</block>
  <block id="521d4edc7c22d5f63bc5912ff2afa61a" category="cell">Indizierung</block>
  <block id="65265b43bef75c5bacc53c21e38eb8fc" category="cell">Ein Indexer indiziert eingehende Daten, die er normalerweise von einer Gruppe von Weiterleitungen erhält.  Der Indexer wandelt die Daten in Ereignisse um und speichert die Ereignisse in einem Index.  Der Indexer durchsucht die indexierten Daten auch als Antwort auf Suchanfragen eines Suchkopfs.</block>
  <block id="ff5b0dc94726e93d5db5cf7922183f2b" category="cell">Suchverwaltung</block>
  <block id="d4c174b1ebc77694020097497547d218" category="cell">Ein Suchkopf dient als zentrale Ressource für die Suche.  Die Suchköpfe in einem Cluster sind austauschbar und haben von jedem Mitglied des Suchkopfclusters aus Zugriff auf dieselben Suchvorgänge, Dashboards, Wissensobjekte usw.</block>
  <block id="86f51d8f8fa8928e0f6ddba31139676e" category="paragraph">In der folgenden Tabelle sind die wichtigen Komponenten aufgeführt, die in einer verteilten Splunk Enterprise-Umgebung verwendet werden.</block>
  <block id="dee8af298acfc4c4bcb9fda657125917" category="cell">Verantwortung</block>
  <block id="3b656ff8459bec2d80d19d367bd71d19" category="cell">Index-Cluster-Master</block>
  <block id="407a3e34682f31b649e8cbd865fdf50c" category="cell">Koordiniert Aktivitäten und Updates eines Indexer-Clusters</block>
  <block id="dad2f7ca532f008e8192d418406da758" category="cell">Indexverwaltung</block>
  <block id="85ba71585b2b8c323c8eb899fa033227" category="cell">Indexcluster</block>
  <block id="f13c7b75bef35de7c42cc0569f76e366" category="cell">Gruppe von Splunk Enterprise-Indexern, die so konfiguriert sind, dass sie Daten untereinander replizieren</block>
  <block id="f8b32f50f478eb80dca360b13aa78e92" category="cell">Suchkopf-Deployer</block>
  <block id="9f45bd6fe25c3f5597af0f46bfdb20db" category="cell">Verarbeitet die Bereitstellung und Aktualisierung des Cluster-Masters</block>
  <block id="bc2eef462c1a0c8b778b607c304ba877" category="cell">Suchkopfverwaltung</block>
  <block id="58f4a17edb05ffec840bf2b176bf6eca" category="cell">Suchkopfcluster</block>
  <block id="70f36c7a653c3724df8921edce177b22" category="cell">Gruppe von Suchköpfen, die als zentrale Ressource für die Suche dient</block>
  <block id="2ddcaa7e88a6ad9c095422ca4e601d85" category="cell">Lastenausgleich</block>
  <block id="fe613dab61d63209235cf49513b00d8a" category="cell">Wird von Clusterkomponenten verwendet, um die steigende Nachfrage von Suchköpfen, Indexern und S3-Zielen zu bewältigen und die Last auf die Clusterkomponenten zu verteilen.</block>
  <block id="184f98cf6a6dd19d0815179e63be4298" category="cell">Lastmanagement für Clusterkomponenten</block>
  <block id="e32d50596edede1bfe3978d8b7b5c5ac" category="paragraph">Entdecken Sie die folgenden Vorteile der verteilten Bereitstellungen von Splunk Enterprise:</block>
  <block id="9431943c093a5cc181eccd505ca50f4c" category="list-text">Zugriff auf vielfältige oder verteilte Datenquellen</block>
  <block id="e825b2fa62f5af51541982cc503c8825" category="list-text">Bereitstellung von Funktionen zur Bewältigung der Datenanforderungen von Unternehmen jeder Größe und Komplexität</block>
  <block id="c63fa16ec4ed3d9b3803c2d1e1548fe6" category="list-text">Erreichen Sie hohe Verfügbarkeit und stellen Sie die Notfallwiederherstellung mit Datenreplikation und Multisite-Bereitstellung sicher</block>
  <block id="fb289ff7f529e1f2477823c61e7d9c8f" category="section-title">Splunk SmartStore</block>
  <block id="e2475a05ae25f0e8f31932cc309db3f1" category="paragraph">SmartStore ist eine Indexerfunktion, die es Remote-Objektspeichern wie Amazon S3 ermöglicht, indizierte Daten zu speichern.  Wenn das Datenvolumen einer Bereitstellung zunimmt, übersteigt der Bedarf an Speicher in der Regel den Bedarf an Rechenressourcen.  Mit SmartStore können Sie Ihren Indexerspeicher und Ihre Rechenressourcen kostengünstig verwalten, indem Sie diese Ressourcen separat skalieren.</block>
  <block id="4b253fe4960ecb87fdd7a6c05a125003" category="paragraph">SmartStore führt eine Remote-Speicherebene und einen Cache-Manager ein.  Diese Funktionen ermöglichen die Speicherung von Daten entweder lokal auf Indexern oder auf der Remote-Speicherebene.  Der Cache-Manager verwaltet die Datenbewegung zwischen dem Indexer und der Remote-Speicherebene, die auf dem Indexer konfiguriert ist.</block>
  <block id="98941a2e255442c92447b445a4a6bc6e" category="paragraph">Mit SmartStore können Sie den Speicherbedarf des Indexers auf ein Minimum reduzieren und E/A-optimierte Rechenressourcen auswählen.  Die meisten Daten befinden sich auf dem Remote-Speicher.  Der Indexer verwaltet einen lokalen Cache, der eine minimale Datenmenge enthält: Hot Buckets, Kopien von Warm Buckets, die an aktiven oder kürzlich durchgeführten Suchvorgängen beteiligt sind, und Bucket-Metadaten.</block>
  <block id="2d153b33a50f3343c2aeb68789ee8e26" category="section-title">Splunk SmartStore-Datenfluss</block>
  <block id="3306b50d7dd22a0698c2245e7cd06bee" category="paragraph">Wenn eingehende Daten aus verschiedenen Quellen die Indexer erreichen, werden die Daten indiziert und lokal in einem Hot Bucket gespeichert.  Der Indexer repliziert außerdem die Hot-Bucket-Daten auf Zielindexer.  Bisher ist der Datenfluss identisch mit dem Datenfluss für Nicht-SmartStore-Indizes.</block>
  <block id="ad1e15c21ba7587e1631977abe48ab09" category="paragraph">Wenn der heiße Eimer ins Warme rollt, divergiert der Datenfluss.  Der Quellindexer kopiert den Warm Bucket in den Remote-Objektspeicher (Remote-Speicherebene), während die vorhandene Kopie in seinem Cache verbleibt, da Suchvorgänge häufig über kürzlich indizierte Daten ausgeführt werden.  Die Zielindexer löschen jedoch ihre Kopien, da der Remotespeicher eine hohe Verfügbarkeit bietet, ohne dass mehrere lokale Kopien verwaltet werden müssen.  Die Masterkopie des Buckets befindet sich jetzt im Remote-Speicher.</block>
  <block id="3d39641a906c56e9e12b0f019f23bc1d" category="paragraph">Das folgende Bild zeigt den Datenfluss von Splunk SmartStore.</block>
  <block id="d7a63eb40866a66e8bb1fc64387b113e" category="paragraph"><block ref="d7a63eb40866a66e8bb1fc64387b113e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7fa16046e839496393e84b6a20e9604e" category="paragraph">Der Cache-Manager auf dem Indexer ist für den SmartStore-Datenfluss von zentraler Bedeutung.  Es ruft bei Bedarf Kopien von Buckets aus dem Remote-Speicher ab, um Suchanfragen zu verarbeiten.  Außerdem werden ältere oder weniger häufig durchsuchte Kopien von Buckets aus dem Cache entfernt, da die Wahrscheinlichkeit, dass sie an Suchvorgängen teilnehmen, mit der Zeit abnimmt.</block>
  <block id="b36837abd403dcb47f93edcd619c14de" category="paragraph">Die Aufgabe des Cache-Managers besteht darin, die Nutzung des verfügbaren Caches zu optimieren und gleichzeitig sicherzustellen, dass Suchvorgänge sofortigen Zugriff auf die benötigten Buckets haben.</block>
  <block id="4b2ba4c21a026c9139cf1484818f31c0" category="paragraph">In der folgenden Tabelle sind die Softwarekomponenten aufgeführt, die zur Implementierung der Lösung erforderlich sind.  Die bei der Implementierung der Lösung verwendeten Softwarekomponenten können je nach Kundenanforderungen variieren.</block>
  <block id="aa76f43f5e0552119cc8d5313c67296e" category="cell">Produktfamilie</block>
  <block id="df644ae155e79abf54175bd15d75f363" category="cell">Produktname</block>
  <block id="892b5a336dfe285f2d5c04ccd3d6c465" category="cell">Produktversion</block>
  <block id="696c660ff8d9323e55146a6dbd4e4088" category="cell">Betriebssystem</block>
  <block id="1b3e6de2b0fe97c3177ea5a4ad142554" category="cell">StorageGRID -Objektspeicher</block>
  <block id="36552b079970ffb2dd1314115af76c4b" category="cell">11,6</block>
  <block id="274b68192b056e268f128ff63bfcd4a4" category="cell">n/a</block>
  <block id="aa1fc3398e84bda331b47203c1e53ad5" category="cell">CentOS</block>
  <block id="d6422a625045167156b3c0d85ca23ebf" category="cell">8,1</block>
  <block id="66985170e641a7e20698bfec3c1d889f" category="cell">CentOS 7.x</block>
  <block id="5dba46907e72d7502229329d2aafd8a2" category="cell">Splunk Enterprise</block>
  <block id="9d8d169ace12276d008f0d0b88b61261" category="cell">Splunk Enterprise mit SmartStore</block>
  <block id="75809dde56e3fe2c2fb740f1b55807ac" category="cell">8.0.3</block>
  <block id="3192356dc19e9b4ec43ba340bad657ee" category="section-title">Anforderungen für Einzel- und Multisite-Standorte</block>
  <block id="98b8bd4f9670277f1f0e59a574019582" category="paragraph">In einer Enterprise-Splunk-Umgebung (mittlere und große Bereitstellungen), in der die Daten von vielen Maschinen stammen und viele Benutzer die Daten durchsuchen müssen, können Sie Ihre Bereitstellung skalieren, indem Sie Splunk Enterprise-Instanzen auf einzelne und mehrere Standorte verteilen.</block>
  <block id="22e1b76cf9acbfd35603b013eefcb079" category="paragraph">In der folgenden Tabelle sind die in einer verteilten Splunk Enterprise-Umgebung verwendeten Komponenten aufgeführt.</block>
  <block id="ee5ff25e83985cc8f46c04780442d06b" category="cell">Gruppe von Splunk Enterprise-Indexern, die so konfiguriert sind, dass sie die Daten des jeweils anderen replizieren</block>
  <block id="4e21e57c1860bf98fe3d0af8068f827d" category="cell">Lastenausgleichsmodule</block>
  <block id="03d7fbb295d0abb68bf4d3ce22d6d448" category="cell">Lastmanagement für Clusterkomponenten</block>
  <block id="a0ebc1066e0250b1b42f1a66ae974836" category="paragraph">Diese Abbildung zeigt ein Beispiel für eine verteilte Bereitstellung an einem einzelnen Standort.</block>
  <block id="d929fa57a2db2b79fca2a0c134995344" category="paragraph"><block ref="d929fa57a2db2b79fca2a0c134995344" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf99a89b389bc74dc1a403695b28d6cd" category="paragraph">Diese Abbildung zeigt ein Beispiel für eine verteilte Bereitstellung an mehreren Standorten.</block>
  <block id="aa56e29281a1be8656361637c931faec" category="paragraph"><block ref="aa56e29281a1be8656361637c931faec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="80d955d16c5178cc40e347dfe675a443" category="paragraph">In den folgenden Tabellen ist die Mindestanzahl an Hardwarekomponenten aufgeführt, die zur Implementierung der Lösung erforderlich sind.  Die in bestimmten Implementierungen der Lösung verwendeten Hardwarekomponenten können je nach Kundenanforderungen variieren.</block>
  <block id="f690a37fe0f7a5932c9eee9dc887f7c7" category="admonition">Unabhängig davon, ob Sie Splunk SmartStore und StorageGRID an einem oder mehreren Standorten bereitgestellt haben, werden alle Systeme über den StorageGRID GRID Manager in einer einzigen Fensteransicht verwaltet.  Weitere Einzelheiten finden Sie im Abschnitt „Einfache Verwaltung mit Grid Manager“.</block>
  <block id="1605af3a62fa950fe8374a69086fdc94" category="paragraph">In dieser Tabelle ist die für einen einzelnen Standort verwendete Hardware aufgeführt.</block>
  <block id="380dbc8d9d2c8a17f6ebb0b2c62d3e85" category="cell">Scheibe</block>
  <block id="b3e1f4c67ee07a73dcdaff1cf34f2640" category="cell">Nutzbare Kapazität</block>
  <block id="3b0649c72650c313a357338dcdfb64ec" category="cell">Hinweis</block>
  <block id="1c594a38f9aafa3a439c25bc55815b40" category="cell">StorageGRID SG1000</block>
  <block id="b179d20c2d3e6e91708b69931e8fcf32" category="cell">Admin-Knoten und Load Balancer</block>
  <block id="48f09b085e666c51e35dbe89367de826" category="cell">StorageGRID SG6060</block>
  <block id="ab570142c34522356bdf33666f6532a3" category="cell">x48, 8 TB (NL-SAS-Festplatte)</block>
  <block id="1792805a48a4da5ef5a78aa014da1f84" category="cell">1PB</block>
  <block id="ecefe4d01bf4079d1e2833e9a7de2db7" category="cell">Remote-Speicher</block>
  <block id="9327a762e04913fc832ee2b182848716" category="paragraph">In dieser Tabelle ist die für eine Multisite-Konfiguration verwendete Hardware (pro Site) aufgeführt.</block>
  <block id="41cac74c281e47bb6feb1ef8db664ce4" category="cell">Admin-Knoten und Load Balancer</block>
  <block id="aadc7d80b20e9c743c2920297937f9fd" category="section-title">NetApp StorageGRID Load Balancer: SG1000</block>
  <block id="b3f51763a6ba0ae7fe6d83095cb24299" category="paragraph">Für die Objektspeicherung ist die Verwendung eines Lastenausgleichs erforderlich, um den Cloud-Speicher-Namespace darzustellen.  StorageGRID unterstützt Load Balancer von Drittanbietern führender Anbieter wie F5 und Citrix, viele Kunden entscheiden sich jedoch aufgrund seiner Einfachheit, Ausfallsicherheit und hohen Leistung für den StorageGRID -Balancer der Enterprise-Klasse.  Der StorageGRID Load Balancer ist als VM, Container oder speziell entwickeltes Gerät verfügbar.</block>
  <block id="01f9bf7333b91ead20b7d1ac12ba4bca" category="paragraph">Das StorageGRID SG1000 ermöglicht die Verwendung von Hochverfügbarkeitsgruppen (HA) und intelligentem Lastenausgleich für S3-Datenpfadverbindungen.  Kein anderes lokales Objektspeichersystem bietet einen angepassten Lastenausgleich.</block>
  <block id="2f1a2bc20d9d0cddf636827860bdeb21" category="paragraph">Das SG1000-Gerät bietet die folgenden Funktionen:</block>
  <block id="fee5222c1281869dd7c4e3e4b7225065" category="list-text">Ein Load Balancer und optional Admin-Node-Funktionen für ein StorageGRID System</block>
  <block id="7ea5a035cfe0609861da7628e7dedc64" category="list-text">Der StorageGRID Appliance Installer vereinfacht die Bereitstellung und Konfiguration von Knoten</block>
  <block id="224d05cfece712836874ae47446c6d1b" category="list-text">Vereinfachte Konfiguration von S3-Endpunkten und SSL</block>
  <block id="59bf11863992b10be7d53c81c21a0220" category="list-text">Dedizierte Bandbreite (im Gegensatz zur gemeinsamen Nutzung eines Load Balancers eines Drittanbieters mit anderen Anwendungen)</block>
  <block id="1436fddc15afc971733cc42610be3718" category="list-text">Bis zu 4 x 100 Gbit/s aggregierte Ethernet-Bandbreite</block>
  <block id="4ff66456ad21f2aa88ad918b2a19287d" category="paragraph">Das folgende Bild zeigt das SG1000 Gateway Services-Gerät.</block>
  <block id="605bc0a01cfe9da48adf3da49367bbdc" category="paragraph"><block ref="605bc0a01cfe9da48adf3da49367bbdc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="40b11d9d6e72b8f3d6f6cd150ea6d5b3" category="paragraph">Das StorageGRID SG6060-Gerät umfasst einen Compute Controller (SG6060) und ein Storage Controller Shelf (E-Series E2860), das zwei Storage Controller und 60 Laufwerke enthält.  Dieses Gerät bietet die folgenden Funktionen:</block>
  <block id="5d61368716b8937ccfa3ae30bdeb3add" category="list-text">Skalieren Sie bis zu 400 PB in einem einzigen Namespace.</block>
  <block id="b08da7d555d413c82fa9476b78a3d1b4" category="list-text">Bis zu 4 x 25 Gbit/s aggregierte Ethernet-Bandbreite.</block>
  <block id="3b384482ee0276a75964f52aab736cac" category="list-text">Enthält den StorageGRID Appliance Installer zur Vereinfachung der Knotenbereitstellung und -konfiguration.</block>
  <block id="3d6b68fb6989ac04a76612b7d50b5046" category="list-text">Jedes SG6060-Gerät kann über ein oder zwei zusätzliche Erweiterungsfächer für insgesamt 180 Laufwerke verfügen.</block>
  <block id="470503fbecc72cbe91b61c6e9b999cbe" category="list-text">Zwei E-Series E2800-Controller (Duplex-Konfiguration) zur Bereitstellung von Speichercontroller-Failover-Unterstützung.</block>
  <block id="920a659800fa3289516e73f0b8d0cd70" category="list-text">Laufwerksfach mit fünf Schubladen für sechzig 3,5-Zoll-Laufwerke (zwei Solid-State-Laufwerke und 58 NL-SAS-Laufwerke).</block>
  <block id="d60b006794c926c67e95ce7f49fffbed" category="paragraph">Das folgende Bild zeigt das Gerät SG6060.</block>
  <block id="cf84ce9e448fb9e498568b901279526a" category="paragraph"><block ref="cf84ce9e448fb9e498568b901279526a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ad24897680a673883f3a8e9467ea3271" category="section-title">Splunk-Design</block>
  <block id="c2d7b4acc3efe890969906f2a0be4bea" category="paragraph">Die folgende Tabelle listet die Splunk-Konfiguration für eine einzelne Site auf.</block>
  <block id="95dd022b7af0f9fcfb9ed21236830169" category="cell">Kerne</block>
  <block id="17bc10091293fdc562a6db69940ee924" category="cell">Betriebssystem</block>
  <block id="5132d0e71971db5ca9827d470220eae9" category="cell">16 Kerne</block>
  <block id="f4e3903ba78addf6fadac4a2d7285203" category="cell">32 GB RAM</block>
  <block id="3988099dd7392a8b60a290ca560ac95d" category="cell">CentOS 8.1</block>
  <block id="aa7f73db0dcc93a83403f1afb650efdd" category="cell">Verwaltet die Benutzerdaten</block>
  <block id="d3d9446802a44259755d38e6d163e820" category="cell">10</block>
  <block id="86e7f660faa5812369ca3195a6ab944a" category="cell">Das Benutzer-Frontend durchsucht Daten in Indexern</block>
  <block id="eccbc87e4b5ce2fe28308fd9f2a7baf3" category="cell">3</block>
  <block id="e14f0b3b9201c717d9cae1db6969fb64" category="cell">Verarbeitet Updates für Suchkopfcluster</block>
  <block id="0ac993c5a472613a0cd368ccfefd6009" category="cell">Verwaltet die Splunk-Installation und Indexer</block>
  <block id="a91966f90c29f7d9420d2fd902f4aac2" category="cell">Überwachungskonsole und Lizenzmaster</block>
  <block id="0cb149f6f77c10496cf7645357f9fd17" category="cell">Führt eine zentrale Überwachung der gesamten Splunk-Bereitstellung durch und verwaltet Splunk-Lizenzen</block>
  <block id="9bc779a08fe3e6d54c4355c4ee8c4a95" category="paragraph">Die folgenden Tabellen beschreiben die Splunk-Konfiguration für Multisite-Konfigurationen.</block>
  <block id="9605b47d211de50422182b81685da619" category="paragraph">Diese Tabelle listet die Splunk-Konfiguration für eine Multisite-Konfiguration (Site A) auf.</block>
  <block id="d9de1b6846e3235226dba66773043a15" category="cell">Verantwortlich für die Aufnahme und Weiterleitung der Daten an die Indexer.</block>
  <block id="76132c1712ff61ff02378720304f6529" category="cell">Führt eine zentrale Überwachung der gesamten Splunk-Bereitstellung durch und verwaltet Splunk-Lizenzen.</block>
  <block id="2d3db4a7f27e8f892b40be60e8c003b4" category="paragraph">Diese Tabelle listet die Splunk-Konfiguration für eine Multisite-Konfiguration (Site B) auf.</block>
  <block id="89586ffe0445b81e878d1032f66f2e12" category="summary">Splunk Enterprise ist die marktführende SIEM-Lösung, die in Sicherheits-, IT- und DevOps-Teams zu besseren Ergebnissen führt.</block>
  <block id="4d39837f3e2d893412540b1652c97cbe" category="paragraph">Splunk Enterprise ist die marktführende SIEM-Lösung, die in Sicherheits-, IT- und DevOps-Teams zu besseren Ergebnissen führt.  Die Nutzung von Splunk hat in den Organisationen unserer Kunden erheblich zugenommen.  Daher müssen weitere Datenquellen hinzugefügt und die Daten gleichzeitig über einen längeren Zeitraum aufbewahrt werden, was die Splunk-Infrastruktur belastet.</block>
  <block id="25c2a1fd1c8874a3e0526920fe7f440d" category="paragraph">Die Kombination aus Splunk SmartStore und NetApp StorageGRID soll Unternehmen eine skalierbare Architektur bieten, mit der sie eine verbesserte Aufnahmeleistung mit SmartStore- und StorageGRID Objektspeicher sowie eine erhöhte Skalierbarkeit für eine Splunk-Umgebung über mehrere geografische Regionen hinweg erreichen können.</block>
  <block id="fbf1f1e6f0848252d39ef48e7e18146f" category="inline-link">NetApp StorageGRID Dokumentationsressourcen</block>
  <block id="a246b965362984dc941c948da019cebe" category="list-text"><block ref="a246b965362984dc941c948da019cebe" category="inline-link-rx"></block></block>
  <block id="1deabb4a384507a50ad75f7c30954fe6" category="list-text"><block ref="1deabb4a384507a50ad75f7c30954fe6" category="inline-link-rx"></block></block>
  <block id="e145cc414457b4a232fb0b63ce9f44ab" category="inline-link">Splunk Enterprise-Dokumentation</block>
  <block id="04e37c317ba66f65142c3479329cc2e3" category="list-text"><block ref="04e37c317ba66f65142c3479329cc2e3" category="inline-link-rx"></block></block>
  <block id="14c366ebe94ed0bdf5d5eecad5a08411" category="inline-link">Splunk Enterprise Über SmartStore</block>
  <block id="fefd29a254418e70038ff08010d7066e" category="list-text"><block ref="fefd29a254418e70038ff08010d7066e" category="inline-link-rx"></block></block>
  <block id="b437e6537685614b8004334bad18e424" category="inline-link">Handbuch zur verteilten Bereitstellung von Splunk Enterprise</block>
  <block id="12c4d056a98e583e653fc125f9f3338d" category="list-text"><block ref="12c4d056a98e583e653fc125f9f3338d" category="inline-link-rx"></block></block>
  <block id="d043516086780b04d9c8b38186019be3" category="inline-link">Splunk Enterprise – Verwalten von Indexern und Indexerclustern</block>
  <block id="634ac9166526f20af850f5021155d4c5" category="list-text"><block ref="634ac9166526f20af850f5021155d4c5" category="inline-link-rx"></block></block>
  <block id="c7ebb883721f7d9264fd6ef2ae03fc71" category="summary">Dieser technische Bericht beschreibt den Nutzen, den NetApp einer Splunk SmartStore-Lösung bietet, und demonstriert gleichzeitig ein Framework für die Gestaltung und Dimensionierung von Splunk SmartStore in Ihrer Umgebung.  Das Ergebnis ist eine einfache, skalierbare und belastbare Lösung mit überzeugenden Gesamtbetriebskosten.</block>
  <block id="766d1a96c4f198ecfe92484b980e9b31" category="doc">TR-4869: NetApp StorageGRID mit Splunk SmartStore</block>
  <block id="fa4442e299e1aa350a002220ee278abc" category="paragraph">Splunk Enterprise ist die marktführende SIEM-Lösung (Security Information and Event Management), die in den Sicherheits-, IT- und DevOps-Teams zu Ergebnissen führt.</block>
  <block id="3b878279a04dc47d60932cb294d96259" category="section-title">Überblick</block>
  <block id="78298f39c2d5411f080a61b3abeb845f" category="paragraph">Das Datenvolumen wächst weiterhin exponentiell und schafft enorme Chancen für Unternehmen, die diese enorme Ressource nutzen können.  Splunk Enterprise wird in immer mehr Anwendungsfällen immer häufiger eingesetzt.  Mit der Zunahme der Anwendungsfälle wächst auch die Datenmenge, die Splunk Enterprise aufnimmt und verarbeitet.  Die traditionelle Architektur von Splunk Enterprise ist ein verteiltes Scale-Out-Design, das hervorragenden Datenzugriff und hervorragende Datenverfügbarkeit bietet.  Unternehmen, die diese Architektur verwenden, sind jedoch mit steigenden Kosten konfrontiert, die mit der Skalierung verbunden sind, um das schnell wachsende Datenvolumen zu bewältigen.</block>
  <block id="6a7254f4c4c618a79510973c24f6b258" category="paragraph">Splunk SmartStore mit NetApp StorageGRID löst diese Herausforderung durch die Bereitstellung eines neuen Bereitstellungsmodells, bei dem Rechenleistung und Speicher entkoppelt sind.  Diese Lösung ermöglicht außerdem eine unübertroffene Skalierbarkeit und Elastizität für Splunk Enterprise-Umgebungen, indem sie Kunden die Skalierung über einzelne und mehrere Standorte hinweg ermöglicht. Gleichzeitig werden die Kosten gesenkt, indem Rechenleistung und Speicher unabhängig voneinander skaliert werden und dem kostengünstigen, Cloud-basierten S3-Objektspeicher intelligentes Tiering hinzugefügt wird.</block>
  <block id="f8ff71716eed4ad221efc3e0d60beaf6" category="paragraph">Die Lösung optimiert die Datenmenge im lokalen Speicher, während die Suchleistung erhalten bleibt, sodass Rechenleistung und Speicher nach Bedarf skaliert werden können.  SmartStore wertet automatisch Datenzugriffsmuster aus, um zu bestimmen, welche Daten für Echtzeitanalysen zugänglich sein müssen und welche Daten im kostengünstigeren S3-Objektspeicher gespeichert werden sollten.</block>
  <block id="5c56ae45ba2fb5c42451dffdb2e64b55" category="paragraph">Dieser technische Bericht beschreibt den Nutzen, den NetApp einer Splunk SmartStore-Lösung bietet, und demonstriert gleichzeitig ein Framework für die Gestaltung und Dimensionierung von Splunk SmartStore in Ihrer Umgebung.  Das Ergebnis ist eine einfache, skalierbare und belastbare Lösung mit überzeugenden Gesamtbetriebskosten.  StorageGRID bietet den skalierbaren und kostengünstigen Objektspeicher auf Basis des S3-Protokolls/API, auch als Remote-Speicher bekannt, sodass Unternehmen ihre Splunk-Lösung kostengünstiger skalieren und gleichzeitig die Ausfallsicherheit erhöhen können.</block>
  <block id="9841b81741e6066deac80b48e24f10fd" category="admonition">Splunk SmartStore bezeichnet Objektspeicher als Remote-Speicher oder Remote-Speicherebenen.</block>
  <block id="4c1ead791cca9ec5a7b94356255ce5ef" category="section-title">Über NetApp StorageGRID</block>
  <block id="57f13ae6637bd7ac5af4d0b1c4342cf7" category="paragraph">NetApp StorageGRID ist eine softwaredefinierte Objektspeicherlösung für große Archive, Medienrepositorys und Webdatenspeicher.  Mit StorageGRID nutzt NetApp zwei Jahrzehnte Erfahrung in der Bereitstellung branchenführender Innovations- und Datenmanagementlösungen und unterstützt Unternehmen dabei, den Wert ihrer Informationen sowohl vor Ort als auch in öffentlichen, privaten oder hybriden Cloud-Bereitstellungen zu verwalten und zu maximieren.</block>
  <block id="6281e52aec6aad8556d89bbf44d95436" category="paragraph">StorageGRID bietet sicheren, dauerhaften Speicher für unstrukturierte Daten in großem Umfang.  Integrierte, metadatengesteuerte Richtlinien zur Lebenszyklusverwaltung optimieren den Verbleib Ihrer Daten während ihrer gesamten Lebensdauer.  Um die Kosten zu senken, werden Inhalte zur richtigen Zeit am richtigen Ort und auf der richtigen Speicherebene platziert.  Der einzelne Namespace ermöglicht den Zugriff auf die Daten über einen einzigen Aufruf, unabhängig vom geografischen Standort des StorageGRID Speichers.  Kunden können mehrere StorageGRID Instanzen zwischen Rechenzentren und in der Cloud-Infrastruktur bereitstellen und verwalten.</block>
  <block id="d0a72d49cbe69b32b6e889db2e1429c9" category="paragraph">Ein StorageGRID -System besteht aus global verteilten, redundanten, heterogenen Knoten, die sowohl in bestehende als auch in Client-Anwendungen der nächsten Generation integriert werden können.</block>
  <block id="a8bc435c89c3235d62a12e0fb3c5c909" category="paragraph"><block ref="a8bc435c89c3235d62a12e0fb3c5c909" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4077a77339f68c64c1e50f20961e468f" category="paragraph">IDC MarketScape hat NetApp kürzlich im neuesten Bericht „IDC MarketScape: Worldwide Object-Based Storage 2019 Vendor Assessment“ als führend bezeichnet.  Mit fast 20 Jahren Erfahrung im Produktionseinsatz in den anspruchsvollsten Branchen ist StorageGRID ein anerkannter Marktführer im Bereich unstrukturierter Daten.</block>
  <block id="a2146cca70b8afc5500f690b84357813" category="paragraph">Mit StorageGRID können Sie Folgendes erreichen:</block>
  <block id="0d29e2d2977160f50fc59018cd24d6ee" category="list-text">Stellen Sie mehrere StorageGRID -Instanzen bereit, um über einen einzigen Namespace, der problemlos auf Hunderte von Petabyte skaliert werden kann, von jedem Standort zwischen Rechenzentren und der Cloud auf Daten zuzugreifen.</block>
  <block id="770d656b5273d26168b61ba6ede38cfd" category="list-text">Bieten Sie Flexibilität bei der Bereitstellung und zentralen Verwaltung über Infrastrukturen hinweg.</block>
  <block id="5926e6b363cbfe237a46219c7f92fe02" category="list-text">Sorgen Sie für unübertroffene Haltbarkeit mit einer Haltbarkeit von 99,9999 % durch Nutzung von mehrschichtigem Erasure Coding (EC).</block>
  <block id="77a48d0beb74ba75ef47c32ed1115a01" category="list-text">Aktivieren Sie mehr Hybrid-Multi-Cloud-Funktionen mit validierten Integrationen in Amazon S3 Glacier und Azure Blob.</block>
  <block id="ffa0a5ca524779112b69eb9e53aacf31" category="list-text">Erfüllen Sie gesetzliche Verpflichtungen und erleichtern Sie die Einhaltung durch manipulationssichere Datenspeicherung, ohne proprietäre APIs oder Anbieterabhängigkeit.</block>
  <block id="6e9d67cdb6f2e5564ae28e0389bcc679" category="inline-link">NetApp StorageGRID Homepage</block>
  <block id="206008935f811359069d9b35cb5c874e" category="paragraph">Weitere Informationen dazu, wie StorageGRID Ihnen bei der Lösung Ihrer komplexesten Probleme im Bereich der unstrukturierten Datenverwaltung helfen kann, finden Sie im<block ref="56ef38793a035acc851dabaa0c795287" category="inline-link-rx"></block> .</block>
  <block id="04bfb82e5f80fda36ff56ad540caaa63" category="section-title">Über Splunk Enterprise</block>
  <block id="a643f0cfa3f1b40b8f79f3609f0aa84f" category="paragraph">Splunk Enterprise ist eine Plattform, mit der Daten in Taten umgesetzt werden.  Von verschiedenen Quellen wie Protokolldateien, Websites, Geräten, Sensoren und Anwendungen generierte Daten werden an die Splunk-Indexer gesendet und von ihnen analysiert, sodass Sie aus den Daten umfassende Erkenntnisse gewinnen können.  Es kann Datenlecks aufdecken, Kunden- und Produkttrends aufzeigen, Möglichkeiten zur Optimierung der Infrastruktur finden oder umsetzbare Erkenntnisse für eine Vielzahl von Anwendungsfällen liefern.</block>
  <block id="6118f726dd6c9b9e82e01638e958e5c8" category="section-title">Über Splunk SmartStore</block>
  <block id="9ce6098334cce9db7edb3314ee645a2e" category="paragraph">Splunk SmartStore erweitert die Vorteile der Splunk-Architektur und vereinfacht gleichzeitig die kostengünstige Skalierung.  Durch die Entkopplung von Rechen- und Speicherressourcen entstehen für E/A optimierte Indexerknoten mit deutlich reduziertem Speicherbedarf, da sie nur eine Teilmenge der Daten als Cache speichern.  Sie müssen keine zusätzlichen Rechen- oder Speicherressourcen hinzufügen, wenn nur eine dieser Ressourcen erforderlich ist, wodurch Sie erhebliche Kosteneinsparungen erzielen können.  Sie können kostengünstigen und leicht skalierbaren S3-basierten Objektspeicher verwenden, der die Umgebung weiter vereinfacht, die Kosten senkt und Ihnen die Verwaltung eines größeren Datensatzes ermöglicht.</block>
  <block id="fde880b7e5def5ccc70e3e98ba15b442" category="paragraph">Splunk SmartStore bietet Unternehmen einen erheblichen Mehrwert, unter anderem durch:</block>
  <block id="16fc7d5921f88ca7b8070e1913a6fb74" category="list-text">Senkung der Speicherkosten durch Verschieben von warmen Daten in den kostenoptimierten S3-Objektspeicher</block>
  <block id="9ce78e75b3ecebf85fe0d43f2cf80505" category="list-text">Nahtlose Skalierung durch Entkopplung von Speicher und Rechenleistung</block>
  <block id="1dd6f3d1f3ac2a43dc2e69386b1b15ca" category="list-text">Vereinfachung der Geschäftskontinuität durch Nutzung robuster Cloud-nativer Speicher</block>
  <block id="bdcc72fc1bad1a939182ad2bde321f1e" category="summary">Auf dieser Seite wird die Leistung von Splunk SmartStore auf einem NetApp StorageGRID Controller beschrieben.</block>
  <block id="b646ed758d0eaa12ba9fab12788f9ad4" category="doc">SmartStore-Leistung an einem einzelnen Standort</block>
  <block id="b72db8dc34d5e01f398d66c9de42c11f" category="paragraph">In diesem Abschnitt wird die Leistung von Splunk SmartStore auf einem NetApp StorageGRID Controller beschrieben.  Splunk SmartStore verschiebt warme Daten in den Remote-Speicher, in diesem Fall in den StorageGRID Objektspeicher bei der Leistungsvalidierung.</block>
  <block id="dd1e8d1bd57ca578a4ba44e789957d0f" category="paragraph"><block ref="dd1e8d1bd57ca578a4ba44e789957d0f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="32b74ac1eb4eb0530a3f976e96e3120d" category="paragraph">Wir haben EF600 für Hot-/Cache-Speicher und StorageGRID 6060 für Remote-Speicher verwendet.  Für die Leistungsvalidierung haben wir die folgende Architektur verwendet.  Wir haben zwei Suchköpfe, vier Heavy Forwarder zum Weiterleiten der Daten an Indexer, sieben Splunk Event Generators (Eventgens) zum Generieren der Echtzeitdaten und 18 Indexer zum Speichern der Daten verwendet.</block>
  <block id="b127bd17913b4ab46912efd5b9a74269" category="paragraph"><block ref="b127bd17913b4ab46912efd5b9a74269" category="inline-image-macro-rx" type="image"></block></block>
  <block id="254f642527b45bc260048e30704edb39" category="section-title">Konfiguration</block>
  <block id="45940e86de61b51821b0ec7959b3d551" category="paragraph">In dieser Tabelle ist die für die Leistungsvalidierung von SmartStorage verwendete Hardware aufgeführt.</block>
  <block id="2fda610cb12c654fe037d4130498d5ae" category="cell">Schwerlast-Forwarder</block>
  <block id="6d53d218eec402993fef5394aef9acdf" category="cell">16 Kerne</block>
  <block id="d3dd61dd737f0e824caf9d717bc1a59d" category="cell">SLED 15 SP2</block>
  <block id="6f4922f45568161a8cdf4ad2299f6d23" category="cell">18</block>
  <block id="21dd53b3176e5a03137d603514a60ece" category="cell">Das Benutzer-Frontend sucht Daten in Indexern</block>
  <block id="c247e74124395bc7279d790ac384786e" category="section-title">SmartStore Remote Store-Leistungsvalidierung</block>
  <block id="30cf0ca744869370aafb6cfecdd7b4c6" category="paragraph">Bei dieser Leistungsvalidierung haben wir den SmartStore-Cache im lokalen Speicher auf allen Indexern für 10 Tage Daten konfiguriert.  Wir haben die<block ref="6255199182bd8af7ba33e8a06e144dc4" prefix=" " category="inline-code"></block> (750 MB Bucket-Größe) im Splunk-Cluster-Manager und habe die Änderungen an alle Indexer gesendet.  Um die Upload-Leistung zu messen, haben wir 10 Tage lang täglich 10 TB aufgenommen und alle Hot Buckets gleichzeitig auf Warm übertragen. Außerdem haben wir den Spitzen- und Durchschnittsdurchsatz pro Instanz und Bereitstellung über das Dashboard der SmartStore Monitoring Console erfasst.</block>
  <block id="4fc95542b54fee8da424a2e0ab281aeb" category="paragraph">Dieses Bild zeigt die an einem Tag aufgenommenen Daten.</block>
  <block id="1c106a39adeca49606809938222599d3" category="paragraph"><block ref="1c106a39adeca49606809938222599d3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b72140907b2e824ba4a35a2f01bac4e6" category="paragraph">Wir haben den folgenden Befehl vom Cluster-Master ausgeführt (der Indexname ist<block ref="b6f5a7e4d9c3de59289306e2636a7438" prefix=" " category="inline-code"></block> ).  Anschließend haben wir den Spitzen- und Durchschnitts-Upload-Durchsatz pro Instanz und Bereitstellungsweite über die Dashboards der SmartStore Monitoring Console erfasst.</block>
  <block id="94a0389fcc3ce42eea7a3f351f5d39b5" category="admonition">Der Cluster-Master verfügt über eine passwortlose Authentifizierung für alle Indexer (rtp-idx0001…rtp-idx0018).</block>
  <block id="d27688c7ebc58e3f620120997e317180" category="paragraph">Um die Download-Leistung zu messen, haben wir alle Daten aus dem Cache entfernt, indem wir die Evict-CLI mit dem folgenden Befehl zweimal ausgeführt haben.</block>
  <block id="4faf8abcf7e17175784cdc9d58df1608" category="admonition">Wir haben den folgenden Befehl vom Clustermaster aus ausgeführt und die Suche vom Suchkopf aus über 10 Tage Daten aus dem Remotespeicher von StorageGRID ausgeführt.  Anschließend haben wir den Spitzen- und Durchschnitts-Upload-Durchsatz pro Instanz und Bereitstellungsweite über die Dashboards der SmartStore Monitoring Console erfasst.</block>
  <block id="995931f06acb79ea5ac83df17d692a1d" category="paragraph">Die Indexerkonfigurationen wurden vom SmartStore-Clustermaster gepusht.  Der Cluster-Master hatte die folgende Konfiguration für den Indexer.</block>
  <block id="514109dd07ed0bb93081e9e36291b879" category="paragraph">Wir haben die folgende Suchanfrage im Suchkopf ausgeführt, um die Leistungsmatrix zu erfassen.</block>
  <block id="71e6150ea19aef0f2e67a79bd131fca8" category="paragraph"><block ref="71e6150ea19aef0f2e67a79bd131fca8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67e03c2395d7a876b5160fefc76f9bb9" category="paragraph">Wir haben die Leistungsinformationen vom Cluster-Master gesammelt.  Die Spitzenleistung betrug 61,34 GBps.</block>
  <block id="c5e60940f195879f09af22af10f55027" category="paragraph"><block ref="c5e60940f195879f09af22af10f55027" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2850e7edd48f5666ab4f82242ddb37d2" category="paragraph">Die durchschnittliche Leistung lag bei etwa 29 GBps.</block>
  <block id="a8eebaef6e6889ddddfe09cfa523009c" category="paragraph"><block ref="a8eebaef6e6889ddddfe09cfa523009c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="283456e93c96a11ef44a18693dd6c886" category="section-title">StorageGRID -Leistung</block>
  <block id="f5451e9a153b2f625ec0bc944af01be5" category="inline-link">Eventgen</block>
  <block id="764a1901ab00adf1e8e26712bf39c23a" category="paragraph">Die Leistung von SmartStore basiert auf der Suche nach bestimmten Mustern und Zeichenfolgen in großen Datenmengen.  Bei dieser Validierung werden die Ereignisse generiert mit<block ref="6cec2d19baf7e588a52847e567dab457" category="inline-link-rx"></block> auf einem bestimmten Splunk-Index (eventgen-test) über den Suchkopf, und die Anfrage geht für die meisten Abfragen an StorageGRID .  Das folgende Bild zeigt die Treffer und Fehlschläge der Abfragedaten.  Die Trefferdaten stammen von der lokalen Festplatte und die Fehlerdaten vom StorageGRID Controller.</block>
  <block id="3b8a6855a0eb4beaf2c787f34a2428d7" category="admonition">Die grüne Farbe zeigt die Trefferdaten und die orange Farbe die Fehltrefferdaten.</block>
  <block id="5776938ffab0b4f2730d8923c004d57e" category="paragraph"><block ref="5776938ffab0b4f2730d8923c004d57e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6fa8244cc2900d6f36b3144c7e748ac" category="paragraph">Wenn die Abfrage für die Suche auf StorageGRID ausgeführt wird, wird die Zeit für die S3-Abrufrate von StorageGRID im folgenden Bild angezeigt.</block>
  <block id="7393ba7bdc5067b2c80450122c8a2f0d" category="paragraph"><block ref="7393ba7bdc5067b2c80450122c8a2f0d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e3fd399eb98a5a8fae1dc144ff614f3" category="section-title">StorageGRID Hardwarenutzung</block>
  <block id="8e8a6c088425467c00be94a9d15d015b" category="paragraph">Die StorageGRID Instanz verfügt über einen Load Balancer und drei StorageGRID Controller.  Die CPU-Auslastung für alle drei Controller liegt zwischen 75 % und 100 %.</block>
  <block id="69851341d968a4444c52d6c167608079" category="paragraph"><block ref="69851341d968a4444c52d6c167608079" category="inline-image-macro-rx" type="image"></block></block>
  <block id="140097f96ea2b213b6f37f9d71009a5e" category="section-title">SmartStore mit NetApp Storage Controller – Vorteile für den Kunden</block>
  <block id="7f18772207b4ab40d0e7574fc68b95b6" category="list-text">*Entkopplung von Rechenleistung und Speicher.*  Der Splunk SmartStore entkoppelt Rechenleistung und Speicher, sodass Sie diese unabhängig voneinander skalieren können.</block>
  <block id="4e1a3208fe0742415bc087d082943293" category="list-text">*Daten auf Anfrage.*  SmartStore bringt Daten bei Bedarf in die Nähe der Rechenleistung und bietet Rechen- und Speicherelastizität sowie Kosteneffizienz, um eine längere Datenaufbewahrung im großen Maßstab zu erreichen.</block>
  <block id="f3295a31a8b7a9b5d76cb1a1e7f67f28" category="list-text">*AWS S3 API-kompatibel.*  SmartStore verwendet die AWS S3-API zur Kommunikation mit dem Wiederherstellungsspeicher, einem AWS S3- und S3-API-kompatiblen Objektspeicher wie StorageGRID.</block>
  <block id="4fda7aba03882818928ff7bc3a03f0e5" category="list-text">*Reduziert Speicherbedarf und Kosten.*  SmartStore reduziert den Speicherbedarf für ältere Daten (warm/kalt).  Es wird nur eine einzige Datenkopie benötigt, da der NetApp Speicher Datenschutz bietet und sich um Ausfälle und hohe Verfügbarkeit kümmert.</block>
  <block id="c27703d92f7f2316dfa63670f02dd6b6" category="list-text">*Hardwarefehler.*  Ein Knotenausfall in einer SmartStore-Bereitstellung macht die Daten nicht unzugänglich und ermöglicht eine viel schnellere Wiederherstellung des Indexers nach einem Hardwarefehler oder Datenungleichgewicht.</block>
  <block id="ed20f2e9df3c744293f044d87722ce0f" category="list-text">Anwendungs- und datenbewusster Cache.</block>
  <block id="f57d44dedead861d1eef7e912b9cbd86" category="list-text">Indexer hinzufügen/entfernen und Cluster nach Bedarf einrichten/abbauen.</block>
  <block id="98613866f09e0e2416018bef4be916d3" category="list-text">Die Speicherebene ist nicht mehr an die Hardware gebunden.</block>
  <block id="c1d2fce5798cdc81a1393206b0332f8a" category="summary">Die Lösung ermöglicht das Hinzufügen von Rechen-, Hot-Storage- oder S3-Ressourcen, um die wachsende Nachfrage hinsichtlich der Anzahl der Benutzer oder der Aufnahmerate bei Bereitstellungen an einem oder mehreren Standorten zu erfüllen.</block>
  <block id="4932435adc5992fde32a04e44fd251b8" category="doc">Vorteile dieser Lösung</block>
  <block id="bf89e1232480b95d07f648df24c3695b" category="list-text">*Leistung.*  Die Kombination aus Splunk SmartStore und NetApp StorageGRID ermöglicht eine schnelle Migration von Daten zwischen Hot Buckets und Warm Buckets mithilfe von Objektspeicher.  StorageGRID beschleunigt den Migrationsprozess, indem es eine schnelle Leistung für große Objekt-Workloads bietet.</block>
  <block id="e0be1ad556d6601e63eb8f1b6208c55e" category="list-text">*Multisite-fähig.*  Die verteilte Architektur von StorageGRID ermöglicht Splunk SmartStore die Ausweitung von Bereitstellungen auf einzelne und mehrere Standorte über einen einzigen globalen Namespace, in dem von jedem Standort aus auf die Daten zugegriffen werden kann, unabhängig davon, wo sich die Daten befinden.</block>
  <block id="9efd709ebdaac869f02b49e17fe9e92b" category="list-text">*Verbesserte Skalierbarkeit.*  Skalieren Sie Speicherressourcen unabhängig von Rechenressourcen, um den sich entwickelnden Bedürfnissen und Anforderungen in Ihrer Splunk-Umgebung gerecht zu werden und so für verbesserte Gesamtbetriebskosten zu sorgen.</block>
  <block id="52fb1ca9da3811c1cb86cd4347f98a64" category="list-text">*Kapazität.*  Bewältigen Sie schnell wachsende Volumina bei der Splunk-Bereitstellung mit StorageGRID , indem Sie einen einzelnen Namespace auf über 560 PB skalieren.</block>
  <block id="ff501c8a6a8c7b1ee7a3c656b6f4055a" category="list-text">*Datenverfügbarkeit.*  Optimieren Sie Datenverfügbarkeit, Leistung, geografische Verteilung, Aufbewahrung, Schutz und Speicherkosten mit metadatengesteuerten Richtlinien, die sich dynamisch an die Entwicklung des Geschäftswerts Ihrer Daten anpassen können.</block>
  <block id="bf1b0e32d877d343f0b3bc9ba43cb688" category="inline-link">Richtlinien von Splunk</block>
  <block id="3c5d06925a5d5bceedd74c82d3d38c04" category="paragraph">Steigern Sie die Leistung mit dem SmartStore-Cache, einer Komponente des Indexers, die die Übertragung von Bucket-Kopien zwischen lokalem (Hot) und Remote-Speicher (Warm) übernimmt.  Die Splunk-Dimensionierung für diese Lösung basiert auf der<block ref="d615ab802f29a9ee4a18e420480d049f" category="inline-link-rx"></block> .  Die Lösung ermöglicht das Hinzufügen von Rechen-, Hot-Storage- oder S3-Ressourcen, um die wachsende Nachfrage hinsichtlich der Anzahl der Benutzer oder der Aufnahmerate bei Bereitstellungen an einem oder mehreren Standorten zu erfüllen.</block>
  <block id="39e4c49e9af8047395aa4031e5c5f3a9" category="summary">Auf dieser Seite werden die Komponenten beschrieben, die zur Vervollständigung dieser Lösung verwendet werden, darunter NetApp StorageGRID, Splunk Enterprise und Splunk SmartStore.</block>
  <block id="c0c4b60d27032c028c91440e9d3be949" category="doc">Lösungsübersicht</block>
  <block id="5ab9d0d9b506bd4b5bf294baccd4ef0a" category="paragraph">NetApp StorageGRID ist eine leistungsstarke und kostengünstige Objektspeicherplattform.  Es bietet intelligentes, richtliniengesteuertes globales Datenmanagement mithilfe einer verteilten, knotenbasierten Grid-Architektur.  Es vereinfacht die Verwaltung von Petabytes unstrukturierter Daten und Milliarden von Objekten durch seinen allgegenwärtigen globalen Objekt-Namespace in Kombination mit ausgefeilten Datenverwaltungsfunktionen.  Der Objektzugriff mit einem einzigen Aufruf erstreckt sich über mehrere Standorte und vereinfacht Hochverfügbarkeitsarchitekturen, während gleichzeitig ein kontinuierlicher Objektzugriff unabhängig von Standort- oder Infrastrukturausfällen gewährleistet wird.</block>
  <block id="d67c579ad5ceca0ec4f8fe6a86f203cf" category="paragraph">Durch Multitenancy können mehrere Cloud- und Unternehmensanwendungen für unstrukturierte Daten sicher innerhalb desselben Grids verwaltet werden, wodurch sich der ROI und die Anwendungsfälle für StorageGRID erhöhen.  Mithilfe von metadatengesteuerten Objektlebenszyklusrichtlinien können mehrere Service-Level erstellt werden, wodurch Haltbarkeit, Schutz, Leistung und Lokalität über mehrere geografische Regionen hinweg optimiert werden.  Benutzer können Richtlinien anpassen und die Datenlandschaft unterbrechungsfrei neu ausrichten, wenn sich ihre Anforderungen ändern.</block>
  <block id="0d2b0fb2b312d872db772396e149b541" category="paragraph">SmartStore nutzt StorageGRID als Remote-Speicherebene und ermöglicht Kunden die Bereitstellung mehrerer geografisch verteilter Sites für robuste Verfügbarkeit und Haltbarkeit, dargestellt als einzelner Objekt-Namespace.  Dadurch kann Splunk SmartStore die hohe Leistung und die hohe Kapazität von StorageGRID nutzen und die Möglichkeit nutzen, mithilfe einer einzigen URL auf Hunderte von Knoten an mehreren physischen Standorten zu skalieren, um mit den Objekten zu interagieren.  Diese einzelne URL ermöglicht außerdem unterbrechungsfreie Speichererweiterungen, Upgrades und Reparaturen, auch über einen einzelnen Standort hinaus.  Die einzigartige Datenverwaltungsrichtlinien-Engine von StorageGRID bietet optimierte Leistungs- und Haltbarkeitsniveaus sowie die Einhaltung der Anforderungen an die Datenlokalität.</block>
  <block id="f9ed96cf2d028d3cfa9c658c6ec5ae72" category="paragraph">Splunk, ein führendes Unternehmen im Bereich der Erfassung und Analyse maschinengenerierter Daten, trägt durch seine operativen Analysefunktionen zur Vereinfachung und Modernisierung der IT bei.  Darüber hinaus wird es auf Anwendungsfälle in den Bereichen Geschäftsanalyse, Sicherheit und IoT ausgeweitet.  Speicher ist ein entscheidender Faktor für die erfolgreiche Bereitstellung der Splunk-Software.</block>
  <block id="1812fb837f2c63812e909b4457b0fa17" category="paragraph">Maschinengenerierte Daten sind die am schnellsten wachsende Art von Big Data.  Das Format ist unvorhersehbar und stammt aus vielen verschiedenen Quellen, oft mit hoher Geschwindigkeit und in großen Mengen.  Diese Arbeitslastmerkmale werden oft als digitale Abgase bezeichnet.  Splunk SmartStore hilft dabei, diese Daten zu verstehen und bietet intelligentes Daten-Tiering für die optimierte Platzierung heißer und warmer Daten auf der kostengünstigsten Speicherebene.</block>
  <block id="bd069a1be23f237559be08ae79727806" category="paragraph">Splunk SmartStore ist eine Indexerfunktion, die Objektspeicher (auch als Remote-Speicher oder Remote-Speicherebenen bezeichnet) wie StorageGRID verwendet, um warme Daten mithilfe des S3-Protokolls zu speichern.</block>
  <block id="9e5e9e455aa469c6579c4cde82cf69fc" category="paragraph">Wenn das Datenvolumen einer Bereitstellung zunimmt, übersteigt der Bedarf an Speicher in der Regel den Bedarf an Computerressourcen.  Mit SmartStore können Sie Ihren Indexerspeicher und Ihre Rechenressourcen kostengünstig verwalten, indem Sie Rechenleistung und Speicher separat skalieren.</block>
  <block id="1ab3873a2fa155a27933ac3e2b4ae709" category="paragraph">SmartStore führt eine Remote-Speicherebene unter Verwendung des S3-Protokolls und eines Cache-Managers ein.  Diese Funktionen ermöglichen die Speicherung von Daten entweder lokal auf Indexern oder im Remote-Speicher.  Der Cache-Manager, der sich auf dem Indexer befindet, verwaltet die Datenbewegung zwischen dem Indexer und der Remote-Speicherebene.  Daten werden zusammen mit Bucket-Metadaten in Buckets (Hot und Warm) gespeichert.</block>
  <block id="85a6e51e1b2fd3e4be531f269e108f39" category="paragraph">Mit SmartStore können Sie den Speicherbedarf des Indexers auf ein Minimum reduzieren und E/A-optimierte Rechenressourcen auswählen, da sich die meisten Daten auf der Remote-Speicherebene befinden.  Der Indexer verwaltet einen lokalen Cache, der die minimale Datenmenge darstellt, die zum Zurückgeben der angeforderten und vorhergesagten Ergebnisse erforderlich ist.  Der lokale Cache enthält Hot Buckets, Kopien von Warm Buckets, die an aktiven oder kürzlich durchgeführten Suchvorgängen beteiligt sind, und Bucket-Metadaten.</block>
  <block id="8cc78103debf2dcfe53620b96565dad4" category="paragraph">Splunk SmartStore mit StorageGRID ermöglicht es Kunden, die Umgebung mit leistungsstarkem und kostengünstigem Remote-Speicher schrittweise zu skalieren und gleichzeitig der Gesamtlösung ein hohes Maß an Elastizität zu verleihen.  Auf diese Weise können Kunden jederzeit beliebige Komponenten (Hot Storage und/oder Warm S3 Storage) in beliebiger Menge hinzufügen, unabhängig davon, ob sie mehr Indexer benötigen, die Datenaufbewahrung ändern oder die Aufnahmerate ohne Unterbrechung erhöhen möchten.</block>
  <block id="d919f51e7020fabd237372f4c163a60e" category="summary">StorageGRID verfügt über eine Vielzahl von Funktionen, die Benutzer nutzen und an ihre sich ständig ändernde Umgebung anpassen können.</block>
  <block id="0fc3cf31004e01f169ca3af4ef687576" category="doc">Flexible StorageGRID -Funktionen für Splunk SmartStore</block>
  <block id="d7ec4db6b0e9313773163a8a2404946e" category="paragraph">StorageGRID verfügt über eine Vielzahl von Funktionen, die Benutzer nutzen und an ihre sich ständig ändernde Umgebung anpassen können.  Von der Bereitstellung bis zur Skalierung Ihres Splunk SmartStore erfordert Ihre Umgebung eine schnelle Anpassung an Änderungen und sollte Splunk nicht stören.  Mit den flexiblen Datenverwaltungsrichtlinien (ILM) und Verkehrsklassifizierern (QoS) von StorageGRID können Sie Ihre Umgebung planen und anpassen.</block>
  <block id="5b552d68210e15d5ed4e4d186264b453" category="paragraph">Grid Manager ist die browserbasierte grafische Benutzeroberfläche, mit der Sie Ihr StorageGRID -System an weltweit verteilten Standorten in einer einzigen Fensteransicht konfigurieren, verwalten und überwachen können, wie in der folgenden Abbildung dargestellt.</block>
  <block id="b426e35a4f24b1452cf4688598a7429c" category="paragraph"><block ref="b426e35a4f24b1452cf4688598a7429c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52d198c85ec187eb3bbff17442a01baa" category="paragraph">Führen Sie die folgenden Aufgaben mit der Grid Manager-Schnittstelle aus:</block>
  <block id="356e4420bfe7b6226984261d66ec9e0b" category="section-title">NetApp StorageGRID App für Splunk</block>
  <block id="d4503ceebebf47c506c3003f760662a2" category="paragraph">Die NetApp StorageGRID App für Splunk ist eine spezielle Anwendung für Splunk Enterprise.  Diese App funktioniert in Verbindung mit dem NetApp StorageGRID Add-on für Splunk.  Es bietet Einblick in den StorageGRID -Zustand, Informationen zur Kontonutzung, Details zur Sicherheitsüberprüfung, Ressourcennutzung und -überwachung usw.</block>
  <block id="c7b8ad57a7270e26eba0ed9da1fa0b6c" category="paragraph">Das folgende Bild zeigt die StorageGRID -App für Splunk.</block>
  <block id="33e8e06b4bbde24cf3f439a1bd66cf19" category="paragraph"><block ref="33e8e06b4bbde24cf3f439a1bd66cf19" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a7e07b036910adce42ba90efc47f818e" category="section-title">ILM-Richtlinien</block>
  <block id="2121ccc9450b2df939a6752c3559486a" category="paragraph">StorageGRID verfügt über flexible Datenverwaltungsrichtlinien, die das Aufbewahren mehrerer Kopien Ihrer Objekte und die Verwendung von EC-Schemata (Erasure Coding) wie 2+1 und 4+2 (und vielen anderen) zum Speichern Ihrer Objekte je nach spezifischen Leistungs- und Datenschutzanforderungen umfassen.  Da sich Arbeitslasten und Anforderungen im Laufe der Zeit ändern, ist es üblich, dass sich auch die ILM-Richtlinien im Laufe der Zeit ändern müssen.  Das Ändern von ILM-Richtlinien ist eine Kernfunktion, die es StorageGRID Kunden ermöglicht, sich schnell und einfach an ihre sich ständig ändernde Umgebung anzupassen.</block>
  <block id="3f7d13681fac5c1ca00c53ae2a27efaa" category="paragraph">StorageGRID skaliert die Leistung durch Hinzufügen weiterer Knoten, bei denen es sich um VMs, Bare Metal oder speziell entwickelte Geräte wie SG5712, SG5760, SG6060 oder SGF6024 handeln kann.  In unseren Tests haben wir die wichtigsten Leistungsanforderungen von SmartStore mit einem Drei-Knoten-Raster der Mindestgröße unter Verwendung des SG6060-Geräts übertroffen.  Wenn Kunden ihre Splunk-Infrastruktur mit zusätzlichen Indexern skalieren, können sie weitere Speicherknoten hinzufügen, um Leistung und Kapazität zu erhöhen.</block>
  <block id="8a0453356d4720c8c5a67e5e2a16b419" category="section-title">Load Balancer und Endpunktkonfiguration</block>
  <block id="08de46c3a8d44cfa799d969abfa407eb" category="paragraph">Admin-Knoten in StorageGRID bieten die Grid Manager-Benutzeroberfläche (Benutzeroberfläche) und den REST-API-Endpunkt zum Anzeigen, Konfigurieren und Verwalten Ihres StorageGRID -Systems sowie Prüfprotokolle zum Verfolgen der Systemaktivität.  Um einen hochverfügbaren S3-Endpunkt für den Remote-Speicher von Splunk SmartStore bereitzustellen, haben wir den StorageGRID Load Balancer implementiert, der als Dienst auf Admin-Knoten und Gateway-Knoten ausgeführt wird.  Darüber hinaus verwaltet der Load Balancer auch den lokalen Datenverkehr und kommuniziert mit dem GSLB (Global Server Load Balancing), um bei der Notfallwiederherstellung zu helfen.</block>
  <block id="d2134190f6b031237d4b1523c86c29a2" category="paragraph">Um die Endpunktkonfiguration weiter zu verbessern, bietet StorageGRID im Admin-Knoten integrierte Richtlinien zur Verkehrsklassifizierung, ermöglicht Ihnen die Überwachung Ihres Workload-Verkehrs und die Anwendung verschiedener Quality-of-Service-Grenzwerte (QoS) auf Ihre Workloads.  Richtlinien zur Verkehrsklassifizierung werden auf Endpunkte des StorageGRID Load Balancer-Dienstes für Gateway-Knoten und Admin-Knoten angewendet.  Diese Richtlinien können bei der Begrenzung und Überwachung des Datenverkehrs helfen.</block>
  <block id="9fa345c6a2f967ec80e8b940a9d2a1c3" category="summary">Da die Kunden die Leistungsfähigkeit und Benutzerfreundlichkeit der Splunk-Datenanalyse erkennen, möchten sie natürlich eine immer größer werdende Datenmenge indizieren.  Mit der wachsenden Datenmenge wächst auch die Rechen- und Speicherinfrastruktur, die zu ihrer Verarbeitung erforderlich ist.</block>
  <block id="f9a3e09b74e61e83c0352f2953dcdc87" category="doc">Intelligentes Tiering und Kosteneinsparungen</block>
  <block id="e09913e41f1a0082ec190482abfeff57" category="paragraph">Da die Kunden die Leistungsfähigkeit und Benutzerfreundlichkeit der Splunk-Datenanalyse erkennen, möchten sie natürlich eine immer größer werdende Datenmenge indizieren.  Mit der wachsenden Datenmenge wächst auch die Rechen- und Speicherinfrastruktur, die zu ihrer Verarbeitung erforderlich ist.  Da auf ältere Daten weniger häufig verwiesen wird, wird es zunehmend ineffizient, die gleiche Menge an Rechenressourcen bereitzustellen und teuren Primärspeicher zu verbrauchen.  Um im großen Maßstab arbeiten zu können, profitieren Kunden von der Verschiebung warmer Daten auf eine kostengünstigere Ebene, wodurch Rechenleistung und Primärspeicher für heiße Daten frei werden.</block>
  <block id="f7300ec91634b8cd535c45fd11ee503f" category="paragraph">Splunk SmartStore mit StorageGRID bietet Unternehmen eine skalierbare, leistungsstarke und kostengünstige Lösung.  Da SmartStore datenbewusst ist, wertet es automatisch Datenzugriffsmuster aus, um zu bestimmen, welche Daten für Echtzeitanalysen zugänglich sein müssen (Hot Data) und welche Daten in einem kostengünstigeren Langzeitspeicher verbleiben sollten (Warm Data).  SmartStore verwendet die branchenübliche AWS S3-API dynamisch und intelligent und platziert Daten im von StorageGRID bereitgestellten S3-Speicher.  Die flexible Scale-Out-Architektur von StorageGRID ermöglicht ein kostengünstiges Wachstum der Warm Data-Ebene nach Bedarf.  Die knotenbasierte Architektur von StorageGRID stellt sicher, dass Leistungs- und Kostenanforderungen optimal erfüllt werden.</block>
  <block id="d75fb5ef86bb0625c22c38dd2229c627" category="paragraph">Das folgende Bild veranschaulicht die Splunk- und StorageGRID -Tiering.</block>
  <block id="f710071dfe9306034297e2bbb442d8bc" category="paragraph"><block ref="f710071dfe9306034297e2bbb442d8bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6821c40fa59a17fa0f78dbb9e556be5" category="paragraph">Die branchenführende Kombination von Splunk SmartStore mit NetApp StorageGRID bietet die Vorteile einer entkoppelten Architektur durch eine Full-Stack-Lösung.</block>
  <block id="404af9ebdf8554a92ea8d3dde06945b4" category="doc">TR-4623: NetApp E-Series E5700 und Splunk Enterprise</block>
  <block id="1dcb8fb2d6ad519f4a7ecd244f9c7c76" category="paragraph">Mitch Blackburn, NetApp</block>
  <block id="8c121c8c1e758ef244a52184e2d48c66" category="paragraph">TR-4623 beschreibt die integrierte Architektur des NetApp E-Series- und Splunk-Designs.  Dieses Design ist für Knotenspeicherbalance, Zuverlässigkeit, Leistung, Speicherkapazität und Dichte optimiert und verwendet das Clustered-Index-Knotenmodell von Splunk mit höherer Skalierbarkeit und niedrigeren Gesamtbetriebskosten.  Durch die Entkopplung von Speicher und Rechenleistung können beide separat skaliert werden, wodurch die Kosten für eine Überbereitstellung des einen oder anderen Elements gespart werden.  Darüber hinaus fasst dieses Dokument die Ergebnisse der Leistungstests zusammen, die mit einem Splunk-Tool zur Simulation von Maschinenprotokollereignissen erzielt wurden.</block>
  <block id="29f20bee1f160a8e20c6ef9d7ce1bfe2" category="paragraph"><block ref="29f20bee1f160a8e20c6ef9d7ce1bfe2" category="inline-link-macro-rx"></block></block>
  <block id="f1739b1d5d1c44e562a8500d3b80579f" category="summary">NetApp KI-Funktionen, die eine nahtlose Datenverwaltung und Datenbewegung über die KI-Pipeline hinweg ermöglichen, um generative KI-Modelle zu trainieren, neu zu trainieren, zu optimieren, zu schlussfolgern und zu überwachen.</block>
  <block id="36cc0281ec7abcd20091f5d39b995cc4" category="doc">Generative KI und NetApp -Wert</block>
  <block id="6dbc3469d4924aa631238769172515d8" category="paragraph">Die Nachfrage nach generativer künstlicher Intelligenz (KI) führt zu Umbrüchen in allen Branchen und steigert die Kreativität der Unternehmen sowie die Produktinnovation.</block>
  <block id="40ed4c797a14998a489b495cd8c9a5e0" category="paragraph">Viele Organisationen nutzen generative KI, um neue Produktfunktionen zu entwickeln, die Produktivität der Ingenieure zu steigern und Prototypen KI-gestützter Anwendungen zu erstellen, die bessere Ergebnisse und ein besseres Kundenerlebnis bieten.  Generative KI wie Generative Pre-trained Transformers (GPT) verwenden neuronale Netzwerke, um neue Inhalte zu erstellen, die so unterschiedlich sind wie Text, Audio und Video.  Angesichts des extremen Umfangs und der enormen Datensätze, die mit großen Sprachmodellen (LLMs) verbunden sind, ist es von entscheidender Bedeutung, eine robuste KI-Infrastruktur zu entwickeln, die die überzeugenden Datenspeicherfunktionen von On-Premises-, Hybrid- und Multi-Cloud-Bereitstellungsoptionen nutzt und die mit Datenmobilität, Datenschutz und Governance verbundenen Risiken reduziert, bevor Unternehmen KI-Lösungen entwickeln können.  In diesem Dokument werden diese Überlegungen und die entsprechenden NetApp KI-Funktionen beschrieben, die eine nahtlose Datenverwaltung und Datenbewegung über die KI-Datenpipeline zum Trainieren, Umtrainieren, Feinabstimmen und Inferenzieren generativer KI-Modelle ermöglichen.</block>
  <block id="a573d92b77d430af7e424879baf78e94" category="section-title">Zusammenfassung</block>
  <block id="3fed37bedb6b36d52c0c5b3aa0089bfe" category="paragraph">Zuletzt haben nach der Einführung von ChatGPT, einem Spin-off von GPT-3 im November 2022, neue KI-Tools, die zur Generierung von Text, Code, Bildern oder sogar therapeutischen Proteinen als Reaktion auf Benutzeraufforderungen verwendet werden, erhebliche Bekanntheit erlangt.  Dies bedeutet, dass Benutzer eine Anfrage in natürlicher Sprache stellen können und die KI Text interpretiert und generiert, beispielsweise Nachrichtenartikel oder Produktbeschreibungen, die die Benutzeranfrage widerspiegeln, oder Code, Musik, Sprache, visuelle Effekte und 3D-Assets mithilfe von Algorithmen erstellt, die auf bereits vorhandenen Daten trainiert wurden.  Infolgedessen tauchen bei der Entwicklung von KI-Systemen immer häufiger Begriffe wie „Stabile Diffusion“, „Halluzinationen“, „Prompt Engineering“ und „Wertausrichtung“ auf.  Diese selbstüberwachten oder halbüberwachten Modelle des maschinellen Lernens (ML) werden als vortrainierte Basismodelle (FM) über Cloud-Service-Provider und andere Anbieter von KI-Unternehmen immer häufiger verfügbar und von verschiedenen Unternehmen branchenübergreifend für eine breite Palette nachgelagerter NLP-Aufgaben (Natural Language Processing) übernommen.  Wie Marktforschungsunternehmen wie McKinsey behaupten: „Die Auswirkungen der generativen KI auf die Produktivität könnten der Weltwirtschaft einen Mehrwert von Billionen Dollar verleihen.“  Während Unternehmen KI als Denkpartner des Menschen neu konzipieren und FMs gleichzeitig ihre Möglichkeiten für Unternehmen und Institutionen mit generativer KI erweitern, werden die Möglichkeiten zur Verwaltung riesiger Datenmengen weiter zunehmen.  Dieses Dokument enthält einführende Informationen zur generativen KI und den Designkonzepten in Bezug auf NetApp -Funktionen, die NetApp Kunden sowohl vor Ort als auch in Hybrid- oder Multicloud-Umgebungen einen Mehrwert bieten.</block>
  <block id="8bcfe22a3d7c5edf904444893704a8de" category="paragraph">*Welchen Vorteil bietet es den Kunden, NetApp in ihren KI-Umgebungen einzusetzen?*  NetApp unterstützt Unternehmen dabei, die Komplexität zu bewältigen, die durch schnelles Daten- und Cloud-Wachstum, Multi-Cloud-Management und die Einführung von Technologien der nächsten Generation wie KI entsteht.  NetApp hat verschiedene Funktionen in intelligenter Datenverwaltungssoftware und Speicherinfrastruktur kombiniert, die gut ausbalanciert und mit hoher Leistung für KI-Workloads optimiert sind.  Generative KI-Lösungen wie LLMs müssen ihre Quelldatensätze mehrmals aus dem Speicher in den Arbeitsspeicher lesen und verarbeiten, um die Intelligenz zu fördern.  NetApp ist ein führender Anbieter von Technologien für Datenmobilität, Datenverwaltung und Datensicherheit im gesamten Edge-to-Core-to-Cloud-Ökosystem und unterstützt Unternehmenskunden beim Aufbau maßstabsgetreuer KI-Lösungen.  NetApp unterstützt mit einem starken Partnernetzwerk Chief Data Officers, KI-Ingenieure, Unternehmensarchitekten und Datenwissenschaftler bei der Entwicklung einer frei fließenden Datenpipeline für die Datenaufbereitung, den Datenschutz und die strategischen Datenverwaltungsaufgaben beim Training und der Inferenz von KI-Modellen und optimiert so die Leistung und Skalierbarkeit des KI/ML-Lebenszyklus.  NetApp Datentechnologien und -Funktionen wie NetApp ONTAP AI für Deep-Learning-Datenpipelines, NetApp SnapMirror für den nahtlosen und effizienten Datentransport zwischen Speicherendpunkten und NetApp FlexCache für Echtzeit-Rendering, wenn der Datenfluss von Batch auf Echtzeit umgestellt wird und die Datenentwicklung zeitnah erfolgt, sind für die Bereitstellung von Echtzeit-Modellen der generativen KI von Nutzen.  Da Unternehmen aller Art neue KI-Tools einsetzen, stehen sie vor Datenherausforderungen vom Rand über das Rechenzentrum bis hin zur Cloud, die skalierbare, verantwortungsvolle und erklärbare KI-Lösungen erfordern.  Als Datenexperte für Hybrid- und Multi-Cloud engagiert sich NetApp für den Aufbau eines Netzwerks aus Partnern und gemeinsamen Lösungen, die bei allen Aspekten der Erstellung einer Datenpipeline und von Datenseen für das Training (Vortraining) generativer KI-Modelle, die Feinabstimmung, kontextbasierte Inferenz und die Überwachung des Modellverfalls von LLMs helfen können.</block>
  <block id="ba4c46fa4f06702b4667d0b3a6b2bdfe" category="section-title">Was ist generative KI?</block>
  <block id="11703c9edbc2bf714a8c4be38891fc77" category="paragraph">Generative KI verändert die Art und Weise, wie wir Inhalte erstellen, neue Designkonzepte entwickeln und neuartige Kompositionen erkunden.  Es veranschaulicht neuronale Netzwerk-Frameworks wie Generative Adversarial Network (GAN), Variational Autoencoders (VAE) und Generative Pre-Trained Transformers (GPT), die neue Inhalte wie Text, Code, Bilder, Audio, Video und synthetische Daten generieren können.  Transformer-basierte Modelle wie Chat-GPT von OpenAI, Bard von Google, BLOOM von Hugging Face und LLaMA von Meta haben sich als grundlegende Technologie herausgestellt, die vielen Fortschritten bei großen Sprachmodellen zugrunde liegt.  Ebenso sind Dall-E von OpenAI, CM3leon von Meta und Imagen von Google Beispiele für Text-zu-Bild-Diffusionsmodelle, die den Kunden einen beispiellosen Grad an Fotorealismus bieten, um neue, komplexe Bilder von Grund auf neu zu erstellen oder vorhandene Bilder zu bearbeiten, um mithilfe von Datensatzerweiterung und Text-zu-Bild-Synthese, die textuelle und visuelle Semantik verknüpft, qualitativ hochwertige kontextsensitive Bilder zu erzeugen.  Digitale Künstler beginnen, eine Kombination aus Rendering-Technologien wie NeRF (Neural Radiance Field) mit generativer KI anzuwenden, um statische 2D-Bilder in immersive 3D-Szenen umzuwandeln.  Im Allgemeinen werden LLMs grob durch vier Parameter charakterisiert: (1) Größe des Modells (normalerweise in Milliarden von Parametern); (2) Größe des Trainingsdatensatzes; (3) Trainingskosten und (4) Modellleistung nach dem Training.  LLMs lassen sich auch hauptsächlich in drei Transformatorarchitekturen unterteilen.  (i) Nur-Encoder-Modelle.  Z. B. BERT (Google, 2018); (ii) Encoder-Decoder, z. B. BART (Meta, 2020) und (iii) Nur-Decoder-Modelle.  Z. B. LLaMA (Meta, 2023), PaLM-E (Google, 2023).  Abhängig von den Geschäftsanforderungen und unabhängig davon, welche Architektur ein Unternehmen wählt, bestimmen im Allgemeinen die Anzahl der Modellparameter (N) und die Anzahl der Token (D) im Trainingsdatensatz die Grundkosten für das Training (Vortraining) oder die Feinabstimmung eines LLM.</block>
  <block id="d1ddcb04dcb447b3f05fa54e9ab492d0" category="section-title">Unternehmensanwendungsfälle und nachgelagerte NLP-Aufgaben</block>
  <block id="a4a7c510156562fb9841dd055348b753" category="paragraph">Unternehmen aller Branchen entdecken immer mehr Potenzial für KI, um aus vorhandenen Daten neue Wertschöpfungsformen für Geschäftsabläufe, Vertrieb, Marketing und Rechtsdienstleistungen zu extrahieren und zu produzieren.  Laut Marktinformationen von IDC (International Data Corporation) zu globalen Anwendungsfällen und Investitionen in generative KI wird das Wissensmanagement in der Softwareentwicklung und im Produktdesign am stärksten betroffen sein, gefolgt von der Storyline-Erstellung für das Marketing und der Codegenerierung für Entwickler.  Im Gesundheitswesen betreten klinische Forschungsorganisationen Neuland in der Medizin.  Vortrainierte Modelle wie ProteinBERT enthalten Gene Ontology (GO)-Anmerkungen, um schnell Proteinstrukturen für Medikamente zu entwerfen, was einen bedeutenden Meilenstein in der Arzneimittelforschung, Bioinformatik und Molekularbiologie darstellt.  Biotech-Unternehmen haben Versuche am Menschen mit einem mithilfe generativer KI entdeckten Medikament eingeleitet, das auf die Behandlung von Krankheiten wie der Lungenfibrose (IPF) abzielt, einer Lungenerkrankung, die zu einer irreversiblen Vernarbung des Lungengewebes führt.</block>
  <block id="8e5aaca094938e3b1a2e08f48f3db558" category="paragraph">Abbildung 1: Anwendungsfälle für generative KI</block>
  <block id="8d04a6a1813e89b5849d40e5113b0902" category="paragraph"><block ref="8d04a6a1813e89b5849d40e5113b0902" category="inline-image-macro-rx" type="image"></block></block>
  <block id="605e4f6997ac64a7de35f4e8a02721e9" category="paragraph">Die zunehmende Automatisierung durch generative KI verändert auch Angebot und Nachfrage bei Arbeitstätigkeiten in vielen Berufen.  Laut McKinsey hat der US-Arbeitsmarkt (Diagramm unten) einen rasanten Wandel durchlaufen, der sich nur fortsetzen könnte, wenn man die Auswirkungen der KI berücksichtigt.</block>
  <block id="844d4a4d01e4441540857f7a302f6239" category="paragraph">Quelle: McKinsey &amp; Company</block>
  <block id="14509aeb117a81412dfa4dc27107f735" category="inline-image-macro">Abbildung 2: Quelle: McKinsey &amp; Company</block>
  <block id="f86a1cf79787f9ca7a0bc2698a14baa8" category="paragraph"><block ref="1cdd0679074896d7373f66c66dc8dda4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="072f966c176c14e4a8ac1b32dff891bc" category="section-title">Rolle des Speichers in der generativen KI</block>
  <block id="6a352eac97ff84fb6680bea0e3f1582b" category="inline-link-macro">512 MB</block>
  <block id="23f951a15f217f2ce467c5d52e3a74a2" category="paragraph">LLMs basieren weitgehend auf Deep Learning, GPUs und Computern.  Wenn der GPU-Puffer jedoch voll ist, müssen die Daten schnell in den Speicher geschrieben werden.  Während einige KI-Modelle klein genug sind, um im Speicher ausgeführt zu werden, erfordern LLMs hohe IOPS und einen Speicher mit hohem Durchsatz, um einen schnellen Zugriff auf große Datensätze zu ermöglichen, insbesondere wenn es sich um Milliarden von Token oder Millionen von Bildern handelt.  Bei einem typischen GPU-Speicherbedarf eines LLM könnte der zum Trainieren eines Modells mit 1 Milliarde Parametern benötigte Speicher bis zu 80 GB bei voller 32-Bit-Präzision betragen.  In diesem Fall benötigt Metas LLaMA 2, eine Familie von LLMs mit einer Größenordnung von 7 bis 70 Milliarden Parametern, möglicherweise 70 x 80, also ca. 5600 GB oder 5,6 TB GPU-RAM.  Darüber hinaus ist die benötigte Speichermenge direkt proportional zur maximalen Anzahl der Token, die Sie generieren möchten.  Wenn Sie beispielsweise Ausgaben von bis zu 512 Token (ca. 380 Wörter) generieren möchten, benötigen Sie<block ref="8b6a924b2b2c8b02d5e56762d0384bc1" category="inline-link-macro-rx"></block> .  Dies mag unbedeutend erscheinen, aber wenn Sie größere Chargen verarbeiten möchten, summiert es sich.  Daher ist es für Unternehmen sehr kostspielig, LLMs im Speicher zu trainieren oder zu optimieren, sodass die Speicherung zu einem Eckpfeiler der generativen KI wird.</block>
  <block id="b0b4b15d26d559735ca79c547ebcf9b6" category="section-title">Drei Hauptansätze für LLMs</block>
  <block id="29ff458fbe275b29aaf5e7dbd636eed4" category="inline-link-macro">Harvard Business Review</block>
  <block id="b026e17fa592b49ccc86f0f9b718b03b" category="paragraph">Basierend auf den aktuellen Trends lässt sich der Ansatz zur Bereitstellung von LLMs für die meisten Unternehmen auf drei grundlegende Szenarien reduzieren.  Wie in einer kürzlich erschienenen<block ref="9b642d86ef84545807d431905b86239d" category="inline-link-macro-rx"></block> Artikel: (1) Training (Vortraining) eines LLM von Grund auf – kostspielig und erfordert Expertenkenntnisse im Bereich KI/ML; (2) Feinabstimmung eines Basismodells mit Unternehmensdaten – komplex, aber machbar; (3) Verwendung von Retrieval-Augmented Generation (RAG) zum Abfragen von Dokument-Repositories, APIs und Vektordatenbanken, die Unternehmensdaten enthalten.  Bei jeder dieser Methoden gibt es Kompromisse zwischen Aufwand, Iterationsgeschwindigkeit, Kosteneffizienz und Modellgenauigkeit in ihren Implementierungen, die zur Lösung unterschiedlicher Arten von Problemen verwendet werden (Diagramm unten).</block>
  <block id="c35884049dd0467b68f884a60d4920ea" category="paragraph">Abbildung 3: Problemtypen</block>
  <block id="2ee3234ece3d669efe95dc1a84c67a06" category="paragraph"><block ref="2ee3234ece3d669efe95dc1a84c67a06" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ff76a02d3da4ad3236fe1704ce7b2a4c" category="section-title">Stiftungsmodelle</block>
  <block id="212ec66e09b7b19d2e397c5c04e8543d" category="paragraph">Ein Foundation-Modell (FM), auch Basismodell genannt, ist ein großes KI-Modell (LLM), das anhand großer Mengen nicht gekennzeichneter Daten trainiert wird, Selbstüberwachung im großen Maßstab nutzt und im Allgemeinen für eine breite Palette nachgelagerter NLP-Aufgaben angepasst ist.  Da die Trainingsdaten nicht von Menschen beschriftet werden, entsteht das Modell, anstatt explizit kodiert zu werden.  Dies bedeutet, dass das Modell eigene Geschichten oder Erzählungen generieren kann, ohne explizit dazu programmiert zu sein.  Daher ist die Homogenisierung ein wichtiges Merkmal von FM, was bedeutet, dass in vielen Bereichen dieselbe Methode verwendet wird.  Dank Personalisierungs- und Feinabstimmungstechniken eignen sich FMs, die heutzutage in neue Produkte integriert werden, jedoch nicht nur gut zum Generieren von Text, zur Umwandlung von Text in Bilder und von Text in Code, sondern auch zum Erklären domänenspezifischer Aufgaben oder zum Debuggen von Code.  Beispielsweise können FMs wie Codex von OpenAI oder Code Llama von Meta Code in mehreren Programmiersprachen basierend auf natürlichsprachlichen Beschreibungen einer Programmieraufgabe generieren.  Diese Modelle beherrschen über ein Dutzend Programmiersprachen, darunter Python, C#, JavaScript, Perl, Ruby und SQL.  Sie verstehen die Absicht des Benutzers und generieren spezifischen Code, der die gewünschte Aufgabe erfüllt und für die Softwareentwicklung, Codeoptimierung und Automatisierung von Programmieraufgaben nützlich ist.</block>
  <block id="09505640cb74de4ed6c0043b4fd83b62" category="section-title">Feinabstimmung, Domänenspezifität und Umschulung</block>
  <block id="d70061bb0ac24d99b6a01f537dfc5836" category="inline-link-macro">Metas Lama 2</block>
  <block id="3983fea9bc2f220141201994aa6cf9de" category="paragraph">Eine der gängigen Vorgehensweisen bei der LLM-Bereitstellung nach der Datenvorbereitung und -vorverarbeitung besteht darin, ein vortrainiertes Modell auszuwählen, das anhand eines großen und vielfältigen Datensatzes trainiert wurde.  Im Rahmen der Feinabstimmung kann dies ein Open-Source-Modell für große Sprachen sein, wie beispielsweise<block ref="40c631914d673c775e5813606a4c652a" category="inline-link-macro-rx"></block> trainiert mit 70 Milliarden Parametern und 2 Billionen Token.  Sobald das vortrainierte Modell ausgewählt ist, besteht der nächste Schritt darin, es anhand der domänenspezifischen Daten zu optimieren.  Dabei werden die Parameter des Modells angepasst und es anhand der neuen Daten trainiert, um es an eine bestimmte Domäne und Aufgabe anzupassen.  Beispielsweise BloombergGPT, ein proprietärer LLM, der auf eine breite Palette von Finanzdaten für die Finanzbranche spezialisiert ist.  Domänenspezifische Modelle, die für eine bestimmte Aufgabe entwickelt und trainiert wurden, weisen in ihrem Anwendungsbereich im Allgemeinen eine höhere Genauigkeit und Leistung auf, sind jedoch nur schwer auf andere Aufgaben oder Domänen übertragbar.  Wenn sich das Geschäftsumfeld und die Daten über einen bestimmten Zeitraum ändern, kann die Vorhersagegenauigkeit des FM im Vergleich zur Leistung während des Tests nachlassen.  In diesem Fall ist eine erneute Schulung oder Feinabstimmung des Modells von entscheidender Bedeutung.  Unter Modellneutraining in herkömmlicher KI/ML versteht man die Aktualisierung eines bereitgestellten ML-Modells mit neuen Daten. Dies wird im Allgemeinen durchgeführt, um zwei Arten von auftretenden Abweichungen zu beseitigen.  (1) Konzeptdrift – wenn sich die Verbindung zwischen den Eingabevariablen und den Zielvariablen im Laufe der Zeit ändert, kann das Modell ungenaue Vorhersagen liefern, da sich die Beschreibung dessen ändert, was wir vorhersagen möchten.  (2) Datendrift – tritt auf, wenn sich die Eigenschaften der Eingabedaten ändern, beispielsweise Änderungen der Gewohnheiten oder des Verhaltens der Kunden im Laufe der Zeit, und das Modell daher nicht in der Lage ist, auf solche Änderungen zu reagieren.  In ähnlicher Weise gilt die Umschulung für FMs/LLMs, sie kann jedoch wesentlich teurer sein (in Millionenhöhe) und ist daher für die meisten Organisationen nichts, was sie in Betracht ziehen würden.  Es wird derzeit aktiv erforscht und befindet sich im Bereich LLMOps noch in der Entwicklung.  Wenn es bei fein abgestimmten FMs zu einem Modellverfall kommt, können sich Unternehmen statt für ein erneutes Training für eine erneute Feinabstimmung (die wesentlich günstiger ist) mit einem neueren Datensatz entscheiden.  Zur Kostenperspektive ist unten ein Beispiel einer Modellpreistabelle von Azure-OpenAI Services aufgeführt.  Für jede Aufgabenkategorie können Kunden Modelle anhand bestimmter Datensätze optimieren und auswerten.</block>
  <block id="95d06c21390dc25827c0fd489dc141e4" category="paragraph">Quelle: Microsoft Azure</block>
  <block id="56307bc010f6f11cf695a4f4a8868ec2" category="paragraph"><block ref="56307bc010f6f11cf695a4f4a8868ec2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="157d80dbb8ad88a26dfd59594b88e11c" category="section-title">Prompte Entwicklung und Inferencing</block>
  <block id="e48b39374db0f3e4c1479cb81f7ebd58" category="paragraph">Prompt Engineering bezieht sich auf die effektiven Methoden zur Kommunikation mit LLMs, um gewünschte Aufgaben auszuführen, ohne die Modellgewichte zu aktualisieren.  So wichtig das Training und die Feinabstimmung von KI-Modellen für NLP-Anwendungen ist, so wichtig ist auch das Inferenzieren, bei dem die trainierten Modelle auf Benutzereingaben reagieren.  Die Systemanforderungen für die Inferenz hängen im Allgemeinen viel stärker von der Leseleistung des KI-Speichersystems ab, das Daten von LLMs an die GPUs überträgt, da es in der Lage sein muss, Milliarden gespeicherter Modellparameter anzuwenden, um die beste Antwort zu erzielen.</block>
  <block id="71451daa1205b079e03924f700485fb7" category="section-title">LLMOps, Modellüberwachung und Vectorstores</block>
  <block id="37dc13dd8c23bd5e417bad0376cb8642" category="paragraph">Wie herkömmliche Machine Learning Ops (MLOps) erfordern auch Large Language Model Operations (LLMOps) die Zusammenarbeit von Datenwissenschaftlern und DevOps-Ingenieuren mit Tools und Best Practices für die Verwaltung von LLMs in Produktionsumgebungen.  Allerdings können der Arbeitsablauf und der Technologie-Stack für LLMs in gewisser Weise variieren.  Beispielsweise reihen LLM-Pipelines, die mit Frameworks wie LangChain erstellt wurden, mehrere LLM-API-Aufrufe an externe Einbettungsendpunkte wie Vektorspeicher oder Vektordatenbanken aneinander.  Die Verwendung eines Einbettungsendpunkts und eines Vektorspeichers für nachgelagerte Konnektoren (z. B. zu einer Vektordatenbank) stellt eine bedeutende Weiterentwicklung in der Art und Weise dar, wie Daten gespeichert und abgerufen werden.  Im Gegensatz zu herkömmlichen ML-Modellen, die von Grund auf neu entwickelt werden, basieren LLMs häufig auf Transferlernen, da diese Modelle mit FMs beginnen, die mit neuen Daten feinabgestimmt werden, um die Leistung in einem spezifischeren Bereich zu verbessern.  Daher ist es von entscheidender Bedeutung, dass LLMOps die Funktionen des Risikomanagements und der Überwachung des Modellverfalls bereitstellt.</block>
  <block id="e1e7449571fe3b65d3a1e689bc700cbc" category="section-title">Risiken und Ethik im Zeitalter der Generativen KI</block>
  <block id="c12a37efb07149af3ee94636c74b80c5" category="paragraph">„ChatGPT – Es ist schick, aber es verbreitet trotzdem Unsinn.“ – MIT Tech Review.  „Garbage in – Garbage out“ war schon immer eine Herausforderung bei der Datenverarbeitung.  Der einzige Unterschied bei generativer KI besteht darin, dass sie den Müll hervorragend glaubwürdig erscheinen lässt, was zu ungenauen Ergebnissen führt.  LLMs neigen dazu, Fakten zu erfinden, die zu der Erzählung passen, die sie aufbauen.  Daher müssen Unternehmen, die in generativer KI eine großartige Möglichkeit sehen, ihre Kosten mit KI-Äquivalenten zu senken, Deep Fakes effizient erkennen, Voreingenommenheit reduzieren und Risiken senken, um die Ehrlichkeit und Ethik der Systeme zu gewährleisten.  Eine frei fließende Datenpipeline mit einer robusten KI-Infrastruktur, die Datenmobilität, Datenqualität, Datenverwaltung und Datenschutz durch End-to-End-Verschlüsselung und KI-Leitplanken unterstützt, ist für die Entwicklung verantwortungsvoller und erklärbarer generativer KI-Modelle von entscheidender Bedeutung.</block>
  <block id="b1c01c916bfeda43bbe010599a3756ef" category="section-title">Kundenszenario und NetApp</block>
  <block id="d475afb6eaf5d8966136580d55f5a688" category="paragraph">Abbildung 3: Workflow für maschinelles Lernen/große Sprachmodelle</block>
  <block id="1d5b6314b7c490b3ba00c157c5d73c98" category="paragraph"><block ref="1d5b6314b7c490b3ba00c157c5d73c98" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9dd90f4ead88ee59ec52f11bac2d164b" category="paragraph">*Trainieren wir oder optimieren wir?*  Die Frage, ob (a) ein LLM-Modell von Grund auf trainiert, ein vortrainiertes FM optimiert oder RAG verwendet werden soll, um Daten aus Dokumentrepositorys außerhalb eines Basismodells abzurufen und Eingabeaufforderungen zu erweitern, und (b) ob Open-Source-LLMs (z. B. Llama 2) oder proprietäre FMs (z. B. ChatGPT, Bard, AWS Bedrock) genutzt werden sollen, ist eine strategische Entscheidung für Unternehmen.  Jeder Ansatz erfordert einen Kompromiss zwischen Kosteneffizienz, Datengravitation, Betrieb, Modellgenauigkeit und Verwaltung von LLMs.</block>
  <block id="8c8696e5c9dd013fefe41f5a257ecba6" category="paragraph">NetApp als Unternehmen integriert KI intern in seine Arbeitskultur und in seinen Ansatz für Produktdesign und Entwicklungsbemühungen.  Beispielsweise basiert der autonome Ransomware-Schutz von NetApp auf KI und maschinellem Lernen.  Es ermöglicht die frühzeitige Erkennung von Dateisystemanomalien und hilft so, Bedrohungen zu identifizieren, bevor sie den Betrieb beeinträchtigen.  Zweitens nutzt NetApp prädiktive KI für seine Geschäftsabläufe, beispielsweise für Verkaufs- und Bestandsprognosen, sowie Chatbots, um Kunden bei Produktsupportdiensten im Callcenter, technischen Daten, Garantien, Servicehandbüchern und vielem mehr zu unterstützen.  Drittens schafft NetApp Kundennutzen für die KI-Datenpipeline und den ML/LLM-Workflow durch Produkte und Lösungen, die Kunden beim Aufbau prädiktiver KI-Lösungen unterstützen, beispielsweise für Bedarfsprognosen, medizinische Bildgebung, Stimmungsanalysen und generative KI-Lösungen wie GANs zur Erkennung von Anomalien bei industriellen Bildern im Fertigungssektor sowie zur Geldwäschebekämpfung und Betrugserkennung im Bank- und Finanzdienstleistungssektor mit NetApp -Produkten und -Funktionen wie NetApp ONTAP AI, NetApp SnapMirror und NetApp FlexCache.</block>
  <block id="1e79e12b94e448f7c2f614e8ab2794ba" category="section-title">NetApp -Funktionen</block>
  <block id="14560cdfa11223c1b6b5ae41321de6d4" category="paragraph">Die Bewegung und Verwaltung von Daten in generativen KI-Anwendungen wie Chatbot, Codegenerierung, Bildgenerierung oder Genommodellausdruck kann sich über das Edge-, private Rechenzentrums- und hybride Multicloud-Ökosystem erstrecken.  Beispielsweise kann ein Echtzeit-KI-Bot, der einem Passagier dabei hilft, sein Flugticket über eine Endbenutzer-App, die über APIs vortrainierter Modelle wie ChatGPT verfügbar ist, auf die Business Class upzugraden, diese Aufgabe nicht alleine bewältigen, da die Passagierinformationen nicht öffentlich im Internet verfügbar sind.  Die API erfordert Zugriff auf die persönlichen Daten des Passagiers und die Ticketinformationen der Fluggesellschaft, die in einem Hybrid- oder Multicloud-Ökosystem vorhanden sein können.  Ein ähnliches Szenario könnte für Wissenschaftler gelten, die ein Arzneimittelmolekül und Patientendaten über eine Endbenutzeranwendung austauschen, die LLMs verwendet, um klinische Studien im Rahmen der Arzneimittelforschung durchzuführen, an denen eine oder mehrere biomedizinische Forschungseinrichtungen beteiligt sind.  Zu den sensiblen Daten, die an FMs oder LLMs weitergegeben werden, können personenbezogene Daten, Finanzinformationen, Gesundheitsinformationen, biometrische Daten, Standortdaten, Kommunikationsdaten, Daten zum Online-Verhalten und rechtliche Informationen gehören.  Bei einem solchen Fall von Echtzeit-Rendering, sofortiger Ausführung und Edge-Inferenz werden Daten von der Endbenutzer-App über Open Source- oder proprietäre LLM-Modelle zu Speicherendpunkten in ein Rechenzentrum vor Ort oder auf öffentliche Cloud-Plattformen verschoben.  In all diesen Szenarien sind Datenmobilität und Datenschutz für die KI-Operationen mit LLMs von entscheidender Bedeutung, die auf großen Trainingsdatensätzen und der Bewegung solcher Daten beruhen.</block>
  <block id="2bf2b67b54f29152ea5e8649dd4b7327" category="paragraph">Abbildung 4: Generative KI – LLM-Datenpipeline</block>
  <block id="206f6329180f9a8251d5f78b853663ab" category="inline-image-macro">Abbildung 4: Generative AI-LLM-Datenpipeline</block>
  <block id="47b42e2c6c693df656a00ec63e39dde3" category="paragraph"><block ref="47b42e2c6c693df656a00ec63e39dde3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc004144b88d4fadbbf7623c57d2c805" category="paragraph">Das Portfolio von NetApp an Speicherinfrastruktur, Daten und Cloud-Diensten basiert auf intelligenter Datenverwaltungssoftware.</block>
  <block id="7d5e80d61d854ee2e646efedf9f5e72d" category="paragraph">*Datenvorbereitung*: Die erste Säule des LLM-Tech-Stacks ist vom älteren traditionellen ML-Stack weitgehend unberührt.  Die Datenvorverarbeitung in der KI-Pipeline ist notwendig, um die Daten vor dem Training oder der Feinabstimmung zu normalisieren und zu bereinigen.  Dieser Schritt umfasst Konnektoren zum Aufnehmen von Daten, wo immer diese sich in Form einer Amazon S3-Ebene oder in lokalen Speichersystemen wie einem Dateispeicher oder einem Objektspeicher wie NetApp StorageGRID befinden.</block>
  <block id="b63aea4b58eede8ed8da27c8b36c34dc" category="paragraph">* NetApp ONTAP* ist die grundlegende Technologie, die den kritischen Speicherlösungen von NetApp im Rechenzentrum und in der Cloud zugrunde liegt.  ONTAP umfasst verschiedene Funktionen und Fähigkeiten zur Datenverwaltung und zum Schutz, darunter automatischen Ransomware-Schutz vor Cyberangriffen, integrierte Datentransportfunktionen und Speichereffizienzfunktionen für eine Reihe von Architekturen von lokalen, hybriden und Multicloud-Umgebungen in NAS-, SAN-, Objekt- und Software Defined Storage (SDS)-Situationen von LLM-Bereitstellungen.</block>
  <block id="77b83e7426a1ca8eea17df3ff3a421f7" category="paragraph">* NetApp ONTAP AI* für das Training von Deep-Learning-Modellen.  NetApp ONTAP unterstützt NVIDIA GPU Direct Storage durch die Verwendung von NFS über RDMA für NetApp -Kunden mit ONTAP -Speichercluster und NVIDIA DGX-Rechenknoten.  Es bietet eine kosteneffiziente Leistung, um Quelldatensätze mehrfach aus dem Speicher zu lesen und in den Arbeitsspeicher zu übertragen, um die Intelligenz zu fördern und Organisationen Schulungen, Feinabstimmungen und Skalierungszugriff auf LLMs zu ermöglichen.</block>
  <block id="420e9d37fdcde42065e69c7f6d925ab3" category="paragraph">* NetApp FlexCache* ist eine Remote-Caching-Funktion, die die Dateiverteilung vereinfacht und nur die aktiv gelesenen Daten zwischenspeichert.  Dies kann für LLM-Schulungen, Umschulungen und Feinabstimmungen nützlich sein und Kunden mit Geschäftsanforderungen wie Echtzeit-Rendering und LLM-Inferenz einen Mehrwert bieten.</block>
  <block id="0aef0293018a6f953acd79d5d6fb52ae" category="paragraph">* NetApp SnapMirror* ist eine ONTAP -Funktion, die Volume-Snapshots zwischen zwei beliebigen ONTAP Systemen repliziert.  Diese Funktion überträgt Daten am Rand optimal in Ihr lokales Rechenzentrum oder in die Cloud.  SnapMirror kann zum sicheren und effizienten Verschieben von Daten zwischen lokalen und Hyperscaler-Clouds verwendet werden, wenn Kunden generative KI in Clouds mit RAG entwickeln möchten, die Unternehmensdaten enthalten.  Es überträgt effizient nur Änderungen, spart Bandbreite und beschleunigt die Replikation und bietet so wichtige Datenmobilitätsfunktionen während des Trainings, des erneuten Trainings und der Feinabstimmung von FMs oder LLMs.</block>
  <block id="67e47ad6c891ade32e226f1b046d1168" category="paragraph">* NetApp SnapLock* ermöglicht die unveränderliche Festplattenfunktion auf ONTAP-basierten Speichersystemen zur Datensatzversionierung.  Die Microcore-Architektur ist darauf ausgelegt, Kundendaten mit der FPolicy Zero Trust-Engine zu schützen.  NetApp stellt die Verfügbarkeit von Kundendaten sicher, indem es Denial-of-Service-Angriffen (DoS) widersteht, wenn ein Angreifer auf besonders ressourcenintensive Weise mit einem LLM interagiert.</block>
  <block id="6fb00f321c345f8a92148aec8d1359f9" category="paragraph">* NetApp Cloud Data Sense* hilft dabei, in Unternehmensdatensätzen vorhandene persönliche Informationen zu identifizieren, abzubilden und zu klassifizieren, Richtlinien umzusetzen, Datenschutzanforderungen vor Ort oder in der Cloud zu erfüllen, die Sicherheitslage zu verbessern und Vorschriften einzuhalten.</block>
  <block id="8bca7c4074d7b3156f8b66e3ad7a5be8" category="paragraph">* NetApp BlueXP*-Klassifizierung, unterstützt durch Cloud Data Sense.  Kunden können Daten im gesamten Datenbestand automatisch scannen, analysieren, kategorisieren und darauf reagieren, Sicherheitsrisiken erkennen, die Speicherung optimieren und Cloud-Bereitstellungen beschleunigen.  Es kombiniert Speicher- und Datendienste über seine einheitliche Steuerebene. Kunden können GPU-Instanzen für Berechnungen und hybride Multicloud-Umgebungen für Cold-Storage-Tiering sowie für Archive und Backups verwenden.</block>
  <block id="528fb7334ec5453cef67bca12d29f735" category="paragraph">* NetApp -Datei-Objekt-Dualität*.  NetApp ONTAP ermöglicht Dual-Protokoll-Zugriff für NFS und S3.  Mit dieser Lösung können Kunden über S3-Buckets von NetApp Cloud Volumes ONTAP auf NFS-Daten von Amazon AWS SageMaker-Notebooks zugreifen.  Dies bietet Flexibilität für Kunden, die einfachen Zugriff auf heterogene Datenquellen mit der Möglichkeit benötigen, Daten sowohl von NFS als auch von S3 gemeinsam zu nutzen.  Beispielsweise zum Feinabstimmen von FMs wie Metas Llama 2-Textgenerierungsmodellen auf SageMaker mit Zugriff auf Dateiobjekt-Buckets.</block>
  <block id="a2e08866ca50b890089d6b77f640d7b5" category="paragraph">Der * NetApp Cloud Sync*-Dienst bietet eine einfache und sichere Möglichkeit, Daten zu jedem Ziel in der Cloud oder vor Ort zu migrieren.  Cloud Sync überträgt und synchronisiert Daten nahtlos zwischen lokalen oder Cloud-Speichern, NAS und Objektspeichern.</block>
  <block id="e53b3c8e83c8d94be048ce5801830a49" category="paragraph">* NetApp XCP* ist eine Client-Software, die schnelle und zuverlässige Datenmigrationen von beliebigen zu NetApp und NetApp-zu- NetApp ermöglicht.  XCP bietet außerdem die Möglichkeit, Massendaten effizient von Hadoop HDFS-Dateisystemen in ONTAP NFS, S3 oder StorageGRID zu verschieben, und die XCP-Dateianalyse bietet Einblick in das Dateisystem.</block>
  <block id="d0d48e5a8fe903e906882461b57dcfd3" category="paragraph">* NetApp DataOps Toolkit* ist eine Python-Bibliothek, die es Datenwissenschaftlern, DevOps und Dateningenieuren erleichtert, verschiedene Datenverwaltungsaufgaben auszuführen, wie etwa die nahezu sofortige Bereitstellung, das Klonen oder das Erstellen von Snapshots eines Datenvolumens oder JupyterLab-Arbeitsbereichs, die durch hochleistungsfähigen Scale-Out- NetApp -Speicher unterstützt werden.</block>
  <block id="97d451a12ea524d66984cc35758777b4" category="paragraph">*Produktsicherheit von NetApp*.  LLMs können in ihren Antworten unbeabsichtigt vertrauliche Daten preisgeben, was für CISOs, die die Schwachstellen im Zusammenhang mit KI-Anwendungen untersuchen, die LLMs nutzen, Anlass zur Sorge gibt.  Wie von OWASP (Open Worldwide Application Security Project) dargelegt, können Sicherheitsprobleme wie Datenvergiftung, Datenlecks, Denial-of-Service und Prompt-Injections innerhalb von LLMs Unternehmen beeinträchtigen, da Daten für Angreifer unberechtigten Zugriff zugänglich gemacht werden.  Zu den Anforderungen an die Datenspeicherung sollten Integritätsprüfungen und unveränderliche Snapshots für strukturierte, halbstrukturierte und unstrukturierte Daten gehören.  Zur Datensatzversionierung werden NetApp Snapshots und SnapLock verwendet.  Es bietet eine strenge rollenbasierte Zugriffskontrolle (RBAC) sowie sichere Protokolle und eine Verschlüsselung nach Industriestandard zum Schutz sowohl der Daten im Ruhezustand als auch während der Übertragung.  Cloud Insights und Cloud Data Sense bieten gemeinsam Funktionen, die Ihnen dabei helfen, die Quelle der Bedrohung forensisch zu identifizieren und die wiederherzustellenden Daten zu priorisieren.</block>
  <block id="0364ee2a32c23b9f35e29f68c79d63e1" category="section-title">* ONTAP AI mit DGX BasePOD*</block>
  <block id="c6f1dc673303b79fafb5e05f0c7a97cb" category="paragraph">Die NetApp ONTAP AI-Referenzarchitektur mit NVIDIA DGX BasePOD ist eine skalierbare Architektur für Workloads im Bereich maschinelles Lernen (ML) und künstliche Intelligenz (KI).  Für die kritische Trainingsphase von LLMs werden Daten typischerweise in regelmäßigen Abständen aus dem Datenspeicher in den Trainingscluster kopiert.  Die in dieser Phase eingesetzten Server nutzen GPUs zur Parallelisierung von Berechnungen, wodurch ein enormer Datenhunger entsteht.  Um eine hohe GPU-Auslastung aufrechtzuerhalten, ist es entscheidend, den Bedarf an Roh-E/A-Bandbreite zu decken.</block>
  <block id="9a05494b8b259619e21e3e78c47f4dc5" category="section-title">* ONTAP AI mit NVIDIA AI Enterprise*</block>
  <block id="65590ec18b850984cfb8bbe6ba35fe7d" category="paragraph">NVIDIA AI Enterprise ist eine durchgängige, Cloud-native Suite von KI- und Datenanalysesoftware, die von NVIDIA für die Ausführung auf VMware vSphere mit NVIDIA-zertifizierten Systemen optimiert, zertifiziert und unterstützt wird.  Diese Software ermöglicht die einfache und schnelle Bereitstellung, Verwaltung und Skalierung von KI-Workloads in der modernen Hybrid-Cloud-Umgebung.  NVIDIA AI Enterprise, unterstützt von NetApp und VMware, bietet KI-Workload- und Datenmanagement der Enterprise-Klasse in einem vereinfachten, vertrauten Paket.</block>
  <block id="1ad177c0b9d841f941eb7d5322dc9b52" category="section-title">*1P Cloud-Plattformen*</block>
  <block id="0e877c6cfb49f5bbdc17c6d204b4b7cb" category="paragraph">Vollständig verwaltete Cloud-Speicherangebote sind nativ auf Microsoft Azure als Azure NetApp Files (ANF), auf AWS als Amazon FSx for NetApp ONTAP (FSx ONTAP) und auf Google als Google Cloud NetApp Volumes (GNCV) verfügbar.  1P ist ein verwaltetes, leistungsstarkes Dateisystem, das es Kunden ermöglicht, hochverfügbare KI-Workloads mit verbesserter Datensicherheit in öffentlichen Clouds auszuführen, um LLMs/FMs mit Cloud-nativen ML-Plattformen wie AWS SageMaker, Azure-OpenAI Services und Googles Vertex AI zu optimieren.</block>
  <block id="64992f0c01704aa99d3bd851b7673bf7" category="section-title">NetApp Partner Solution Suite</block>
  <block id="0e3151175898c0a6687552a854a08b00" category="paragraph">Zusätzlich zu seinen Kerndatenprodukten, -technologien und -funktionen arbeitet NetApp auch eng mit einem robusten Netzwerk von KI-Partnern zusammen, um den Kunden einen Mehrwert zu bieten.</block>
  <block id="5c682f526a6d29391ad4d45cd7c7cae9" category="paragraph">* NVIDIA Leitplanken* in KI-Systemen dienen als Sicherheitsvorkehrungen, um den ethischen und verantwortungsvollen Einsatz von KI-Technologien sicherzustellen.  KI-Entwickler können das Verhalten von LLM-basierten Anwendungen zu bestimmten Themen definieren und sie daran hindern, sich an Diskussionen zu unerwünschten Themen zu beteiligen.  Guardrails, ein Open-Source-Toolkit, bietet die Möglichkeit, ein LLM nahtlos und sicher mit anderen Diensten zu verbinden, um vertrauenswürdige und sichere LLM-Konversationssysteme aufzubauen.</block>
  <block id="0b46f95333d136197f1bb757634ebae2" category="paragraph">*Domino Data Lab* bietet vielseitige Tools auf Unternehmensniveau zum Erstellen und zur Produktisierung generativer KI – schnell, sicher und wirtschaftlich, egal, wo Sie sich auf Ihrer KI-Reise befinden.  Mit der Enterprise MLOps-Plattform von Domino können Datenwissenschaftler bevorzugte Tools und alle ihre Daten nutzen, Modelle überall problemlos trainieren und bereitstellen sowie Risiken und Kosten effizient verwalten – alles von einem Kontrollzentrum aus.</block>
  <block id="20350fb42ff163b07d9d4a2636b4a555" category="paragraph">*Modzy für Edge AI*.  NetApp und Modzy haben sich zusammengeschlossen, um KI im großen Maßstab für alle Arten von Daten bereitzustellen, darunter Bilder, Audio, Text und Tabellen.  Modzy ist eine MLOps-Plattform zum Bereitstellen, Integrieren und Ausführen von KI-Modellen. Sie bietet Datenwissenschaftlern die Möglichkeit zur Modellüberwachung, Drifterkennung und Erklärbarkeit mit einer integrierten Lösung für nahtlose LLM-Inferenz.</block>
  <block id="50841f507614d3540c25e7671dc0cdc0" category="paragraph">*Run:AI* und NetApp haben sich zusammengetan, um die einzigartigen Fähigkeiten der NetApp ONTAP AI-Lösung mit der Run:AI-Cluster-Management-Plattform zur Vereinfachung der Orchestrierung von KI-Workloads zu demonstrieren.  Es teilt und verbindet GPU-Ressourcen automatisch und ist darauf ausgelegt, Ihre Datenverarbeitungs-Pipelines mit integrierten Integrationsframeworks für Spark, Ray, Dask und Rapids auf Hunderte von Maschinen zu skalieren.</block>
  <block id="7f8ef2f7d9a73eb64e35d815049ddd46" category="paragraph">Generative KI kann nur dann effektive Ergebnisse erzielen, wenn das Modell anhand großer Mengen hochwertiger Daten trainiert wird.  Obwohl LLMs bemerkenswerte Meilensteine erreicht haben, ist es wichtig, ihre Grenzen, Designherausforderungen und Risiken im Zusammenhang mit Datenmobilität und Datenqualität zu erkennen.  LLMs basieren auf großen und unterschiedlichen Trainingsdatensätzen aus heterogenen Datenquellen.  Ungenaue oder verzerrte Ergebnisse der Modelle können sowohl Unternehmen als auch Verbraucher gefährden.  Diese Risiken können Einschränkungen für LLMs entsprechen, die möglicherweise aus Herausforderungen im Datenmanagement im Zusammenhang mit Datenqualität, Datensicherheit und Datenmobilität entstehen.  NetApp unterstützt Unternehmen dabei, die Komplexität zu bewältigen, die durch schnelles Datenwachstum, Datenmobilität, Multi-Cloud-Management und die Einführung von KI entsteht.  Eine maßstabsgetreue KI-Infrastruktur und ein effizientes Datenmanagement sind entscheidend für den Erfolg von KI-Anwendungen wie generativer KI.  Für die Kunden ist es entscheidend, alle Bereitstellungsszenarien abzudecken, ohne Kompromisse bei der Expansionsfähigkeit einzugehen, die die Unternehmen benötigen, und gleichzeitig Kosteneffizienz, Datenverwaltung und ethische KI-Praktiken unter Kontrolle zu halten.  NetApp arbeitet ständig daran, Kunden dabei zu unterstützen, ihre KI-Bereitstellungen zu vereinfachen und zu beschleunigen.</block>
  <block id="cea78864209b835e9b37cbe0a2cb862e" category="doc">NVA-1172-DESIGN: NetApp AIPod mit Lenovo für NVIDIA OVX</block>
  <block id="cd270e0e169361bb079873f1cb21e6b5" category="paragraph">Bobby Oommen, Abhinav Singh, Roney Daniel, NetApp</block>
  <block id="999a2bd7b329bd7fe4178352281b558b" category="paragraph">Diese Referenzarchitektur kombiniert NVIDIA-zertifizierte OVX Lenovo ThinkSystem-Server, die von NVIDIA L40S-GPUs angetrieben werden, mit NVIDIA Spectrum-Netzwerken, um eine optimale Infrastrukturlösung zur Optimierung und Bereitstellung von LLMs (Large Language Models) bereitzustellen.  Der Zweck dieses Dokuments besteht darin, eine Anleitung zum Speicher für eine OVX-Konfiguration bereitzustellen.  Diese Plattform eignet sich für verschiedene generative KI-Workloads, einschließlich RAG (Retrieval Augmented Generation), Feinabstimmung und leichtes Modelltraining.</block>
  <block id="688a655aa25fa96dbcd977348cc95acc" category="inline-link-macro">NVA-1172-DESIGN: NetApp AIPod mit Lenovo für NVIDIA OVX-Designhandbuch</block>
  <block id="07ba0b8aab1e2887d9dc0f7f9d5dad4f" category="paragraph"><block ref="07ba0b8aab1e2887d9dc0f7f9d5dad4f" category="inline-link-macro-rx"></block></block>
  <block id="82b67ae3d50932b0d818b7c3a23b3428" category="summary">NetApp AIPod mit NVIDIA DGX-Systemen – Architektur</block>
  <block id="92527686d5dc11342676e296e31b0b51" category="doc">NVA-1173 NetApp AIPod mit NVIDIA DGX H100-Systemen – Lösungsarchitektur</block>
  <block id="34fc6f8c7d10337be1b911dd98627e40" category="paragraph">Dieser Abschnitt konzentriert sich auf die Architektur für den NetApp AIPod mit NVIDIA DGX-Systemen.</block>
  <block id="b10a3a95ab83cbad7acc457e6bc13a1b" category="section-title">NetApp AIPod mit DGX-Systemen</block>
  <block id="990e00b86cef2bb25d2e346df6e7adfe" category="paragraph">Diese Referenzarchitektur nutzt separate Fabrics für die Verbindung von Rechenclustern und den Speicherzugriff mit 400 Gb/s InfiniBand (IB)-Konnektivität zwischen Rechenknoten.  Die folgende Zeichnung zeigt die Gesamtlösungstopologie von NetApp AIPod mit DGX H100-Systemen.</block>
  <block id="5d065d1080de5349462d7a342f622bf3" category="paragraph">_Topologie der NetApp AIpod-Lösung_</block>
  <block id="552dcf63ade7f6a706107c5da1f5a2a6" category="paragraph"><block ref="552dcf63ade7f6a706107c5da1f5a2a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="19c939070c0b6ebbb52e1e0119b15301" category="section-title">Netzwerkdesign</block>
  <block id="57f55a30c80dbf621eb119c782a8b3c5" category="paragraph">In dieser Konfiguration verwendet das Compute-Cluster-Fabric ein Paar QM9700 400Gb/s IB-Switches, die für eine hohe Verfügbarkeit miteinander verbunden sind.  Jedes DGX H100-System ist über acht Verbindungen mit den Switches verbunden, wobei die Ports mit geraden Nummern mit einem Switch und die Ports mit ungeraden Nummern mit dem anderen Switch verbunden sind.</block>
  <block id="8ee4ef799026973266981f7c555ea058" category="paragraph">Für den Zugriff auf das Speichersystem, die In-Band-Verwaltung und den Clientzugriff wird ein Paar SN4600-Ethernet-Switches verwendet.  Die Switches sind über Inter-Switch-Links verbunden und mit mehreren VLANs konfiguriert, um die verschiedenen Verkehrstypen zu isolieren.  Grundlegendes L3-Routing wird zwischen bestimmten VLANs aktiviert, um mehrere Pfade zwischen Client- und Speicherschnittstellen auf demselben Switch sowie zwischen Switches für hohe Verfügbarkeit zu ermöglichen.  Bei größeren Bereitstellungen kann das Ethernet-Netzwerk durch Hinzufügen zusätzlicher Switch-Paare für Spine-Switches und zusätzlicher Leaves nach Bedarf auf eine Leaf-Spine-Konfiguration erweitert werden.</block>
  <block id="082b01f67d64181611dc998408a2b121" category="inline-link-macro">Bereitstellungsdetails</block>
  <block id="41b55cdcb36636c126a5ef6c6e873a08" category="paragraph">Zusätzlich zur Computerverbindung und den Hochgeschwindigkeits-Ethernet-Netzwerken sind alle physischen Geräte für die Out-of-Band-Verwaltung auch mit einem oder mehreren SN2201-Ethernet-Switches verbunden.  Bitte beachten Sie die<block ref="11e89a956fe8616ed611e595e22cdb97" category="inline-link-macro-rx"></block> Weitere Informationen zur Netzwerkkonfiguration finden Sie auf der Seite.</block>
  <block id="9eaf2c6f65cf6ad700b387972ddc345e" category="section-title">Speicherzugriffsübersicht für DGX H100-Systeme</block>
  <block id="b1cdc2ac23891a1bf0e697359ffeeef6" category="paragraph">Jedes DGX H100-System ist mit zwei ConnectX-7-Adaptern mit zwei Ports für Verwaltungs- und Speicherverkehr ausgestattet und für diese Lösung sind beide Ports auf jeder Karte mit demselben Switch verbunden.  Ein Port von jeder Karte wird dann in eine LACP MLAG-Verbindung konfiguriert, wobei ein Port mit jedem Switch verbunden ist, und VLANs für In-Band-Management, Clientzugriff und Speicherzugriff auf Benutzerebene werden auf dieser Verbindung gehostet.</block>
  <block id="891c72a31ed1199769c3f62cab11e7b4" category="paragraph">Der andere Port auf jeder Karte wird für die Verbindung mit den AFF A90 Speichersystemen verwendet und kann je nach Arbeitslastanforderungen in mehreren Konfigurationen verwendet werden.  Bei Konfigurationen, die NFS über RDMA zur Unterstützung von NVIDIA Magnum IO GPUDirect Storage verwenden, werden die Ports einzeln mit IP-Adressen in separaten VLANs verwendet.  Für Bereitstellungen, die kein RDMA erfordern, können die Speicherschnittstellen auch mit LACP-Bonding konfiguriert werden, um hohe Verfügbarkeit und zusätzliche Bandbreite bereitzustellen.  Mit oder ohne RDMA können Clients das Speichersystem mithilfe von NFS v4.1 pNFS und Session Trunking mounten, um parallelen Zugriff auf alle Speicherknoten im Cluster zu ermöglichen.  Bitte beachten Sie die<block ref="11e89a956fe8616ed611e595e22cdb97" category="inline-link-macro-rx"></block> Seite für weitere Informationen zur Clientkonfiguration.</block>
  <block id="c95998835114a4e50f348f8c5e5686ed" category="inline-link-macro">NVIDIA BasePOD-Dokumentation</block>
  <block id="8660b0a825d671d8855117ae496d3af6" category="paragraph">Weitere Einzelheiten zur Konnektivität des DGX H100-Systems finden Sie in der<block ref="784f66b69fd9a6fd2983e969e5202b40" category="inline-link-macro-rx"></block> .</block>
  <block id="42dc99c097c1b9b9af75ba060788e1f1" category="section-title">Speichersystemdesign</block>
  <block id="61b2fad5f824784462363e1b366833fa" category="paragraph">Jedes AFF A90 Speichersystem ist über sechs 200-GbE-Ports von jedem Controller aus verbunden.  Vier Ports von jedem Controller werden für den Workload-Datenzugriff von den DGX-Systemen verwendet und zwei Ports von jedem Controller sind als LACP-Schnittstellengruppe konfiguriert, um den Zugriff von den Management-Plane-Servern auf Cluster-Management-Artefakte und Benutzer-Home-Verzeichnisse zu unterstützen.  Der gesamte Datenzugriff vom Speichersystem erfolgt über NFS, wobei eine Storage Virtual Machine (SVM) für den Zugriff auf KI-Workloads und eine separate SVM für Clusterverwaltungszwecke vorgesehen ist.</block>
  <block id="6c9aef89eae0fd771909b15623e452df" category="paragraph">Das Management-SVM benötigt nur ein einziges LIF, das auf den auf jedem Controller konfigurierten 2-Port-Schnittstellengruppen gehostet wird.  Andere FlexGroup -Volumes werden auf der Management-SVM bereitgestellt, um Cluster-Management-Artefakte wie Cluster-Knoten-Images, historische Systemüberwachungsdaten und Endbenutzer-Home-Verzeichnisse aufzunehmen.  Die folgende Zeichnung zeigt die logische Konfiguration des Speichersystems.</block>
  <block id="995db3e6bdfdd81bd5e1b6a98b33e5b7" category="paragraph">_Logische Konfiguration des NetApp A90-Speicherclusters_</block>
  <block id="1e7a613d4d1ae838806eb303b8f25492" category="paragraph"><block ref="1e7a613d4d1ae838806eb303b8f25492" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6420553f17ebdab39fa9a1825d57651" category="section-title">Management-Plane-Server</block>
  <block id="e6391a8600a62f5346ec27d437d43626" category="paragraph">Diese Referenzarchitektur umfasst außerdem fünf CPU-basierte Server für den Einsatz auf Verwaltungsebene.  Zwei dieser Systeme werden als Hauptknoten für NVIDIA Base Command Manager zur Clusterbereitstellung und -verwaltung verwendet.  Die anderen drei Systeme werden verwendet, um zusätzliche Clusterdienste wie Kubernetes-Masterknoten oder Anmeldeknoten für Bereitstellungen bereitzustellen, die Slurm für die Jobplanung verwenden.  Bereitstellungen mit Kubernetes können den NetApp Trident CSI-Treiber nutzen, um automatisierte Bereitstellungs- und Datendienste mit persistentem Speicher für Management- und KI-Workloads auf dem AFF A900 Speichersystem bereitzustellen.</block>
  <block id="108f9bbf932c304dff7d03edbf186c18" category="paragraph">Jeder Server ist physisch mit den IB-Switches und den Ethernet-Switches verbunden, um die Clusterbereitstellung und -verwaltung zu ermöglichen, und mit NFS-Mounts zum Speichersystem über die Verwaltungs-SVM zur Speicherung von Clusterverwaltungsartefakten konfiguriert, wie zuvor beschrieben.</block>
  <block id="19a97f58216292f6ce34aa1a3ad9e96e" category="summary">NetApp AIPod mit NVIDIA DGX-Systemen – Wo Sie weitere Informationen finden</block>
  <block id="43e1c1d93ec30f643ac7004cd6fafc47" category="doc">NVA-1173 NetApp AIPod mit NVIDIA DGX-Systemen – Fazit und weitere Informationen</block>
  <block id="7c3d91801a54614f755a9f2897ee42f3" category="paragraph">Dieser Abschnitt enthält Verweise auf zusätzliche Informationen zum NetApp AIPod mit NVIDIA DGX-Systemen.</block>
  <block id="bcde7144e6a13836183bd03e403987ef" category="paragraph">Die DGX BasePOD-Architektur ist eine Deep-Learning-Plattform der nächsten Generation, die ebenso fortschrittliche Speicher- und Datenverwaltungsfunktionen erfordert.  Durch die Kombination von DGX BasePOD mit NetApp AFF -Systemen kann die NetApp AIPod -Architektur mit DGX-Systemen in nahezu jedem Maßstab implementiert werden.  In Kombination mit der überlegenen Cloud-Integration und den softwaredefinierten Funktionen von NetApp ONTAP ermöglicht AFF eine vollständige Palette von Datenpipelines, die sich über den Rand, den Kern und die Cloud erstrecken, für erfolgreiche DL-Projekte.</block>
  <block id="092bf78f9c97ba171b8232ddff585392" category="section-title">Weitere Informationen</block>
  <block id="68e34599e7058d633da08de84c55032d" category="paragraph">Weitere Informationen zu den in diesem Dokument beschriebenen Informationen finden Sie in den folgenden Dokumenten und/oder auf den folgenden Websites:</block>
  <block id="f85150beb9ce598095b212b1de60815f" category="list-text">NetApp ONTAP Datenverwaltungssoftware – ONTAP Informationsbibliothek</block>
  <block id="5f60faf04d2b972aa0cf8c369cfc6a26" category="inline-link"><block ref="5f60faf04d2b972aa0cf8c369cfc6a26" category="inline-link-rx"></block></block>
  <block id="d99ede023f079413a479e349dcb54616" category="paragraph"><block ref="d99ede023f079413a479e349dcb54616" category="inline-link-rx"></block></block>
  <block id="b8667e5a766c0335e106bdd9b4ea825f" category="list-text">NetApp AFF A90 Speichersysteme-</block>
  <block id="8a5df1408a92dc0ef3181cd15cbc989e" category="inline-link"><block ref="8a5df1408a92dc0ef3181cd15cbc989e" category="inline-link-rx"></block></block>
  <block id="22ef65e375f266c2889509f939e1ac83" category="paragraph"><block ref="22ef65e375f266c2889509f939e1ac83" category="inline-link-rx"></block></block>
  <block id="29b91fda4bb7baae0176d0ca5870634a" category="list-text">NetApp ONTAP RDMA-Informationen –</block>
  <block id="0f4b138acdd63a2f36e4aeb66ce027c5" category="inline-link-macro"><block ref="0f4b138acdd63a2f36e4aeb66ce027c5" category="inline-link-rx"></block></block>
  <block id="c08c09703d9322a16ef4a93b82ff897e" category="paragraph"><block ref="c08c09703d9322a16ef4a93b82ff897e" category="inline-link-macro-rx"></block></block>
  <block id="e71e852dc96d4d0e2da95de923a6f8ff" category="list-text">NetApp Trident</block>
  <block id="3daf8b3b7ee9b11922ef3d82e81e3a2c" category="paragraph"><block ref="3daf8b3b7ee9b11922ef3d82e81e3a2c" category="inline-link-macro-rx"></block></block>
  <block id="4613e07c94020e7ba8189d048f9d61c1" category="list-text">NetApp GPUDirect Storage Blog –</block>
  <block id="cf8832fa60205a911c1036fb274f649e" category="inline-link"><block ref="cf8832fa60205a911c1036fb274f649e" category="inline-link-rx"></block></block>
  <block id="0f1f9907ba0a6f040f1fa28d77e74fb8" category="paragraph"><block ref="0f1f9907ba0a6f040f1fa28d77e74fb8" category="inline-link-rx"></block></block>
  <block id="64dc43320ec1a44c390fafb5e2408f4b" category="list-text">NVIDIA DGX BasePOD</block>
  <block id="6ff1278864800ae134fcd2dda1a5e0e9" category="inline-link"><block ref="6ff1278864800ae134fcd2dda1a5e0e9" category="inline-link-rx"></block></block>
  <block id="0c2cd58ffa7f091c420ae61854a0a8db" category="paragraph"><block ref="0c2cd58ffa7f091c420ae61854a0a8db" category="inline-link-rx"></block></block>
  <block id="e3d6e4bdd7281f2c5d652f6f01825970" category="list-text">NVIDIA DGX H100-Systeme</block>
  <block id="f3d1cd3a647a52b1157c812ae2d90248" category="inline-link"><block ref="f3d1cd3a647a52b1157c812ae2d90248" category="inline-link-rx"></block></block>
  <block id="f4e11a54d0110771220fa05425235763" category="paragraph"><block ref="f4e11a54d0110771220fa05425235763" category="inline-link-rx"></block></block>
  <block id="d90238071267e4279a25de2c6945b227" category="list-text">NVIDIA Netzwerk</block>
  <block id="51c8257f6c8ba308b83f9f13b405dad0" category="inline-link"><block ref="51c8257f6c8ba308b83f9f13b405dad0" category="inline-link-rx"></block></block>
  <block id="a19d7568aa9c7e4c1f3bf3e831367115" category="paragraph"><block ref="a19d7568aa9c7e4c1f3bf3e831367115" category="inline-link-rx"></block></block>
  <block id="a96fecd8b3666b7b60c0bc0a24db79b2" category="list-text">NVIDIA Magnum IO – GPUDirect – Speicher</block>
  <block id="74079d06fd0015403a15f89699e6bcba" category="inline-link"><block ref="74079d06fd0015403a15f89699e6bcba" category="inline-link-rx"></block></block>
  <block id="110c88150ddcbc728071b2fcd7848bd2" category="paragraph"><block ref="110c88150ddcbc728071b2fcd7848bd2" category="inline-link-rx"></block></block>
  <block id="c7bef72157cc39b6eb7c391a393a20d2" category="list-text">NVIDIA Basisbefehl</block>
  <block id="bbae10fb46fb1d3604fe601d556f4187" category="inline-link"><block ref="bbae10fb46fb1d3604fe601d556f4187" category="inline-link-rx"></block></block>
  <block id="936c47b696a994feb0ad33a2addb1168" category="paragraph"><block ref="936c47b696a994feb0ad33a2addb1168" category="inline-link-rx"></block></block>
  <block id="b4675c30af15f661c8112c2853f97970" category="list-text">NVIDIA Base Command Manager</block>
  <block id="5cb8e16a3e555ee938b528aaeb45b703" category="inline-link"><block ref="5cb8e16a3e555ee938b528aaeb45b703" category="inline-link-rx"></block></block>
  <block id="6b36fdb81918af4b96afe2ba587a8ae1" category="paragraph"><block ref="6b36fdb81918af4b96afe2ba587a8ae1" category="inline-link-rx"></block></block>
  <block id="51ab86189ca8b1d1a08ac2970d39f90c" category="list-text">NVIDIA AI Enterprise</block>
  <block id="42c9b161f86365b647172182503d9520" category="inline-link"><block ref="42c9b161f86365b647172182503d9520" category="inline-link-rx"></block></block>
  <block id="f5802e2c53799babc0ac27f6cb392604" category="paragraph"><block ref="f5802e2c53799babc0ac27f6cb392604" category="inline-link-rx"></block></block>
  <block id="9132ee4ebfc1bcccf9be22b87e818413" category="paragraph">Dieses Dokument ist das Werk der NetApp Solutions- und ONTAP Engineering-Teams – David Arnette, Olga Kornievskaia, Dustin Fischer, Srikanth Kaligotla, Mohit Kumar und Raghuram Sudhaakar.  Die Autoren möchten sich außerdem bei NVIDIA und dem NVIDIA DGX BasePOD Entwicklungsteam für ihre anhaltende Unterstützung bedanken.</block>
  <block id="7c4d674fe3a4532c3ffe553151378a3f" category="summary">NetApp AIPod mit NVIDIA DGX-Systemen – Bereitstellung</block>
  <block id="302db59f0ad2458d76aedcc8a6fdd7be" category="doc">NVA-1173 NetApp AIPod mit NVIDIA DGX-Systemen – Bereitstellungsdetails</block>
  <block id="c584dd3e1383c7899a434fb7b8e1a341" category="paragraph">In diesem Abschnitt werden die Bereitstellungsdetails beschrieben, die während der Validierung dieser Lösung verwendet wurden.  Die verwendeten IP-Adressen sind Beispiele und sollten je nach Bereitstellungsumgebung geändert werden.  Weitere Informationen zu bestimmten Befehlen, die bei der Implementierung dieser Konfiguration verwendet werden, finden Sie in der entsprechenden Produktdokumentation.</block>
  <block id="b5f0a1ca7b5559b93159bcc11b7b99e9" category="paragraph">Das folgende Diagramm zeigt detaillierte Netzwerk- und Konnektivitätsinformationen für 1 DGX H100-System und 1 HA-Paar AFF A90 Controller.  Die Bereitstellungshinweise in den folgenden Abschnitten basieren auf den Details in diesem Diagramm.</block>
  <block id="a1ce9904a2cc7e8a6e1267980553c732" category="paragraph">_NetApp AIpod-Netzwerkkonfiguration_</block>
  <block id="c4e9bce0ddaf289da0094c0a0560c136" category="paragraph"><block ref="c4e9bce0ddaf289da0094c0a0560c136" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ea12591fa7a8663c28086764fc393d35" category="paragraph">Die folgende Tabelle zeigt beispielhafte Verkabelungszuweisungen für bis zu 16 DGX-Systeme und 2 AFF A90 HA-Paare.</block>
  <block id="4919e7d6c7a8481619e206520f937aaf" category="cell">Schalter und Port</block>
  <block id="e0ac20adce6ffee48c7151b070aa5737" category="cell">Gerät</block>
  <block id="e85450f6454a8b84aa3dd8ab4cfe658c" category="cell">Geräteanschluss</block>
  <block id="bdbd5451b62f5c0739cd0300b29d0db1" category="cell">Switch1-Ports 1-16</block>
  <block id="b6bf51e15f6d9d931c3ef52dcf7c2e74" category="cell">DGX-H100-01 bis -16</block>
  <block id="4d866d6d7dc3628895dbedb26f1bdf96" category="cell">enp170s0f0np0, Steckplatz 1, Port 1</block>
  <block id="6438dabe67e09d4e0ec2e3d17d7074f9" category="cell">Switch1-Ports 17-32</block>
  <block id="744d517d131df3b9ae1b4bdbdf70b282" category="cell">enp170s0f1np1, Steckplatz 1, Port 2</block>
  <block id="2914cd4a87277c08ac1f71cafd311de5" category="cell">Switch1-Ports 33-36</block>
  <block id="b08a34f62ae5d3df1c59356cb996a50a" category="cell">AFF-A90-01 bis -04</block>
  <block id="3d163afca230cdca293d07b9bce1004f" category="cell">Anschluss E6a</block>
  <block id="09a5a99bfdac461078765cf577fa36c1" category="cell">Switch1-Ports 37-40</block>
  <block id="67d1565f0da7861ffc787acf0cc159af" category="cell">Port E11a</block>
  <block id="d350694943ec1acbb17fb85d69fd2aa9" category="cell">Switch1-Ports 41-44</block>
  <block id="44b26214a7c3f5ffe5ec1db0aa3e4f98" category="cell">Port E2A</block>
  <block id="9e444fba13b3dd8f65bd7deb1b742747" category="cell">Switch1-Ports 57-64</block>
  <block id="7a744922ca20208077a50d69271d15fd" category="cell">ISL zu Switch2</block>
  <block id="68813ae3b3a11b5b786ffe4305c5d542" category="cell">Anschlüsse 57-64</block>
  <block id="9b878f628cccd99408682b50785b3598" category="cell">Switch2-Ports 1-16</block>
  <block id="3cdeea9afe6ab2952bd32f14b371d0c3" category="cell">enp41s0f0np0, Steckplatz 2, Port 1</block>
  <block id="6a11ad764d8b60d242c533b565b99142" category="cell">Switch2-Ports 17-32</block>
  <block id="e26d3524de049d551125c01b1d65729e" category="cell">enp41s0f1np1, Steckplatz 2, Port 2</block>
  <block id="59ba8265a302f2fb97997075c8f27f6d" category="cell">Switch2-Ports 33-36</block>
  <block id="9df3af84859046bac07e13013fce0466" category="cell">Port E6b</block>
  <block id="d9a9acdd71cb92eb03299a9702a84577" category="cell">Switch2-Ports 37-40</block>
  <block id="0b9b24c59934606f5e10f1c15b3a86cb" category="cell">Port E11b</block>
  <block id="2f4b59b7b40dec7ee6362e6017960380" category="cell">Switch2-Ports 41-44</block>
  <block id="2c635d05e781d03137efe254ee8f86a1" category="cell">Port E2B</block>
  <block id="67a367a7d31cdd640df71104820055c4" category="cell">Switch2-Ports 57-64</block>
  <block id="ed38d5a59568aa5dd0a40c94574cf056" category="cell">ISL zu Switch1</block>
  <block id="c470336f17afce51494a7db95c91de92" category="paragraph">Die folgende Tabelle zeigt die Softwareversionen für die verschiedenen Komponenten, die bei dieser Validierung verwendet wurden.</block>
  <block id="40ddf58fef213ff0d6433ef322edfe2e" category="cell">Softwareversion</block>
  <block id="b1c079bf2940033fab8f8dffbf4a5ff2" category="cell">NVIDIA SN4600-Switches</block>
  <block id="90db213df8a0c782abe8388881fce336" category="cell">Cumulus Linux v5.9.1</block>
  <block id="18cf8e6ece8a122dba390f844981b900" category="cell">NVIDIA DGX-System</block>
  <block id="cfba00e4a4b4df8f6a7ebf83cfd81c4c" category="cell">DGX OS v6.2.1 (Ubuntu 22.04 LTS)</block>
  <block id="857ecbf3846b57d505e2a1b49da67f65" category="cell">Mellanox OFED</block>
  <block id="38aa87e1c845f13e459d6a71f7049cac" category="cell">24,01</block>
  <block id="3eb4233634d4c27ee1a1ddf72619b98d" category="cell">NetApp AFF A90</block>
  <block id="6944cefb93932417ed3a50959c66a9c5" category="cell">NetApp ONTAP 9.14.1</block>
  <block id="93fb68f81a2ad999b6aae02d586c4ef4" category="section-title">Speichernetzwerkkonfiguration</block>
  <block id="84814a12bbb8397e0a8f1357446c94e5" category="inline-link-macro">NVIDIA Cumulus Linux-Dokumentation</block>
  <block id="5d27fc003227b21f0392098a85eb18c2" category="paragraph">In diesem Abschnitt werden die wichtigsten Details zur Konfiguration des Ethernet-Speichernetzwerks beschrieben.  Informationen zur Konfiguration des InfiniBand-Rechnernetzwerks finden Sie im<block ref="784f66b69fd9a6fd2983e969e5202b40" category="inline-link-macro-rx"></block> .  Weitere Einzelheiten zur Switch-Konfiguration finden Sie im<block ref="5e4d481e02111d80d9871bbc3802a082" category="inline-link-macro-rx"></block> .</block>
  <block id="57719be20908b73e68d37637555b97d6" category="paragraph">Die grundlegenden Schritte zur Konfiguration der SN4600-Switches werden unten beschrieben.  Dieser Vorgang setzt voraus, dass die Verkabelung und die grundlegende Switch-Einrichtung (Verwaltung der IP-Adresse, Lizenzierung usw.) abgeschlossen sind.</block>
  <block id="e55cea47183e18fc2e2e86a5dcee8ec7" category="list-text">Konfigurieren Sie die ISL-Verbindung zwischen den Switches, um Multi-Link Aggregation (MLAG) und Failover-Verkehr zu ermöglichen</block>
  <block id="72a998485758ede34cc727692eda3bd2" category="list-text">Bei dieser Validierung wurden 8 Links verwendet, um mehr als genug Bandbreite für die getestete Speicherkonfiguration bereitzustellen.</block>
  <block id="3051c0af523b2627a57ce2bf1e587655" category="list-text">Spezifische Anweisungen zum Aktivieren von MLAG finden Sie in der Cumulus Linux-Dokumentation.</block>
  <block id="8ae9a0f6054b5fb4a974e1f0d735ff8d" category="list-text">Konfigurieren Sie LACP MLAG für jedes Paar von Client-Ports und Speicher-Ports auf beiden Switches</block>
  <block id="3c81bce81a92df032d58d66eb88265b0" category="list-text">Port swp17 auf jedem Switch für DGX-H100-01 (enp170s0f1np1 und enp41s0f1np1), Port swp18 für DGX-H100-02 usw. (bond1-16)</block>
  <block id="563a9dfd999aa71e1b86c22188243c2b" category="list-text">Port swp41 auf jedem Switch für AFF-A90-01 (e2a und e2b), Port swp42 für AFF-A90-02 usw. (bond17-20)</block>
  <block id="44f6b0b1ffb3c7d26ff370ef2db934bb" category="list-text">nv set interface bondX bond member swpX</block>
  <block id="e88a9fc1fac9e835ce4f94863fa6c017" category="list-text">nv set interface bondx bond mlag id X</block>
  <block id="53e5d1cb8672703c6d9c6468088afa1a" category="list-text">Fügen Sie alle Ports und MLAG-Verbindungen zur Standard-Bridge-Domäne hinzu</block>
  <block id="e196c3365de079c5ab9127511e0dd99c" category="list-text">nv set int swp1-16,33-40 Bridge-Domäne br_default</block>
  <block id="807ec963a7ac91bb05d484cf2aedb28c" category="list-text">nv set int bond1-20 Bridge-Domäne br_default</block>
  <block id="812bc6c1e22132212f3bd611d2be624b" category="list-text">Aktivieren Sie RoCE auf jedem Switch</block>
  <block id="5b474542c656a524ee80214d547f357f" category="list-text">nv set roce mode lossless</block>
  <block id="e1ddeeabdb3c578a39e7f7457c83adcb" category="list-text">Konfigurieren Sie VLANs – 2 für Client-Ports, 2 für Speicher-Ports, 1 für die Verwaltung, 1 für L3-Switch zu Switch</block>
  <block id="e8c935d4b4d1ac2ba8e60a311d4dd3e3" category="list-text">Schalter 1-</block>
  <block id="d0dbd46c5b3822649194130f76e47a74" category="list-text">VLAN 3 für L3-Switch-zu-Switch-Routing im Falle eines Client-NIC-Ausfalls</block>
  <block id="4d0ddcd703c2db59dd2b93a0864f348e" category="list-text">VLAN 101 für Speicherport 1 auf jedem DGX-System (enp170s0f0np0, Slot1-Port 1)</block>
  <block id="988d3fe9d9a9c24bdfaf0d1e8c04c718" category="list-text">VLAN 102 für Port e6a und e11a auf jedem AFF A90 Speichercontroller</block>
  <block id="8534bf29bf68cf0b3a4ef8fc1c8367ef" category="list-text">VLAN 301 für die Verwaltung über die MLAG-Schnittstellen zu jedem DGX-System und Speichercontroller</block>
  <block id="decdf257b13a488f92fa3c1f3c758e26" category="list-text">Schalter 2-</block>
  <block id="9d406d38f0c9d262294560c3ffe601e6" category="list-text">VLAN 201 für Speicherport 2 auf jedem DGX-System (enp41s0f0np0, Slot2-Port 1)</block>
  <block id="ad80d15b1164d5cda913549da61e6aa3" category="list-text">VLAN 202 für Port e6b und e11b auf jedem AFF A90 Speichercontroller</block>
  <block id="09417c9a09b9c4ceb39f1b21b0c805ce" category="list-text">Weisen Sie jedem VLAN die entsprechenden physischen Ports zu, z. B. Client-Ports in Client-VLANs und Speicher-Ports in Speicher-VLANs.</block>
  <block id="30add6fef18e27847f71d245bce4adf2" category="list-text">nv set int &lt;swpX&gt; Bridge-Domäne br_default access &lt;VLAN-ID&gt;</block>
  <block id="8c088863d87c4744d16775f50bd22826" category="list-text">MLAG-Ports sollten als Trunk-Ports verbleiben, um bei Bedarf mehrere VLANs über die verbundenen Schnittstellen zu ermöglichen.</block>
  <block id="dc7dbdf7949b0253d64542d3a6648b53" category="list-text">Konfigurieren Sie Switch Virtual Interfaces (SVI) auf jedem VLAN, um als Gateway zu fungieren und L3-Routing zu aktivieren</block>
  <block id="bbc11fb8434953cf5f8a56090594c94e" category="list-text">nv set int vlan3 IP-Adresse 100.127.0.0/31</block>
  <block id="56a4338a8bbb720e395dea767276043e" category="list-text">nv set int vlan101 IP-Adresse 100.127.101.1/24</block>
  <block id="c88e27e83683371775c79ed4db025a42" category="list-text">nv set int vlan102 IP-Adresse 100.127.102.1/24</block>
  <block id="c8e18763efa8332ade09b61ec6c43e79" category="list-text">nv set int vlan3 IP-Adresse 100.127.0.1/31</block>
  <block id="d39015045c0b670844a63ea89a0558e1" category="list-text">nv set int vlan201 IP-Adresse 100.127.201.1/24</block>
  <block id="72caedfc84ea977b468f72cc81db5b0f" category="list-text">nv set int vlan202 IP-Adresse 100.127.202.1/24</block>
  <block id="4d86d7ad33785bddc3f3227d7cfe8c00" category="list-text">Erstellen statischer Routen</block>
  <block id="957e71bdd90bad3e445176749a6e839a" category="list-text">Statische Routen werden automatisch für Subnetze auf demselben Switch erstellt</block>
  <block id="ba77f5caf647fd0155f2edd382f4c005" category="list-text">Für das Switch-to-Switch-Routing sind im Falle eines Client-Link-Ausfalls zusätzliche statische Routen erforderlich.</block>
  <block id="cb6543cc4fa221dc0cadbcce30a3d708" category="list-text">nv set vrf Standardrouter statisch 100.127.128.0/17 über 100.127.0.1</block>
  <block id="3616a5e3448d387e297a217363fcd491" category="list-text">nv set vrf default router static 100.127.0.0/17 via 100.127.0.0</block>
  <block id="2139fe384d5ae165545994dff01961d9" category="section-title">Speichersystemkonfiguration</block>
  <block id="eb75aeb3b4b2b9734ba3e52f5483f0b2" category="inline-link-macro">ONTAP-Dokumentation</block>
  <block id="6c077f840844078f56944a0699577ff6" category="paragraph">In diesem Abschnitt werden die wichtigsten Details zur Konfiguration des A90-Speichersystems für diese Lösung beschrieben.  Weitere Einzelheiten zur Konfiguration von ONTAP -Systemen finden Sie im<block ref="c9be69f343f12523b36264fad0c62551" category="inline-link-macro-rx"></block> .  Das folgende Diagramm zeigt die logische Konfiguration des Speichersystems.</block>
  <block id="a2720bc0a2d05de970087a0c7fad9311" category="paragraph">Die grundlegenden Schritte zur Konfiguration des Speichersystems werden unten beschrieben.  Dieser Vorgang setzt voraus, dass die grundlegende Installation des Speicherclusters abgeschlossen ist.</block>
  <block id="a65ed1368170b15ddddd6ee0b2408084" category="list-text">Konfigurieren Sie 1 Aggregat auf jedem Controller mit allen verfügbaren Partitionen abzüglich 1 Ersatz</block>
  <block id="104afbbbf990a88bdaee0bb7222c4b8e" category="list-text">aggr create -node &lt;Knoten&gt; -aggregate &lt;Knoten&gt;_data01 -diskcount &lt;47&gt;</block>
  <block id="40531cd604f58d3ba347b865243c7e48" category="list-text">Konfigurieren Sie ifgrps auf jedem Controller</block>
  <block id="f72dfa57e15677b92e70b5a144e0b5f9" category="list-text">Netzport ifgrp erstellen -node &lt;Knoten&gt; -ifgrp a1a -mode multimode_lacp -distr-function port</block>
  <block id="55be7178bd14f4153f1b019457ede4a9" category="list-text">net port ifgrp add-port -node &lt;Knoten&gt; -ifgrp &lt;ifgrp&gt; -ports &lt;Knoten&gt;:e2a,&lt;Knoten&gt;:e2b</block>
  <block id="b13faeadb39006cbcc1d3c2e50344bf1" category="list-text">Konfigurieren Sie den Mgmt-VLAN-Port auf IFgrp auf jedem Controller</block>
  <block id="e6e28ccd055fb443d6dd14a9a6eb7d1a" category="list-text">net port vlan erstellen -node aff-a90-01 -port a1a -vlan-id 31</block>
  <block id="f740c9ebcb9caacb0b5d819655c488ed" category="list-text">net port vlan erstellen -node aff-a90-02 -port a1a -vlan-id 31</block>
  <block id="5d71abf584a26ed36de342533bc6b11f" category="list-text">net port vlan erstellen -node aff-a90-03 -port a1a -vlan-id 31</block>
  <block id="21e3a0fbbbf79005355b371bbcdd44e6" category="list-text">net port vlan erstellen -node aff-a90-04 -port a1a -vlan-id 31</block>
  <block id="cd002818e71e3e15ea7d845a92b82053" category="list-text">Erstellen von Broadcastdomänen</block>
  <block id="060c8e724635c9585153496e36c5fe64" category="list-text">Broadcast-Domäne erstellen -Broadcast-Domäne vlan21 -MTU 9000 -Ports aff-a90-01:e6a,aff-a90-01:e11a,aff-a90-02:e6a,aff-a90-02:e11a,aff-a90-03:e6a,aff-a90-03:e11a,aff-a90-04:e6a,aff-a90-04:e11a</block>
  <block id="f0375c78fd286627e0ea2e893298127b" category="list-text">Broadcast-Domäne erstellen -Broadcast-Domäne vlan22 -MTU 9000 -Ports aaff-a90-01:e6b,aff-a90-01:e11b,aff-a90-02:e6b,aff-a90-02:e11b,aff-a90-03:e6b,aff-a90-03:e11b,aff-a90-04:e6b,aff-a90-04:e11b</block>
  <block id="46bd5a85171233df8aad89e1ea34eca2" category="list-text">Broadcast-Domäne erstellen -Broadcast-Domäne vlan31 -MTU 9000 -Ports aff-a90-01:a1a-31,aff-a90-02:a1a-31,aff-a90-03:a1a-31,aff-a90-04:a1a-31</block>
  <block id="623ea6b05fb05729ffd64b3aecd6e969" category="list-text">Management-SVM erstellen *</block>
  <block id="5619023db11b9124790191d573fd6c9a" category="list-text">Konfigurieren der Verwaltungs-SVM</block>
  <block id="a085de8c20c0316efb0b620d42f96f5d" category="list-text">LIF erstellen</block>
  <block id="f2a8aff28094374e836aba88837e4ecd" category="list-text">net int create -vserver basepod-mgmt -lif vlan31-01 -home-node aff-a90-01 -home-port a1a-31 -address 192.168.31.X -netmask 255.255.255.0</block>
  <block id="025643e2f4f3d8255f6a74703e817f10" category="list-text">FlexGroup -Volumes erstellen-</block>
  <block id="ff251de7d10dfd4d224adb00c9771d80" category="list-text">vol erstellen -vserver basepod-mgmt -volume home -size 10T -auto-provision-as flexgroup -junction-path /home</block>
  <block id="7eadd281ac9fa05f29dd10931c800b73" category="list-text">vol erstellen -vserver basepod-mgmt -volume cm -size 10T -auto-provision-as flexgroup -junction-path /cm</block>
  <block id="4daa96de5bcd998457adea84b3b0d3f2" category="list-text">Exportrichtlinie erstellen</block>
  <block id="0224cbf10aded53062d1c33a00ed3f00" category="list-text">Exportrichtlinienregel erstellen -vserver basepod-mgmt -policy default -client-match 192.168.31.0/24 -rorule sys -rwrule sys -superuser sys</block>
  <block id="d5c522a3ee4c4fb65fcbe94d031d0a08" category="list-text">Daten-SVM erstellen *</block>
  <block id="6310e0b69ca3cd6447bec629307180b7" category="list-text">Daten-SVM konfigurieren</block>
  <block id="8aa04063c0eff21564b4943f7c5bd0af" category="list-text">Konfigurieren Sie SVM für RDMA-Unterstützung</block>
  <block id="f67ee8861066661a87085502a485f642" category="list-text">vserver nfs modify -vserver basepod-data -rdma enabled</block>
  <block id="f29cc71670e3362a894e54ea9924917c" category="list-text">LIFs erstellen</block>
  <block id="3df4cfdffe24b83cba807ded784fb107" category="list-text">net int create -vserver basepod-data -lif c1-6a-lif1 -home-node aff-a90-01 -home-port e6a -address 100.127.102.101 -netmask 255.255.255.0</block>
  <block id="26a6d29a1530006b710e49ad940bc64a" category="list-text">net int create -vserver basepod-data -lif c1-6a-lif2 -home-node aff-a90-01 -home-port e6a -address 100.127.102.102 -netmask 255.255.255.0</block>
  <block id="985d0d4d212dc0238d9f101fee0a3418" category="list-text">net int create -vserver basepod-data -lif c1-6b-lif1 -home-node aff-a90-01 -home-port e6b -address 100.127.202.101 -netmask 255.255.255.0</block>
  <block id="07f93d0815d9e298cb8b02049c677706" category="list-text">net int create -vserver basepod-data -lif c1-6b-lif2 -home-node aff-a90-01 -home-port e6b -address 100.127.202.102 -netmask 255.255.255.0</block>
  <block id="2d977106413211171eefeeb51af2bdf7" category="list-text">net int create -vserver basepod-data -lif c1-11a-lif1 -home-node aff-a90-01 -home-port e11a -address 100.127.102.103 -netmask 255.255.255.0</block>
  <block id="10d75b950d2d9634a2804a1ed92f0df7" category="list-text">net int create -vserver basepod-data -lif c1-11a-lif2 -home-node aff-a90-01 -home-port e11a -address 100.127.102.104 -netmask 255.255.255.0</block>
  <block id="7e3ec60a178738ba9ac6680a6bf6340d" category="list-text">net int create -vserver basepod-data -lif c1-11b-lif1 -home-node aff-a90-01 -home-port e11b -address 100.127.202.103 -netmask 255.255.255.0</block>
  <block id="b14efeaf4c17d63f2e6011dc35f5722c" category="list-text">net int create -vserver basepod-data -lif c1-11b-lif2 -home-node aff-a90-01 -home-port e11b -address 100.127.202.104 -netmask 255.255.255.0</block>
  <block id="74c24c93e98c023e9fe31988005f6735" category="list-text">net int create -vserver basepod-data -lif c2-6a-lif1 -home-node aff-a90-02 -home-port e6a -address 100.127.102.105 -netmask 255.255.255.0</block>
  <block id="d00b578414c1bb9f219c72ef1262d701" category="list-text">net int create -vserver basepod-data -lif c2-6a-lif2 -home-node aff-a90-02 -home-port e6a -address 100.127.102.106 -netmask 255.255.255.0</block>
  <block id="c49b52997695ebd048410b0b8f9f19f2" category="list-text">net int create -vserver basepod-data -lif c2-6b-lif1 -home-node aff-a90-02 -home-port e6b -address 100.127.202.105 -netmask 255.255.255.0</block>
  <block id="912c10c91d670dee279852756245a063" category="list-text">net int create -vserver basepod-data -lif c2-6b-lif2 -home-node aff-a90-02 -home-port e6b -address 100.127.202.106 -netmask 255.255.255.0</block>
  <block id="031724ef6867c2ff3771e70c8520b1d0" category="list-text">net int create -vserver basepod-data -lif c2-11a-lif1 -home-node aff-a90-02 -home-port e11a -address 100.127.102.107 -netmask 255.255.255.0</block>
  <block id="8b417c98283cde9dc265541e2455e2f5" category="list-text">net int create -vserver basepod-data -lif c2-11a-lif2 -home-node aff-a90-02 -home-port e11a -address 100.127.102.108 -netmask 255.255.255.0</block>
  <block id="f129b43cd7a26c7049c4340ac4ef86e1" category="list-text">net int create -vserver basepod-data -lif c2-11b-lif1 -home-node aff-a90-02 -home-port e11b -address 100.127.202.107 -netmask 255.255.255.0</block>
  <block id="5a6d6f4dbbb1d6f8f5558b1c36f5e671" category="list-text">net int create -vserver basepod-data -lif c2-11b-lif2 -home-node aff-a90-02 -home-port e11b -address 100.127.202.108 -netmask 255.255.255.0</block>
  <block id="057f5c63653dacba830db83ad6ad78ee" category="list-text">Konfigurieren von LIFs für RDMA-Zugriff</block>
  <block id="ea7a0f026442b56683f1e50cb21a0d06" category="list-text">Bei Bereitstellungen mit ONTAP 9.15.1 erfordert die RoCE-QoS-Konfiguration für physische Informationen Befehle auf Betriebssystemebene, die in der ONTAP CLI nicht verfügbar sind.  Wenden Sie sich an den NetApp -Support, um Hilfe bei der Konfiguration der Ports für die RoCE-Unterstützung zu erhalten.  NFS über RDMA funktioniert ohne Probleme</block>
  <block id="2e94a4ea05164067f4cb6f27639c8b7a" category="list-text">Ab ONTAP 9.16.1 werden physische Schnittstellen automatisch mit den entsprechenden Einstellungen für die End-to-End-RoCE-Unterstützung konfiguriert.</block>
  <block id="95f5fd496607048d9a2d17c6c6577aa2" category="list-text">net int modifizieren -vserver basepod-data -lif * -rdma-protocols roce</block>
  <block id="29789a25d415e0f3b5d8cef38626fadc" category="list-text">Konfigurieren Sie NFS-Parameter auf der Daten-SVM</block>
  <block id="37013073e580c7f2ed500849958f49cd" category="list-text">nfs ändern -vserver basepod-data -v4.1 aktiviert -v4.1-pnfs aktiviert -v4.1-trunking aktiviert -tcp-max-transfer-size 262144</block>
  <block id="8f7c2b974d2b68275b99738f2db92da7" category="list-text">FlexGroup -Volumes erstellen-</block>
  <block id="375a2038f90b0da452502ee281313fdd" category="list-text">vol erstellen -vserver basepod-data -volume data -size 100T -auto-provision-as flexgroup -junction-path /data</block>
  <block id="48e79d83943623a53289accfc05a7108" category="list-text">Exportrichtlinie erstellen</block>
  <block id="f36c67518ab2b84b8b81ef59c8d30976" category="list-text">Exportrichtlinienregel erstellen -vserver basepod-data -policy default -client-match 100.127.101.0/24 -rorule sys -rwrule sys -superuser sys</block>
  <block id="738b25d5c96222859fa0d9f34e585e1d" category="list-text">Exportrichtlinienregel erstellen -vserver basepod-data -policy default -client-match 100.127.201.0/24 -rorule sys -rwrule sys -superuser sys</block>
  <block id="14f424e270715fb6e8bf7277cb075650" category="list-text">Routen erstellen</block>
  <block id="086c700f168ee8ad618b80e189d3ab75" category="list-text">Route hinzufügen -vserver basepod_data -destination 100.127.0.0/17 -gateway 100.127.102.1 Metrik 20</block>
  <block id="e6bf4bcbe9f12d429928fe014e660008" category="list-text">Route hinzufügen -vserver basepod_data -destination 100.127.0.0/17 -gateway 100.127.202.1 Metrik 30</block>
  <block id="35dc59e7fce425d44a0f407fcd227c43" category="list-text">Route hinzufügen -vserver basepod_data -destination 100.127.128.0/17 -gateway 100.127.202.1 Metrik 20</block>
  <block id="50a387548848ab61afe342aa18b992c7" category="list-text">Route hinzufügen -vserver basepod_data -destination 100.127.128.0/17 -gateway 100.127.102.1 Metrik 30</block>
  <block id="dc8a99ae9ee0b79d432c8eac1124edb5" category="section-title">DGX H100-Konfiguration für RoCE-Speicherzugriff</block>
  <block id="206274d0712987318a4f897f7e6ae75c" category="inline-link-macro">BCM-Dokumentation</block>
  <block id="0448e5984ca30c8aeeb162534801fe92" category="paragraph">In diesem Abschnitt werden die wichtigsten Details zur Konfiguration der DGX H100-Systeme beschrieben.  Viele dieser Konfigurationselemente können in das auf den DGX-Systemen bereitgestellte Betriebssystem-Image aufgenommen oder beim Booten vom Base Command Manager implementiert werden.  Sie sind hier als Referenz aufgeführt. Weitere Informationen zum Konfigurieren von Knoten und Software-Images in BCM finden Sie im<block ref="21b53d84e45529faee31545df8020d3b" category="inline-link-macro-rx"></block> .</block>
  <block id="12211cca460b22741ca0d08e3f60fb0c" category="list-text">Installieren Sie zusätzliche Pakete</block>
  <block id="0df162aa5e7703fc2c2a77a7d1d5a1fe" category="list-text">ipmitool</block>
  <block id="e08cb560fa0fac340ce6e958daaf5e4d" category="list-text">python3-pip</block>
  <block id="8cd5d0cdb86cde9f0dc88352811817ec" category="list-text">Installieren Sie Python-Pakete</block>
  <block id="32760a760ea625ddb856e92f3b089802" category="list-text">Paramiko</block>
  <block id="f02113237a5a5fff03e34c9eeeb46640" category="list-text">matplotlib</block>
  <block id="9b162ba267ba83b0a5f5cb6cdbe972dd" category="list-text">Konfigurieren Sie dpkg nach der Paketinstallation neu</block>
  <block id="a8bc68a93f8c901b4a33e27af2f21da0" category="list-text">dpkg --configure -a</block>
  <block id="0243e3d81be4d79f622d517c103c3ae0" category="list-text">Installieren von MOFED</block>
  <block id="08c24ffe86544b752cd2764895595237" category="list-text">Legen Sie die MST-Werte zur Leistungsoptimierung fest</block>
  <block id="d5bedef65a3750cb3c0a2b86f80a11e4" category="list-text">mstconfig -y -d &lt;aa:00.0,29:00.0&gt; set ADVANCED_PCI_SETTINGS=1 NUM_OF_VFS=0 MAX_ACC_OUT_READ=44</block>
  <block id="bdacbd6c214d3cc42e1d1f8305ef92c9" category="list-text">Setzen Sie die Adapter nach dem Ändern der Einstellungen zurück</block>
  <block id="9af48ffdb9436775e220fda80ded47ad" category="list-text">mlxfwreset -d &lt;aa:00.0,29:00.0&gt; -y zurücksetzen</block>
  <block id="c7cb0d4934d36b9bb0816b3a5c49f0b1" category="list-text">MaxReadReq auf PCI-Geräten festlegen</block>
  <block id="1a252b6a7629ccb0f15527f8ca5f627c" category="list-text">setpci -s &lt;aa:00.0,29:00.0&gt; 68.W=5957</block>
  <block id="29aaf92306610006fe7ce7d8c90411ca" category="list-text">Legen Sie die Größe des RX- und TX-Ringpuffers fest</block>
  <block id="3d789bdc86cf1d51f9b23d11b808ddd5" category="list-text">ethtool -G &lt;enp170s0f0np0,enp41s0f0np0&gt; rx 8192 tx 8192</block>
  <block id="a0340fb71fb195f79ce47dabe6242f8e" category="list-text">Legen Sie PFC und DSCP mit mlnx_qos fest</block>
  <block id="6537005ab5e42cbee146ce9b17d892d8" category="list-text">mlnx_qos -i &lt;enp170s0f0np0,enp41s0f0np0&gt; --pfc 0,0,0,1,0,0,0,0 --trust=dscp --cable_len=3</block>
  <block id="a277efb29c974f8ae6d1925383335b05" category="list-text">Legen Sie ToS für RoCE-Verkehr auf Netzwerkports fest</block>
  <block id="8c1e8c1481d777723e305f147f16012d" category="list-text">echo 106 &gt; /sys/class/infiniband/&lt;mlx5_7,mlx5_1&gt;/tc/1/traffic_class</block>
  <block id="05dae9ad2cfb95dc1f78bc696aa0d6a4" category="list-text">Konfigurieren Sie jede Speicher-NIC mit einer IP-Adresse im entsprechenden Subnetz</block>
  <block id="fa2bddc64b24b8cd13f0be734ce934ca" category="list-text">100.127.101.0/24 für Speicher-NIC 1</block>
  <block id="945382c87aa13867b8b36da66c8ae8fc" category="list-text">100.127.201.0/24 für Speicher-NIC 2</block>
  <block id="ed769c091c9112ad2d1a5c89de5c0c65" category="list-text">Konfigurieren Sie In-Band-Netzwerkports für LACP-Bonding (enp170s0f1np1,enp41s0f1np1).</block>
  <block id="af487da74a6eeea9aa52d90c5c8cd04d" category="list-text">Konfigurieren Sie statische Routen für primäre und sekundäre Pfade zu jedem Speichersubnetz</block>
  <block id="593c13037333a6722527c42d1d0b156c" category="list-text">Route hinzufügen –net 100.127.0.0/17 gw 100.127.101.1 Metrik 20</block>
  <block id="8656e83d4d88a713f09d848f3cc09702" category="list-text">Route hinzufügen –net 100.127.0.0/17 gw 100.127.201.1 Metrik 30</block>
  <block id="85f6d08b3d54f8d8785ef6f36f7c61c3" category="list-text">Route hinzufügen –net 100.127.128.0/17 gw 100.127.201.1 Metrik 20</block>
  <block id="d70120de1b67fd20affa2557aca990ef" category="list-text">Route hinzufügen –net 100.127.128.0/17 gw 100.127.101.1 Metrik 30</block>
  <block id="7fc2f78e0bd34dcefec071f2a70514c2" category="list-text">Mounten Sie das /home-Volume</block>
  <block id="9ff7402ee00f4969ccc4395a7241c47c" category="list-text">mount -o vers=3,nconnect=16,rsize=262144,wsize=262144 192.168.31.X:/home /home</block>
  <block id="152cd866abad6e43429948eb4715b973" category="list-text">Mounten/Datenvolumen</block>
  <block id="1cd39f0089800bb9511317cc53d73557" category="list-text">Beim Mounten des Datenvolumes wurden die folgenden Mount-Optionen verwendet:</block>
  <block id="bcd39ebb3417a185678d6de2189af4b9" category="list-text">vers=4.1 # aktiviert pNFS für den parallelen Zugriff auf mehrere Speicherknoten</block>
  <block id="5cd472c72f4b3a3c75cbdb77edc30528" category="list-text">proto=rdma # setzt das Übertragungsprotokoll auf RDMA statt auf das Standard-TCP</block>
  <block id="f8553c0c0cde0245d779c37090c093a7" category="list-text">max_connect=16 # aktiviert NFS-Sitzungs-Trunking, um die Bandbreite des Speicherports zu aggregieren</block>
  <block id="f8a3438d5712d48a22100c8109ea556e" category="list-text">write=eager # verbessert die Schreibleistung von gepufferten Schreibvorgängen</block>
  <block id="42fdb382646439a01d661ce9d2127a1c" category="list-text">rsize=262144,wsize=262144 # setzt die I/O-Übertragungsgröße auf 256k</block>
  <block id="7f86b6f2a05fc6e5c5931f73e9af29fd" category="summary">NetApp AIPod mit NVIDIA DGX-Systemen – Hardwarekomponenten</block>
  <block id="7c451f18f811f88a48907bf86377cdd8" category="doc">NVA-1173 NetApp AIPod mit NVIDIA DGX-Systemen – Hardwarekomponenten</block>
  <block id="bd6e083031bf15817a67b63cc58a211c" category="paragraph">Dieser Abschnitt konzentriert sich auf die Hardwarekomponenten für den NetApp AIPod mit NVIDIA DGX-Systemen.</block>
  <block id="68674fa5fbd6fb83969183d07d48b8cd" category="section-title">NetApp AFF -Speichersysteme</block>
  <block id="3b6d33ce139758ecf9b0b83f9ecce001" category="paragraph">Mit den hochmodernen AFF -Speichersystemen von NetApp können IT-Abteilungen die Speicheranforderungen von Unternehmen mit branchenführender Leistung, überragender Flexibilität, Cloud-Integration und erstklassigem Datenmanagement erfüllen.  AFF -Systeme wurden speziell für Flash entwickelt und helfen bei der Beschleunigung, Verwaltung und dem Schutz geschäftskritischer Daten.</block>
  <block id="d1d40f451fb75b4e7160785e64a75da3" category="section-title">AFF A90 Speichersysteme</block>
  <block id="df7df1dd54ea101ca8a417ee258e2693" category="paragraph">Der NetApp AFF A90 mit der Datenverwaltungssoftware NetApp ONTAP bietet integrierten Datenschutz, optionale Anti-Ransomware-Funktionen sowie die hohe Leistung und Ausfallsicherheit, die zur Unterstützung der kritischsten Geschäfts-Workloads erforderlich sind.  Es verhindert Störungen unternehmenskritischer Vorgänge, minimiert die Leistungsoptimierung und schützt Ihre Daten vor Ransomware-Angriffen.  Es bietet: • Branchenführende Leistung • Kompromisslose Datensicherheit • Vereinfachte, unterbrechungsfreie Upgrades</block>
  <block id="6bd43dd4b56bb5bfe362d48a0d5219e0" category="paragraph">_NetApp AFF A90 Speichersystem_</block>
  <block id="df3fd00dc667f05e52f1e05b8dedfd55" category="paragraph"><block ref="df3fd00dc667f05e52f1e05b8dedfd55" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1863aa82dcf92831635aa05e975d399d" category="section-title">Branchenführende Leistung</block>
  <block id="a261fc6acbe5e140d750bc3f1dd8c7a7" category="paragraph">Die AFF A90 bewältigt problemlos Workloads der nächsten Generation wie Deep Learning, KI und Hochgeschwindigkeitsanalysen sowie traditionelle Unternehmensdatenbanken wie Oracle, SAP HANA, Microsoft SQL Server und virtualisierte Anwendungen.  Es sorgt dafür, dass geschäftskritische Anwendungen mit bis zu 2,4 Millionen IOPS pro HA-Paar und einer Latenz von nur 100 µs mit Höchstgeschwindigkeit ausgeführt werden – und steigert die Leistung im Vergleich zu früheren NetApp Modellen um bis zu 50 %.  Mit NFS über RDMA, pNFS und Session Trunking können Kunden mithilfe der vorhandenen Netzwerkinfrastruktur ihres Rechenzentrums die für Anwendungen der nächsten Generation erforderliche hohe Netzwerkleistung erreichen.  Kunden können außerdem mit einheitlicher Multiprotokollunterstützung für SAN, NAS und Objektspeicher skalieren und wachsen und mit einheitlicher und einzelner ONTAP Datenverwaltungssoftware für Daten vor Ort oder in der Cloud maximale Flexibilität erzielen.  Darüber hinaus kann die Systemintegrität mit KI-basierten prädiktiven Analysen von Active IQ und Cloud Insights optimiert werden.</block>
  <block id="773efff7a0bbe1582ceff936530b5ae3" category="section-title">Kompromisslose Datensicherheit</block>
  <block id="b867e6aa9b3e46766f55ab250eb69715" category="paragraph">AFF A90 -Systeme enthalten eine vollständige Suite integrierter und anwendungskonsistenter Datenschutzsoftware von NetApp .  Es bietet integrierten Datenschutz und hochmoderne Anti-Ransomware-Lösungen zur Vorbeugung und Wiederherstellung nach einem Angriff.  Das Schreiben schädlicher Dateien auf die Festplatte kann blockiert werden und Speicheranomalien können einfach überwacht werden, um Erkenntnisse zu gewinnen.</block>
  <block id="f6353452ddd71a9ef0e4d8578d7dc7e3" category="section-title">Vereinfachte, unterbrechungsfreie Upgrades</block>
  <block id="4015e152c676ca730da1d797ef1e9993" category="paragraph">Der AFF A90 ist als unterbrechungsfreies In-Chassis-Upgrade für bestehende A800-Kunden verfügbar.  NetApp vereinfacht die Aktualisierung und Beseitigung von Störungen unternehmenskritischer Vorgänge durch unsere erweiterten Funktionen für Zuverlässigkeit, Verfügbarkeit, Wartungsfreundlichkeit und Verwaltbarkeit (RASM).  Darüber hinaus steigert NetApp die Betriebseffizienz weiter und vereinfacht die täglichen Aktivitäten der IT-Teams, da die ONTAP -Software automatisch Firmware-Updates für alle Systemkomponenten anwendet.</block>
  <block id="13ab18b8510a80a65aefbf9a56e3b3d3" category="paragraph">Für die größten Bereitstellungen bieten AFF A1K -Systeme die höchsten Leistungs- und Kapazitätsoptionen, während andere NetApp Speichersysteme wie AFF A70 und AFF C800 Optionen für kleinere Bereitstellungen zu niedrigeren Kosten bieten.</block>
  <block id="3ebd416d1b3232ef4125025ab8f437a9" category="paragraph">NVIDIA DGX BasePOD ist eine integrierte Lösung, die aus NVIDIA -Hardware- und Softwarekomponenten, MLOps-Lösungen und Speicher von Drittanbietern besteht.  Durch die Nutzung bewährter Methoden des Scale-Out-Systemdesigns mit NVIDIA Produkten und validierten Partnerlösungen können Kunden eine effiziente und verwaltbare Plattform für die KI-Entwicklung implementieren.  Abbildung 1 zeigt die verschiedenen Komponenten von NVIDIA DGX BasePOD.</block>
  <block id="76d810a9cb0440f2de2c7104493e266f" category="paragraph">_NVIDIA DGX BasePOD-Lösung_</block>
  <block id="559d10ed60e21f546209442a6aade09d" category="paragraph"><block ref="559d10ed60e21f546209442a6aade09d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0a5f31a2eea3b274409614f4eb63433c" category="section-title">NVIDIA DGX H100-Systeme</block>
  <block id="2cdfa62855978fa129d36e4602f41e0b" category="paragraph">Das NVIDIA DGX H100™-System ist das KI-Kraftpaket, das durch die bahnbrechende Leistung der NVIDIA H100 Tensor Core GPU beschleunigt wird.</block>
  <block id="4a8da04b1b7a51ad2e9c77e221e0d9d9" category="paragraph">_NVIDIA DGX H100-System_</block>
  <block id="b9ab32cd1976da02bb3c074578d491c3" category="paragraph"><block ref="b9ab32cd1976da02bb3c074578d491c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="93b775e18b65e433d85d83ad863c1797" category="paragraph">Die wichtigsten Spezifikationen des DGX H100-Systems sind: • Acht NVIDIA H100-GPUs.  • 80 GB GPU-Speicher pro GPU, insgesamt 640 GB.  • Vier NVIDIA NVSwitch-Chips.  • Duale 56-Core Intel Xeon Platinum 8480-Prozessoren mit PCIe 5.0-Unterstützung.  • 2 TB DDR5-Systemspeicher.  • Vier OSFP-Ports für acht NVIDIA ConnectX-7-Adapter (InfiniBand/Ethernet) mit einem Port und zwei NVIDIA ConnectX-7-Adapter (InfiniBand/Ethernet) mit zwei Ports.  • Zwei 1,92 TB M.2 NVMe-Laufwerke für DGX OS, acht 3,84 TB U.2 NVMe-Laufwerke für Speicher/Cache.  • 10,2 kW maximale Leistung.  Die hinteren Anschlüsse des DGX H100 CPU-Fachs sind unten dargestellt.  Vier der OSFP-Ports bedienen acht ConnectX-7-Adapter für das InfiniBand-Compute-Fabric.  Jedes Paar ConnectX-7-Adapter mit zwei Anschlüssen bietet parallele Pfade zu den Speicher- und Verwaltungsstrukturen.  Der Out-of-Band-Port wird für den BMC Zugriff verwendet.</block>
  <block id="1811b955f76e78d806cc9f89eca9365d" category="paragraph">_Rückseite des NVIDIA DGX H100_</block>
  <block id="7d94d25261d22723cf1dcbc550472562" category="paragraph"><block ref="7d94d25261d22723cf1dcbc550472562" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e64325a640583a5afbe8ce27e88608e" category="section-title">NVIDIA Quantum-2 QM9700-Switch</block>
  <block id="96e834f144fffd019191dee8b2e3fa9e" category="paragraph">_NVIDIA Quantum-2 QM9700 InfiniBand-Schalter_</block>
  <block id="02e6cd41035da9c303b4223fcb954c57" category="paragraph"><block ref="02e6cd41035da9c303b4223fcb954c57" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58e83b10341e2ec3a48b164715b6ba34" category="paragraph">NVIDIA Quantum-2 QM9700-Switches mit 400 Gb/s InfiniBand-Konnektivität versorgen das Compute Fabric in NVIDIA Quantum-2 InfiniBand BasePOD-Konfigurationen mit Strom.  Für das InfiniBand-Compute-Fabric werden ConnectX-7-Einzelportadapter verwendet.  Jedes NVIDIA DGX-System verfügt über zwei Verbindungen zu jedem QM9700-Switch und bietet so mehrere Pfade mit hoher Bandbreite und geringer Latenz zwischen den Systemen.</block>
  <block id="88f086b3f05858ad120601108f0821a7" category="section-title">NVIDIA Spectrum-3 SN4600-Switch</block>
  <block id="69dc0a65b1f9cc56bf9d1b38913e279e" category="paragraph">_NVIDIA Spectrum-3 SN4600-Schalter_</block>
  <block id="a5317e31cdc481b4371010e9f47b541d" category="paragraph"><block ref="a5317e31cdc481b4371010e9f47b541d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="df2b71117642b0bdbf87a4e9d643c47e" category="paragraph">NVIDIA Spectrum™-3 SN4600-Switches bieten insgesamt 128 Ports (64 pro Switch), um redundante Konnektivität für die In-Band-Verwaltung des DGX BasePOD bereitzustellen.  Der NVIDIA SN4600-Switch kann Geschwindigkeiten zwischen 1 GbE und 200 GbE bereitstellen.  Für über Ethernet angeschlossene Speichergeräte werden ebenfalls die NVIDIA SN4600-Switches verwendet.  Die Ports der NVIDIA DGX Dual-Port ConnectX-7-Adapter werden sowohl für die In-Band-Verwaltung als auch für die Speicherkonnektivität verwendet.</block>
  <block id="9bc83d36ebb307eef9521860d72d6a83" category="section-title">NVIDIA Spectrum SN2201-Switch</block>
  <block id="0a58d2e4f07c9b74c7b9f0f643df366e" category="paragraph">_NVIDIA Spectrum SN2201-Schalter_</block>
  <block id="63573ea3854985f600f8cc8c44aa5bea" category="paragraph"><block ref="63573ea3854985f600f8cc8c44aa5bea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6714f3120a26d6eb7222fbbd52715a6c" category="paragraph">NVIDIA Spectrum SN2201-Switches bieten 48 Ports, um Konnektivität für Out-of-Band-Management bereitzustellen.  Out-of-Band-Management bietet konsolidierte Verwaltungskonnektivität für alle Komponenten in DGX BasePOD.</block>
  <block id="82e5da407cc33e26189f053503aa2bf6" category="section-title">NVIDIA ConnectX-7-Adapter</block>
  <block id="74baf984365e15a6f92345e68021621a" category="paragraph">_NVIDIA ConnectX-7-Adapter_</block>
  <block id="062446821e85b6d2c053705d69b2c037" category="paragraph"><block ref="062446821e85b6d2c053705d69b2c037" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1f31835004684d86091e359c9a240e92" category="paragraph">Der NVIDIA ConnectX-7-Adapter kann einen Durchsatz von 25/50/100/200/400 G bereitstellen.  NVIDIA DGX-Systeme verwenden sowohl die ConnectX-7-Adapter mit einem als auch mit zwei Anschlüssen, um Flexibilität bei DGX BasePOD-Bereitstellungen mit 400 Gb/s InfiniBand und Ethernet zu bieten.</block>
  <block id="9f68b039fbd3ecc8729ee9a4be7903ea" category="summary">NetApp AIPod mit NVIDIA DGX-Systemen ist eine unternehmensreife Referenzarchitektur basierend auf NVIDIA BasePOD für Deep Learning und künstliche Intelligenz unter Verwendung von NetApp ONTAP AFF -Speichersystemen und NVIDIA Netzwerk- und DGX-Systemen.</block>
  <block id="9b07efa8439fb4859742ace8bb15c070" category="doc">NVA-1173 NetApp AIPod mit NVIDIA DGX-Systemen – Einführung</block>
  <block id="03a5dba0ba7f06a853319a59ab10f1db" category="inline-image-macro">200,200,Fehler: Fehlendes Grafikbild</block>
  <block id="540456658a35dff79ec59aa1338d398e" category="paragraph"><block ref="540456658a35dff79ec59aa1338d398e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="217432d0ec5a422d97fdd8082983c438" category="paragraph">NetApp Solution Engineering</block>
  <block id="617f17b8f2c8c0557ec9f79c918464eb" category="paragraph">Der NetApp® AIPod mit NVIDIA DGX®-Systemen und NetApp Cloud-verbundenen Speichersystemen vereinfacht die Infrastrukturbereitstellung für Workloads im Bereich maschinelles Lernen (ML) und künstliche Intelligenz (KI), indem er Designkomplexität und Rätselraten eliminiert.  AIPod mit NVIDIA DGX-Systemen baut auf dem NVIDIA DGX BasePOD™-Design auf, um eine außergewöhnliche Rechenleistung für Workloads der nächsten Generation zu liefern, und fügt NetApp AFF Speichersysteme hinzu, die es Kunden ermöglichen, klein anzufangen und unterbrechungsfrei zu wachsen, während sie gleichzeitig Daten vom Rand über den Kern bis zur Cloud und zurück intelligent verwalten.  NetApp AIPod ist Teil des größeren Portfolios an NetApp KI-Lösungen, wie in der folgenden Abbildung dargestellt.</block>
  <block id="194ff09c8e869017b4ffe91887dde829" category="paragraph">_NetApp AI-Lösungsportfolio_</block>
  <block id="629225e0ba0d0325f35ee6fcfd7ebf4e" category="paragraph"><block ref="629225e0ba0d0325f35ee6fcfd7ebf4e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ff9a398ccda9f0fc1e44521cf40ca977" category="paragraph">Dieses Dokument beschreibt die Hauptkomponenten der AIPod -Referenzarchitektur, Informationen zur Systemkonnektivität und -konfiguration, Ergebnisse der Validierungstests und Leitlinien zur Größenbestimmung der Lösung.  Dieses Dokument richtet sich an Lösungsingenieure von NetApp und Partnern sowie an strategische Entscheidungsträger bei Kunden, die an der Bereitstellung einer Hochleistungsinfrastruktur für ML/DL- und Analyse-Workloads interessiert sind.</block>
  <block id="77f2324c2483df30f029d522599f882e" category="summary">NetApp AIPod mit NVIDIA DGX-Systemen – Softwarekomponenten</block>
  <block id="751547b5efb176a435e672a4015bb7e9" category="doc">NVA-1173 NetApp AIPod mit NVIDIA DGX-Systemen – Softwarekomponenten</block>
  <block id="c3d68fb38e0db372152f5a3a84fed148" category="paragraph">Dieser Abschnitt konzentriert sich auf die Softwarekomponenten des NetApp AIPod mit NVIDIA DGX-Systemen.</block>
  <block id="5475410ded0787143601d2206a245532" category="section-title">NVIDIA -Software</block>
  <block id="96a0475a5e6d02d46b5b8d7f1327a530" category="paragraph">NVIDIA Base Command™ treibt jeden DGX BasePOD an und ermöglicht es Unternehmen, das Beste der NVIDIA -Softwareinnovation zu nutzen.  Unternehmen können das volle Potenzial ihrer Investition mit einer bewährten Plattform ausschöpfen, die Orchestrierung und Clusterverwaltung auf Unternehmensniveau, Bibliotheken zur Beschleunigung der Rechen-, Speicher- und Netzwerkinfrastruktur sowie ein für KI-Workloads optimiertes Betriebssystem (OS) umfasst.</block>
  <block id="f30878d7bf93bf61a8d0a25e397a8583" category="paragraph">_NVIDIA BaseCommand-Lösung_</block>
  <block id="26997aefe36f4fb8a168ede0ec7189e1" category="paragraph"><block ref="26997aefe36f4fb8a168ede0ec7189e1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9052758d35faeab8995feefc50d729ed" category="section-title">NVIDIA GPU Cloud (NGC)</block>
  <block id="5cbbb9592d14a268aacbc5ecd838a166" category="paragraph">NVIDIA NGC bietet Software, die den Anforderungen von Datenwissenschaftlern, Entwicklern und Forschern mit unterschiedlichem KI-Fachwissen gerecht wird.  Auf NGC gehostete Software wird auf einen aggregierten Satz gängiger Schwachstellen und Gefährdungen (CVEs), Kryptografie und privater Schlüssel geprüft.  Es ist für die Skalierung auf mehrere GPUs und in vielen Fällen auf mehrere Knoten getestet und konzipiert, um sicherzustellen, dass Benutzer ihre Investition in DGX-Systeme maximieren.</block>
  <block id="d19c3b09db45ed579ed1aa2895637b7d" category="paragraph">_NVIDIA GPU Cloud_</block>
  <block id="c46997ba8e7fdf0cb96f12b451129203" category="paragraph"><block ref="c46997ba8e7fdf0cb96f12b451129203" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b4d69ee10ecec0ac3d21aba6691dc53" category="paragraph">NVIDIA AI Enterprise ist die End-to-End-Softwareplattform, die generative KI für jedes Unternehmen erreichbar macht und die schnellste und effizienteste Laufzeit für generative KI-Basismodelle bietet, die für die Ausführung auf der NVIDIA DGX-Plattform optimiert sind.  Mit produktionsreifer Sicherheit, Stabilität und Verwaltbarkeit rationalisiert es die Entwicklung generativer KI-Lösungen.  NVIDIA AI Enterprise ist in DGX BasePOD enthalten, damit Unternehmensentwickler auf vortrainierte Modelle, optimierte Frameworks, Microservices, beschleunigte Bibliotheken und Unternehmenssupport zugreifen können.</block>
  <block id="9aeccfb63defa46cb78ffa3611d362c6" category="section-title">NetApp Software</block>
  <block id="f45c2aa2e74e3412ee9883eb28b7549e" category="paragraph">ONTAP 9, die neueste Generation der Speicherverwaltungssoftware von NetApp, ermöglicht Unternehmen die Modernisierung ihrer Infrastruktur und den Übergang zu einem Cloud-fähigen Rechenzentrum.  Durch die Nutzung branchenführender Datenverwaltungsfunktionen ermöglicht ONTAP die Verwaltung und den Schutz von Daten mit einem einzigen Satz von Tools, unabhängig davon, wo sich diese Daten befinden.  Sie können Daten auch frei dorthin verschieben, wo sie benötigt werden: an den Rand, in den Kern oder in die Cloud.  ONTAP 9 umfasst zahlreiche Funktionen, die die Datenverwaltung vereinfachen, kritische Daten beschleunigen und schützen und Infrastrukturfunktionen der nächsten Generation in Hybrid-Cloud-Architekturen ermöglichen.</block>
  <block id="28e23b5888c04e1859e75c594c6cec26" category="section-title">Beschleunigen und schützen Sie Daten</block>
  <block id="d9cd75773d759d63134b34db3490eab3" category="paragraph">ONTAP bietet ein Höchstmaß an Leistung und Datenschutz und erweitert diese Funktionen auf folgende Weise:</block>
  <block id="7c282a19ff405710e49738f9d0a03a85" category="list-text">Leistung und geringere Latenz.  ONTAP bietet den höchstmöglichen Durchsatz bei der geringstmöglichen Latenz, einschließlich Unterstützung für NVIDIA GPUDirect Storage (GDS) mit NFS über RDMA, parallelem NFS (pNFS) und NFS-Sitzungs-Trunking.</block>
  <block id="b2d0aaf645ff5747fbe1e0aec0cf528c" category="list-text">Datenschutz.  ONTAP bietet integrierte Datenschutzfunktionen und die branchenweit stärkste Anti-Ransomware-Garantie mit gemeinsamer Verwaltung über alle Plattformen hinweg.</block>
  <block id="892dd840b39835d7da795bbd29f99987" category="list-text">NetApp Volume Encryption (NVE).  ONTAP bietet native Verschlüsselung auf Volume-Ebene mit Unterstützung für integriertes und externes Schlüsselmanagement.</block>
  <block id="651928f77d87184265ec1be1ab0b8aff" category="list-text">Mandantenfähigkeit der Speicherung und Multifaktor-Authentifizierung.  ONTAP ermöglicht die gemeinsame Nutzung von Infrastrukturressourcen mit höchster Sicherheit.</block>
  <block id="f1586460cef11d0abaaf5270f37f18d7" category="section-title">Vereinfachen Sie die Datenverwaltung</block>
  <block id="47b2e74e56111387efd2ff8314d1154c" category="paragraph">Das Datenmanagement ist für den IT-Betrieb in Unternehmen und für Datenwissenschaftler von entscheidender Bedeutung, damit für KI-Anwendungen und das Training von KI/ML-Datensätzen die richtigen Ressourcen verwendet werden.  Die folgenden zusätzlichen Informationen zu NetApp -Technologien fallen nicht in den Geltungsbereich dieser Validierung, können jedoch je nach Bereitstellung relevant sein.</block>
  <block id="31c0318dee8b7049a328f752c457824f" category="paragraph">Die ONTAP Datenmanagementsoftware umfasst die folgenden Funktionen zur Optimierung und Vereinfachung von Abläufen und zur Senkung Ihrer Gesamtbetriebskosten:</block>
  <block id="621721e0b0144695aabce4090fa40eed" category="list-text">Snapshots und Klone ermöglichen Zusammenarbeit, paralleles Experimentieren und verbesserte Datenverwaltung für ML/DL-Workflows.</block>
  <block id="b1932ff070760d4f32c0a3701982558d" category="list-text">SnapMirror ermöglicht eine nahtlose Datenbewegung in Hybrid-Cloud- und Multi-Site-Umgebungen und stellt Daten bereit, wo und wann sie benötigt werden.</block>
  <block id="258ce6748736436345d3a4ade7bfcd47" category="list-text">Inline-Datenkomprimierung und erweiterte Deduplizierung.  Durch die Datenkomprimierung wird der verschwendete Speicherplatz in Speicherblöcken reduziert und durch die Deduplizierung wird die effektive Kapazität erheblich erhöht.  Dies gilt für lokal gespeicherte Daten und für in der Cloud gespeicherte Daten.</block>
  <block id="e0243dd3e4c9bff6b7a18cab1c1e37c8" category="list-text">Minimale, maximale und adaptive Dienstqualität (AQoS).  Durch granulare Quality of Service (QoS)-Kontrollen wird die Aufrechterhaltung des Leistungsniveaus kritischer Anwendungen in Umgebungen mit hoher gemeinsamer Nutzung unterstützt.</block>
  <block id="74959a361bdb223dafbb94226dd84e3e" category="list-text">NetApp FlexGroups ermöglichen die Verteilung von Daten auf alle Knoten im Speichercluster und bieten enorme Kapazität und höhere Leistung für extrem große Datensätze.</block>
  <block id="c3528a5e48bbe189e76cf8d737aa5961" category="inline-link">TR-4598: Best Practices für FabricPool</block>
  <block id="adc171e1d8b6a0bed3a98762139c9875" category="list-text">NetApp FabricPool.  Bietet automatisches Tiering von Cold Data für öffentliche und private Cloud-Speicheroptionen, einschließlich Amazon Web Services (AWS), Azure und der NetApp StorageGRID -Speicherlösung.  Weitere Informationen zu FabricPool finden Sie unter<block ref="234c921b7066bc1bdd676ae1a510e5c5" category="inline-link-rx"></block> .</block>
  <block id="eec4aeb85db42cd9055b9aba24052c7e" category="list-text">NetApp FlexCache.  Bietet Remote-Volume-Caching-Funktionen, die die Dateiverteilung vereinfachen, die WAN-Latenz reduzieren und die WAN-Bandbreitenkosten senken.  FlexCache ermöglicht die verteilte Produktentwicklung über mehrere Standorte hinweg sowie einen beschleunigten Zugriff auf Unternehmensdatensätze von entfernten Standorten aus.</block>
  <block id="685f280ead44650493627d9ac47818e1" category="section-title">Zukunftssichere Infrastruktur</block>
  <block id="836ed833c0dea3b588f04d16ca3f850d" category="paragraph">ONTAP unterstützt Sie mit den folgenden Funktionen bei der Erfüllung anspruchsvoller und sich ständig ändernder Geschäftsanforderungen:</block>
  <block id="483e92f76323d9d7b2d7f2ec6d4c0590" category="list-text">Nahtlose Skalierung und unterbrechungsfreier Betrieb.  ONTAP unterstützt die Online-Kapazitätserweiterung bestehender Controller und Scale-Out-Cluster.  Kunden können ohne kostspielige Datenmigrationen oder Ausfälle auf die neuesten Technologien wie NVMe und 32 GB FC upgraden.</block>
  <block id="96cf8f94fadb527d958ae5373082d6d7" category="list-text">Cloud-Verbindung.  ONTAP ist die Speicherverwaltungssoftware mit der stärksten Cloud-Anbindung und bietet Optionen für softwaredefinierten Speicher (ONTAP Select) und Cloud-native Instanzen (Google Cloud NetApp Volumes) in allen öffentlichen Clouds.</block>
  <block id="2a7e7bc180cc3d059089e02f091bac27" category="list-text">Integration mit neuen Anwendungen.  ONTAP bietet Datendienste der Enterprise-Klasse für Plattformen und Anwendungen der nächsten Generation, wie etwa autonome Fahrzeuge, Smart Cities und Industrie 4.0, und nutzt dabei dieselbe Infrastruktur, die auch bestehende Unternehmens-Apps unterstützt.</block>
  <block id="2c7194a99a4f7de8ffbf3ba400a92df8" category="paragraph">Das NetApp DataOps Toolkit ist ein Python-basiertes Tool, das die Verwaltung von Entwicklungs-/Schulungsarbeitsbereichen und Inferenzservern vereinfacht, die durch leistungsstarken, skalierbaren NetApp -Speicher unterstützt werden.  Das DataOps Toolkit kann als eigenständiges Dienstprogramm betrieben werden und ist in Kubernetes-Umgebungen, in denen NetApp Trident zur Automatisierung von Speichervorgängen genutzt wird, noch effektiver.  Zu den wichtigsten Funktionen gehören:</block>
  <block id="f9e55f3095ff79acd2c7f6315222ba4a" category="list-text">Stellen Sie schnell neue JupyterLab-Arbeitsbereiche mit hoher Kapazität bereit, die durch leistungsstarken, skalierbaren NetApp Speicher unterstützt werden.</block>
  <block id="a9e4b1a2cc4b445907d2b986ab2f3515" category="list-text">Stellen Sie schnell neue NVIDIA Triton Inference Server-Instanzen bereit, die durch NetApp -Speicher der Enterprise-Klasse unterstützt werden.</block>
  <block id="44ce48cceac53b351ab54ca5685fcf55" category="list-text">Nahezu sofortiges Klonen von JupyterLab-Arbeitsbereichen mit hoher Kapazität, um Experimente oder schnelle Iterationen zu ermöglichen.</block>
  <block id="b47bad7e2a479b14e613be5ba1af90a0" category="list-text">Nahezu sofortige Snapshots von JupyterLab-Arbeitsbereichen mit hoher Kapazität für Backups und/oder Rückverfolgbarkeit/Baselining.</block>
  <block id="afe9b022bbe49ebc232dc11679a61bb4" category="list-text">Nahezu sofortige Bereitstellung, Klonen und Snapshots von Datenvolumes mit hoher Kapazität und hoher Leistung.</block>
  <block id="b242f57e51b5f507797a088899c22df7" category="paragraph">Trident ist ein vollständig unterstützter Open-Source-Speicherorchestrator für Container und Kubernetes-Distributionen, einschließlich Anthos. Trident funktioniert mit dem gesamten NetApp -Speicherportfolio, einschließlich NetApp ONTAP, und unterstützt auch NFS-, NVMe/TCP- und iSCSI-Verbindungen. Trident beschleunigt den DevOps-Workflow, indem es Endbenutzern ermöglicht, Speicher von ihren NetApp -Speichersystemen bereitzustellen und zu verwalten, ohne dass ein Speicheradministrator eingreifen muss.</block>
  <block id="1efc1a71dad2451e243efa783d9aaba0" category="summary">NetApp AIPod mit NVIDIA DGX-Systemen – Leitfaden zur Lösungsvalidierung und Größenbestimmung</block>
  <block id="1baf67b0ad3fef1cc60370bda6ebc7f9" category="doc">NVA-1173 NetApp AIPod mit NVIDIA DGX-Systemen – Leitfaden zur Lösungsvalidierung und Größenbestimmung</block>
  <block id="d2fb9fca0fa09d949a54ae42e337c891" category="paragraph">Dieser Abschnitt konzentriert sich auf die Lösungsvalidierung und Größenrichtlinien für den NetApp AIPod mit NVIDIA DGX-Systemen.</block>
  <block id="773a9689ba6682deeabffa6746d64105" category="section-title">Lösungsvalidierung</block>
  <block id="364bed9cbf28e51b3a87b1cece482054" category="paragraph">Die Speicherkonfiguration in dieser Lösung wurde mithilfe einer Reihe synthetischer Workloads unter Verwendung des Open-Source-Tools FIO validiert.  Diese Tests umfassen Lese- und Schreib-E/A-Muster, die die Speicherarbeitslast simulieren sollen, die von DGX-Systemen generiert wird, die Deep-Learning-Trainingsjobs ausführen.  Die Speicherkonfiguration wurde mithilfe eines Clusters aus 2-Sockel-CPU-Servern validiert, auf denen die FIO-Workloads gleichzeitig ausgeführt wurden, um einen Cluster aus DGX-Systemen zu simulieren.  Jeder Client wurde mit der gleichen Netzwerkkonfiguration wie zuvor beschrieben konfiguriert, wobei die folgenden Details hinzugefügt wurden.</block>
  <block id="5c553fedff3f40a2af76bb0c410b404f" category="paragraph">Für diese Validierung wurden die folgenden Mount-Optionen verwendet:</block>
  <block id="cb8472643b1176f8340370ce5a0b204d" category="cell">vers=4.1</block>
  <block id="893b3a13ba8b6b5a60094306461bc370" category="cell">ermöglicht pNFS für den parallelen Zugriff auf mehrere Speicherknoten</block>
  <block id="1df213ce94ed5cdef706c9350768f0c2" category="cell">proto=rdma</block>
  <block id="42cc89ba8e1299f3640ad771a94abfaa" category="cell">setzt das Übertragungsprotokoll auf RDMA statt auf das Standard-TCP</block>
  <block id="9b7b56ffe75ec2daff44ba8923725d27" category="cell">Port=20049</block>
  <block id="52c223170500f2f347a266328f0c4216" category="cell">Geben Sie den richtigen Port für den RDMA-NFS-Dienst an</block>
  <block id="5b75616cf8bcd004a7fb0c78bcf4cb1e" category="cell">max_connect=16</block>
  <block id="82264615e17e10dec975d19de56f7e01" category="cell">ermöglicht NFS-Sitzungsbündelung zur Aggregation der Speicherportbandbreite</block>
  <block id="b0b79785aa490d51befbe60046fe59a6" category="cell">schreiben=eifrig</block>
  <block id="27d6ebb9c804f9228e43f1362d2ad502" category="cell">verbessert die Schreibleistung gepufferter Schreibvorgänge</block>
  <block id="df2285a23b7de4affb43985a03a9b955" category="cell">rsize=262144,wsize=262144</block>
  <block id="226cf9c18b16f30e1381d76500dcd2c3" category="cell">setzt die I/O-Transfergröße auf 256k</block>
  <block id="1275e87e965ab2e83ee1a3d508393bb1" category="paragraph">Darüber hinaus wurden die Clients mit einem NFS-max_session_slots-Wert von 1024 konfiguriert.  Da die Lösung mit NFS über RDMA getestet wurde, wurden die Ports der Speichernetzwerke mit einer aktiven/passiven Verbindung konfiguriert.  Für diese Validierung wurden folgende Bindungsparameter verwendet:</block>
  <block id="dc2f1400a2999b58888391b52366d42d" category="cell">Modus=aktive Sicherung</block>
  <block id="ceafe9fbea6d2853c0ef101fde263114" category="cell">setzt die Bindung in den Aktiv/Passiv-Modus</block>
  <block id="0772e25cb688aaddbfcafe9a95042ae0" category="cell">primary=&lt;Schnittstellenname&gt;</block>
  <block id="126d68b093e92a0eeafa0ea632b5dee2" category="cell">Primäre Schnittstellen für alle Clients wurden auf die Switches verteilt</block>
  <block id="cbfd831ae9cd4bbc2c5955b278fc1464" category="cell">mii-monitor-interval=100</block>
  <block id="ef530a18c3e08c2e1454d98413c8995a" category="cell">gibt Überwachungsintervall von 100ms an</block>
  <block id="4a7a0a399fdd09cc77725d4bca22c5d2" category="cell">Failover-Mac-Richtlinie = aktiv</block>
  <block id="1cddea1ebc0f8a54ddb9d1b5d3701199" category="cell">gibt an, dass die MAC-Adresse des aktiven Links die MAC der Verbindung ist.  Dies ist für den ordnungsgemäßen Betrieb von RDMA über die verbundene Schnittstelle erforderlich.</block>
  <block id="13e766ae456cff38288a10e042da1460" category="paragraph">Das Speichersystem wurde wie beschrieben mit zwei A900 HA-Paaren (4 Controller) mit zwei NS224-Festplattenregalen mit 24 1,9 TB NVMe-Festplatten konfiguriert, die an jedes HA-Paar angeschlossen waren.  Wie im Abschnitt zur Architektur erwähnt, wurde die Speicherkapazität aller Controller mithilfe eines FlexGroup Volumes kombiniert und die Daten aller Clients auf alle Controller im Cluster verteilt.</block>
  <block id="4534545218c3df22ad30ec5ab0466128" category="section-title">Leitfaden zur Größenbestimmung von Speichersystemen</block>
  <block id="e58e8ec46be51c65fb6895529b19620c" category="paragraph">NetApp hat die DGX BasePOD-Zertifizierung erfolgreich abgeschlossen und die beiden getesteten A90 HA-Paare können problemlos einen Cluster aus sechzehn DGX H100-Systemen unterstützen.  Für größere Bereitstellungen mit höheren Anforderungen an die Speicherleistung können dem NetApp ONTAP -Cluster zusätzliche AFF -Systeme hinzugefügt werden, bis zu 12 HA-Paare (24 Knoten) in einem einzigen Cluster.  Mithilfe der in dieser Lösung beschriebenen FlexGroup -Technologie kann ein Cluster mit 24 Knoten über 79 PB und bis zu 552 GBps Durchsatz in einem einzigen Namespace bereitstellen.  Andere NetApp Speichersysteme wie AFF A400, A250 und C800 bieten Optionen mit geringerer Leistung und/oder höherer Kapazität für kleinere Bereitstellungen zu niedrigeren Kosten.  Da ONTAP 9 Cluster mit gemischten Modellen unterstützt, können Kunden mit einem kleineren anfänglichen Footprint beginnen und dem Cluster weitere oder größere Speichersysteme hinzufügen, wenn die Kapazitäts- und Leistungsanforderungen steigen.  Die folgende Tabelle zeigt eine grobe Schätzung der Anzahl der von jedem AFF Modell unterstützten A100- und H100-GPUs.</block>
  <block id="d151e6348ab5291d10caeda2db802b75" category="paragraph">_Leitfaden zur Größenbestimmung von NetApp-Speichersystemen_</block>
  <block id="c61d72d95f504983715ce76fcfdfb864" category="paragraph"><block ref="c61d72d95f504983715ce76fcfdfb864" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28e8b3e83af233fe7085ba954fc6fd36" category="doc">BeeGFS auf NetApp mit E-Series Storage</block>
  <block id="e8afe31a21b6aae9717484d865743dae" category="paragraph">BeeGFS auf NetApp mit E-Series-Speicher ist eine bewährte, integrierte Lösung mit einer einfachen, zuverlässigen, skalierbaren und kostengünstigen HPC-Infrastruktur, die mit Ihren extremsten Workloads Schritt hält.</block>
  <block id="d18d454d6ae7128c6b49bf41c9ea2cf4" category="paragraph"><block ref="d18d454d6ae7128c6b49bf41c9ea2cf4" category="inline-link-macro-rx"></block></block>
  <block id="fcf432f7f886df6aeafb1dec9357085d" category="doc">NVA-1150-DEPLOY: Quantum StorNext mit NetApp E-Series-Systemen – Bereitstellungshandbuch</block>
  <block id="806008ac96286a2e08058ba3a3daa601" category="paragraph">Ryan Rodine, NetApp</block>
  <block id="25dbf1b5193ae9eff63687c18c19e6f5" category="paragraph">Dieses Dokument enthält Einzelheiten zur Bereitstellung einer parallelen StorNext-Dateisystemlösung mit Speichersystemen der NetApp E-Serie.  Diese Lösung umfasst das NetApp EF280 All-Flash-Array, das NetApp EF300 All-Flash-NVMe-Array, das NetApp EF600 All-Flash-NVMe-Array und das NetApp E5760-Hybridsystem.  Es bietet eine Leistungscharakterisierung basierend auf Frametest-Benchmarking, einem Tool, das in der Medien- und Unterhaltungsbranche häufig zum Testen verwendet wird.</block>
  <block id="a06fe4c2db4f7b09c705e4e8dafb5627" category="paragraph"><block ref="a06fe4c2db4f7b09c705e4e8dafb5627" category="inline-link-macro-rx"></block></block>
  <block id="96f5c57f6fea73d6692c5f8c2703e9b9" category="doc">NVA-1150-DESIGN: Designhandbuch für Quantum StorNext mit NetApp E-Series-Systemen</block>
  <block id="5ee668b979e736471a8d46609abdc49b" category="paragraph">Dieses Dokument enthält Einzelheiten zum Entwerfen einer parallelen StorNext-Dateisystemlösung mit Speichersystemen der NetApp E-Serie.  Diese Lösung umfasst das NetApp EF280 All-Flash-Array, das NetApp EF300 All-Flash-NVMe-Array, das EF600 All-Flash-NVMe-Array und das NetApp E5760-Hybridsystem.  Es bietet eine Leistungscharakterisierung basierend auf Frametest-Benchmarking, einem Tool, das in der Medien- und Unterhaltungsbranche häufig zum Testen verwendet wird.</block>
  <block id="4f8b12df588cb1e82eb6d578f26c6c62" category="paragraph"><block ref="4f8b12df588cb1e82eb6d578f26c6c62" category="inline-link-macro-rx"></block></block>
  <block id="bf6adc497a862180909278cf6ed029f1" category="doc">TR-4859: Bereitstellung von IBM Spectrum Scale mit NetApp E-Series-Speicher – Installation und Validierung</block>
  <block id="7d8a7f37eb34080960253271b824ab2f" category="paragraph">Chris Seirer, NetApp</block>
  <block id="06bd55c4b576fd1f13eb5e25a1415bba" category="paragraph">TR-4859 beschreibt den Prozess der Bereitstellung einer vollständig parallelen Dateisystemlösung basierend auf dem Spectrum Scale-Software-Stack von IBM.  TR-4859 soll Einzelheiten zur Installation von Spectrum Scale, zur Validierung der Infrastruktur und zur Verwaltung der Konfiguration bereitstellen.</block>
  <block id="6a51aeb3b4e11ee4436f8ad323e23c5a" category="paragraph"><block ref="6a51aeb3b4e11ee4436f8ad323e23c5a" category="inline-link-macro-rx"></block></block>
  <block id="3026654be6be955b54735554371ee5a0" category="summary">Diese NetApp Verified Architecture beschreibt das Design des NVIDIA DGX SuperPOD mit NetApp BeeGFS-Bausteinen.  Bei dieser Lösung handelt es sich um eine Full-Stack-Rechenzentrumsplattform, die auf einem dedizierten Abnahmecluster bei NVIDIA validiert wird.</block>
  <block id="85505186d8e84ecff8e7e71596423747" category="doc">NVIDIA DGX SuperPOD mit NetApp – Designleitfaden</block>
  <block id="49ba6c0ee9149acc4bdb6fac5165b7b0" category="paragraph">Diese NetApp Verified Architecture beschreibt das Design des NVIDIA DGX SuperPOD mit NetApp BeeGFS-Bausteinen.  Bei dieser Lösung handelt es sich um eine Full-Stack-Rechenzentrumsplattform, die auf einem dedizierten Akzeptanzcluster bei NVIDIA validiert wurde.</block>
  <block id="adb0b7d6a9d5c0af32d1c6fe9a103229" category="inline-image-macro">200.200</block>
  <block id="0a8dfa4d72d5f9b29ce5ac529286b37f" category="paragraph"><block ref="0a8dfa4d72d5f9b29ce5ac529286b37f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0a7225e9429ab905378b45f3aa288040" category="paragraph">Amine Bennani, Christian Whiteside, David Arnette und Sathish Thyagarajan, NetApp</block>
  <block id="7919e821dc18f3e88c0201e01bf6a240" category="section-title">Zusammenfassung</block>
  <block id="d83b5adf97fe549e1dc83bb95e6f2cdf" category="paragraph">In der heutigen, sich schnell entwickelnden Technologielandschaft revolutioniert KI das Kundenerlebnis und treibt Innovationen in allen Branchen voran.  Allerdings stellt es auch erhebliche Herausforderungen für IT-Abteilungen dar, die unter dem Druck stehen, High-Performance-Computing-Lösungen (HPC) einzusetzen, die den hohen Anforderungen von KI-Workloads gewachsen sind.  Während Unternehmen darum wetteifern, die Leistungsfähigkeit der KI zu nutzen, wächst die Dringlichkeit einer Lösung, die einfach bereitzustellen, zu skalieren und zu verwalten ist.</block>
  <block id="2e93342ec6458064edd50d209383c787" category="paragraph">NVIDIA DGX SuperPOD ist eine KI-Rechenzentrumsinfrastrukturplattform, die als schlüsselfertige Lösung für die IT bereitgestellt wird, um die komplexesten KI-Workloads zu unterstützen, mit denen Unternehmen heute konfrontiert sind.  Den Kern jedes präzisen Deep-Learning-Modells (DL) bilden große Datenmengen, die eine Hochdurchsatz-Speicherlösung erfordern, die diese Daten effizient bereitstellen und erneut bereitstellen kann.  Die NetApp BeeGFS-Lösung, bestehend aus NetApp EF600-Speicherarrays mit dem parallelen BeeGFS-Dateisystem, ermöglicht es dem NVIDIA DGX SuperPOD, sein volles Potenzial zu entfalten.  Die NetApp BeeGFS-Lösung wurde von NVIDIA für die Integration und Skalierung mit der SuperPOD-Architektur validiert.  Das Ergebnis ist eine vereinfachte Bereitstellung und Verwaltung von KI-Rechenzentren bei gleichzeitig nahezu unbegrenzter Skalierbarkeit hinsichtlich Leistung und Kapazität.</block>
  <block id="77e585eeb67a682a6445c0154fd9a028" category="paragraph">Die NetApp BeeGFS-Lösung, die auf den leistungsstarken NetApp EF600 NVMe-Speichersystemen und dem skalierbaren parallelen BeeGFS-Dateisystem basiert, bietet eine robuste und effiziente Speichergrundlage für anspruchsvolle KI-Workloads.  Seine Shared-Disk-Architektur gewährleistet hohe Verfügbarkeit und sorgt für gleichbleibende Leistung und Zugänglichkeit, selbst bei Systemproblemen.  Diese Lösung bietet eine skalierbare und flexible Architektur, die an unterschiedliche Speicheranforderungen angepasst werden kann.  Kunden können ihre Speicherleistung und -kapazität problemlos erweitern, indem sie zusätzliche Speicherbausteine integrieren, um selbst die anspruchsvollsten Arbeitslasten zu bewältigen.</block>
  <block id="1ad3f73d04f7a3d0b225d62bf707c034" category="list-text">NVIDIA DGX SuperPOD nutzt DGX H100- und H200-Systeme mit einem validierten, extern angeschlossenen gemeinsam genutzten Speicher:</block>
  <block id="8dc89fa0c821b38b2ab07d3f5dd4385f" category="list-text">Jede skalierbare DGX SuperPOD-Einheit (SU) besteht aus 32 DGX-Systemen und ist zu einer KI-Leistung von 640 PetaFLOPS bei FP8-Präzision fähig.  NetApp empfiehlt, die NetApp BeeGFS-Speicherlösung mit mindestens 2 Bausteinen für eine einzelne DGX SuperPOD-Konfiguration zu dimensionieren.</block>
  <block id="0aa799745475dedefbc0785863494b75" category="paragraph">_Eine Übersicht über die Lösung_</block>
  <block id="0e06b8493198d6e7d8d53d9201ddd9bc" category="inline-image-macro">Abbildung mit einer allgemeinen Übersicht über die NetApp BeeGFS-Lösung mit einem NVIDIA DGX SuperPOD.</block>
  <block id="6bfc1196652f29c394bdbe8e2807a4a0" category="paragraph"><block ref="6bfc1196652f29c394bdbe8e2807a4a0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="949e06b94ff43763386683593267b5d3" category="list-text">Die NetApp BeeGFS-Bausteine bestehen aus zwei NetApp EF600-Arrays und zwei x86-Servern:</block>
  <block id="53a59094fc8cf61c8ceb5488c68798f9" category="list-text">Mit den All-Flash-Arrays NetApp EF600 als Grundlage von NVIDIA DGX SuperPOD erhalten Kunden eine zuverlässige Speichergrundlage mit einer Verfügbarkeit von 9 ...</block>
  <block id="23830778b135794055062035d895d122" category="list-text">Die Dateisystemschicht zwischen den NetApp EF600- und den NVIDIA DGX-Systemen ist das parallele Dateisystem BeeGFS.  BeeGFS wurde vom Fraunhofer-Zentrum für Hochleistungsrechnen in Deutschland entwickelt, um die Schwachstellen älterer paralleler Dateisysteme zu lösen.  Das Ergebnis ist ein Dateisystem mit einer modernen User-Space-Architektur, das jetzt von ThinkParQ entwickelt und bereitgestellt und von vielen Supercomputing-Umgebungen verwendet wird.</block>
  <block id="d6dbc9a4d449d8584f1bc7766a233055" category="list-text">Der NetApp -Support für BeeGFS richtet die hervorragende Support-Organisation von NetApp an den Kundenanforderungen hinsichtlich Leistung und Verfügbarkeit aus.  Kunden erhalten Zugriff auf erstklassige Supportressourcen, frühzeitigen Zugriff auf BeeGFS-Versionen und Zugriff auf ausgewählte BeeGFS-Unternehmensfunktionen wie Quotendurchsetzung und Hochverfügbarkeit (HA).</block>
  <block id="06723075d010c851032e77543613704f" category="list-text">Die Kombination aus NVIDIA SuperPOD SUs und NetApp BeeGFS-Bausteinen bietet eine agile KI-Lösung, bei der Rechenleistung oder Speicher einfach und nahtlos skaliert werden können.</block>
  <block id="e0d00c6a1325f01dc14822163a1d43fe" category="paragraph">_NetApp BeeGFS-Baustein_</block>
  <block id="f2ccf42799ed738590ee8a95c9a2e5c9" category="inline-image-macro">Abbildung, die einen einzelnen NetApp BeeGFS-Baustein zeigt.</block>
  <block id="9390da63574f67fe268b45392cf0ec3e" category="paragraph"><block ref="9390da63574f67fe268b45392cf0ec3e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="df07b47923825d5392c14e80cea2d72a" category="section-title">Zusammenfassung des Anwendungsfalls</block>
  <block id="976894dcc596e37094668684315ccac4" category="paragraph">Diese Lösung gilt für die folgenden Anwendungsfälle:</block>
  <block id="30e31e5dc6388c3434cea1711261b743" category="list-text">Künstliche Intelligenz (KI), einschließlich maschinelles Lernen (ML), Deep Learning (DL), Verarbeitung natürlicher Sprache (NLP), Verständnis natürlicher Sprache (NLU) und generative KI (GenAI).</block>
  <block id="c21f50752fbbe8f54e46848c0f9ce70a" category="list-text">KI-Training im mittleren bis großen Maßstab</block>
  <block id="137c3bef49af695737b7c23000204b5c" category="list-text">Computer Vision, Sprache, Audio und Sprachmodelle</block>
  <block id="15ed9179636b107f0a88e83f782e6cec" category="list-text">HPC, einschließlich Anwendungen, die durch Message Passing Interface (MPI) und andere verteilte Computertechniken beschleunigt werden</block>
  <block id="90b7289b464ec4d544bf5a9eacbaf7f0" category="list-text">Anwendungs-Workloads, die durch Folgendes gekennzeichnet sind:</block>
  <block id="c9ccfce7935790c9fd0d9ccf98da5177" category="list-text">Lesen oder Schreiben in Dateien, die größer als 1 GB sind</block>
  <block id="680e47afa4860ce2ac4a078a0d466121" category="list-text">Lesen oder Schreiben in dieselbe Datei durch mehrere Clients (10er, 100er und 1000er)</block>
  <block id="af7aa0607b7f1d728a529edd21a52763" category="list-text">Multiterabyte- oder Multipetabyte-Datensätze</block>
  <block id="efc155766b6000aefdf459d6ff3ecd75" category="list-text">Umgebungen, die einen einzigen Speichernamespace benötigen, der für eine Mischung aus großen und kleinen Dateien optimiert werden kann</block>
  <block id="dcbd8f687e2ef904380c2b6c942c989e" category="paragraph">Dieser Abschnitt behandelt die Technologieanforderungen für die NVIDIA DGX SuperPOD Lösung mit NetApp .</block>
  <block id="b95d6ba22cd7d0fb6a3c655d4c24d180" category="inline-link">NVIDIA DGX H100 SuperPOD-Referenzarchitektur</block>
  <block id="02399dc2f4ffe6e6772456736a8522d7" category="inline-link">NVA-1164-DESIGN: BeeGFS auf NetApp NVA-Design</block>
  <block id="5425be0e2232456057166446265f9a88" category="paragraph">In der folgenden Tabelle 1 sind die Hardwarekomponenten aufgeführt, die zur Implementierung der Lösung für eine einzelne SU erforderlich sind.  Die Dimensionierung der Lösung beginnt mit 32 NVIDIA DGX H100-Systemen und zwei oder drei NetApp BeeGFS-Bausteinen.  Ein einzelner NetApp BeeGFS-Baustein besteht aus zwei NetApp EF600-Arrays und zwei x86-Servern.  Kunden können zusätzliche Bausteine hinzufügen, wenn die Bereitstellungsgröße zunimmt.  Weitere Informationen finden Sie im<block ref="55ded0354bf42e7e117b50dda2359a8a" category="inline-link-rx"></block> Und<block ref="de7b61948f391c0bb69985cc0357d2a5" category="inline-link-rx"></block> .</block>
  <block id="5aa595c84818428979f9fa2d99bb6f83" category="cell">NVIDIA DGX H100 oder H200</block>
  <block id="6364d3f0f495b6ab9dcf8d3b5c6e0b01" category="cell">32</block>
  <block id="eef6c1a81c81a43f02e2b7749d260ef5" category="cell">NVIDIA Quantum QM9700-Switches</block>
  <block id="34a2c495ed1b62db3e0fffd75420aca5" category="cell">8 Blätter, 4 Rücken</block>
  <block id="be3accc5713b4d53186215779c2deeed" category="cell">NetApp BeeGFS-Bausteine</block>
  <block id="0dbcb15fd014d19061fb2910f0a1ab0e" category="paragraph">In der folgenden Tabelle 2 sind die zur Implementierung der Lösung erforderlichen Softwarekomponenten aufgeführt.  Die in einer bestimmten Implementierung der Lösung verwendeten Softwarekomponenten können je nach Kundenanforderungen variieren.</block>
  <block id="b9e807b01f3ef86c9dfed350c8c3d49f" category="cell">NVIDIA DGX-Software-Stack</block>
  <block id="32ac4a04c126e4e450b2f93ae6cfd3a7" category="cell">Paralleles Dateisystem ThinkParQ BeeGFS</block>
  <block id="dc140913e754c7554bc598a02951fa66" category="section-title">Lösungsüberprüfung</block>
  <block id="f95f7879d178879af0b5a728259ce9a3" category="inline-link">NVIDIA DGX SuperPOD: NetApp EF600 und BeeGFS-Referenzarchitektur</block>
  <block id="24e45924f52e38078756fd5fb1d83668" category="paragraph">NVIDIA DGX SuperPOD mit NetApp wurde auf einem dedizierten Akzeptanzcluster bei NVIDIA unter Verwendung von NetApp BeeGFS-Bausteinen validiert.  Die Annahmekriterien basierten auf einer Reihe von Anwendungs-, Leistungs- und Belastungstests, die von NVIDIA durchgeführt wurden. Weitere Informationen finden Sie im<block ref="2ffc6657f5234f1aed913433d4ce09f3" category="inline-link-rx"></block> .</block>
  <block id="b7f81445ff8908f0aa2a3356e8231f05" category="paragraph">NetApp und NVIDIA arbeiten seit langem zusammen, um ein Portfolio von KI-Lösungen auf den Markt zu bringen.  NVIDIA DGX SuperPOD mit dem NetApp EF600 All-Flash-Array ist eine bewährte, validierte Lösung, die Kunden bedenkenlos einsetzen können.  Diese vollständig integrierte, schlüsselfertige Architektur eliminiert das Risiko der Bereitstellung und ermöglicht jedem, das Rennen um die KI-Führung zu gewinnen.</block>
  <block id="dcd86a18e8aa77675f1b2f792cb6ba5c" category="inline-link-macro">NVIDIA DGX SuperPOD -Referenzarchitektur</block>
  <block id="98d56828382118fe5dcd8ef673b93afb" category="list-text"><block ref="98d56828382118fe5dcd8ef673b93afb" category="inline-link-macro-rx"></block></block>
  <block id="4fafe9ef5c2efce123913e9ac744f4d6" category="inline-link-macro">NVIDIA DGX SuperPOD Referenzhandbuch zum Design von Rechenzentren</block>
  <block id="473bfb82bbec433a8f08fa15c67e0c08" category="list-text"><block ref="473bfb82bbec433a8f08fa15c67e0c08" category="inline-link-macro-rx"></block></block>
  <block id="6f698ddb1773933b8e41b2ed16297ce7" category="inline-link-macro">NVIDIA DGX SuperPOD: NetApp EF600 und BeeGFS</block>
  <block id="a552f45479fc3484a4356ed78090fa76" category="list-text"><block ref="7f25f2868948e2fffc54c32cf9c33644" category="inline-link-macro-rx"></block></block>
  <block id="58415f353579ec62f4e5d8047761a3cc" category="summary">KI-gesteuerte Automatisierung und Edge Computing sind ein führender Ansatz, der Unternehmen dabei unterstützt, die digitale Transformation zu erreichen und die betriebliche Effizienz und Sicherheit zu maximieren.  Mit Edge Computing werden Daten viel schneller verarbeitet, da sie nicht zu und von einem Rechenzentrum transportiert werden müssen.  Dadurch werden die Kosten für das Hin- und Hersenden von Daten an Rechenzentren oder die Cloud verringert.</block>
  <block id="7d7c5045abef00692470c8d5ed1aeebd" category="paragraph">KI-gesteuerte Automatisierung und Edge Computing sind ein führender Ansatz, der Unternehmen dabei unterstützt, die digitale Transformation zu erreichen und die betriebliche Effizienz und Sicherheit zu maximieren.  Mit Edge Computing werden Daten viel schneller verarbeitet, da sie nicht zu und von einem Rechenzentrum transportiert werden müssen.  Dadurch werden die Kosten für das Hin- und Hersenden von Daten an Rechenzentren oder die Cloud verringert.  Eine geringere Latenz und eine höhere Geschwindigkeit können von Vorteil sein, wenn Unternehmen mithilfe von am Edge bereitgestellten KI-Inferenzmodellen Entscheidungen nahezu in Echtzeit treffen müssen.</block>
  <block id="691e8c5d8b13259848ef2e5515d14ca9" category="paragraph">NetApp -Speichersysteme bieten die gleiche oder eine bessere Leistung als lokaler SSD-Speicher und bieten Datenwissenschaftlern, Dateningenieuren, KI-/ML-Entwicklern sowie Geschäfts- oder IT-Entscheidungsträgern die folgenden Vorteile:</block>
  <block id="59ceee4c2b9743d6e9aae43f1e9ee547" category="list-text">Müheloses Teilen von Daten zwischen KI-Systemen, Analysen und anderen wichtigen Geschäftssystemen.  Diese gemeinsame Datennutzung reduziert den Infrastrukturaufwand, verbessert die Leistung und rationalisiert die Datenverwaltung im gesamten Unternehmen.</block>
  <block id="b9f30f0e1030c74a0db7ca1a1e82a22f" category="list-text">Unabhängig skalierbare Rechenleistung und Speicherung zur Minimierung der Kosten und Verbesserung der Ressourcennutzung.</block>
  <block id="40454c2a63608aacf0433b6a47f388f4" category="list-text">Optimierte Entwicklungs- und Bereitstellungs-Workflows durch integrierte Snapshot-Kopien und -Klone für sofortige und platzsparende Benutzerarbeitsbereiche, integrierte Versionskontrolle und automatisierte Bereitstellung.</block>
  <block id="0543f71645ff9108a860d92965cc1383" category="list-text">Unternehmensweiter Datenschutz für Notfallwiederherstellung und Geschäftskontinuität.  Bei der in diesem Dokument vorgestellten Lösung von NetApp und Lenovo handelt es sich um eine flexible, skalierbare Architektur, die sich ideal für KI-Inferenzbereitstellungen auf Unternehmensniveau am Edge eignet.</block>
  <block id="84ffd62e595c9d0122e136c3b255f4df" category="section-title">Danksagung</block>
  <block id="68c8080de8c25b2c95e86546db2c34f4" category="list-text">JJ  Falkanger, Senior Manager, HPC &amp; AI Solutions, Lenovo</block>
  <block id="a1be3af64bad65325413de79cbdd38ec" category="list-text">Dave Arnette, Technischer Marketingingenieur, NetApp</block>
  <block id="ab7eb4cf2e6900db95523411e2e2d968" category="list-text">Joey Parnell, Tech Lead E-Series AI Solutions, NetApp</block>
  <block id="7506341ffff969b3db4120a09a3cd873" category="list-text">Cody Harryman, QA-Ingenieur, NetApp</block>
  <block id="345245c83d2b2c4c2a5eb9f2887da627" category="paragraph">Weitere Informationen zu den in diesem Dokument beschriebenen Informationen finden Sie in den folgenden Dokumenten und/oder auf den folgenden Websites:</block>
  <block id="16d9e623379df2a050a5042b643bf4fc" category="list-text">Produktseite der NetApp AFF A-Series-Arrays</block>
  <block id="2eea2276b1fb61cd770f311f77c0f440" category="inline-link"><block ref="2eea2276b1fb61cd770f311f77c0f440" category="inline-link-rx"></block></block>
  <block id="3ac5561d8de2087fdd9ac49ace880bff" category="paragraph"><block ref="3ac5561d8de2087fdd9ac49ace880bff" category="inline-link-rx"></block></block>
  <block id="ac2e4973250b614c4ffed16837be9bda" category="list-text">NetApp ONTAP -Datenverwaltungssoftware – ONTAP 9-Informationsbibliothek</block>
  <block id="974aeb47ab8fd0a635d02d8ac80b9eb1" category="inline-link"><block ref="974aeb47ab8fd0a635d02d8ac80b9eb1" category="inline-link-rx"></block></block>
  <block id="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="paragraph"><block ref="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="inline-link-rx"></block></block>
  <block id="5dbac8b4dac620b04fd11b54388ac506" category="list-text">TR-4727: Einführung in die NetApp EF-Serie</block>
  <block id="3df74183de4e18a002d0a9dadd2b4b41" category="inline-link"><block ref="3df74183de4e18a002d0a9dadd2b4b41" category="inline-link-rx"></block></block>
  <block id="5e60359f54f57375f6417990b408bc8d" category="paragraph"><block ref="5e60359f54f57375f6417990b408bc8d" category="inline-link-rx"></block></block>
  <block id="bf8eb67f3476640d74487d7395b166a8" category="list-text">Datenblatt zur NetApp E-Series SANtricity Software</block>
  <block id="01e4cb0e0f13f033fd419d3abf905d34" category="inline-link"><block ref="01e4cb0e0f13f033fd419d3abf905d34" category="inline-link-rx"></block></block>
  <block id="62cabab367af4d0d4f74456d673e91e7" category="paragraph"><block ref="62cabab367af4d0d4f74456d673e91e7" category="inline-link-rx"></block></block>
  <block id="f11b61c13d771c4795415471f8362f8c" category="list-text">Persistenter NetApp -Speicher für Container – NetApp Trident</block>
  <block id="36c1c8df527a7721115f4ba53b5ea5a6" category="inline-link"><block ref="36c1c8df527a7721115f4ba53b5ea5a6" category="inline-link-rx"></block></block>
  <block id="e582bd0f584c041fb70164ea1502666b" category="paragraph"><block ref="e582bd0f584c041fb70164ea1502666b" category="inline-link-rx"></block></block>
  <block id="6bd5e585bc974f029ff9c7cc8a2b68dd" category="list-text">MLPerf</block>
  <block id="856500f909a4984692886f9549398b67" category="inline-link"><block ref="856500f909a4984692886f9549398b67" category="inline-link-rx"></block></block>
  <block id="fe6e33e3be237f2a488d04432ad4b35f" category="list-text"><block ref="fe6e33e3be237f2a488d04432ad4b35f" category="inline-link-rx"></block></block>
  <block id="9083657cbd1d0fb49ada01ab2e2cc193" category="inline-link"><block ref="9083657cbd1d0fb49ada01ab2e2cc193" category="inline-link-rx"></block></block>
  <block id="3de4b3f21621e41c0738a82d4e694114" category="list-text"><block ref="3de4b3f21621e41c0738a82d4e694114" category="inline-link-rx"></block></block>
  <block id="1f07318e5a4df96a96fc92d83bbe5d70" category="inline-link"><block ref="1f07318e5a4df96a96fc92d83bbe5d70" category="inline-link-rx"></block></block>
  <block id="25b3dca46bdabc4612ba4ba5dac0f9db" category="list-text"><block ref="25b3dca46bdabc4612ba4ba5dac0f9db" category="inline-link-rx"></block></block>
  <block id="b658c024dad07cbf1d8523e4c3ba8d21" category="inline-link"><block ref="b658c024dad07cbf1d8523e4c3ba8d21" category="inline-link-rx"></block></block>
  <block id="fdad8301fde8271edff994d643d18865" category="paragraph"><block ref="fdad8301fde8271edff994d643d18865" category="inline-link-rx"></block></block>
  <block id="7749687216549469e9a78db087fbb44b" category="list-text">TensorFlow-Benchmark</block>
  <block id="7c8f9b5afa9dfab5f8f375d1b977b046" category="inline-link"><block ref="7c8f9b5afa9dfab5f8f375d1b977b046" category="inline-link-rx"></block></block>
  <block id="be1b7087c9993d320070b1e676c832f9" category="paragraph"><block ref="be1b7087c9993d320070b1e676c832f9" category="inline-link-rx"></block></block>
  <block id="13f9a963bd60406520ccdc128d44b54a" category="list-text">Lenovo ThinkSystem SE350 Edge-Server</block>
  <block id="e15fea5c6bb7e2f7d8e055fbb773fc11" category="inline-link"><block ref="e15fea5c6bb7e2f7d8e055fbb773fc11" category="inline-link-rx"></block></block>
  <block id="b1a88588a48ee9492506277f8561b392" category="paragraph"><block ref="b1a88588a48ee9492506277f8561b392" category="inline-link-rx"></block></block>
  <block id="f9732caa47051768fc11729f5535891b" category="list-text">Lenovo ThinkSystem DM5100F Unified Flash-Speicher-Array</block>
  <block id="a031d2e6ff4219cf38830b0db9d366b1" category="inline-link"><block ref="a031d2e6ff4219cf38830b0db9d366b1" category="inline-link-rx"></block></block>
  <block id="a4113bc79b3920d11274d7bf9cfafe10" category="paragraph"><block ref="a4113bc79b3920d11274d7bf9cfafe10" category="inline-link-rx"></block></block>
  <block id="207e9f2f3c6b5a3e8c9228ceadc806b2" category="summary">In diesem Abschnitt werden die getesteten Konfigurationen, die Netzwerkinfrastruktur, der SE350-Server und die Details zur Speicherbereitstellung beschrieben.</block>
  <block id="32d798df7254f6703ed2262024e0e174" category="doc">Testkonfiguration</block>
  <block id="a55faacbe457d923ebd296421a71b898" category="paragraph">Die folgende Abbildung zeigt die Testkonfiguration.  Wir verwendeten das NetApp AFF C190 Speichersystem und zwei Lenovo ThinkSystem SE350-Server (jeweils mit einem NVIDIA T4-Beschleuniger).  Diese Komponenten sind über einen 10GbE-Netzwerk-Switch verbunden.  Der Netzwerkspeicher enthält Validierungs-/Testdatensätze und vortrainierte Modelle.  Die Server stellen Rechenleistung bereit und der Zugriff auf den Speicher erfolgt über das NFS-Protokoll.</block>
  <block id="d8c97013f1e301478b23530ad6ed1ef6" category="paragraph">In diesem Abschnitt werden die getesteten Konfigurationen, die Netzwerkinfrastruktur, der SE350-Server und die Details zur Speicherbereitstellung beschrieben.  In der folgenden Tabelle sind die Basiskomponenten für die Lösungsarchitektur aufgeführt.</block>
  <block id="d552f08a6baeb9bee58f2ca6ff5090d2" category="cell">Lenovo ThinkSystem-Server</block>
  <block id="fe8ab8cb391be4f8cf88a9b64c3ce3cd" category="list-text">2x SE350-Server mit jeweils einer NVIDIA T4-GPU-Karte</block>
  <block id="acd4671bd4d78c7fc0ac8cbc66a01483" category="list-text">Jeder Server enthält eine Intel Xeon D-2123IT CPU mit vier physischen Kernen mit 2,20 GHz und 128 GB RAM</block>
  <block id="d7d02fd9ab069a2d95dee248370100f9" category="cell">NetApp AFF Speichersystem der Einstiegsklasse (HA-Paar)</block>
  <block id="1d680806b37a387e8d84b0c21be4d816" category="list-text">NetApp ONTAP 9 Software</block>
  <block id="0c1dcc458c4dd96728e0b0998cba7305" category="list-text">24 x 960 GB SSDs</block>
  <block id="a2a817ee9a8e05389f7b11bd8ce4bbdb" category="list-text">NFS-Protokoll</block>
  <block id="d8e87bd5878266cd4137e82d919799eb" category="list-text">Eine Schnittstellengruppe pro Controller mit vier logischen IP-Adressen für Mount-Punkte</block>
  <block id="e2921b0ff5efef521f662303c467e27f" category="paragraph"><block ref="e2921b0ff5efef521f662303c467e27f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="208eac927f1261c6e6eaa3135a529cf3" category="paragraph">Die folgende Tabelle listet die Speicherkonfiguration auf: AFF C190 mit 2 HE, 24 Laufwerkssteckplätzen.</block>
  <block id="9bbf373797bf7cf7ba62c80023682e25" category="cell">Regler</block>
  <block id="2ee34178bb8415b7d7234cd27b83aed6" category="cell">Aggregat</block>
  <block id="e9db3004828d9514fafc57881dfbdbd2" category="cell">FlexGroup -Volumen</block>
  <block id="2e0fb97d51b96b1635dcc3ca51f74fee" category="cell">Aggregatgröße</block>
  <block id="b94c9ec583603e13b5c32d83199c7376" category="cell">Volumengröße</block>
  <block id="53a35f8b51acc9748a3e172a76f542a7" category="cell">Einhängepunkt des Betriebssystems</block>
  <block id="6a1ab89ed912a96429c83ff1ba0f48d0" category="cell">Controller1</block>
  <block id="4d80d82716f0b771738e7fad121e059a" category="cell">Aggr1</block>
  <block id="e39298390e27007517a0cb199728188a" category="cell">/netapplenovo_AI_fg</block>
  <block id="4923ec171d721fba1d4547deefc98e8c" category="cell">8.42TiB</block>
  <block id="f13cb116755b4e8fa1af1b201025f377" category="cell">15 TB</block>
  <block id="3fe74875837b518b23813988af1e39d9" category="cell">/netapp_lenovo_fg</block>
  <block id="3877384a92be771d61972d07648b799f" category="cell">Controller2</block>
  <block id="f3913037ef38679d334aa0cf30e2b6fd" category="cell">Aggr2</block>
  <block id="6b02e3a677be18a8be3641bb43e8b220" category="paragraph">Der Ordner /netappLenovo_AI_fg enthält die für die Modellvalidierung verwendeten Datensätze.</block>
  <block id="e4239f67d8e47773c69a7cb4be34d949" category="paragraph">Die folgende Abbildung zeigt die Testkonfiguration.  Wir haben das NetApp EF280-Speichersystem und zwei Lenovo ThinkSystem SE350-Server (jeweils mit einem NVIDIA T4-Beschleuniger) verwendet.  Diese Komponenten sind über einen 10GbE-Netzwerk-Switch verbunden.  Der Netzwerkspeicher enthält Validierungs-/Testdatensätze und vortrainierte Modelle.  Die Server stellen Rechenleistung bereit und der Zugriff auf den Speicher erfolgt über das NFS-Protokoll.</block>
  <block id="efb90877bc42cc445eb6e1b59c0e1b16" category="paragraph">In der folgenden Tabelle ist die Speicherkonfiguration für EF280 aufgeführt.</block>
  <block id="0951a6690e5dc87411346792c9f941c7" category="cell">Volumengruppe</block>
  <block id="bd7a9717d29c5ddcab1bc175eda1e298" category="cell">Volumen</block>
  <block id="6c88d21af6046f64871457b825dcf1c8" category="cell">DDP-Größe</block>
  <block id="59b02558285aa326c0e9018324ed0c4f" category="cell">Verbindungsmethode</block>
  <block id="db320b0194c895c7ac56fedae7928e63" category="cell">DDP1</block>
  <block id="fc452c26db3c4aa6f6213b9c5d9e3abc" category="cell">Band 1</block>
  <block id="fe066d0b9d36398d5f525d6ac7f8e8c5" category="cell">16 TB</block>
  <block id="e0d2b052ec3dbd102ff7a7f2b356ea41" category="cell">SE350-1 zu iSCSI LUN 0</block>
  <block id="ef0e038a9f9b0db74b504d5521e7a0fc" category="cell">Band 2</block>
  <block id="5b846730a13fc5ea0a76a6b7b9a69d5a" category="cell">SE350-2 zu iSCSI LUN 1</block>
  <block id="7192b14affaba8b38680e0cd3749622e" category="paragraph"><block ref="7192b14affaba8b38680e0cd3749622e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="00760d3595ff19f6db2da5213b1fdd58" category="summary">Dieses Dokument beschreibt eine Rechen- und Speicherarchitektur zur Bereitstellung von GPU-basierter künstlicher Intelligenz (KI)-Inferenz auf NetApp -Speichercontrollern und Lenovo ThinkSystem-Servern in einer Edge-Umgebung, die neuen Anwendungsszenarien gerecht wird.</block>
  <block id="09f4ae28e2596e14a7568f3e12a77834" category="doc">TR-4886: KI-Inferenz am Edge – NetApp mit Lenovo ThinkSystem – Lösungsdesign</block>
  <block id="6671938f046112e34e990cb75cc642dd" category="paragraph">Sathish Thyagarajan, NetApp Miroslav Hodak, Lenovo</block>
  <block id="290612199861c31d1036b185b4e69b75" category="section-title">Zusammenfassung</block>
  <block id="ee0e2e290e4e02a3860382ef2cc42ca0" category="paragraph">Mehrere neue Anwendungsszenarien, wie beispielsweise fortschrittliche Fahrerassistenzsysteme (ADAS), Industrie 4.0, Smart Cities und das Internet der Dinge (IoT), erfordern die Verarbeitung kontinuierlicher Datenströme mit einer Latenz von nahezu null.  Dieses Dokument beschreibt eine Rechen- und Speicherarchitektur zur Bereitstellung von GPU-basierter künstlicher Intelligenz (KI)-Inferenz auf NetApp -Speichercontrollern und Lenovo ThinkSystem-Servern in einer Edge-Umgebung, die diese Anforderungen erfüllt.  Dieses Dokument enthält außerdem Leistungsdaten für den branchenüblichen MLPerf-Inferenz-Benchmark, der verschiedene Inferenzaufgaben auf Edge-Servern mit NVIDIA T4-GPUs bewertet.  Wir untersuchen die Leistung von Offline-, Single-Stream- und Multistream-Inferenzszenarien und zeigen, dass die Architektur mit einem kostengünstigen gemeinsam genutzten Netzwerkspeichersystem hochleistungsfähig ist und einen zentralen Punkt für die Daten- und Modellverwaltung für mehrere Edge-Server bietet.</block>
  <block id="a27de0758c1fc778a0fb19ebcb6a8aff" category="paragraph">Unternehmen generieren zunehmend riesige Datenmengen am Netzwerkrand.  Um den maximalen Nutzen aus intelligenten Sensoren und IoT-Daten zu erzielen, suchen Unternehmen nach einer Echtzeit-Event-Streaming-Lösung, die Edge Computing ermöglicht.  Rechenintensive Aufgaben werden daher zunehmend am Rand, außerhalb von Rechenzentren, ausgeführt.  Einer der Treiber dieses Trends ist die KI-Inferenz.  Edge-Server bieten ausreichend Rechenleistung für diese Workloads, insbesondere bei Verwendung von Beschleunigern, aber begrenzter Speicherplatz ist oft ein Problem, insbesondere in Multiserver-Umgebungen.  In diesem Dokument zeigen wir, wie Sie ein gemeinsam genutztes Speichersystem in der Edge-Umgebung bereitstellen können und wie es KI-Inferenz-Workloads zugutekommt, ohne dass es zu Leistungseinbußen kommt.</block>
  <block id="c22ef83c0446b759f6cd8835206adaae" category="paragraph">Dieses Dokument beschreibt eine Referenzarchitektur für KI-Inferenz am Rand.  Es kombiniert mehrere Lenovo ThinkSystem Edge-Server mit einem NetApp -Speichersystem, um eine Lösung zu erstellen, die einfach bereitzustellen und zu verwalten ist.  Es soll als grundlegender Leitfaden für den praktischen Einsatz in verschiedenen Situationen dienen, beispielsweise in der Fabrikhalle mit mehreren Kameras und Industriesensoren, in Point-of-Sale-Systemen (POS) im Einzelhandel oder in Full Self-Driving-Systemen (FSD), die visuelle Anomalien in autonomen Fahrzeugen erkennen.</block>
  <block id="36d77288dbd3663ec436c43b32682300" category="paragraph">Dieses Dokument behandelt das Testen und Validieren einer Rechen- und Speicherkonfiguration, die aus einem Lenovo ThinkSystem SE350 Edge Server und einem NetApp AFF und EF-Series-Speichersystem der Einstiegsklasse besteht.  Die Referenzarchitekturen bieten eine effiziente und kostengünstige Lösung für KI-Bereitstellungen und bieten gleichzeitig umfassende Datendienste, integrierten Datenschutz, nahtlose Skalierbarkeit und Cloud-verbundene Datenspeicherung mit der Datenmanagementsoftware NetApp ONTAP und NetApp SANtricity .</block>
  <block id="5dd536dd8122d7ba5df3ce642e603305" category="paragraph">Dieses Dokument richtet sich an folgende Zielgruppen:</block>
  <block id="ebb25f3a3991f2ad744d7ec643c950fe" category="list-text">Führungskräfte und Unternehmensarchitekten, die KI am Netzwerkrand zu Produkten machen möchten.</block>
  <block id="c19c4b63370004c67b540d52ae4d0ba3" category="list-text">Datenwissenschaftler, Dateningenieure, KI-/Maschinelles Lernen (ML)-Forscher und Entwickler von KI-Systemen.</block>
  <block id="d64b2d5963d22d2d9c15222cbbe4a41c" category="list-text">Unternehmensarchitekten, die Lösungen für die Entwicklung von KI/ML-Modellen und -Anwendungen entwerfen.</block>
  <block id="563f47ae807a7a985313a5186e239a5d" category="list-text">Datenwissenschaftler und KI-Ingenieure suchen nach effizienten Möglichkeiten zur Bereitstellung von Deep Learning (DL)- und ML-Modellen.</block>
  <block id="c1df171c3c219ea01c2724d28fa03f93" category="list-text">Edge-Gerätemanager und Edge-Server-Administratoren, die für die Bereitstellung und Verwaltung von Edge-Inferenzmodellen verantwortlich sind.</block>
  <block id="a40893fa754ed62d5268702b023fea91" category="section-title">Lösungsarchitektur</block>
  <block id="cc402abc10a0191493024c4510783afc" category="paragraph">Dieser Lenovo ThinkSystem-Server und die NetApp ONTAP oder NetApp SANtricity -Speicherlösung sind für die Verarbeitung von KI-Inferenzen auf großen Datensätzen konzipiert und nutzen dabei die Verarbeitungsleistung von GPUs neben herkömmlichen CPUs.  Diese Validierung demonstriert hohe Leistung und optimales Datenmanagement mit einer Architektur, die entweder einen oder mehrere Lenovo SR350-Edge-Server verwendet, die mit einem einzigen NetApp AFF Speichersystem verbunden sind, wie in den folgenden beiden Abbildungen dargestellt.</block>
  <block id="f21cce3e60a01cff1e8e221c6536fe78" category="paragraph"><block ref="f21cce3e60a01cff1e8e221c6536fe78" category="inline-image-macro-rx" type="image"></block></block>
  <block id="94aa1b43a547a9dd2c4d023dbc98322b" category="paragraph"><block ref="94aa1b43a547a9dd2c4d023dbc98322b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fa68c0f0557e1b1d9b151c9be9aae26a" category="paragraph">Die Übersicht über die logische Architektur in der folgenden Abbildung zeigt die Rollen der Rechen- und Speicherelemente in dieser Architektur.  Konkret zeigt es Folgendes:</block>
  <block id="f2e5640bc98f623bd0a257e3088ead2c" category="list-text">Edge-Compute-Geräte führen Schlussfolgerungen auf der Grundlage der Daten durch, die sie von Kameras, Sensoren usw. erhalten.</block>
  <block id="ba8dee772ce5a627767af000b8bbb826" category="list-text">Ein gemeinsam genutztes Speicherelement, das mehreren Zwecken dient:</block>
  <block id="8a1d15a179258733a83884fac2d16e38" category="list-text">Bietet einen zentralen Ort für Inferenzmodelle und andere Daten, die zur Durchführung der Inferenz erforderlich sind.  Rechenserver greifen direkt auf den Speicher zu und verwenden Inferenzmodelle im gesamten Netzwerk, ohne dass sie lokal kopiert werden müssen.</block>
  <block id="6c20432374a9a40cfb818250edf55367" category="list-text">Aktualisierte Modelle werden hier gepusht.</block>
  <block id="4a32229da6d6fceda48d909ad92a952a" category="list-text">Archiviert Eingabedaten, die Edge-Server zur späteren Analyse empfangen.  Wenn die Edge-Geräte beispielsweise mit Kameras verbunden sind, speichert das Speicherelement die von den Kameras aufgenommenen Videos.</block>
  <block id="3c5974fb92ca4b40257a58c213d0f137" category="paragraph"><block ref="3c5974fb92ca4b40257a58c213d0f137" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bda9643ac6601722a28f238714274da4" category="cell">Rot</block>
  <block id="48d6215903dff56238e52e8891380c8f" category="cell">Blau</block>
  <block id="95e6ac9e87f07caf580a7b83adb1526b" category="cell">Lenovo-Rechnersystem</block>
  <block id="81a15d59c420e43b55830213cc8c16b9" category="cell">NetApp AFF Speichersystem</block>
  <block id="f46e4977aa2e9918471e011cafc5cbe1" category="cell">Edge-Geräte, die Inferenzen auf Grundlage von Eingaben von Kameras, Sensoren usw. durchführen.</block>
  <block id="edb1af4b83edf30ec5e56e3f4a6352f3" category="cell">Gemeinsam genutzter Speicher für Inferenzmodelle und Daten von Edge-Geräten zur späteren Analyse.</block>
  <block id="6fa1f5494d341a20c6c746a33cbb31b3" category="paragraph">Diese Lösung von NetApp und Lenovo bietet die folgenden Hauptvorteile:</block>
  <block id="f1bd3fc2711f634964362fb2a96445bf" category="list-text">GPU-beschleunigtes Computing am Rand.</block>
  <block id="a644cc245485a603217667e7cbdb7ef9" category="list-text">Bereitstellung mehrerer Edge-Server, die von einem gemeinsamen Speicher gesichert und verwaltet werden.</block>
  <block id="d649f2b00c65fe4953b1a7e7469c9431" category="list-text">Robuster Datenschutz zur Erreichung niedriger Recovery Point Objectives (RPOs) und Recovery Time Objectives (RTOs) ohne Datenverlust.</block>
  <block id="2d0fcf5abf2f152f10ecfbf80a62e9db" category="list-text">Optimiertes Datenmanagement mit NetApp Snapshot-Kopien und -Klonen zur Optimierung von Entwicklungs-Workflows.</block>
  <block id="94d9a1cd726b8a3fed2b6beb07904959" category="section-title">So verwenden Sie diese Architektur</block>
  <block id="9a22eb3c4ef782aa04a39e5ad3ffc8b5" category="paragraph">Dieses Dokument validiert das Design und die Leistung der vorgeschlagenen Architektur.  Allerdings haben wir bestimmte Teile auf Softwareebene, wie etwa Container-, Workload- oder Modellverwaltung und Datensynchronisierung mit der Cloud oder dem Rechenzentrum vor Ort, nicht getestet, da sie spezifisch für ein Bereitstellungsszenario sind.  Hier gibt es mehrere Auswahlmöglichkeiten.</block>
  <block id="543ca2d3d9aa63e1a63c69dd219d5f2a" category="inline-link-macro">NetApp KI-Steuerungsebene</block>
  <block id="bfbeeaf5d09672568692829ade4ca556" category="paragraph">Auf der Ebene der Containerverwaltung ist die Kubernetes-Containerverwaltung eine gute Wahl und wird entweder in einer vollständig Upstream-Version (Canonical) oder in einer modifizierten Version, die für Unternehmensbereitstellungen geeignet ist (Red Hat), gut unterstützt.  Der<block ref="cba35aa1f9d4aeed351c50bd57559a4d" category="inline-link-macro-rx"></block> welches NetApp Trident und das neu hinzugefügte<block ref="18f9f1b3975974bec435249b1752c2d6" category="inline-link-rx"></block> bietet integrierte Rückverfolgbarkeit, Datenverwaltungsfunktionen, Schnittstellen und Tools für Datenwissenschaftler und Dateningenieure zur Integration mit NetApp Speicher.  Kubeflow, das ML-Toolkit für Kubernetes, bietet zusätzliche KI-Funktionen sowie Unterstützung für Modellversionierung und KFServing auf mehreren Plattformen wie TensorFlow Serving oder NVIDIA Triton Inference Server.  Eine weitere Option ist die NVIDIA EGX-Plattform, die Workload-Management sowie Zugriff auf einen Katalog GPU-fähiger KI-Inferenzcontainer bietet.  Allerdings kann die Umsetzung dieser Optionen in die Produktion einen erheblichen Aufwand und viel Fachwissen erfordern und die Unterstützung eines unabhängigen Softwareanbieters (ISV) oder Beraters erfordern.</block>
  <block id="1a667cf8dc2ace931f29baf9aeed69d9" category="section-title">Lösungsbereiche</block>
  <block id="560d585bccd63f1ccf34b07b325adbcd" category="paragraph">Der Hauptvorteil von KI-Inferenz und Edge Computing besteht in der Fähigkeit der Geräte, Daten mit hoher Qualität und ohne Latenz zu berechnen, zu verarbeiten und zu analysieren.  Es gibt viel zu viele Beispiele für Edge-Computing-Anwendungsfälle, um sie in diesem Dokument zu beschreiben, aber hier sind einige herausragende:</block>
  <block id="8106f228c3a2b774c2e47d0d2ca766eb" category="section-title">Automobile: Autonome Fahrzeuge</block>
  <block id="49f3cb6fe79fc77d0b151dcc2f7d7109" category="paragraph">Das klassische Beispiel für Edge Computing sind die fortschrittlichen Fahrerassistenzsysteme (ADAS) in autonomen Fahrzeugen (AV).  Die KI in selbstfahrenden Autos muss schnell viele Daten von Kameras und Sensoren verarbeiten, um ein erfolgreicher und sicherer Fahrer zu sein.  Wenn die Interpretation zwischen einem Objekt und einem Menschen zu lange dauert, kann dies über Leben und Tod entscheiden. Daher ist es von entscheidender Bedeutung, diese Daten so nah wie möglich am Fahrzeug verarbeiten zu können.  In diesem Fall verarbeitet ein oder mehrere Edge-Compute-Server die Eingaben von Kameras, Radar, LiDAR und anderen Sensoren, während der gemeinsam genutzte Speicher Inferenzmodelle enthält und Eingabedaten von Sensoren speichert.</block>
  <block id="e5e51dcd521792cb797e6e3c53736987" category="section-title">Gesundheitswesen: Patientenüberwachung</block>
  <block id="bace962401fe7f588dcfdc4444fa9cfd" category="paragraph">Eine der größten Auswirkungen von KI und Edge Computing ist ihre Fähigkeit, die kontinuierliche Überwachung von Patienten mit chronischen Krankheiten sowohl in der häuslichen Pflege als auch auf Intensivstationen zu verbessern.  Daten von Edge-Geräten, die Insulinspiegel, Atmung, neurologische Aktivität, Herzrhythmus und Magen-Darm-Funktionen überwachen, erfordern eine sofortige Analyse der Daten, auf die sofort reagiert werden muss, da nur begrenzt Zeit zum Handeln bleibt, um ein Menschenleben zu retten.</block>
  <block id="7e4b8a4224f71143d7bd188ceeea4acd" category="section-title">Einzelhandel: Kassiererloses Bezahlen</block>
  <block id="a8712e81fee7af830aa2cd6466cfb339" category="paragraph">Edge Computing kann KI und ML unterstützen und Einzelhändlern dabei helfen, die Kassenzeit zu verkürzen und die Kundenfrequenz zu erhöhen.  Kassenlose Systeme unterstützen verschiedene Komponenten, beispielsweise die folgenden:</block>
  <block id="dbc0817910529140e6894b79ec51b412" category="list-text">Authentifizierung und Zugriff.  Verbinden Sie den physischen Käufer mit einem validierten Konto und ermöglichen Sie ihm den Zugang zum Einzelhandelsgeschäft.</block>
  <block id="349a2650c71706ec201ef08d57dc58e7" category="list-text">Bestandsüberwachung.  Einsatz von Sensoren, RFID-Tags und Computer-Vision-Systemen zur Bestätigung der Auswahl oder Abwahl von Artikeln durch Käufer.</block>
  <block id="86f5df5b4d7496a74d1d41bed2929983" category="paragraph">Dabei verwaltet jeder der Edge-Server die einzelnen Kassen und das gemeinsame Speichersystem dient als zentraler Synchronisierungspunkt.</block>
  <block id="498375fc1d2fd41616385f8abfd37893" category="section-title">Finanzdienstleistungen: Sicherheit von Menschen an Kiosken und Betrugsprävention</block>
  <block id="1dd0f8c70693faa846f69d76af9ffbf7" category="paragraph">Bankorganisationen nutzen KI und Edge Computing, um Innovationen zu schaffen und personalisierte Bankerlebnisse zu schaffen.  Interaktive Kioske, die Echtzeit-Datenanalysen und KI-Inferenz nutzen, ermöglichen es Geldautomaten jetzt nicht nur, Kunden beim Abheben von Geld zu unterstützen, sondern sie auch proaktiv anhand der von Kameras aufgenommenen Bilder zu überwachen, um Risiken für die menschliche Sicherheit oder betrügerisches Verhalten zu erkennen.  In diesem Szenario werden Edge-Compute-Server und gemeinsam genutzte Speichersysteme mit interaktiven Kiosken und Kameras verbunden, um Banken bei der Erfassung und Verarbeitung von Daten mit KI-Inferenzmodellen zu unterstützen.</block>
  <block id="0014200d8a9f4fe7a8b65ae923557be6" category="section-title">Fertigung: Industrie 4.0</block>
  <block id="18bfb27ab22a9db6eb932a3bfe5f51a4" category="paragraph">Die vierte industrielle Revolution (Industrie 4.0) hat begonnen, zusammen mit neuen Trends wie Smart Factory und 3D-Druck.  Um sich auf eine datengesteuerte Zukunft vorzubereiten, werden groß angelegte Machine-to-Machine-Kommunikation (M2M) und IoT integriert, um eine stärkere Automatisierung ohne menschliches Eingreifen zu erreichen.  Die Fertigung ist bereits hochgradig automatisiert und die Hinzufügung von KI-Funktionen ist eine natürliche Fortsetzung dieses langfristigen Trends.  KI ermöglicht die Automatisierung von Vorgängen, die mithilfe von Computer Vision und anderen KI-Funktionen automatisiert werden können.  Sie können die Qualitätskontrolle oder Aufgaben automatisieren, die auf menschlichem Sehen oder Entscheidungsfindung beruhen, um schnellere Materialanalysen an Fließbändern in Fabrikhallen durchzuführen und so Produktionsanlagen dabei zu helfen, die erforderlichen ISO-Standards für Sicherheit und Qualitätsmanagement zu erfüllen.  Dabei ist jeder Compute-Edge-Server mit einer Reihe von Sensoren verbunden, die den Herstellungsprozess überwachen, und aktualisierte Inferenzmodelle werden bei Bedarf in den gemeinsamen Speicher übertragen.</block>
  <block id="a2df8c6c694bb6d9b42851d95a6d7814" category="section-title">Telekommunikation: Rosterkennung, Turminspektion und Netzwerkoptimierung</block>
  <block id="d562d0e475687af21d44b6ea803c10a8" category="paragraph">Die Telekommunikationsbranche nutzt Computer Vision und KI-Techniken zur Bildverarbeitung, die automatisch Rost erkennen und Mobilfunkmasten identifizieren, die Korrosion aufweisen und daher einer weiteren Inspektion bedürfen.  Die Verwendung von Drohnenbildern und KI-Modellen zur Identifizierung bestimmter Bereiche eines Turms zur Analyse von Rost, Oberflächenrissen und Korrosion hat in den letzten Jahren zugenommen.  Die Nachfrage nach KI-Technologien, die eine effiziente Inspektion der Telekommunikationsinfrastruktur und Mobilfunkmasten, eine regelmäßige Überprüfung auf Verschlechterung und eine schnelle Reparatur bei Bedarf ermöglichen, steigt weiterhin.</block>
  <block id="d88e40cd850f8bd6b5e737761a1786fd" category="paragraph">Ein weiterer neuer Anwendungsfall in der Telekommunikation ist die Verwendung von KI- und ML-Algorithmen zur Vorhersage von Datenverkehrsmustern, zur Erkennung von 5G-fähigen Geräten und zur Automatisierung und Erweiterung des Multiple-Input- und Multiple-Output-Energiemanagements (MIMO).  MIMO-Hardware wird an Funktürmen eingesetzt, um die Netzwerkkapazität zu erhöhen. Dies ist jedoch mit zusätzlichen Energiekosten verbunden.  ML-Modelle für den „MIMO-Schlafmodus“, die an Mobilfunkstandorten eingesetzt werden, können die effiziente Nutzung von Funkgeräten vorhersagen und dazu beitragen, die Energieverbrauchskosten für Mobilfunknetzbetreiber (MNOs) zu senken.  KI-Inferenz- und Edge-Computing-Lösungen helfen Mobilfunknetzbetreibern, die Menge der zwischen Rechenzentren und ihnen übertragenen Daten zu reduzieren, ihre Gesamtbetriebskosten zu senken, den Netzwerkbetrieb zu optimieren und die Gesamtleistung für Endbenutzer zu verbessern.</block>
  <block id="228af426af79aabaa0b969d8cee05002" category="summary">Dieses Dokument folgt dem Code und den Regeln von MLPerf Inference v0.7 und MLPerf Inference v1.1.  Wir haben Benchmarks ausgeführt, die für die Inferenz am Rand konzipiert sind, wie in den Tabellen in diesem Abschnitt definiert.</block>
  <block id="b3e6ac4f3c523ea5a90f4f79ca3e585d" category="doc">Testplan</block>
  <block id="c13367945d5d4c91047b3b50234aa7ab" category="inline-link">Code</block>
  <block id="a4f86f7bfc24194b276c22e0ef158197" category="inline-link">Regeln</block>
  <block id="eb190159f20d63d1c7687ecafd03fc73" category="paragraph">Dieses Dokument folgt MLPerf Inference v0.7<block ref="72ea1359ddbf7a99cdb0a438fda3e022" category="inline-link-rx"></block> , MLPerf-Inferenz v1.1<block ref="7dc141edfa21f33dbd4b0757be1ad69f" category="inline-link-rx"></block> , Und<block ref="efc21f34f290528320a21a8cc99ffcfc" category="inline-link-rx"></block> .  Wir haben MLPerf-Benchmarks ausgeführt, die für die Inferenz am Rand entwickelt wurden, wie in der folgenden Tabelle definiert.</block>
  <block id="deec4ff19974f12ed781cb9a59064214" category="cell">Bereich</block>
  <block id="a559b87068921eec05086ce5485e9784" category="cell">Modell</block>
  <block id="239658e016e3d5d06ae719d280a79fec" category="cell">Datensatz</block>
  <block id="e110cde47b67924ec0ef64500e8cb067" category="cell">QSL-Größe</block>
  <block id="571094bb27864b600d8e6b561a137a55" category="cell">Qualität</block>
  <block id="77f086368f7402e03b21bb823cda2eb3" category="cell">Multistream-Latenzbeschränkung</block>
  <block id="99a0628d9f7179c032e0cf59efbc0fad" category="cell">Vision</block>
  <block id="c84e3388f5bc3e4ce028dc81625bf819" category="cell">Bildklassifizierung</block>
  <block id="4cf67db3abdf54de6064fce40cf27398" category="cell">Resnet50v1.5</block>
  <block id="05e96e35d2778a07f18ff8b414821ee8" category="cell">ImageNet (224 x 224)</block>
  <block id="021bbc7ee20b71134d53e20206bd6feb" category="cell">1024</block>
  <block id="79267804a18aa7217c234994e26bb5c7" category="cell">99 % von FP32</block>
  <block id="c2010c9d1312ce345a2313d3acb5c6d5" category="cell">50 ms</block>
  <block id="5d9387d7bf46f8c6854a5caafd6cfbf3" category="cell">Objekterkennung (groß)</block>
  <block id="7dd82182395c2720676a1e82b781ef04" category="cell">SSD-ResNet34</block>
  <block id="0505dc2363120e454308e12e47f6d354" category="cell">COCO (1200x1200)</block>
  <block id="ea5d2f1c4608232e07d3aa3d998e5135" category="cell">64</block>
  <block id="f336aeb0ea3de7c70100c292338460e3" category="cell">66 ms</block>
  <block id="a3e1c35debe58b3684abba30911eb0f9" category="cell">Objekterkennung (klein)</block>
  <block id="d05a0b1a6c857a559314f24c10825416" category="cell">SSD – MobileNetsv1</block>
  <block id="f471fd17e298022a58bcbd05aa25a819" category="cell">COCO (300x300)</block>
  <block id="f718499c1c8cef6730f9fd03c8125cab" category="cell">256</block>
  <block id="ed076605284997250d9cc771eedbfc61" category="cell">Medizinische Bildsegmentierung</block>
  <block id="b8ffefa5ddac895023e8ab6fe1b55b45" category="cell">3D UNET</block>
  <block id="5ea5e4840c21271f42762e8b9271527a" category="cell">BraTS 2019 (224x224x160)</block>
  <block id="c74d97b01eae257e44aa9d5bade97baf" category="cell">16</block>
  <block id="8322d3768dee2653e9cc15c955ee60a8" category="cell">99 % und 99,9 % von FP32</block>
  <block id="04a83927cfa1af6ae14f94e90aab9ebb" category="cell">Rede</block>
  <block id="ade9e8d743e7e78d87c5c5603b0aa4ae" category="cell">Sprache-zu-Text</block>
  <block id="69ee0ff6f427bb2dfd286a55bbc181ea" category="cell">RNNT</block>
  <block id="d3c7d61f6e8ea0b76fd8b65e5115b28b" category="cell">Librispeech dev-clean</block>
  <block id="84b20b1f5a0d103f5710bb67a043cd78" category="cell">2513</block>
  <block id="4994a8ffeba4ac3140beb89e8d41f174" category="cell">Sprache</block>
  <block id="f8672b43ad1f9d3531557d69b6da380c" category="cell">Sprachverarbeitung</block>
  <block id="f50c0cca078c7426bed1eb196911c809" category="cell">SQuAD v1.1</block>
  <block id="d56da061d55e2175bd67901d5f0948be" category="cell">10833</block>
  <block id="816720c0b642aa1eef01c4f9108f54c5" category="paragraph">Die folgende Tabelle zeigt Edge-Benchmark-Szenarien.</block>
  <block id="85051346c766b4444af7bfaaa0c189f5" category="cell">Szenarien</block>
  <block id="4bb9c2b62dbc9558da74af948130693b" category="cell">Bildklassifizierung</block>
  <block id="d5348bf8d0ff8e72043bdbb08aef9767" category="cell">Einzelstream, Offline, Multistream</block>
  <block id="468acb809a41b49bb7fcdf7425dcd7ee" category="cell">Einzelner Stream, offline</block>
  <block id="3d1aa46be43bf2f29633e829d42082af" category="cell">Sprache-zu-Text</block>
  <block id="7966e67de4ba20fb5412257b4023f4d1" category="paragraph">Wir haben diese Benchmarks mit der bei dieser Validierung entwickelten Netzwerkspeicherarchitektur durchgeführt und die Ergebnisse mit denen aus lokalen Läufen auf den Edge-Servern verglichen, die zuvor an MLPerf übermittelt wurden.  Der Vergleich soll ermitteln, welchen Einfluss der gemeinsam genutzte Speicher auf die Inferenzleistung hat.</block>
  <block id="b481424c052310e67a9b67a931165509" category="summary">In diesem Abschnitt werden die Testverfahren beschrieben, die zur Validierung dieser Lösung verwendet wurden.</block>
  <block id="3562305aa864cd56d3e2840eb5071caa" category="doc">Testverfahren</block>
  <block id="1b0981f820949c10d68daad3fdf03976" category="section-title">Betriebssystem und KI-Inferenz-Setup</block>
  <block id="fe03e7fb4a8d3a1afb24c94c4c88d32f" category="paragraph">Für AFF C190 haben wir Ubuntu 18.04 mit NVIDIA -Treibern und Docker mit Unterstützung für NVIDIA -GPUs verwendet und MLPerf verwendet<block ref="72ea1359ddbf7a99cdb0a438fda3e022" category="inline-link-rx"></block> verfügbar als Teil der Lenovo-Einreichung zu MLPerf Inference v0.7.</block>
  <block id="504812acf44740b8f536a0d166375734" category="paragraph">Für EF280 haben wir Ubuntu 20.04 mit NVIDIA -Treibern und Docker mit Unterstützung für NVIDIA -GPUs und MLPerf verwendet<block ref="7dc141edfa21f33dbd4b0757be1ad69f" category="inline-link-rx"></block> verfügbar als Teil der Lenovo-Einreichung zu MLPerf Inference v1.1.</block>
  <block id="fbd2228a821a8ab1948d4a8c3121fb0e" category="paragraph">Um die KI-Inferenz einzurichten, gehen Sie folgendermaßen vor:</block>
  <block id="9177ba75c6dc50d818c52360f10e2fe1" category="list-text">Laden Sie Datensätze herunter, für die eine Registrierung erforderlich ist, das ImageNet 2012-Validierungsset, das Criteo Terabyte-Dataset und das BraTS 2019-Trainingsset, und entpacken Sie anschließend die Dateien.</block>
  <block id="12dda17fb1d76556387dceb2e85a9290" category="list-text">Erstellen Sie ein Arbeitsverzeichnis mit mindestens 1 TB und definieren Sie die Umgebungsvariable<block ref="597c05a331d3bca9b42845049a851c94" prefix=" " category="inline-code"></block> mit Verweis auf das Verzeichnis.</block>
  <block id="342ecacc441a9548b60eae46065039f8" category="paragraph">Sie sollten dieses Verzeichnis auf dem freigegebenen Speicher für den Netzwerkspeicher-Anwendungsfall oder auf der lokalen Festplatte freigeben, wenn Sie mit lokalen Daten testen.</block>
  <block id="7c5f7553ff57e0548889000668d1cf39" category="list-text">Führen Sie das Make-<block ref="ba8a3d8e03d727387e03ca6ef842d4c5" prefix=" " category="inline-code"></block> Befehl, der den Docker-Container für die erforderlichen Inferenzaufgaben erstellt und startet.</block>
  <block id="9cfc451dfe052c5c3835b0355375b1b7" category="admonition">Die folgenden Befehle werden alle innerhalb des laufenden Docker-Containers ausgeführt:</block>
  <block id="b25e1e6ba392fe4c0e0da7617a67fa4d" category="list-text">Laden Sie vortrainierte KI-Modelle für MLPerf-Inferenzaufgaben herunter:<block ref="b59a4beb5c95f2e0e1fed56d89e16cf0" prefix=" " category="inline-code"></block></block>
  <block id="ed43016366915f1fc65fe332de60965f" category="list-text">Laden Sie zusätzliche Datensätze herunter, die kostenlos herunterladbar sind:<block ref="fd0245b042cdcee1ab8bd760c8b4bfbc" prefix=" " category="inline-code"></block></block>
  <block id="41165a10471c0644aef30b976f113946" category="list-text">Vorverarbeitung der Daten: make<block ref="03275934d57d2ecfe9e68f7023f456ce" prefix=" " category="inline-code"></block></block>
  <block id="f0bacb5df46d2e8bed3d6d0d863fce01" category="list-text">Laufen:<block ref="be647e69451a82a2f326980291e0f781" prefix=" " category="inline-code"></block> .</block>
  <block id="189eed4566c6894d64b4d4f8bc9df94c" category="list-text">Erstellen Sie für die GPU in Compute-Servern optimierte Inferenzmaschinen:<block ref="37496efe33254cb883b0705fde55fcc1" prefix=" " category="inline-code"></block></block>
  <block id="4efea18a74f8c5a6fa0f4b239ff2d734" category="list-text">Um Inference-Workloads auszuführen, führen Sie Folgendes aus (ein Befehl):</block>
  <block id="9ce2624cb32bec75a2ad4e276fa594f6" category="section-title">KI-Inferenzläufe</block>
  <block id="2a71d3fa50a14f6fa9c62d9fe3935d5d" category="paragraph">Es wurden drei Arten von Läufen durchgeführt:</block>
  <block id="3a4a320ee019614122e99baebf056b86" category="list-text">Einzelserver-KI-Inferenz mit lokalem Speicher</block>
  <block id="adf25fe660bba733a104887732393fdd" category="list-text">Einzelserver-KI-Inferenz mit Netzwerkspeicher</block>
  <block id="34e4c32e4097a70208139be85d5dc892" category="list-text">Multiserver-KI-Inferenz mit Netzwerkspeicher</block>
  <block id="8708911de20cfce9bafb315fd0cde0a2" category="summary">Um die Leistung der vorgeschlagenen Architektur zu bewerten, wurden zahlreiche Tests durchgeführt.  Es gibt sechs verschiedene Workloads (Bildklassifizierung, Objekterkennung [klein], Objekterkennung [groß], medizinische Bildgebung, Sprache-zu-Text und natürliche Sprachverarbeitung [NLP]), die Sie in drei verschiedenen Szenarien ausführen können – offline, Single-Stream und Multistream.</block>
  <block id="3274a50ba9f0d3c0adefdfa11c5094be" category="doc">Testergebnisse</block>
  <block id="a274daca2deace9b89099b24f248715c" category="paragraph">Um die Leistung der vorgeschlagenen Architektur zu bewerten, wurden zahlreiche Tests durchgeführt.</block>
  <block id="37bf74d7f686cd395d40af1cc2ed7c55" category="paragraph">Es gibt sechs verschiedene Workloads (Bildklassifizierung, Objekterkennung [klein], Objekterkennung [groß], medizinische Bildgebung, Sprache-zu-Text und natürliche Sprachverarbeitung [NLP]), die Sie in drei verschiedenen Szenarien ausführen können: offline, Einzelstream und Multistream.</block>
  <block id="aaabb57453387e4d8fdae92cdf5d558b" category="admonition">Das letzte Szenario wird nur für die Bildklassifizierung und Objekterkennung implementiert.</block>
  <block id="e7b8f9d880e5e20f44e5277ba99d101b" category="paragraph">Daraus ergeben sich 15 mögliche Workloads, die alle unter drei verschiedenen Setups getestet wurden:</block>
  <block id="6beb824a1e58582d2c0c733600244087" category="list-text">Einzelserver/lokaler Speicher</block>
  <block id="0ce03975d1039901bae5d17f67b2ac39" category="list-text">Einzelserver/Netzwerkspeicher</block>
  <block id="ffac1c611ceb8a0bd6268359872e3e68" category="list-text">Multiserver-/Netzwerkspeicher</block>
  <block id="f5b98cda08f17c4b221c6ef2fbf7217f" category="paragraph">Die Ergebnisse werden in den folgenden Abschnitten beschrieben.</block>
  <block id="18d566b8a783b6684a78fc2924714180" category="section-title">KI-Inferenz im Offline-Szenario für AFF</block>
  <block id="0aee493b887954641c1ba2e779adcf85" category="paragraph">In diesem Szenario standen dem Server alle Daten zur Verfügung und es wurde die Zeit gemessen, die für die Verarbeitung aller Proben benötigt wurde.  Als Ergebnisse der Tests geben wir Bandbreiten in Samples pro Sekunde an.  Wenn mehr als ein Rechenserver verwendet wurde, geben wir die Gesamtbandbreite aller Server an.  Die Ergebnisse für alle drei Anwendungsfälle sind in der folgenden Abbildung dargestellt.  Für den Fall mit zwei Servern melden wir die kombinierte Bandbreite beider Server.</block>
  <block id="50c1d1baa999e0997ecc5b2fb7ce848c" category="paragraph"><block ref="50c1d1baa999e0997ecc5b2fb7ce848c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a0d89c8c627ec0463d3f82a6cbbc04bd" category="paragraph">Die Ergebnisse zeigen, dass sich der Netzwerkspeicher nicht negativ auf die Leistung auswirkt – die Änderung ist minimal und bei einigen Aufgaben wird keine Änderung festgestellt.  Beim Hinzufügen des zweiten Servers verdoppelt sich die Gesamtbandbreite entweder genau oder die Änderung beträgt im schlimmsten Fall weniger als 1 %.</block>
  <block id="d0be2e7e62dc4b0bdbb35ded9b6d842e" category="section-title">KI-Inferenz in einem Single-Stream-Szenario für AFF</block>
  <block id="fbbf5a4ee90b9175f00f7c8cab5a0670" category="paragraph">Dieser Benchmark misst die Latenz.  Für den Fall mehrerer Rechenserver geben wir die durchschnittliche Latenz an.  Die Ergebnisse für die Aufgabenreihe sind in der folgenden Abbildung dargestellt.  Für den Fall mit zwei Servern geben wir die durchschnittliche Latenz beider Server an.</block>
  <block id="e3a127ece515b351ac983cdc09f48eb3" category="paragraph"><block ref="e3a127ece515b351ac983cdc09f48eb3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9ef9ced66e0746938556409b4c473052" category="paragraph">Die Ergebnisse zeigen erneut, dass der Netzwerkspeicher zur Bewältigung der Aufgaben ausreicht.  Der Unterschied zwischen lokalem und Netzwerkspeicher ist im Fall eines Servers minimal oder nicht vorhanden.  Wenn zwei Server denselben Speicher verwenden, bleibt die Latenz auf beiden Servern gleich oder ändert sich nur geringfügig.</block>
  <block id="64a84459b695510c92164965941ad8f1" category="section-title">KI-Inferenz im Multistream-Szenario für AFF</block>
  <block id="22ca0fa830d8fd46fe137f6748374c21" category="paragraph">In diesem Fall ist das Ergebnis die Anzahl der Streams, die das System verarbeiten kann, während die QoS-Einschränkung eingehalten wird.  Das Ergebnis ist also immer eine Ganzzahl.  Bei mehr als einem Server geben wir die Gesamtzahl der Streams aller Server an.  Dieses Szenario wird nicht von allen Workloads unterstützt, wir haben jedoch die entsprechenden Workloads ausgeführt. Die Ergebnisse unserer Tests sind in der folgenden Abbildung zusammengefasst.  Im Fall mit zwei Servern melden wir die kombinierte Anzahl der Streams von beiden Servern.</block>
  <block id="79bd7075b14462178ff1e836cefd5d04" category="paragraph"><block ref="79bd7075b14462178ff1e836cefd5d04" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f3eefb9cc4232b7df67a3c63566ae707" category="paragraph">Die Ergebnisse zeigen eine perfekte Leistung des Setups – lokaler und Netzwerkspeicher liefern die gleichen Ergebnisse und durch Hinzufügen des zweiten Servers verdoppelt sich die Anzahl der Streams, die das vorgeschlagene Setup verarbeiten kann.</block>
  <block id="4ecb5ff41d7f3bd6f1c92bc183f1cb32" category="section-title">Testergebnisse für EF</block>
  <block id="ee7c693721c881b091fdb1adf8a37707" category="paragraph">Um die Leistung der vorgeschlagenen Architektur zu bewerten, wurden zahlreiche Tests durchgeführt.  Es gibt sechs verschiedene Workloads (Bildklassifizierung, Objekterkennung [klein], Objekterkennung [groß], medizinische Bildgebung, Sprache-zu-Text und natürliche Sprachverarbeitung [NLP]), die in zwei verschiedenen Szenarien ausgeführt wurden: offline und Einzelstream.  Die Ergebnisse werden in den folgenden Abschnitten beschrieben.</block>
  <block id="010bb9776a194ae73e567f4812c8be99" category="section-title">KI-Inferenz im Offline-Szenario für EF</block>
  <block id="f4fc0d2711e472dedfd5d2952191989c" category="paragraph">In diesem Szenario standen dem Server alle Daten zur Verfügung und es wurde die Zeit gemessen, die für die Verarbeitung aller Proben benötigt wurde.  Als Ergebnisse der Tests geben wir Bandbreiten in Samples pro Sekunde an.  Bei Läufen mit einem einzelnen Knoten geben wir den Durchschnitt beider Server an, während wir bei Läufen mit zwei Servern die Gesamtbandbreite aller Server angeben.  Die Ergebnisse für Anwendungsfälle sind in der folgenden Abbildung dargestellt.</block>
  <block id="063dd3a1aadafc5ef1c52be7451bda1d" category="paragraph"><block ref="063dd3a1aadafc5ef1c52be7451bda1d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb71ae4a7513a21f0771b9aa65aeef9c" category="section-title">KI-Inferenz in einem Single-Stream-Szenario für EF</block>
  <block id="ca0aa5c3a448e511d9334d94174b8b85" category="paragraph">Dieser Benchmark misst die Latenz.  Für alle Fälle geben wir die durchschnittliche Latenz aller an den Läufen beteiligten Server an.  Die Ergebnisse für die Aufgabenreihe werden angegeben.</block>
  <block id="bcd5a75126c6cafd37838b2f3c6e138b" category="paragraph"><block ref="bcd5a75126c6cafd37838b2f3c6e138b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f02eaec2bc90de6689765cffde92e809" category="paragraph">Die Ergebnisse zeigen erneut, dass der Netzwerkspeicher zur Bewältigung der Aufgaben ausreicht.  Der Unterschied zwischen dem lokalen und dem Netzwerkspeicher ist im Fall eines Servers minimal oder nicht vorhanden.  Wenn zwei Server denselben Speicher verwenden, bleibt die Latenz auf beiden Servern gleich oder ändert sich nur geringfügig.</block>
  <block id="354967c7509f48d7d8a6d2845803bfbc" category="summary">Sie können das für die Validierung verwendete Setup an andere Anwendungsfälle anpassen.</block>
  <block id="c4236be1a211aab0c15476d08b3e7e0c" category="doc">Größenoptionen für die Architektur</block>
  <block id="9d8c4ebebb4b789e6ec48dda7ac54406" category="section-title">Rechenserver</block>
  <block id="1b3bfec82c01730e4379631c5f74db2d" category="paragraph">Wir haben eine Intel Xeon D-2123IT-CPU verwendet, die niedrigste in SE350 unterstützte CPU-Stufe mit vier physischen Kernen und 60 W TDP.  Der Server unterstützt zwar keinen CPU-Austausch, kann aber mit einer leistungsstärkeren CPU bestellt werden.  Die am besten unterstützte CPU ist Intel Xeon D-2183IT mit 16 Kernen, 100 W und 2,20 GHz.  Dadurch wird die Rechenleistung der CPU erheblich gesteigert.  Während die CPU bei der Ausführung der Inferenz-Workloads selbst keinen Engpass darstellte, hilft sie bei der Datenverarbeitung und anderen Aufgaben im Zusammenhang mit der Inferenz.  Derzeit ist NVIDIA T4 die einzige GPU, die für Edge-Anwendungsfälle verfügbar ist. Daher besteht derzeit keine Möglichkeit, die GPU zu aktualisieren oder herunterzustufen.</block>
  <block id="928fe421f0c735b90f3b3ec353741235" category="section-title">Gemeinsam genutzter Speicher</block>
  <block id="ba49c21e7aa335a8ea452042c02f306a" category="paragraph">Für die Tests und Validierungen wurde für dieses Dokument das NetApp AFF C190 System verwendet, das eine maximale Speicherkapazität von 50,5 TB, einen Durchsatz von 4,4 GBps für sequenzielle Lesevorgänge und 230.000 IOPS für kleine zufällige Lesevorgänge aufweist und sich als gut geeignet für Edge-Inferenz-Workloads erwiesen hat.</block>
  <block id="44114b1635cead15f56735bad0467251" category="inline-link">NetApp EF300</block>
  <block id="043774815e3806ded716086e0c8c3d03" category="paragraph">Wenn Sie jedoch mehr Speicherkapazität oder schnellere Netzwerkgeschwindigkeiten benötigen, sollten Sie die Speichersysteme NetApp AFF A220 oder NetApp AFF A250 verwenden.  Darüber hinaus wurde für die Validierung dieser Lösung auch das NetApp EF280-System mit einer maximalen Kapazität von 1,5 PB und einer Bandbreite von 10 GBps verwendet.  Wenn Sie mehr Speicherkapazität mit höherer Bandbreite bevorzugen,<block ref="ab4f2e0c1e56faa457a7a1f93253a647" category="inline-link-rx"></block> verwendet werden.</block>
  <block id="6c2749dd86f49cdb85fde6976a317e4b" category="summary">In diesem Abschnitt werden die technologischen Grundlagen dieser KI-Lösung beschrieben.</block>
  <block id="b2412d3528eff2c1e191154bf1ecfd60" category="section-title">NetApp AFF -Systeme</block>
  <block id="b7bec75e06d57a8576b1ec632131ea53" category="paragraph">Hochmoderne NetApp AFF Speichersysteme ermöglichen die Bereitstellung von KI-Inferenz am Edge, um die Speicheranforderungen von Unternehmen mit branchenführender Leistung, überragender Flexibilität, Cloud-Integration und erstklassigem Datenmanagement zu erfüllen.  NetApp AFF -Systeme wurden speziell für Flash entwickelt und helfen bei der Beschleunigung, Verwaltung und dem Schutz geschäftskritischer Daten.</block>
  <block id="45f242ad7738d4805c03311378260bbf" category="list-text">NetApp AFF Speichersysteme der Einstiegsklasse basieren auf FAS2750 -Hardware und SSD-Flash-Medien</block>
  <block id="d308392edcd4d2f839897b51e24cf6f6" category="list-text">Zwei Controller in HA-Konfiguration</block>
  <block id="b2ed189fbf328f509ec4ca77960d3e1a" category="paragraph"><block ref="b2ed189fbf328f509ec4ca77960d3e1a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6b0a1e5585dc8095dd546c5930f1a6c" category="paragraph">NetApp AFF C190 Speichersysteme der Einstiegsklasse unterstützen die folgenden Funktionen:</block>
  <block id="42087aa1683ece2ea30ab7fa45862cd6" category="list-text">Eine maximale Laufwerksanzahl von 24 x 960 GB SSDs</block>
  <block id="d7123d8583ed65e3090da25ea5aee965" category="list-text">Zwei mögliche Konfigurationen:</block>
  <block id="35b9fc01c3820062d5969f142bdc5ce5" category="list-text">Ethernet (10 GbE): 4 x 10GBASE-T (RJ-45)-Ports</block>
  <block id="f5e2ae88aead451be011eb9f8abfdd6e" category="list-text">Unified (16 Gb FC oder 10 GbE): 4x Unified Target Adapter 2 (UTA2)-Ports</block>
  <block id="1e927fd215e516034d85785b393b0efb" category="list-text">Maximal 50,5 TB effektive Kapazität</block>
  <block id="aa9cba7f7b6d2ff8fb2251620a584dcd" category="admonition">Für NAS-Workloads unterstützt ein einzelnes AFF C190 System der Einstiegsklasse einen Durchsatz von 4,4 GBps für sequenzielle Lesevorgänge und 230.000 IOPS für kleine zufällige Lesevorgänge bei Latenzen von 1 ms oder weniger.</block>
  <block id="1672d070f346948fb25e819b40bb3ade" category="section-title">NetApp AFF A220</block>
  <block id="ac7bdd389786fda32ee572c48eef4838" category="paragraph">NetApp bietet auch andere Speichersysteme der Einstiegsklasse an, die eine höhere Leistung und Skalierbarkeit für größere Bereitstellungen bieten.  Für NAS-Workloads unterstützt ein einzelnes AFF A220 System der Einstiegsklasse:</block>
  <block id="732568c5581337c7341011c38721e2db" category="list-text">Durchsatz von 6,2 GBps für sequenzielle Lesevorgänge</block>
  <block id="4900f6d90a4169888690f2c04f3c6603" category="list-text">375.000 IOPS für kleine zufällige Lesevorgänge bei Latenzen von 1 ms oder weniger</block>
  <block id="fbcd9d84b2d7be8631cbf7226884f17a" category="list-text">Maximale Laufwerksanzahl von 144 x 960 GB, 3,8 TB oder 7,6 TB SSDs</block>
  <block id="db527e605a2eacc627448a70b8a745db" category="list-text">AFF A220 lässt sich auf über 1 PB effektive Kapazität skalieren</block>
  <block id="25297dbc8df2aecff2fa2e9e47638d35" category="section-title">NetApp AFF A250</block>
  <block id="cac36335022421f12e1c8e999ffeb1af" category="list-text">Die maximale effektive Kapazität beträgt 35 PB mit maximaler Skalierung von 2–24 Knoten (12 HA-Paare).</block>
  <block id="62a23a7791227c5f5e3d068e70759128" category="list-text">Bietet ≥ 45 % Leistungssteigerung gegenüber AFF A220</block>
  <block id="dc7ac33362f108fc7f4b7d8eb0e2cf4e" category="list-text">440.000 IOPS zufällige Lesevorgänge bei 1 ms</block>
  <block id="0f4615fb8d6105bcb2cbce504f8f091c" category="list-text">Basierend auf der neuesten NetApp ONTAP -Version: ONTAP 9.8</block>
  <block id="440a976974d702d027543e058c1fffc0" category="list-text">Nutzt zwei 25-Gb-Ethernet-Anschlüsse für HA und Cluster-Verbindungen</block>
  <block id="4dc1c0d5a0f0257d8d9e183bc226ab45" category="section-title">NetApp E-Serie EF-Systeme</block>
  <block id="f5e23a285b378cde99c2d7fb43586c1b" category="paragraph">Die EF-Serie ist eine Familie von All-Flash-SAN-Speicher-Arrays der Einstiegs- und Mittelklasse, die den Zugriff auf Ihre Daten beschleunigen und Ihnen mithilfe der NetApp SANtricity -Software dabei helfen können, schneller einen Nutzen daraus zu ziehen.  Diese Systeme bieten sowohl SAS- als auch NVMe-Flash-Speicher und bieten Ihnen erschwingliche bis extreme IOPS, Reaktionszeiten unter 100 Mikrosekunden und eine Bandbreite von bis zu 44 GBps – und sind damit ideal für gemischte Workloads und anspruchsvolle Anwendungen wie KI-Inferenz und High-Performance Computing (HPC).</block>
  <block id="96e4797e3006bef737785f8627faae06" category="paragraph">Die folgende Abbildung zeigt das NetApp EF280-Speichersystem.</block>
  <block id="94bb9af4c6eb62dbf44f691e2565e77e" category="paragraph"><block ref="94bb9af4c6eb62dbf44f691e2565e77e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6f17b7c2ad64f8977585fc43d702abf" category="section-title">NetApp EF280</block>
  <block id="2d6477e98cb834485323c97da975c640" category="list-text">32 Gb/16 Gb FC, 25 Gb/10 Gb iSCSI und 12 Gb SAS-Unterstützung</block>
  <block id="d637a0904677ae775d98b9ce0beda3d6" category="list-text">Die maximale effektive Kapazität beträgt 96 Laufwerke mit insgesamt 1,5 PB</block>
  <block id="6f409cb54d8cb27deac8a918fe03f3cc" category="list-text">Durchsatz von 10 GBps (sequentielles Lesen)</block>
  <block id="7c61b8793dbe5a66cbf144bdabcf76cd" category="list-text">300.000 IOPs (zufällige Lesevorgänge)</block>
  <block id="4c5a963973ae3026e92baab2ef522c6c" category="list-text">Das NetApp EF280 ist das kostengünstigste All-Flash-Array (AFA) im NetApp Portfolio</block>
  <block id="f1330bea5ad6aa446aa17d0a324bb579" category="list-text">24x NVMe-SSD-Laufwerke für eine Gesamtkapazität von 367 TB</block>
  <block id="6768e0b9e957297070e3822e98a4b8f9" category="list-text">Erweiterungsmöglichkeiten auf insgesamt 240x NL-SAS HDDs, 96x SAS SSDs oder eine Kombination</block>
  <block id="0fa40de31cbd933cc9a954d82204feb9" category="list-text">100 GB NVMe/IB, NVMe/RoCE, iSER/IB und SRP/IB</block>
  <block id="aee7a4e3788dbbff7166952ed0e2d2c9" category="list-text">32 GB NVME/FC, FCP</block>
  <block id="c4b9deb88d9cf1b1a2160cb28a2c41ca" category="list-text">25 GB iSCSI</block>
  <block id="03597240f9b0b4a23f3ffdf6e159d6ca" category="list-text">20 GB/s (sequentielles Lesen)</block>
  <block id="ffe3b3adfe232ee25f1914e7e7d266c4" category="list-text">670.000 IOPs (zufällige Lesevorgänge)</block>
  <block id="7105ea3513c2bdae1a0d63a9f0703579" category="inline-link">NetApp EF-Serie – Datenblatt zu den All-Flash-Arrays der NetApp EF-Serie EF600, F300, EF570 und EF280</block>
  <block id="6e69804b180359b12a32a56c17c0641e" category="admonition">Weitere Informationen finden Sie im<block ref="5f5484869dc0c271e2b062d172d38bee" category="inline-link-rx"></block> .</block>
  <block id="a5119a6bd0f4d733e0f1f4c10f9d063b" category="section-title">NetApp ONTAP 9</block>
  <block id="b407d5a86fd662f03d5a1615963e0827" category="paragraph">ONTAP 9.8.1, die neueste Generation der Speicherverwaltungssoftware von NetApp, ermöglicht Unternehmen die Modernisierung ihrer Infrastruktur und den Übergang zu einem Cloud-fähigen Rechenzentrum.  Durch die Nutzung branchenführender Datenverwaltungsfunktionen ermöglicht ONTAP die Verwaltung und den Schutz von Daten mit einem einzigen Satz von Tools, unabhängig davon, wo sich diese Daten befinden.  Sie können Daten auch frei dorthin verschieben, wo sie benötigt werden: an den Rand, in den Kern oder in die Cloud.  ONTAP 9.8.1 umfasst zahlreiche Funktionen, die das Datenmanagement vereinfachen, kritische Daten beschleunigen und schützen und Infrastrukturfunktionen der nächsten Generation in Hybrid-Cloud-Architekturen ermöglichen.</block>
  <block id="2e2b24551fd50942c6da57d4f8efdfae" category="paragraph">Das Datenmanagement ist für den IT-Betrieb in Unternehmen von entscheidender Bedeutung, damit für Anwendungen und Datensätze die richtigen Ressourcen verwendet werden.  ONTAP umfasst die folgenden Funktionen zur Rationalisierung und Vereinfachung des Betriebs und zur Senkung der Gesamtbetriebskosten:</block>
  <block id="4934cd09a8e487be128d2b6321ee3279" category="list-text">*Inline-Datenkomprimierung und erweiterte Deduplizierung.*  Durch die Datenkomprimierung wird der verschwendete Speicherplatz in Speicherblöcken reduziert und durch die Deduplizierung wird die effektive Kapazität erheblich erhöht.  Dies gilt für lokal gespeicherte Daten und für in der Cloud gespeicherte Daten.</block>
  <block id="0ddc097c124782f16e8a0a1b014fc2bb" category="list-text">*Minimale, maximale und adaptive Dienstqualität (AQoS).*  Durch granulare Quality of Service (QoS)-Kontrollen wird die Aufrechterhaltung des Leistungsniveaus kritischer Anwendungen in Umgebungen mit hoher gemeinsamer Nutzung unterstützt.</block>
  <block id="0c720f269a89477f24f77f6f027719cc" category="inline-link-macro">TR-4598</block>
  <block id="7920a2957aeb5c70e8ee2fa43c94e741" category="list-text">* NetApp FabricPool.*  Diese Funktion ermöglicht die automatische Einstufung kalter Daten in öffentliche und private Cloud-Speicheroptionen, einschließlich der Speicherlösung Amazon Web Services (AWS), Azure und NetApp StorageGRID .  Weitere Informationen zu FabricPool finden Sie unter<block ref="38e4393e170a142db2e52760317ecb7f" category="inline-link-macro-rx"></block> .</block>
  <block id="85e643b872d0d98ec2251220de803a1f" category="paragraph">ONTAP 9 bietet ein Höchstmaß an Leistung und Datenschutz und erweitert diese Funktionen auf folgende Weise:</block>
  <block id="bfb9fa643243eb975ccd9d158cf97800" category="list-text">*Leistung und geringere Latenz.*  ONTAP bietet den höchstmöglichen Durchsatz bei der geringstmöglichen Latenz.</block>
  <block id="ef9770ee572f97c59254dc0d022afda8" category="list-text">*Datenschutz.*  ONTAP bietet integrierte Datenschutzfunktionen mit gemeinsamer Verwaltung auf allen Plattformen.</block>
  <block id="86a12b3dbbf039b371f714a515919535" category="list-text">* NetApp Volume Encryption (NVE).*  ONTAP bietet native Verschlüsselung auf Volume-Ebene mit Unterstützung für integriertes und externes Schlüsselmanagement.</block>
  <block id="b3023c0a4db125fc22f0d6056c6e379d" category="list-text">*Mandantenfähigkeit und Multifaktor-Authentifizierung.*  ONTAP ermöglicht die gemeinsame Nutzung von Infrastrukturressourcen mit höchster Sicherheit.</block>
  <block id="f9eaef0b2cf89b234c431c18aec36bf3" category="paragraph">ONTAP 9 unterstützt Sie mit den folgenden Funktionen dabei, anspruchsvolle und sich ständig ändernde Geschäftsanforderungen zu erfüllen:</block>
  <block id="9e98379ad83b5c60933a3437c7fb61c7" category="list-text">*Nahtlose Skalierung und unterbrechungsfreier Betrieb.*  ONTAP unterstützt die unterbrechungsfreie Kapazitätserweiterung bestehender Controller und Scale-Out-Cluster.  Kunden können ohne kostspielige Datenmigrationen oder Ausfälle auf die neuesten Technologien wie NVMe und 32 GB FC upgraden.</block>
  <block id="7d97721ced74a2279b6645f506722980" category="list-text">*Cloud-Verbindung.*  ONTAP ist die Speicherverwaltungssoftware mit der stärksten Cloud-Anbindung und bietet Optionen für softwaredefinierten Speicher (ONTAP Select) und Cloud-native Instanzen (Google Cloud NetApp Volumes) in allen öffentlichen Clouds.</block>
  <block id="b5dc6026803056308b6bf7007af32a2b" category="list-text">*Integration mit neuen Anwendungen.*  ONTAP bietet Datendienste der Enterprise-Klasse für Plattformen und Anwendungen der nächsten Generation, wie etwa autonome Fahrzeuge, Smart Cities und Industrie 4.0, und nutzt dabei dieselbe Infrastruktur, die auch bestehende Unternehmens-Apps unterstützt.</block>
  <block id="e4872d9c30e978d9408425f0e08882c5" category="section-title">NetApp SANtricity</block>
  <block id="965539211ad2d7bc981e7e954db08850" category="inline-link">Datenblatt zur NetApp E-Series SANtricity Software</block>
  <block id="568549d316f6f749a07012e522e0bca3" category="paragraph">NetApp SANtricity wurde entwickelt, um branchenführende Leistung, Zuverlässigkeit und Einfachheit für Hybrid-Flash-Arrays der E-Serie und All-Flash-Arrays der EF-Serie bereitzustellen.  Erreichen Sie maximale Leistung und Auslastung Ihrer Hybrid-Flash- und All-Flash-Arrays der E-Serie und der EF-Serie für Anwendungen mit hoher Arbeitslast, einschließlich Datenanalyse, Videoüberwachung sowie Sicherung und Wiederherstellung.  Mit SANtricity können Konfigurationsoptimierungen, Wartungsarbeiten, Kapazitätserweiterungen und andere Aufgaben durchgeführt werden, während der Speicher online bleibt.  SANtricity bietet außerdem hervorragenden Datenschutz, proaktive Überwachung und zertifizierte Sicherheit – alles zugänglich über die benutzerfreundliche, integrierte System Manager-Schnittstelle.  Weitere Informationen finden Sie im<block ref="64769f0652e98a060ba5d2cd17320298" category="inline-link-rx"></block> .</block>
  <block id="c4cf91172f1e96366d0dfa38c1167df9" category="section-title">Leistungsoptimiert</block>
  <block id="3d615c3559b8d33749ea23cf3a34b759" category="paragraph">Die leistungsoptimierte SANtricity -Software liefert Daten – mit hohen IOPs, hohem Durchsatz und geringer Latenz – an alle Ihre Datenanalyse-, Videoüberwachungs- und Backup-Apps.  Beschleunigen Sie die Leistung für Anwendungen mit hohem IOPS, geringer Latenz und hoher Bandbreite und hohem Durchsatz.</block>
  <block id="8238dd9365065265be82d79d4dd38a98" category="section-title">Maximieren Sie die Betriebszeit</block>
  <block id="28ed557ae8b4ff60f83da71465cbcb9b" category="paragraph">Erledigen Sie alle Ihre Verwaltungsaufgaben, während der Speicher online bleibt.  Optimieren Sie Konfigurationen, führen Sie Wartungsarbeiten durch oder erweitern Sie die Kapazität, ohne den E/A-Betrieb zu unterbrechen.  Erreichen Sie erstklassige Zuverlässigkeit mit automatisierten Funktionen, Online-Konfiguration, modernster Dynamic Disk Pools (DPP)-Technologie und mehr.</block>
  <block id="2b34e4806834294a7dd611ad1d7d0308" category="section-title">Ruhe dich aus</block>
  <block id="7847b3892c0f355acdb3fe824654e209" category="paragraph">Die SANtricity -Software bietet überlegenen Datenschutz, proaktive Überwachung und zertifizierte Sicherheit – alles über die benutzerfreundliche, integrierte System Manager-Schnittstelle.  Vereinfachen Sie die Speicherverwaltungsaufgaben.  Gewinnen Sie die Flexibilität, die Sie für die erweiterte Optimierung aller Speichersysteme der E-Serie benötigen.  Verwalten Sie Ihr NetApp E-Series-System – jederzeit und überall.  Unsere integrierte, webbasierte Schnittstelle optimiert Ihren Verwaltungsworkflow.</block>
  <block id="10f0fa4079121b371145e16713fdbb44" category="inline-link">Trident</block>
  <block id="2758085534b10a85f702f6a61737eefb" category="paragraph"><block ref="d14308042ff124582c531f74c03d90f3" category="inline-link-rx"></block>von NetApp ist ein Open-Source-Orchestrator für dynamischen Speicher für Docker und Kubernetes, der die Erstellung, Verwaltung und Nutzung von persistentem Speicher vereinfacht.  Trident, eine native Kubernetes-Anwendung, läuft direkt in einem Kubernetes-Cluster.  Trident ermöglicht Kunden die nahtlose Bereitstellung von DL-Container-Images auf NetApp Speicher und bietet eine unternehmenstaugliche Erfahrung für die Bereitstellung von KI-Containern.  Kubernetes-Benutzer (wie etwa ML-Entwickler und Datenwissenschaftler) können Orchestrierung und Klonen erstellen, verwalten und automatisieren, um die erweiterten Datenverwaltungsfunktionen von NetApp auf Basis der NetApp -Technologie zu nutzen.</block>
  <block id="9b6334cb865bfb3ae702677852339a38" category="paragraph"><block ref="9f25cf06e22037e38bb7442b4d301b6c" category="inline-link-rx"></block>ist ein NetApp -Dienst für die schnelle und sichere Datensynchronisierung.  Unabhängig davon, ob Sie Dateien zwischen lokalen NFS- oder SMB-Dateifreigaben, NetApp StorageGRID, NetApp ONTAP S3, Google Cloud NetApp Volumes, Azure NetApp Files, Amazon Simple Storage Service (Amazon S3), Amazon Elastic File System (Amazon EFS), Azure Blob, Google Cloud Storage oder IBM Cloud Object Storage übertragen müssen, verschiebt BlueXP Copy and Sync die Dateien schnell und sicher dorthin, wo Sie sie benötigen.  Nachdem Ihre Daten übertragen wurden, stehen sie sowohl auf der Quelle als auch auf dem Ziel vollständig zur Verwendung zur Verfügung.  BlueXP Copy and Sync synchronisiert die Daten kontinuierlich basierend auf Ihrem vordefinierten Zeitplan und verschiebt nur die Deltas, sodass der Zeit- und Kostenaufwand für die Datenreplikation minimiert wird.  BlueXP Copy and Sync ist ein Software-as-a-Service-Tool (SaaS), das extrem einfach einzurichten und zu verwenden ist.  Datenübertragungen, die durch BlueXP Copy and Sync ausgelöst werden, werden von Datenbrokern durchgeführt.  Sie können BlueXP Copy and Sync-Datenbroker in AWS, Azure, Google Cloud Platform oder vor Ort bereitstellen.</block>
  <block id="8eb0c6a27656d04de6abfc6d24a1a8d5" category="paragraph">Lenovo ThinkSystem-Server verfügen über innovative Hardware, Software und Services, die die Herausforderungen der Kunden von heute lösen und einen evolutionären, zweckmäßigen und modularen Designansatz bieten, um die Herausforderungen von morgen zu bewältigen.  Diese Server nutzen branchenführende Technologien nach Industriestandard in Verbindung mit differenzierten Innovationen von Lenovo, um die größtmögliche Flexibilität bei x86-Servern zu bieten.</block>
  <block id="493e1540ce727fb5f465fff015aa4733" category="paragraph">Zu den wichtigsten Vorteilen der Bereitstellung von Lenovo ThinkSystem-Servern gehören:</block>
  <block id="b7c6c5eb82b90f69eddd06060626e5e3" category="list-text">Hochgradig skalierbare, modulare Designs, die mit Ihrem Unternehmen wachsen</block>
  <block id="c2599c559a0be54b242b8aa3c67325c8" category="list-text">Branchenführende Ausfallsicherheit, um Stunden kostspieliger ungeplanter Ausfallzeiten zu vermeiden</block>
  <block id="c57cb88fcbeb47afa8496b8fc32cbf03" category="list-text">Schnelle Flash-Technologien für geringere Latenzen, schnellere Reaktionszeiten und intelligenteres Datenmanagement in Echtzeit</block>
  <block id="6d72d9a0181555ca86c9562861e47058" category="paragraph">Im KI-Bereich verfolgt Lenovo einen praktischen Ansatz, um Unternehmen dabei zu helfen, die Vorteile von ML und KI für ihre Arbeitslasten zu verstehen und zu nutzen.  Lenovo-Kunden können die KI-Angebote von Lenovo in den Lenovo AI Innovation Centers erkunden und bewerten, um den Wert für ihren speziellen Anwendungsfall vollständig zu verstehen.  Um die Time-to-Value zu verbessern, bietet dieser kundenorientierte Ansatz den Kunden einen Proof of Concept für einsatzbereite und für KI optimierte Lösungsentwicklungsplattformen.</block>
  <block id="6bf0f92a7340921305982a91f7277085" category="paragraph">Edge Computing ermöglicht die Analyse von Daten von IoT-Geräten am Rand des Netzwerks, bevor sie an das Rechenzentrum oder die Cloud gesendet werden.  Das Lenovo ThinkSystem SE350, wie in der Abbildung unten dargestellt, ist für die einzigartigen Anforderungen der Bereitstellung am Rand konzipiert, wobei der Schwerpunkt auf Flexibilität, Konnektivität, Sicherheit und Fernverwaltung in einem kompakten, robusten und umgebungsbeständigen Formfaktor liegt.</block>
  <block id="72dd0df190a1bdc8d3043fafdba7122b" category="paragraph">Der SE350 ist mit dem Intel Xeon D-Prozessor ausgestattet und bietet die Flexibilität, die Beschleunigung für Edge-KI-Workloads zu unterstützen. Er wurde speziell für die Herausforderungen von Serverbereitstellungen in einer Vielzahl von Umgebungen außerhalb des Rechenzentrums entwickelt.</block>
  <block id="c45cd4236e9fecc47291c206c4aac70a" category="paragraph"><block ref="c45cd4236e9fecc47291c206c4aac70a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="16bb0d66e42a8bb99cbefc63c53bcfdc" category="paragraph"><block ref="16bb0d66e42a8bb99cbefc63c53bcfdc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45c08b3aee1d5fb5dc3447ec1271a853" category="inline-link">MLPerf-Inferenz v0.7</block>
  <block id="f6922096e43c9e99d2be9d521357ff1c" category="paragraph">MLPerf ist die branchenführende Benchmark-Suite zur Bewertung der KI-Leistung.  Es deckt viele Bereiche der angewandten KI ab, darunter Bildklassifizierung, Objekterkennung, medizinische Bildgebung und Verarbeitung natürlicher Sprache (NLP).  Bei dieser Validierung haben wir Inference v0.7-Workloads verwendet, die zum Zeitpunkt der Fertigstellung dieser Validierung die neueste Iteration von MLPerf Inference darstellt.  Der<block ref="1303efdddf9d8dbc0de31c402aa4ef22" category="inline-link-rx"></block> Die Suite umfasst vier neue Benchmarks für Rechenzentren und Edge-Systeme:</block>
  <block id="c781a146774780843a929b97004ba720" category="list-text">*BERT.*  Bidirektionale Encoder-Darstellung von Transformatoren (BERT), optimiert für die Beantwortung von Fragen mithilfe des SQuAD-Datensatzes.</block>
  <block id="cb93b50c2b2216543a9eee4d9a38b38c" category="list-text">*DLRM.*  Das Deep Learning Recommendation Model (DLRM) ist ein Personalisierungs- und Empfehlungsmodell, das darauf trainiert ist, die Klickrate (CTR) zu optimieren.</block>
  <block id="16139bb6e8da8fe8f8aaf1e5fb8bde0d" category="list-text">*3D U-Net.*  Die 3D-U-Net-Architektur wird anhand des Brain Tumor Segmentation (BraTS)-Datensatzes trainiert.</block>
  <block id="5691eec0e5e0ea401478ea67b8168d64" category="list-text">*RNN-T.* Recurrent Neural Network Transducer (RNN-T) ist ein Modell zur automatischen Spracherkennung (ASR), das mit einer Teilmenge von LibriSpeech trainiert wird.  Die Ergebnisse und der Code von MLPerf Inference sind öffentlich verfügbar und werden unter der Apache-Lizenz veröffentlicht.  MLPerf Inference verfügt über eine Edge-Abteilung, die die folgenden Szenarien unterstützt:</block>
  <block id="e772865569495cb43ba25be1d6eed756" category="list-text">*Einzelner Stream.*  Dieses Szenario ahmt Systeme nach, bei denen die Reaktionsfähigkeit ein kritischer Faktor ist, wie etwa Offline-KI-Abfragen, die auf Smartphones durchgeführt werden.  Dabei werden einzelne Anfragen an das System gesendet und die Antwortzeiten erfasst.  Als Ergebnis wird die Latenz des 90. Perzentils aller Antworten gemeldet.</block>
  <block id="f9cf7025c2d80af397a9b960974631e2" category="list-text">*Multistream.*  Dieser Benchmark gilt für Systeme, die Eingaben von mehreren Sensoren verarbeiten.  Während des Tests werden in einem festen Zeitintervall Abfragen gesendet.  Es wird eine QoS-Einschränkung (maximal zulässige Latenz) auferlegt.  Der Test meldet die Anzahl der Streams, die das System verarbeiten kann, während die QoS-Einschränkung eingehalten wird.</block>
  <block id="78a9abbe3c771a5882830fc8e2a73a8f" category="list-text">*Offline.*  Dies ist das einfachste Szenario für Stapelverarbeitungsanwendungen und die Messgröße ist der Durchsatz in Samples pro Sekunde.  Alle Daten stehen dem System zur Verfügung und der Benchmark misst die Zeit, die für die Verarbeitung aller Proben benötigt wird.</block>
  <block id="cc8cc2653d3a795d17b5d90b14d00e19" category="inline-link"><block ref="cc8cc2653d3a795d17b5d90b14d00e19" category="inline-link-rx"></block></block>
  <block id="13176cbb826705821e77b735791d29d4" category="paragraph">Lenovo hat MLPerf-Inferenzwerte für SE350 mit T4 veröffentlicht, den in diesem Dokument verwendeten Server.  Die Ergebnisse finden Sie unter<block ref="8efc95b379113ebfb6f66010213223ce" category="inline-link-rx"></block> im Abschnitt „Edge, Closed Division“ im Eintrag Nr. 0.7-145.</block>
  <block id="686ebb62ce1be84dcfae0007fb84562d" category="summary">Das für die Validierung verwendete Setup kann an andere Anwendungsfälle angepasst werden.</block>
  <block id="bf46169695d75ff844d955af09f33e75" category="doc">Architekturanpassungen</block>
  <block id="1cf27bd587c6c632877c322cf42c0d97" category="paragraph">Das für diese Validierung verwendete Setup kann an andere Anwendungsfälle angepasst werden.</block>
  <block id="a752efb5fb2512dc99b2045f032779f7" category="section-title">CPU-Anpassungen</block>
  <block id="122acc941b98ef5a11208d23ed0a8090" category="paragraph">Für diese Validierung haben wir, wie von Lenovo empfohlen, einen Skylake Intel Xeon Platinum 8360Y-Prozessor verwendet.  Wir gehen davon aus, dass die entsprechende Cascade Lake-CPU, ein Intel Xeon Gold 6330-Prozessor, eine ähnliche Leistung liefern würde, da diese Arbeitslast nicht CPU-gebunden ist.</block>
  <block id="3cc37c167d58a1828b00c13cc6018ae8" category="section-title">Erhöhung der Speicherkapazität</block>
  <block id="f40ff1aaa4f2e4ccd4189adfb3584e29" category="paragraph">Basierend auf Ihrem Speicherkapazitätsbedarf können Sie den gemeinsam genutzten Speicher (NFS-Volume) bei Bedarf erhöhen, vorausgesetzt, Sie verfügen über die zusätzlichen Festplatten-Shelves und Controller-Modelle.  Sie können dies über die CLI oder als Administratorbenutzer über die NetApp Weboberfläche des Speichercontrollers tun.</block>
  <block id="15977ebfd8c3685ca2d8911f74efcc2d" category="summary">Diese Lösung von NetApp und Lenovo ist eine flexible Scale-Out-Architektur, die sich ideal für den Einstieg in die KI mittlerer Unternehmensebene eignet.  NetApp -Speicher bietet die gleiche oder eine bessere Leistung als lokaler SSD-Speicher und bietet Datenwissenschaftlern, Dateningenieuren und IT-Entscheidungsträgern die folgenden Vorteile.</block>
  <block id="994c1f46e0860094a86d2a822416646b" category="paragraph">Bei der hier validierten Lösung von NetApp und Lenovo handelt es sich um eine flexible Scale-Out-Architektur, die sich ideal für den Einstieg in die KI mittlerer Unternehmensebene eignet.</block>
  <block id="bcbfcce438abee9a9a41cb7e588eb4de" category="paragraph">NetApp Storage bietet die gleiche oder eine bessere Leistung als lokaler SSD-Speicher und bietet Datenwissenschaftlern, Dateningenieuren und IT-Entscheidungsträgern die folgenden Vorteile:</block>
  <block id="6127562591a3f60f8ac270d3967754dd" category="list-text">Unabhängig skalierbare Rechenleistung und Speicherung zur Minimierung der Kosten und Verbesserung der Ressourcennutzung.</block>
  <block id="74902bcc2ed17395305301b925afee3f" category="list-text">Optimierte Entwicklungs- und Bereitstellungs-Workflows durch integrierte Snapshots und Klone für sofortige und platzsparende Benutzerarbeitsbereiche, integrierte Versionskontrolle und automatisierte Bereitstellung.</block>
  <block id="42e2aaa2f651d8ad800a51f65a258f1e" category="list-text">Unternehmensweiter Datenschutz für Notfallwiederherstellung und Geschäftskontinuität.</block>
  <block id="2ea563f362255807faae7242f06c9881" category="list-text">Karthikeyan Nagalingam, technischer Marketingingenieur, NetApp</block>
  <block id="cccf21ceeae034a9e54b62eb00d9b6b3" category="list-text">Jarrett Upton, Administrator, AI Lab Systems, Lenovo</block>
  <block id="fdc944d7a0de8d8e3dfff03c6a0e03c6" category="list-text">Produktseite zu NetApp All Flash Arrays</block>
  <block id="d875955d78b62e4aff0847425410f79a" category="inline-link"><block ref="d875955d78b62e4aff0847425410f79a" category="inline-link-rx"></block></block>
  <block id="45f6f9585c85146b389a4f896653a5f9" category="paragraph"><block ref="45f6f9585c85146b389a4f896653a5f9" category="inline-link-rx"></block></block>
  <block id="ec5282877903d9d2aceb3db45b21da54" category="list-text">NetApp AFF A400 Seite</block>
  <block id="1f84bc4168c48270f2cc931b900d9eb4" category="inline-link"><block ref="1f84bc4168c48270f2cc931b900d9eb4" category="inline-link-rx"></block></block>
  <block id="04438df627d0343d17b2f6f307b489ed" category="paragraph"><block ref="04438df627d0343d17b2f6f307b489ed" category="inline-link-rx"></block></block>
  <block id="9d92155996555576a58d20e697fc2bd6" category="list-text">Produktseite der NetApp ONTAP Datenmanagementsoftware</block>
  <block id="dae4be95628a9cc8cb5ecb4b90cd738e" category="inline-link"><block ref="dae4be95628a9cc8cb5ecb4b90cd738e" category="inline-link-rx"></block></block>
  <block id="2f08744b4a39af375744e1fc4a15b53a" category="paragraph"><block ref="2f08744b4a39af375744e1fc4a15b53a" category="inline-link-rx"></block></block>
  <block id="45913847e0b47b72b60766711f7a8c21" category="inline-link"><block ref="45913847e0b47b72b60766711f7a8c21" category="inline-link-rx"></block></block>
  <block id="229469a202dbd3052c7b165bd55eda87" category="paragraph"><block ref="229469a202dbd3052c7b165bd55eda87" category="inline-link-rx"></block></block>
  <block id="dedba6b3261804ab1e5c2b75051c62ac" category="list-text">NVIDIA SMI (nvidia-smi)</block>
  <block id="f5800a0bf7fbf711d11868c2913c218f" category="inline-link"><block ref="f5800a0bf7fbf711d11868c2913c218f" category="inline-link-rx"></block></block>
  <block id="41299b529a1014318d5e7776b9f92ad1" category="paragraph"><block ref="41299b529a1014318d5e7776b9f92ad1" category="inline-link-rx"></block></block>
  <block id="bd7c9d63c88eb380170362e93db6ba46" category="summary">In diesem Abschnitt werden die getesteten Konfigurationen, die Netzwerkinfrastruktur, der SR670 V2-Server und die Details zur Speicherbereitstellung beschrieben.</block>
  <block id="a1052c50691421535c201fa50690a1ca" category="paragraph">In diesem Abschnitt werden die getesteten Konfigurationen, die Netzwerkinfrastruktur, der SR670 V2-Server und die Details zur Bereitstellung des NetApp Speichers beschrieben.</block>
  <block id="7c8d74d4c719b2f2e30a143bb98717ad" category="paragraph">Für diese Validierung haben wir die in der folgenden Tabelle aufgeführten Lösungskomponenten verwendet.</block>
  <block id="35c99b744e4464f42b9b61595c1a1e79" category="list-text">Zwei SR670 V2-Server mit jeweils acht NVIDIA A100 80GB GPU-Karten</block>
  <block id="222a9edda77d8676279c651c1b06d653" category="list-text">Jeder Server enthält 2 Intel Xeon Platinum 8360Y CPUs (28 physische Kerne) und 1 TB RAM</block>
  <block id="e18f1a9d73bf89b2b1245e5af1a99cf4" category="cell">Linux (Ubuntu – 20.04 mit CUDA 11.8)</block>
  <block id="2113187ee3a9451b60e960fdea11bbac" category="cell">NetApp AFF Speichersystem (HA-Paar)</block>
  <block id="73b4d2da39f967445be9b79a6016c84c" category="list-text">NetApp ONTAP 9.10.1 Software</block>
  <block id="4028b206981977bc3aea334fd55f4cb9" category="list-text">1 Schnittstellengruppe (ifgrp) pro Controller mit vier logischen IP-Adressen für Mount-Punkte</block>
  <block id="82693066c3bae0719e01ba8060494172" category="paragraph">Bei dieser Validierung haben wir ResNet v2.0 mit dem ImageNet-Basissatz gemäß MLPerf v2.0 verwendet.  Der Datensatz wird in einem NetApp AFF Speichersystem mit dem NFS-Protokoll gespeichert.  Die SR670 wurden über einen 100GbE-Switch mit dem NetApp AFF A400 -Speichersystem verbunden.</block>
  <block id="e4869dda2a4e140bc138f43895626550" category="paragraph">ImageNet ist ein häufig verwendeter Bilddatensatz.  Es enthält fast 1,3 Millionen Bilder mit einer Gesamtgröße von 144 GB.  Die durchschnittliche Bildgröße beträgt 108 KB.</block>
  <block id="3961f6874ee29dab2f4982bc3e0a1be5" category="paragraph">Die folgende Abbildung zeigt die Netzwerktopologie der getesteten Konfiguration.</block>
  <block id="d015822ec6fd4a7fc9867768f5a27898" category="inline-image-macro">Diese Grafik zeigt die Rechenschicht, ein Lenovo ThinkSystem SR670 V2, die Netzwerkschicht, einen Lenovo Ethernet-Switch, und die Speicherschicht, einen NetApp AFF A400 -Speichercontroller.  Alle Netzwerkverbindungen sind inklusive.</block>
  <block id="74ae44f09af988f16e87e4e2e31ef81a" category="paragraph"><block ref="74ae44f09af988f16e87e4e2e31ef81a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18866bc1d6ba54b48522f7a219e02740" category="paragraph">In der folgenden Tabelle ist die Speicherkonfiguration aufgeführt.</block>
  <block id="f64bc191156dac76ffce8622c16cb21d" category="cell">Aggregatgröße</block>
  <block id="6bb41960470a19d97556b9240ac0b3ff" category="cell">Volumengröße</block>
  <block id="abd2beb6abe5072ffab5f1aad1a8c27f" category="cell">Einhängepunkt des Betriebssystems</block>
  <block id="a38b6dcf7d1d2c2957803ba9a28b472e" category="cell">/a400-100g</block>
  <block id="43f5cd38d362fc55ace2f313e6b5cf09" category="cell">9,9 TB</block>
  <block id="09808554056bf39d02319e3dbc2d6667" category="cell">19 TB</block>
  <block id="a27053e11ec415312f3dc32f4e351b67" category="admonition">Der Ordner /a400-100g enthält den für die ResNet-Validierung verwendeten Datensatz.</block>
  <block id="1f599c1b266e901a2c8d38e266e23c6f" category="summary">In diesem Abschnitt werden die Ergebnisse des Testverfahrens im Detail beschrieben.</block>
  <block id="c87fa6e515cf0976291b387e5a8ab6f6" category="doc">Testablauf und detaillierte Ergebnisse</block>
  <block id="b70dd619781891706b7d2f44c418a2b5" category="section-title">Bilderkennungstraining mit ResNet in ONTAP</block>
  <block id="bf523bb892b07c71c90bd7ea34a091a9" category="paragraph">Wir haben den ResNet50-Benchmark mit einem und zwei SR670 V2-Servern ausgeführt.  Bei diesem Test wurde der MXNet 22.04-py3 NGC-Container zum Ausführen des Trainings verwendet.</block>
  <block id="a08c4eedb9047aae68f44b82037739b0" category="paragraph">Bei dieser Validierung haben wir folgendes Testverfahren verwendet:</block>
  <block id="df1a5f60f20e6aa3336812f58095e04f" category="list-text">Wir haben den Host-Cache vor dem Ausführen des Skripts geleert, um sicherzustellen, dass die Daten nicht bereits zwischengespeichert waren:</block>
  <block id="ab93a65fabd2eaae21f5a6e097320730" category="list-text">Wir haben das Benchmark-Skript mit dem ImageNet-Datensatz im Serverspeicher (lokaler SSD-Speicher) sowie auf dem NetApp AFF Speichersystem ausgeführt.</block>
  <block id="9f98453c4a6eede45b87d72527b49e7e" category="list-text">Wir haben die Netzwerk- und lokale Speicherleistung mithilfe von<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> Befehl.</block>
  <block id="47b048d9dcf1d84d76bddb033b842b3b" category="list-text">Für den Einzelknotenlauf haben wir den folgenden Befehl verwendet:</block>
  <block id="cf9a86ba8909a23b4d67d509b389a080" category="list-text">Für die verteilten Läufe haben wir das Parallelisierungsmodell des Parameterservers verwendet.  Wir haben zwei Parameterserver pro Knoten verwendet und die Anzahl der Epochen auf die gleiche Anzahl wie beim Einzelknotenlauf eingestellt.  Wir haben dies getan, weil verteiltes Training aufgrund einer unvollständigen Synchronisierung zwischen Prozessen oft mehr Epochen benötigt.  Die unterschiedliche Anzahl von Epochen kann Vergleiche zwischen Einzelknoten- und verteilten Fällen verzerren.</block>
  <block id="8f74be345dbaeac65cc3a488503b2a1f" category="section-title">Datenlesegeschwindigkeit: Lokaler Speicher im Vergleich zum Netzwerkspeicher</block>
  <block id="16d8fe364e1a7846c093983bec75e764" category="paragraph">Die Lesegeschwindigkeit wurde getestet mit dem<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> Befehl für eine der Dateien für den ImageNet-Datensatz.  Insbesondere haben wir die folgenden Befehle sowohl für lokale als auch für Netzwerkdaten ausgeführt:</block>
  <block id="c685a224eb9a88c5b7bd2be45fe5a128" category="paragraph">Beide Werte sind ähnlich und zeigen, dass der Netzwerkspeicher Daten mit einer ähnlichen Geschwindigkeit wie der lokale Speicher liefern kann.</block>
  <block id="aa613e8f689a1a64605aef401595bfd2" category="section-title">Gemeinsamer Anwendungsfall: Mehrere, unabhängige, gleichzeitige Jobs</block>
  <block id="7e4312d3e922a98bfc1dc4a84c80f12c" category="paragraph">Dieser Test simulierte den erwarteten Anwendungsfall für diese Lösung: KI-Training für mehrere Jobs und mehrere Benutzer.  Jeder Knoten führte sein eigenes Training durch und nutzte dabei den gemeinsam genutzten Netzwerkspeicher.  Die Ergebnisse sind in der folgenden Abbildung dargestellt. Sie zeigt, dass der Lösungsfall eine hervorragende Leistung lieferte, wobei alle Jobs im Wesentlichen mit der gleichen Geschwindigkeit wie die einzelnen Jobs ausgeführt wurden.  Der Gesamtdurchsatz skaliert linear mit der Anzahl der Knoten.</block>
  <block id="2b9215e7cc3c2422637b6f95b0d47d97" category="inline-image-macro">Diese Abbildung zeigt die Gesamtanzahl der Bilder pro Sekunde.</block>
  <block id="568b99e77256e0aa65f03e3612709ffc" category="paragraph"><block ref="568b99e77256e0aa65f03e3612709ffc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45f5fcaaad259a917b031b3169cd5ad4" category="inline-image-macro">Diese Abbildung zeigt die Laufzeit in Minuten.</block>
  <block id="c8a726b6eb44bab6b01c319420a7605a" category="paragraph"><block ref="c8a726b6eb44bab6b01c319420a7605a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="289b386724c768cabf5ad786a3842335" category="paragraph">Diese Diagramme stellen die Laufzeit in Minuten und die aggregierten Bilder pro Sekunde für Rechenknoten dar, die acht GPUs von jedem Server in einem 100-GbE-Clientnetzwerk verwendeten und sowohl das gleichzeitige Trainingsmodell als auch das Einzeltrainingsmodell kombinierten.  Die durchschnittliche Laufzeit des Trainingsmodells betrug 35 Minuten und 9 Sekunden.  Die einzelnen Laufzeiten betrugen 34 Minuten und 32 Sekunden, 36 Minuten und 21 Sekunden, 34 Minuten und 37 Sekunden, 35 Minuten und 25 Sekunden sowie 34 Minuten und 31 Sekunden.  Die durchschnittliche Anzahl an Bildern pro Sekunde für das Trainingsmodell betrug 22.573 und die Anzahl an Einzelbildern pro Sekunde betrug 21.764, 23.438, 22.556, 22.564 und 22.547.</block>
  <block id="ce47a442fe1dc7c09bf9a3ec5ed71236" category="paragraph">Basierend auf unserer Validierung betrug die Laufzeit eines unabhängigen Trainingsmodells mit NetApp -Daten 34 Minuten und 54 Sekunden bei 22.231 Bildern/Sek.  Ein unabhängiges Trainingsmodell mit lokalen Daten (DAS) benötigte eine Laufzeit von 34 Minuten und 21 Sekunden bei 22.102 Bildern/Sek.  Während dieser Läufe lag die durchschnittliche GPU-Auslastung bei 96 %, wie auf nvidia-smi beobachtet.  Beachten Sie, dass dieser Durchschnitt die Testphase umfasst, in der keine GPUs verwendet wurden, während die CPU-Auslastung laut mpstat-Messung 40 % betrug.  Dies zeigt, dass die Datenübermittlungsrate in jedem Fall ausreichend ist.</block>
  <block id="1d126a9d86b70dcdbc0585754993a848" category="summary">Diese Lösung konzentriert sich auf Clusterarchitekturen der Einstiegs- und Mittelklasse unter Verwendung von NetApp -Speicher und Lenovo-Servern, die für Workloads im Bereich künstliche Intelligenz optimiert sind.  Es ist für kleine und mittelgroße Teams gedacht, bei denen die meisten Rechenaufgaben Einzelknoten (Einzel- oder Mehrfach-GPU) sind oder auf wenige Rechenknoten verteilt sind.  Dies stellt keine große Einschränkung dar, da die meisten alltäglichen KI-Trainingsaufgaben Einzelknoten sind.</block>
  <block id="119a956725a313a60a3ef97db900f9fa" category="doc">TR-4810: NetApp AFF A400 mit Lenovo ThinkSystem SR670 V2 für KI- und ML-Modelltraining</block>
  <block id="db297dc3a6b72858a5039fa6507a2b34" category="paragraph">Sathish Thyagarajan, David Arnette, NetApp Mircea Troaca, Lenovo</block>
  <block id="252875fbe73a0c4ecbd42a23cc730022" category="paragraph">Diese Lösung stellt eine Clusterarchitektur mittlerer Preisklasse mit NetApp -Speicher und Lenovo-Servern dar, die für Workloads im Bereich künstliche Intelligenz (KI) optimiert sind.  Es ist für kleine bis mittelgroße Unternehmen gedacht, bei denen die meisten Rechenaufgaben auf einem einzigen Knoten (einzelner oder mehrerer GPUs) ausgeführt werden oder auf einige wenige Rechenknoten verteilt sind.  Diese Lösung ist für die meisten alltäglichen KI-Schulungsaufgaben vieler Unternehmen geeignet.</block>
  <block id="2fd79dc2b0743358191fe41cd806d103" category="paragraph">Dieses Dokument behandelt das Testen und Validieren einer Rechen- und Speicherkonfiguration, die aus Lenovo SR670V2-Servern mit acht GPUs, einem NetApp AFF A400 Speichersystem der Mittelklasse und einem 100-GbE-Verbindungsswitch besteht.  Zur Messung der Leistung haben wir ResNet50 mit dem ImageNet-Datensatz, einer Batchgröße von 408, halber Präzision, CUDA und cuDNN verwendet.  Diese Architektur bietet eine effiziente und kostengünstige Lösung für kleine und mittelgroße Unternehmen, die gerade erst mit KI-Initiativen beginnen, die die unternehmensweiten Funktionen des Cloud-verbundenen Datenspeichers NetApp ONTAP benötigen.</block>
  <block id="a186cc4a556d59a6e7b787796afd96a6" category="list-text">Datenwissenschaftler, Dateningenieure, Datenadministratoren und Entwickler von KI-Systemen</block>
  <block id="9f16d751276619605acf16a23befe48e" category="list-text">Unternehmensarchitekten, die Lösungen für die Entwicklung von KI-Modellen entwerfen</block>
  <block id="e8982c30a351cd862612b0062923a81e" category="list-text">Datenwissenschaftler und Dateningenieure, die nach effizienten Wegen suchen, um Entwicklungsziele im Bereich Deep Learning (DL) und Machine Learning (ML) zu erreichen</block>
  <block id="ca84e34dfe1115f7b462050a20377876" category="list-text">Führungskräfte und OT/IT-Entscheidungsträger, die die schnellstmögliche Markteinführungszeit für KI-Initiativen erreichen möchten</block>
  <block id="a2dac0ecb0b60ec2625d20a5003869fb" category="paragraph">Diese Lösung mit Lenovo ThinkSystem-Servern und NetApp ONTAP mit AFF -Speicher ist für das KI-Training großer Datensätze konzipiert und nutzt dabei die Verarbeitungsleistung von GPUs neben herkömmlichen CPUs.  Diese Validierung demonstriert hohe Leistung und optimales Datenmanagement mit einer Scale-Out-Architektur, die entweder einen, zwei oder vier Lenovo SR670 V2-Server neben einem einzelnen NetApp AFF A400 -Speichersystem verwendet.  Die folgende Abbildung bietet einen Überblick über die Architektur.</block>
  <block id="9eaa73568302c6f5b850762b65b3f334" category="inline-image-macro">Dieses Bild zeigt einen Ethernet-Switch, umgeben vom Verwaltungsserver, vier SR670 V2 mit jeweils acht GPUs und einem NetApp ONTAP Speichersystem.</block>
  <block id="98230d6fe5f2e966446d65810c888228" category="paragraph"><block ref="98230d6fe5f2e966446d65810c888228" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9336931f4103d973313cb8539e5c2613" category="list-text">Hocheffiziente und kostengünstige Leistung bei der parallelen Ausführung mehrerer Trainingsjobs</block>
  <block id="81c3992924ee5cdc4cb02692dcae98b4" category="list-text">Skalierbare Leistung basierend auf unterschiedlicher Anzahl von Lenovo-Servern und verschiedenen Modellen von NetApp -Speichercontrollern</block>
  <block id="bdcea52fecbcd9741f95a6bc0dbbde0f" category="list-text">Robuster Datenschutz zur Einhaltung niedriger Recovery Point Objectives (RPOs) und Recovery Time Objectives (RTOs) ohne Datenverlust</block>
  <block id="98393526d67c065feb588e5665301706" category="list-text">Optimiertes Datenmanagement mit Snapshots und Klonen zur Rationalisierung der Entwicklungsabläufe</block>
  <block id="f737e7cc3d8aa89c5b49c4fe701e9e40" category="summary">Bei dieser Validierung haben wir ein Bilderkennungstraining gemäß MLPerf v2.0 durchgeführt.  Insbesondere haben wir das ResNet v2.0-Modell mit dem ImageNet-Datensatz trainiert.  Die wichtigste Messgröße ist die Zeit, die benötigt wird, um die gewünschte Genauigkeit zu erreichen.  Wir geben auch die Trainingsbandbreite in Bildern pro Sekunde an, um die Skalierungseffizienz besser beurteilen zu können.</block>
  <block id="0f25983094bc4cf5cea830260da8ee75" category="paragraph">Bei dieser Validierung haben wir ein Bilderkennungstraining gemäß MLPerf v2.0 durchgeführt.  Insbesondere haben wir das ResNet v2.0-Modell mit dem ImageNet-Datensatz trainiert, bis wir eine Genauigkeit von 76,1 % erreichten.  Die wichtigste Messgröße ist die Zeit, die benötigt wird, um die gewünschte Genauigkeit zu erreichen.  Wir geben auch die Trainingsbandbreite in Bildern pro Sekunde an, um die Skalierungseffizienz besser beurteilen zu können.</block>
  <block id="ac3e6a4fbe8e02d639c2defeebeac17f" category="paragraph">Der primäre Testfall bewertete mehrere unabhängige Trainingsprozesse (einer pro Knoten), die gleichzeitig ausgeführt wurden.  Dies simuliert den Hauptanwendungsfall, ein gemeinsam genutztes System, das von mehreren Datenwissenschaftlern verwendet wird.  Im zweiten Testfall wurde die Scale-Out-Effizienz bewertet.</block>
  <block id="2d316c5d9e0cd748d1890ee69f57dc6c" category="summary">In diesem Abschnitt werden die Testergebnisse dieser Lösung zusammengefasst.</block>
  <block id="80b6b969d6707ba1b92d65466e8325f0" category="paragraph">Die folgende Tabelle fasst die Ergebnisse aller für diese Lösung durchgeführten Tests zusammen.</block>
  <block id="f5bc14ae022ba581c26f3bdb35badef1" category="cell">Testbeschreibung</block>
  <block id="34d8129946f1108a296f033dc66db266" category="cell">Zusammenfassung der Ergebnisse</block>
  <block id="ab0d993807168c3a70cdd2952d4edfc0" category="cell">Bilderkennungstraining: mehrere gleichzeitige Jobs</block>
  <block id="290ba1c81812edd0651d8e18c5895054" category="cell">Hocheffiziente Leistung.  Alle Jobs liefen mit voller Geschwindigkeit, auch wenn der Cluster voll ausgelastet war.  Die NetApp -Speichersysteme lieferten eine Trainingsleistung, die mit lokalem SSD-Speicher vergleichbar war, und ermöglichten gleichzeitig einen einfachen Datenaustausch zwischen Servern.</block>
  <block id="d58827ca3ccfccb5c83b1dc9c7e12289" category="cell">Bilderkennungstraining: Skalieren</block>
  <block id="afb4fda11ecde317daa521e054df2bd4" category="cell">Hocheffizient für bis zu vier Knoten.  Zu diesem Zeitpunkt war die Skalierung zwar weniger effizient, aber immer noch machbar.  Die Verwendung eines schnelleren Computernetzwerks verbessert die Skalierbarkeit.  Das NetApp -Speichersystem lieferte eine Trainingsleistung, die mit lokalem SSD-Speicher vergleichbar war, und ermöglichte gleichzeitig die einfache gemeinsame Nutzung von Daten zwischen Servern.</block>
  <block id="e59b92fc604ecde201ab865ddefca7c2" category="summary">In diesem Abschnitt werden die Hauptkomponenten dieser Lösung ausführlicher vorgestellt.</block>
  <block id="995049066ee0a46858d3a35e74f687fc" category="paragraph">Mit NetApp AFF -Speichersystemen können Unternehmen ihre Speicheranforderungen mit branchenführender Leistung, überragender Flexibilität, Cloud-Integration und erstklassigem Datenmanagement erfüllen.  AFF -Systeme wurden speziell für Flash entwickelt und helfen bei der Beschleunigung, Verwaltung und dem Schutz geschäftskritischer Daten.</block>
  <block id="9cdcb25bd8b8e9dd029f0c58f1c1ce14" category="inline-image-macro">Diese Grafik zeigt die Vorderseite des NetApp AFF A400 Speichercontrollers.</block>
  <block id="f150868d2ce410023c5087a2a86bf51e" category="paragraph"><block ref="f150868d2ce410023c5087a2a86bf51e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a4c41eb7420fce0589579f0f045df87" category="inline-image-macro">Diese Grafik zeigt die Rückseite des NetApp AFF A400 Speichercontrollers.</block>
  <block id="11540913656d83142b2b0f7aed3df7e4" category="paragraph"><block ref="11540913656d83142b2b0f7aed3df7e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="32fbd740c28afd94422aeceef5424762" category="paragraph">NetApp AFF A400 ist ein NVMe-Flash-Speichersystem der Mittelklasse, das die folgenden Funktionen umfasst:</block>
  <block id="4b78ed4e994ac9de0ed2b09e38067a6a" category="list-text">Maximale effektive Kapazität: ~20PB</block>
  <block id="9b150a217729988c3dd54fdaf7b0f9b3" category="list-text">Maximale Skalierung: 2–24 Knoten (12 HA-Paare)</block>
  <block id="ae3b033d221455bb2825ac51bee7200e" category="list-text">25GbE und 16Gb FC-Host-Unterstützung</block>
  <block id="e16f4e2b178ce47880c3556c501efea4" category="list-text">100GbE RDMA über Converged Ethernet (RoCE)-Konnektivität zu NVMe-Erweiterungsspeicherregalen</block>
  <block id="e9038c807b352c2a4dcfd8cf1ac2cdd4" category="list-text">100GbE RoCE-Ports können für die Host-Netzwerkverbindung verwendet werden, wenn keine NVMe-Shelves angeschlossen sind</block>
  <block id="dff1410020c1b676f56ee973acea57d3" category="list-text">Vollständige 12-Gbit/s-SAS-Konnektivität, Erweiterungsspeicherfächer</block>
  <block id="565637725a05c879995851c50d41275c" category="list-text">In zwei Konfigurationen erhältlich:</block>
  <block id="8e707b713d26c4b020eda98a37207373" category="list-text">Ethernet: 4 x 25-Gbit-Ethernet-Ports (SFP28)</block>
  <block id="1d3c6ad9f15fc70a1cf63e449e90436a" category="list-text">Fiber Channel: 4 x 16 Gb FC (SFP+)-Ports</block>
  <block id="6a2a811bcec501901ab6f8f94694d1b2" category="list-text">100 % 8 KB wahlfreies Lesen bei 0,4 ms, 400.000 IOPS</block>
  <block id="d3309961dfabc3043c3ea1878752450b" category="paragraph">Zu den Funktionen von NetApp AFF A250 für KI/ML-Implementierungen der Einstiegsklasse gehören die folgenden:</block>
  <block id="68448ae40d26fce5bb74cd3bf75999c4" category="list-text">Maximale effektive Kapazität: 35 PB</block>
  <block id="83fa45e9cc2def5751527547e3c57b61" category="list-text">Maximale Skalierung: 2–24 Knoten (12 HA-Paare)</block>
  <block id="1283cfcd2651148a611c2c4b105458c3" category="list-text">Basierend auf der neuesten NetApp ONTAP -Version ONTAP 9.8 oder höher</block>
  <block id="f31903137775862e1157677f447b0f52" category="list-text">Zwei 25-Gbit-Ethernet-Ports für HA und Cluster-Verbindung</block>
  <block id="f6c48fdc99c510156e0364e03a6fbd9e" category="paragraph">NetApp bietet auch andere Speichersysteme wie AFF A800 und AFF A700 an, die eine höhere Leistung und Skalierbarkeit für KI/ML-Bereitstellungen in größerem Maßstab bieten.</block>
  <block id="3f0cb8a376b551c058cd6886f68bceb0" category="paragraph">ONTAP 9, die neueste Generation der Speicherverwaltungssoftware von NetApp, ermöglicht Unternehmen die Modernisierung ihrer Infrastruktur und den Übergang zu einem Cloud-fähigen Rechenzentrum.  Durch die Nutzung branchenführender Datenverwaltungsfunktionen ermöglicht ONTAP die Verwaltung und den Schutz von Daten mit einem einzigen Satz von Tools, unabhängig davon, wo sich diese Daten befinden.  Daten können außerdem frei dorthin verschoben werden, wo sie benötigt werden: an den Rand, in den Kern oder in die Cloud.  ONTAP 9 umfasst zahlreiche Funktionen, die das Datenmanagement vereinfachen, kritische Daten beschleunigen und schützen und die Infrastruktur in Hybrid-Cloud-Architekturen zukunftssicher machen.</block>
  <block id="c5b25bb449b07e8b863f41dbe3b90a2a" category="list-text">*Minimale, maximale und adaptive Dienstqualität (QoS).*  Granulare QoS-Kontrollen helfen dabei, das Leistungsniveau kritischer Anwendungen in Umgebungen mit hoher gemeinsamer Nutzung aufrechtzuerhalten.</block>
  <block id="ddf38f965aeb6f6b5785254e6f143a09" category="list-text">* ONTAP FabricPool.*  Diese Funktion verteilt kalte Daten automatisch auf öffentliche und private Cloud-Speicheroptionen, einschließlich Amazon Web Services (AWS), Azure und NetApp StorageGRID Objektspeicher.</block>
  <block id="2a228ac6322b6d496b4cb0cf22cfbfe4" category="list-text">*Leistung und geringere Latenz.*  ONTAP bietet den höchstmöglichen Durchsatz bei der geringstmöglichen Latenz.</block>
  <block id="493a7caad772a79b06f5d4a7dd98afcd" category="list-text">* NetApp Volume-Verschlüsselung.*  ONTAP bietet native Verschlüsselung auf Volume-Ebene mit integrierter und externer Schlüsselverwaltungsunterstützung.</block>
  <block id="cf4d3359e3cce4324a54d8e1864d2647" category="paragraph">ONTAP 9 hilft dabei, anspruchsvolle und sich ständig ändernde Geschäftsanforderungen zu erfüllen:</block>
  <block id="99f4fd3a9ea4a861a7095bfe26937f28" category="list-text">*Nahtlose Skalierung und unterbrechungsfreier Betrieb.*  ONTAP unterstützt die unterbrechungsfreie Kapazitätserweiterung bestehender Controller sowie von Scale-Out-Clustern.  Kunden können ohne kostspielige Datenmigrationen oder Ausfälle auf die neuesten Technologien wie NVMe und 32 GB FC upgraden.</block>
  <block id="ba1e7aff40da44f3c5b86ba78a62e7d0" category="list-text">*Integration mit neuen Anwendungen.*  ONTAP bietet Datendienste der Enterprise-Klasse für Plattformen und Anwendungen der nächsten Generation wie OpenStack, Hadoop und MongoDB und nutzt dabei dieselbe Infrastruktur, die auch vorhandene Unternehmensanwendungen unterstützt.</block>
  <block id="0fdd508a09442b5caa00e47bc0563112" category="section-title">NetApp FlexGroup Volumes</block>
  <block id="641653fdc449e0b1e30f3ee9d04182ab" category="paragraph">Trainingsdatensätze sind normalerweise eine Sammlung von potenziell Milliarden von Dateien.  Dateien können Text, Audio, Video und andere Formen unstrukturierter Daten enthalten, die gespeichert und verarbeitet werden müssen, um parallel gelesen werden zu können.  Das Speichersystem muss viele kleine Dateien speichern und diese Dateien für sequenzielle und zufällige E/A parallel lesen.</block>
  <block id="e6ad1152aea2aa4f79a47e3b80410fce" category="paragraph">Ein FlexGroup -Volume (die folgende Abbildung) ist ein einzelner Namespace, der aus mehreren Mitgliedsvolumes besteht, verwaltet wird und für Speicheradministratoren wie ein NetApp FlexVol volume fungiert.  Dateien in einem FlexGroup -Volume werden einzelnen Mitgliedsvolumes zugewiesen und nicht über Volumes oder Knoten verteilt.  Sie ermöglichen die folgenden Funktionen:</block>
  <block id="381a99cae8c29b3b8fd64a207b811935" category="list-text">Bis zu 20 Petabyte Kapazität und vorhersehbar niedrige Latenz für Workloads mit hohem Metadatenumfang</block>
  <block id="b0e05251a53a0118d23cd469db4b1903" category="list-text">Bis zu 400 Milliarden Dateien im selben Namespace</block>
  <block id="4eb6665794643a2afabf63f90ddbe4da" category="list-text">Parallelisierte Vorgänge in NAS-Workloads über CPUs, Knoten, Aggregate und einzelne FlexVol -Volumes hinweg</block>
  <block id="55f5279d0b1378eee63af77d4c7ac7bd" category="inline-image-macro">Dieses Bild zeigt ein HA-Paar von Speichercontrollern, das viele Volumes mit Hauptdateien innerhalb einer FlexGroup enthält.</block>
  <block id="27f19cee54b11d13039a99839ca83e4c" category="paragraph"><block ref="27f19cee54b11d13039a99839ca83e4c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f52dbcd9b43086f1d2957e6eb89f4113" category="section-title">Lenovo ThinkSystem Portfolio</block>
  <block id="c5ac419e5467e7539d60c18be3da4b99" category="paragraph">Zu den wichtigsten Vorteilen der Bereitstellung von Lenovo ThinkSystem-Servern gehören die folgenden:</block>
  <block id="c19629173ec04d03fae09e96ce30b98c" category="list-text">Hochgradig skalierbare, modulare Designs, die mit Ihrem Unternehmen wachsen</block>
  <block id="9ac34c98220e3dd285a7cd6c8679caeb" category="paragraph">Im KI-Bereich verfolgt Lenovo einen praktischen Ansatz, um Unternehmen dabei zu helfen, die Vorteile von ML und KI für ihre Arbeitslasten zu verstehen und zu nutzen.  Lenovo-Kunden können die KI-Angebote von Lenovo in den Lenovo AI Innovation Centers erkunden und bewerten, um den Wert für ihren speziellen Anwendungsfall vollständig zu verstehen.  Um die Time-to-Value zu verbessern, bietet dieser kundenorientierte Ansatz den Kunden Proofs of Concept für einsatzbereite und für KI optimierte Lösungsentwicklungsplattformen.</block>
  <block id="7cbc0e3d7cff391aa0e61b487dc29df1" category="section-title">Lenovo SR670 V2</block>
  <block id="5889950b76dcc45f10977523225c92a8" category="paragraph">Der Lenovo ThinkSystem SR670 V2 Rack-Server bietet optimale Leistung für beschleunigte KI und High-Performance-Computing (HPC).  Der SR670 V2 unterstützt bis zu acht GPUs und ist für die rechenintensiven Arbeitsanforderungen von ML, DL und Inferenz geeignet.</block>
  <block id="327669874a587f6f9336f608f83d451d" category="inline-image-macro">Dieses Bild zeigt drei SR670-Konfigurationen.  Die erste zeigt vier SXM-GPUs mit acht 2,5-Zoll-HS-Laufwerken und 2 PCIe-E/A-Steckplätzen.  Die zweite zeigt vier doppelt breite oder acht einfach breite GPU-Steckplätze und zwei PCIe-E/A-Steckplätze mit acht 2,5-Zoll- oder vier 3,5-Zoll-HS-Laufwerken.  Der dritte zeigt acht doppelt breite GPU-Steckplätze mit sechs EDSFF HS-Laufwerken und zwei PCIe-E/A-Steckplätzen.</block>
  <block id="20b8a0ab50b43efab313a63b4c461c6e" category="paragraph"><block ref="20b8a0ab50b43efab313a63b4c461c6e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="85b1e2eb4bc61f3bdaea9a9f040eb3a0" category="paragraph">Mit den neuesten skalierbaren Intel Xeon-CPUs, die High-End-GPUs unterstützen (einschließlich der NVIDIA A100 80 GB PCIe 8x GPU), bietet das ThinkSystem SR670 V2 optimierte, beschleunigte Leistung für KI- und HPC-Workloads.</block>
  <block id="d7ed5fdb2102567c3c051078e7c72e11" category="paragraph">Da mehr Workloads die Leistung von Beschleunigern nutzen, ist die Nachfrage nach GPU-Dichte gestiegen.  Branchen wie Einzelhandel, Finanzdienstleistungen, Energie und Gesundheitswesen nutzen GPUs, um mithilfe von ML-, DL- und Inferenztechniken tiefere Erkenntnisse zu gewinnen und Innovationen voranzutreiben.</block>
  <block id="89a846b0823ae167964c8a02382225cf" category="paragraph">Das ThinkSystem SR670 V2 ist eine optimierte Lösung der Enterprise-Klasse für die Bereitstellung beschleunigter HPC- und KI-Workloads in der Produktion. Es maximiert die Systemleistung und behält gleichzeitig die Rechenzentrumsdichte für Supercomputing-Cluster mit Plattformen der nächsten Generation bei.</block>
  <block id="9378d87a3787bb6ab3fe4605dd558aaf" category="paragraph">Weitere Funktionen sind:</block>
  <block id="fe62ffc0b0188329f10e2bfc0c560ece" category="list-text">Unterstützung für GPU Direct RDMA I/O, bei dem Hochgeschwindigkeitsnetzwerkadapter direkt mit den GPUs verbunden werden, um die I/O-Leistung zu maximieren.</block>
  <block id="03e5fd8f257caa94eae847639e18b1a9" category="list-text">Unterstützung für GPU-Direktspeicher, bei dem NVMe-Laufwerke direkt mit den GPUs verbunden sind, um die Speicherleistung zu maximieren.</block>
  <block id="ad7857a40388167e99516cfe367478d5" category="paragraph">MLPerf ist die branchenführende Benchmark-Suite zur Bewertung der KI-Leistung.  Bei dieser Validierung haben wir den Bildklassifizierungs-Benchmark mit MXNet verwendet, einem der beliebtesten KI-Frameworks.  Das Trainingsskript MXNet_benchmarks wurde zum Durchführen des KI-Trainings verwendet.  Das Skript enthält Implementierungen mehrerer beliebter konventioneller Modelle und ist auf größtmögliche Geschwindigkeit ausgelegt.  Es kann auf einer einzelnen Maschine oder im verteilten Modus auf mehreren Hosts ausgeführt werden.</block>
  <block id="75c1d09e56fd67f885464b85c424c1a6" category="summary">Dieses Dokument stellt ein validiertes Referenzdesign von NetApp AIPod für Enterprise RAG mit Technologien und kombinierten Funktionen von Intel Xeon 6-Prozessoren und NetApp -Datenverwaltungslösungen vor.  Die Lösung demonstriert eine nachgelagerte ChatQnA-Anwendung, die ein großes Sprachmodell nutzt und gleichzeitigen Benutzern genaue, kontextrelevante Antworten liefert.  Die Antworten werden über eine Air-Gap-RAG-Inferenzpipeline aus dem internen Wissensspeicher einer Organisation abgerufen.</block>
  <block id="98082f297da0ed06e10c426d26145b83" category="doc">NetApp AIPod Mini – Enterprise RAG Inferencing mit NetApp und Intel</block>
  <block id="f7b06c1111212ddff169549b5e723f7d" category="inline-image-macro">Intel-Logo</block>
  <block id="0e15068b5c1105ba9f4537e00817149b" category="paragraph"><block ref="0e15068b5c1105ba9f4537e00817149b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7c6562cf6ae61e882bf5b2ce4cfcba9d" category="paragraph">Sathish Thyagarajan, Michael Oglesby, NetApp</block>
  <block id="609170132b6430c9060811e3315d482b" category="paragraph">Immer mehr Unternehmen nutzen Retrieval-Augmented Generation (RAG)-Anwendungen und große Sprachmodelle (LLMs), um Benutzereingaben zu interpretieren und Antworten zu generieren und so die Produktivität und den Geschäftswert zu steigern.  Diese Eingabeaufforderungen und Antworten können Text, Code, Bilder oder sogar therapeutische Proteinstrukturen umfassen, die aus der internen Wissensdatenbank, Datenseen, Code-Repositories und Dokument-Repositories einer Organisation abgerufen werden.  Dieses Dokument behandelt das Referenzdesign der NetApp AIPod Mini-Lösung, die aus NetApp AFF -Speicher und Servern mit Intel Xeon 6-Prozessoren besteht.  Es umfasst die Datenverwaltungssoftware NetApp ONTAP in Kombination mit Intel Advanced Matrix Extensions (Intel AMX) und die auf Open Platform for Enterprise AI (OPEA) basierende Software Intel AI for Enterprise Retrieval-augmented Generation (RAG).  Mit dem NetApp AIPod Mini für Enterprise RAG können Unternehmen ein öffentliches LLM zu einer privaten generativen KI-Inferenzlösung (GenAI) erweitern.  Die Lösung demonstriert effizientes und kostengünstiges RAG-Inferencing im Unternehmensmaßstab, das die Zuverlässigkeit verbessern und Ihnen eine bessere Kontrolle über Ihre geschützten Informationen bieten soll.</block>
  <block id="ad17078c7a931a9c4e7e96f485d5a504" category="section-title">Validierung durch Intel-Speicherpartner</block>
  <block id="56f2eda910ca62395eb64d1a789a0edd" category="paragraph">Server mit Intel Xeon 6-Prozessoren sind für die Verarbeitung anspruchsvoller KI-Inferenz-Workloads ausgelegt und nutzen Intel AMX für maximale Leistung.  Um optimale Speicherleistung und Skalierbarkeit zu ermöglichen, wurde die Lösung erfolgreich mit NetApp ONTAP validiert, sodass Unternehmen die Anforderungen von RAG-Anwendungen erfüllen können.  Diese Validierung wurde auf Servern mit Intel Xeon 6-Prozessoren durchgeführt.  Intel und NetApp pflegen eine starke Partnerschaft, deren Schwerpunkt auf der Bereitstellung optimierter, skalierbarer und auf die Geschäftsanforderungen der Kunden abgestimmter KI-Lösungen liegt.</block>
  <block id="679a14435daad5bf55fe65cf54175466" category="section-title">Vorteile des Betriebs von RAG-Systemen mit NetApp</block>
  <block id="320696921fb4cab1e55c519f97302d91" category="paragraph">Bei RAG-Anwendungen geht es um den Abruf von Wissen aus den Dokumentenspeichern von Unternehmen in verschiedenen Formaten wie PDF, Text, CSV, Excel oder Wissensgraphen.  Diese Daten werden normalerweise in Lösungen wie einem S3-Objektspeicher oder NFS vor Ort als Datenquelle gespeichert.  NetApp ist ein führender Anbieter von Technologien für Datenmanagement, Datenmobilität, Datenverwaltung und Datensicherheit im gesamten Ökosystem von Edge, Rechenzentrum und Cloud.  Das NetApp ONTAP Datenmanagement bietet Speicher der Enterprise-Klasse zur Unterstützung verschiedener Arten von KI-Workloads, einschließlich Batch- und Echtzeit-Inferenz, und bietet einige der folgenden Vorteile:</block>
  <block id="18fb2614ff78418dcaae1e9141862c62" category="list-text">Geschwindigkeit und Skalierbarkeit.  Sie können große Datensätze mit hoher Geschwindigkeit für die Versionierung verarbeiten und dabei Leistung und Kapazität unabhängig voneinander skalieren.</block>
  <block id="71861e9c8f9e5be0d026ab6bdf1a8a1a" category="list-text">Datenzugriff.  Durch die Multiprotokollunterstützung können Clientanwendungen Daten mithilfe der Dateifreigabeprotokolle S3, NFS und SMB lesen.  ONTAP S3 NAS-Buckets können den Datenzugriff in multimodalen LLM-Inferenzszenarien erleichtern.</block>
  <block id="27a2888f3fc62ef093e756c75c45081e" category="list-text">Zuverlässigkeit und Vertraulichkeit.  ONTAP bietet Datenschutz, integrierten NetApp Autonomous Ransomware Protection (ARP) und dynamische Speicherbereitstellung und bietet sowohl software- als auch hardwarebasierte Verschlüsselung zur Verbesserung der Vertraulichkeit und Sicherheit.  ONTAP ist für alle SSL-Verbindungen mit FIPS 140-2 kompatibel.</block>
  <block id="104d96e571b334e50365e35ae17299d9" category="paragraph">Dieses Dokument richtet sich an KI-Entscheidungsträger, Dateningenieure, Unternehmensleiter und Abteilungsleiter, die die Vorteile einer Infrastruktur nutzen möchten, die für die Bereitstellung von RAG- und GenAI-Unternehmenslösungen entwickelt wurde.  Vorkenntnisse in KI-Inferenz, LLMs, Kubernetes sowie Netzwerken und deren Komponenten sind in der Implementierungsphase hilfreich.</block>
  <block id="63b41ad25402b4d0e25695e062bb14ad" category="section-title">Intel KI-Technologien</block>
  <block id="d8f5efc84f626ba14a7b3cf5ec1b06c7" category="inline-link">Xeon 6 Prozessor</block>
  <block id="9dc22cb886e2ea682197d9ab3292ba79" category="paragraph">Mit Xeon 6 als Host-CPU profitieren beschleunigte Systeme von hoher Single-Thread-Leistung, höherer Speicherbandbreite, verbesserter Zuverlässigkeit, Verfügbarkeit und Wartungsfreundlichkeit (RAS) und mehr E/A-Lanes.  Intel AMX beschleunigt die Inferenz für INT8 und BF16 und bietet Unterstützung für FP16-trainierte Modelle mit bis zu 2.048 Gleitkommaoperationen pro Zyklus pro Kern für INT8 und 1.024 Gleitkommaoperationen pro Zyklus pro Kern für BF16/FP16.  Für die Bereitstellung einer RAG-Lösung mit Xeon 6-Prozessoren werden im Allgemeinen mindestens 250 GB RAM und 500 GB Festplattenspeicher empfohlen.  Dies hängt jedoch stark von der Größe des LLM-Modells ab.  Weitere Informationen finden Sie im Intel<block ref="5d6ada86cc7a762cca0505b98060c709" category="inline-link-rx"></block> Produktbeschreibung.</block>
  <block id="c3f5f2ae46fce3305ec2b138111a93b9" category="inline-image-macro">300.300</block>
  <block id="1e2eb4a765ee46d2a2a5ec4ace0544fc" category="paragraph">Abbildung 1 – Compute-Server mit Intel Xeon 6-Prozessoren<block ref="791fbab5dd410f620397cbb8a7265767" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d7c9993f09f717fcec0e1d09837e1efc" category="section-title">NetApp AFF Speicher</block>
  <block id="969e81477626b41849d992785dfcd02d" category="paragraph">Die NetApp AFF A-Series-Systeme der Einstiegs- und Mittelklasse bieten mehr Leistung, Dichte und höhere Effizienz.  Die Systeme NetApp AFF A20, AFF A30 und AFF A50 bieten echten Unified Storage, der Block-, Datei- und Objektspeicher unterstützt und auf einem einzigen Betriebssystem basiert, das Daten für RAG-Anwendungen nahtlos verwalten, schützen und mobilisieren kann – und das zu den niedrigsten Kosten in der gesamten Hybrid Cloud.</block>
  <block id="f89af68595f296408d40bf9a33b8df16" category="paragraph">Abbildung 2 – NetApp AFF A-Series-System.<block ref="f19ab1d9dc0e27bd83c8759fade26d2a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="958c530ea1ae0e18b942f8784148734c" category="cell">*Hardware*</block>
  <block id="ddcac68770926479de530a8b7b73319e" category="cell">*Menge*</block>
  <block id="9bdc480955b350f1fe8089392ad36cbe" category="cell">*Kommentar*</block>
  <block id="f0ef78c28754fd06e4d1d893f113852d" category="cell">Intel Xeon 6-basierter Server</block>
  <block id="3e18c872662c63bcc37a4934b1161411" category="cell">RAG-Inferenzknoten – mit Dual-Socket-Prozessoren der Intel Xeon 6900-Serie oder Intel Xeon 6700-Serie und 250 GB bis 3 TB RAM mit DDR5 (6400 MHz) oder MRDIMM (8800 MHz).  2HE-Server.</block>
  <block id="e5cb14453a0aa5c9218e9b6f4a2468d1" category="cell">Control Plane Server mit Intel-Prozessor</block>
  <block id="f5aa1aa461d9a8bb35210fb241f42cda" category="cell">Kubernetes-Steuerebene/1U-Server.</block>
  <block id="5a0cd1929a98cebd107b65ee74abdd78" category="cell">Auswahl eines 100-Gb-Ethernet-Switches</block>
  <block id="8bfef0f2ef10319beae9f37e53900e5a" category="cell">Rechenzentrums-Switch.</block>
  <block id="7a2bdeec28cc635e8de5bbcea81978e1" category="cell">NetApp AFF A20 (oder AFF A30; AFF A50)</block>
  <block id="4e42b39bc940168c6df430c647a36a11" category="cell">Maximale Speicherkapazität: 9,3 PB.  Hinweis: Netzwerk: 10/25/100 GbE-Ports.</block>
  <block id="44959688d91c76b11d501b550db01844" category="paragraph">Zur Validierung dieses Referenzdesigns wurden Server mit Intel Xeon 6 Prozessoren von Supermicro (222HA-TN-OTO-37) und ein 100GbE Switch von Arista (7280R3A) verwendet.</block>
  <block id="aa6ecfe41f4b8c352896cd6cf7bc99f7" category="section-title">Offene Plattform für Enterprise-KI</block>
  <block id="6fbfd0726b7202aebde976680ced22c4" category="paragraph">Die Open Platform for Enterprise AI (OPEA) ist eine Open-Source-Initiative unter der Leitung von Intel in Zusammenarbeit mit Ökosystempartnern.  Es bietet eine modulare Plattform aus zusammensetzbaren Bausteinen, die die Entwicklung hochmoderner generativer KI-Systeme beschleunigen soll, mit einem starken Fokus auf RAG.  OPEA umfasst ein umfassendes Framework mit LLMs, Datenspeichern, Prompt-Engines, RAG-Architekturentwürfen und einer vierstufigen Bewertungsmethode, die generative KI-Systeme anhand von Leistung, Funktionen, Vertrauenswürdigkeit und Unternehmensbereitschaft bewertet.</block>
  <block id="cbe45632fbbac4e94036260c2653169b" category="paragraph">Im Kern besteht OPEA aus zwei Schlüsselkomponenten:</block>
  <block id="4293e41be4afaf5127828398b7c550da" category="list-text">GenAIComps: ein servicebasiertes Toolkit bestehend aus Microservice-Komponenten</block>
  <block id="b93ca66f4736b98ad6d348c3b08a6806" category="list-text">GenAIExamples: einsatzbereite Lösungen wie ChatQnA, die praktische Anwendungsfälle demonstrieren</block>
  <block id="de3c6a3259d3e324c7703889f55a4dde" category="inline-link">OPEA-Projektdokumentation</block>
  <block id="95a35f38b1c8257e521a361226ddc22d" category="paragraph">Weitere Einzelheiten finden Sie im<block ref="61827ec0b891f01987001b685543f04f" category="inline-link-rx"></block></block>
  <block id="515b4067e1d91f462d68de8996b254f6" category="section-title">Intel AI für Enterprise-Inferenz mit OPEA</block>
  <block id="36a128563cdcf54e3a3e0bfe9a0952a5" category="paragraph">OPEA für Intel AI for Enterprise RAG vereinfacht die Umwandlung Ihrer Unternehmensdaten in umsetzbare Erkenntnisse.  Es basiert auf Intel Xeon-Prozessoren und integriert Komponenten von Branchenpartnern, um einen optimierten Ansatz für die Bereitstellung von Unternehmenslösungen zu bieten.  Es lässt sich nahtlos mit bewährten Orchestrierungsframeworks skalieren und bietet die Flexibilität und Auswahl, die Ihr Unternehmen benötigt.</block>
  <block id="9cc188487c3944246ae7f6c5402d3c53" category="paragraph">Aufbauend auf der Grundlage von OPEA erweitert Intel AI for Enterprise RAG diese Basis um wichtige Funktionen, die Skalierbarkeit, Sicherheit und Benutzererfahrung verbessern.  Zu diesen Funktionen gehören Service-Mesh-Funktionen für die nahtlose Integration in moderne servicebasierte Architekturen, eine produktionsreife Validierung der Pipeline-Zuverlässigkeit und eine funktionsreiche Benutzeroberfläche für RAG als Service, die eine einfache Verwaltung und Überwachung von Arbeitsabläufen ermöglicht.  Darüber hinaus bieten Intel und der Partner-Support Zugriff auf ein breites Ökosystem von Lösungen, kombiniert mit integriertem Identity and Access Management (IAM) mit UI und Anwendungen für sichere und konforme Vorgänge.  Programmierbare Leitplanken bieten eine fein abgestufte Kontrolle über das Pipeline-Verhalten und ermöglichen benutzerdefinierte Sicherheits- und Compliance-Einstellungen.</block>
  <block id="1671448a75b3c116c61a1ac925267b0b" category="inline-link">Erfahren Sie mehr über die ONTAP S3-Konfiguration</block>
  <block id="90c6a896851e2b2d442ba1cd9d8de55a" category="paragraph">NetApp ONTAP ist die grundlegende Technologie, die den kritischen Datenspeicherlösungen von NetApp zugrunde liegt.  ONTAP umfasst verschiedene Datenverwaltungs- und Datenschutzfunktionen, wie z. B. automatischen Ransomware-Schutz vor Cyberangriffen, integrierte Datentransportfunktionen und Speichereffizienzfunktionen.  Diese Vorteile gelten für eine Reihe von Architekturen, von lokalen bis hin zu hybriden Multiclouds in NAS, SAN, Objekt- und softwaredefiniertem Speicher für LLM-Bereitstellungen.  Sie können einen ONTAP S3-Objektspeicherserver in einem ONTAP Cluster zum Bereitstellen von RAG-Anwendungen verwenden und dabei die Speichereffizienz und Sicherheit von ONTAP nutzen, die durch autorisierte Benutzer und Clientanwendungen bereitgestellt wird.  Weitere Informationen finden Sie unter<block ref="5ba5b9c5717eb24d2b5fdfe0fd9cfc0e" category="inline-link-rx"></block></block>
  <block id="c1b379b8a85b20135cbeae3496ac9cb9" category="inline-link">NetApp Trident auf Git</block>
  <block id="05ff24c52b7f489f2df6dab1ac93a444" category="paragraph">Die NetApp Trident -Software ist ein Open-Source- und vollständig unterstützter Speicherorchestrator für Container und Kubernetes-Distributionen, einschließlich Red Hat OpenShift.  Trident funktioniert mit dem gesamten NetApp -Speicherportfolio, einschließlich NetApp ONTAP , und unterstützt auch NFS- und iSCSI-Verbindungen.  Weitere Informationen finden Sie unter<block ref="b09494428fb81fc17c232fdf3cd6ebfd" category="inline-link-rx"></block></block>
  <block id="7eef23b11d6e87eee968a9bef33fd707" category="cell">*Software*</block>
  <block id="45cc01ab5f209e8760027e9c30097025" category="cell">*Version*</block>
  <block id="b968b232dc718c194c40c140b496647a" category="cell">OPEA für Intel AI für Enterprise RAG</block>
  <block id="522c33efdda0b8dc6ce90c991beb9666" category="cell">1.1.2</block>
  <block id="cec6a9b163aa2911c259a1fd129fafec" category="cell">Enterprise-RAG-Plattform basierend auf OPEA-Microservices</block>
  <block id="7b02c13e31cd24ff2d950fc29a8f9d53" category="cell">Container Storage Interface (CSI-Treiber)</block>
  <block id="a821a7b77c7f65a585f8b5e2b6679cd3" category="cell">NetApp Trident 25.02</block>
  <block id="4d437b953db79f111d6140d4d62384e4" category="cell">Ermöglicht dynamische Bereitstellung, NetApp Snapshot-Kopien und Volumes.</block>
  <block id="3d945423f8e9496c429a5d8c65b4604f" category="cell">Ubuntu</block>
  <block id="5e3add1fd258bd782aade74ed9a9877d" category="cell">22.04.5</block>
  <block id="d63705a0c12ee1eea0e9fa2f30be636d" category="cell">Betriebssystem auf einem Cluster mit zwei Knoten</block>
  <block id="d7ac58512991ed45f3abecbfbb9cddf1" category="cell">Container-Orchestrierung</block>
  <block id="307ea69c7c6931f75ee51c5349fefb05" category="cell">Kubernetes 1.31.4</block>
  <block id="382fc90b48fccde9d59f816ea9dc9b4a" category="cell">Umgebung zum Ausführen des RAG-Frameworks</block>
  <block id="6f72c11338419e7cbef5d90da27338b1" category="cell">ONTAP 9.16.1P4</block>
  <block id="345ec8aa297f872cecdbf6b3c0e32bfd" category="cell">Speicherbetriebssystem auf AFF A20.  Es verfügt über Vscan und ARP.</block>
  <block id="77e4d80ae2f4257081e17476b146608a" category="section-title">Lösungsbereitstellung</block>
  <block id="e137b1b38be73f6e2bb5d628d2325215" category="section-title">Software-Stack</block>
  <block id="4b9b3f178d68004f22177def38ac1a0a" category="paragraph">Die Lösung wird auf einem Kubernetes-Cluster bereitgestellt, der aus Intel Xeon-basierten App-Knoten besteht.  Um eine grundlegende Hochverfügbarkeit für die Kubernetes-Steuerebene zu implementieren, sind mindestens drei Knoten erforderlich.  Wir haben die Lösung mithilfe des folgenden Cluster-Layouts validiert.</block>
  <block id="9a5c044d129dc6879fa0ab37fdf1da36" category="paragraph">Tabelle 3 – Kubernetes-Cluster-Layout</block>
  <block id="6c3a6944a808a7c0bbb6788dbec54a9f" category="cell">Node</block>
  <block id="bbbabdbe1b262f75d99d62880b953be1" category="cell">Rolle</block>
  <block id="f6deba375b4908f8ab44946cb1ac15ec" category="cell">Server mit Intel Xeon 6 Prozessoren und 1TB RAM</block>
  <block id="5e13dbdc232ae09e4bcf3ca30f51de88" category="cell">App-Knoten, Steuerebenenknoten</block>
  <block id="c8b75ba615f900ff258046bb36a7fc62" category="cell">Generischer Server</block>
  <block id="6f8f92d5847446fe4b0ae5b71badd7cd" category="cell">Steuerebenenknoten</block>
  <block id="b1ee6de34c23dd606b6401a06907e658" category="inline-image-macro">600.600</block>
  <block id="13c96942dd3c3b3bdb84e02b2a303778" category="paragraph">Die folgende Abbildung zeigt eine „Software-Stack-Ansicht“ der Lösung.<block ref="841e6c807fed1e7947a5b7ebff264e4b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8388066510b59c8d3387373b6969a7af" category="section-title">Bereitstellungsschritte</block>
  <block id="6c00804e5ebc94e7610086e3e0f7e581" category="section-title">Bereitstellen des ONTAP Speichergeräts</block>
  <block id="ec6e72d1c4bb7dccdc62b6caf35c95f7" category="inline-link">Dokumentation zu ONTAP -Hardwaresystemen</block>
  <block id="c5ba881390fd2c8d5f9d0fb165ad1049" category="paragraph">Implementieren und Bereitstellen Ihres NetApp ONTAP Speichergeräts.  Weitere Informationen finden Sie im<block ref="8f6fc8fb2a7bb6f821a0fddf6c335b91" category="inline-link-rx"></block> für Details.</block>
  <block id="9df0c5d4eab5f45fac1c5ad20e8fdade" category="section-title">Konfigurieren Sie ein ONTAP SVM für den NFS- und S3-Zugriff</block>
  <block id="b0e271f740ae6f03e699c988b5b7c576" category="paragraph">Konfigurieren Sie eine ONTAP Storage Virtual Machine (SVM) für den NFS- und S3-Zugriff in einem Netzwerk, auf das Ihre Kubernetes-Knoten zugreifen können.</block>
  <block id="05ef9b22209f0e35efc9b6f875ad3c55" category="inline-link">ONTAP -Dokumentation.</block>
  <block id="a647bfcaa1b11c3008439f5c2a0a888f" category="paragraph">Um eine SVM mit ONTAP System Manager zu erstellen, navigieren Sie zu Speicher &gt; Speicher-VMs und klicken Sie auf die Schaltfläche + Hinzufügen.  Wenn Sie den S3-Zugriff für Ihre SVM aktivieren, wählen Sie die Option zur Verwendung eines von einer externen Zertifizierungsstelle (CA) signierten Zertifikats und nicht eines systemgenerierten Zertifikats.  Sie können entweder ein selbstsigniertes Zertifikat oder ein Zertifikat verwenden, das von einer öffentlich vertrauenswürdigen Zertifizierungsstelle signiert wurde.  Weitere Einzelheiten finden Sie im<block ref="9162972b1d9e1d587a9c620aa7cb22be" category="inline-link-rx"></block></block>
  <block id="59ea3be65306f9546fb9ed8da06a4fc4" category="paragraph">Der folgende Screenshot zeigt die Erstellung einer SVM mit ONTAP System Manager.  Ändern Sie die Details je nach Bedarf entsprechend Ihrer Umgebung.</block>
  <block id="ba045795e96e030beb3430fdc0bcf388" category="paragraph">Abbildung 4 – SVM-Erstellung mit ONTAP System Manager.<block ref="eddc39049915c5d642c02b97b2cbe95e" category="inline-image-macro-rx" type="image"></block> <block ref="d6e1134442a83aae943e8555fe42f14e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e98de7098944681485c37173696a48b" category="section-title">Konfigurieren von S3-Berechtigungen</block>
  <block id="9e677f1fe64f248526596041ab78f505" category="paragraph">Konfigurieren Sie die S3-Benutzer-/Gruppeneinstellungen für die SVM, die Sie im vorherigen Schritt erstellt haben.  Stellen Sie sicher, dass Sie einen Benutzer mit vollem Zugriff auf alle S3-API-Operationen für diese SVM haben.  Weitere Informationen finden Sie in der ONTAP S3-Dokumentation.</block>
  <block id="8182eb49f0464e8a5b6d2e7b642a6da5" category="paragraph">Hinweis: Dieser Benutzer wird für den Datenaufnahmedienst der Intel AI for Enterprise RAG-Anwendung benötigt.  Wenn Sie Ihre SVM mit ONTAP System Manager erstellt haben, hat System Manager automatisch einen Benutzer mit dem Namen erstellt.<block ref="331dbbf377ee7b82a198a7a8bb5f24e6" prefix=" " category="inline-code"></block> und eine Richtlinie namens<block ref="0268c876e4588f7ad98bacb113933dab" prefix=" " category="inline-code"></block> beim Erstellen Ihrer SVM, aber es wurden keine Berechtigungen zugewiesen<block ref="331dbbf377ee7b82a198a7a8bb5f24e6" prefix=" " category="inline-code"></block> .</block>
  <block id="c00a2800b71457eb0e0cabb2511b615a" category="paragraph">Um die Berechtigungen für diesen Benutzer zu bearbeiten, navigieren Sie zu „Speicher“ &gt; „Speicher-VMs“, klicken Sie auf den Namen der SVM, die Sie im vorherigen Schritt erstellt haben, klicken Sie auf „Einstellungen“ und dann auf das Stiftsymbol neben „S3“.  Geben<block ref="331dbbf377ee7b82a198a7a8bb5f24e6" prefix=" " category="inline-code"></block> Vollzugriff auf alle S3-API-Operationen, erstellen Sie eine neue Gruppe, die verknüpft<block ref="331dbbf377ee7b82a198a7a8bb5f24e6" prefix=" " category="inline-code"></block> mit dem<block ref="0268c876e4588f7ad98bacb113933dab" prefix=" " category="inline-code"></block> Richtlinie, wie im folgenden Screenshot dargestellt.</block>
  <block id="229c665cb2b8cb2576229fea9470bfe6" category="paragraph">Abbildung 5 – S3-Berechtigungen.</block>
  <block id="3ce7236b065597bbadf2a14e9845558e" category="paragraph"><block ref="3ce7236b065597bbadf2a14e9845558e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7cc27c397bf2aa7589869b84e048e24c" category="section-title">Erstellen eines S3-Buckets</block>
  <block id="bd31776e6efcf27fc82ed6ba0862c4fb" category="paragraph">Erstellen Sie einen S3-Bucket innerhalb der SVM, die Sie zuvor erstellt haben.  Um eine SVM mit ONTAP System Manager zu erstellen, navigieren Sie zu Speicher &gt; Buckets und klicken Sie auf die Schaltfläche + Hinzufügen.  Weitere Einzelheiten finden Sie in der ONTAP S3-Dokumentation.</block>
  <block id="0b755fcdfc7b6b61938269f21db3f841" category="paragraph">Der folgende Screenshot zeigt die Erstellung eines S3-Buckets mit ONTAP System Manager.</block>
  <block id="9568e70889a07b151a91a53d10969aed" category="paragraph">Abbildung 6 – Erstellen Sie einen S3-Bucket.<block ref="06e84b109f1e09150cd4d15502f0a16d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="847d5eae44750df0abbb4d655d69c6a7" category="section-title">Konfigurieren von S3-Bucket-Berechtigungen</block>
  <block id="c23ccda8191e76cb192f1bd40cae534b" category="paragraph">Konfigurieren Sie die Berechtigungen für den S3-Bucket, den Sie im vorherigen Schritt erstellt haben.  Stellen Sie sicher, dass der Benutzer, den Sie in einem vorherigen Schritt konfiguriert haben, über die folgenden Berechtigungen verfügt:<block ref="82cabf6bd017130caa599103617f61df" prefix=" " category="inline-code"></block></block>
  <block id="c3bf5d608f066a6b405a40012a2fc10c" category="inline-link">ONTAP S3-Dokumentation</block>
  <block id="cc944a7541814572eb9767d03e306277" category="paragraph">Um S3-Bucket-Berechtigungen mit ONTAP System Manager zu bearbeiten, navigieren Sie zu Speicher &gt; Buckets, klicken Sie auf den Namen Ihres Buckets, klicken Sie auf Berechtigungen und dann auf Bearbeiten.  Weitere Informationen finden Sie im<block ref="3c678e24d354397cff48df8b3cf3f717" category="inline-link-rx"></block> für weitere Einzelheiten.</block>
  <block id="0d1bf17e818c5b150c239afaa05e5f17" category="paragraph">Der folgende Screenshot zeigt die erforderlichen Bucket-Berechtigungen im ONTAP System Manager.</block>
  <block id="54bf7776c2d0b7f0ee45097aaad50403" category="paragraph">Abbildung 7 – S3-Bucket-Berechtigungen.<block ref="cc0f8d7f1fe9cc3d53404327451495be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="000356058e153b3be211db974d645a75" category="section-title">Erstellen einer Bucket-Cross-Origin-Ressourcenfreigaberegel</block>
  <block id="004935665424a8d10e5e54b7140e97e1" category="paragraph">Erstellen Sie mithilfe der ONTAP CLI eine Bucket-Cross-Origin-Resource-Sharing-Regel (CORS) für den Bucket, den Sie im vorherigen Schritt erstellt haben:</block>
  <block id="51704d982c17dad72393ced89212b5ca" category="paragraph">Diese Regel ermöglicht es der OPEA für die Intel AI for Enterprise RAG-Webanwendung, über einen Webbrowser mit dem Bucket zu interagieren.</block>
  <block id="d2a899c39e099bd681cfe52af554b20c" category="section-title">Bereitstellen von Servern</block>
  <block id="fa3bc02ffb34d7c680db187aa209dddd" category="paragraph">Stellen Sie Ihre Server bereit und installieren Sie Ubuntu 22.04 LTS auf jedem Server.  Installieren Sie nach der Installation von Ubuntu die NFS-Dienstprogramme auf jedem Server.  Führen Sie zum Installieren der NFS-Dienstprogramme den folgenden Befehl aus:</block>
  <block id="5ed0c66dfa2ac395ad8e9830aa5964aa" category="section-title">Installieren Sie Kubernetes</block>
  <block id="7a21958624d0a70f3a6b70bcf03ba09a" category="inline-link">Kubespray-Dokumentation</block>
  <block id="eb6273ed753aae187941e09aa142f02a" category="paragraph">Installieren Sie Kubernetes mit Kubespray auf Ihren Servern.  Weitere Informationen finden Sie im<block ref="1d9598782a4be0d8f1003429c1865811" category="inline-link-rx"></block> für Details.</block>
  <block id="b0583213f3e2e379b7dd549fd41f909f" category="section-title">Installieren Sie den Trident CSI-Treiber</block>
  <block id="c17b9b6d3e5d228bcc6c08edc3438f7f" category="inline-link">Trident -Installationsdokumentation</block>
  <block id="1ba254856621ddad1eb72d0beee0001c" category="paragraph">Installieren Sie den NetApp Trident CSI-Treiber in Ihrem Kubernetes-Cluster.  Weitere Informationen finden Sie im<block ref="0fa543c14587a20e022922b0d6d40500" category="inline-link-rx"></block> für Details.</block>
  <block id="cca56b6e3954004aac402213ce3054e6" category="section-title">Erstellen Sie ein Trident -Backend</block>
  <block id="f95ebb45354495c835f81296b11e95c1" category="inline-link">Trident -Backend-Dokumentation</block>
  <block id="31f53fbd09b24f455b372567da98766f" category="paragraph">Erstellen Sie ein Trident Backend für die SVM, die Sie zuvor erstellt haben.  Verwenden Sie beim Erstellen Ihres Backends die<block ref="8321592ce24c8a122ecf26a63cfca407" prefix=" " category="inline-code"></block> Treiber.  Weitere Informationen finden Sie im<block ref="4b8fa33525637fa26acc3e336d80affb" category="inline-link-rx"></block> für Details.</block>
  <block id="14f4c7abe09c4481722f1fa6563f2604" category="section-title">Erstellen einer Speicherklasse</block>
  <block id="bdecb047bffb568e0e8e84eeca503f89" category="paragraph">Erstellen Sie eine Kubernetes-Speicherklasse, die dem Trident Back-End entspricht, das Sie im vorherigen Schritt erstellt haben.  Weitere Informationen finden Sie in der Dokumentation zur Trident -Speicherklasse.</block>
  <block id="6a61b11e836f0eeccddb33643f7aa4cd" category="inline-link">Intel KI für Enterprise RAG-Bereitstellung</block>
  <block id="ba489bb61012c1097c380a06f7b20cbe" category="paragraph">Installieren Sie OPEA für Intel AI for Enterprise RAG in Ihrem Kubernetes-Cluster.  Weitere Informationen finden Sie im<block ref="d6f70ce0ce5c9ddf0b1e28a93f0968a7" category="inline-link-rx"></block> Einzelheiten finden Sie in der Dokumentation.  Beachten Sie unbedingt die erforderlichen Änderungen an der Konfigurationsdatei, die später in diesem Dokument beschrieben werden.  Sie müssen diese Änderungen vornehmen, bevor Sie das Installations-Playbook ausführen, damit die Intel AI for Enterprise RAG-Anwendung ordnungsgemäß mit Ihrem ONTAP Speichersystem funktioniert.</block>
  <block id="cd806c912d9a85a913016682326e17bc" category="section-title">Aktivieren Sie die Verwendung von ONTAP S3</block>
  <block id="4a65f719a33b2a0cdefdd371bc5b4aa9" category="paragraph">Bearbeiten Sie beim Installieren von OPEA für Intel AI for Enterprise RAG Ihre Hauptkonfigurationsdatei, um die Verwendung von ONTAP S3 als Quelldaten-Repository zu ermöglichen.</block>
  <block id="3bbecd0884a5e013f45ca28fdee8daf4" category="paragraph">Um die Verwendung von ONTAP S3 zu ermöglichen, legen Sie die folgenden Werte innerhalb der<block ref="ed9bdb883dd5d0bf37bd5d208a17fadc" prefix=" " category="inline-code"></block> Abschnitt.</block>
  <block id="799685b83814ceb35225cd15c9221159" category="paragraph">Hinweis: Standardmäßig nimmt die Intel AI for Enterprise RAG-Anwendung Daten aus allen vorhandenen Buckets in Ihrem SVM auf.  Wenn Sie mehrere Buckets in Ihrem SVM haben, können Sie die<block ref="50d6f108d2717f6e9be4eae460e94414" prefix=" " category="inline-code"></block> Feld, sodass Daten nur aus bestimmten Buckets aufgenommen werden.</block>
  <block id="533e38d744354d370be3e86bd8fe8b28" category="section-title">Konfigurieren der Einstellungen für die geplante Synchronisierung</block>
  <block id="ad99b73b01de134452a17a0dfa32cec2" category="paragraph">Aktivieren Sie bei der Installation der OPEA für Intel AI for Enterprise RAG-Anwendung<block ref="a8f39acdcf1094097a8bc645ced45455" prefix=" " category="inline-code"></block> damit die Anwendung automatisch neue oder aktualisierte Dateien aus Ihren S3-Buckets aufnimmt.</block>
  <block id="c64dcda39c59bb872461bbb0e651a561" category="paragraph">Wann<block ref="a8f39acdcf1094097a8bc645ced45455" prefix=" " category="inline-code"></block> aktiviert ist, überprüft die Anwendung Ihre Quell-S3-Buckets automatisch auf neue oder aktualisierte Dateien.  Alle neuen oder aktualisierten Dateien, die im Rahmen dieses Synchronisierungsprozesses gefunden werden, werden automatisch aufgenommen und der RAG-Wissensdatenbank hinzugefügt.  Die Anwendung überprüft Ihre Quell-Buckets basierend auf einem voreingestellten Zeitintervall.  Das Standardzeitintervall beträgt 60 Sekunden, was bedeutet, dass die Anwendung alle 60 Sekunden nach Änderungen sucht.  Möglicherweise möchten Sie dieses Intervall Ihren speziellen Anforderungen entsprechend ändern.</block>
  <block id="6d6914305f62085b3a9f416c96b4d127" category="paragraph">So aktivieren Sie<block ref="a8f39acdcf1094097a8bc645ced45455" prefix=" " category="inline-code"></block> und legen Sie das Synchronisierungsintervall fest, legen Sie die folgenden Werte fest<block ref="84bfd070139b7efc56f8e85ce50bc0b4" prefix=" " category="inline-code"></block></block>
  <block id="b9edd7aa680f588a01b814c4969d387b" category="section-title">Ändern der Volume-Zugriffsmodi</block>
  <block id="2fe889d552298c286373b708cafda8e7" category="paragraph">In<block ref="cd37fd54d9ac25bbfe45a164824d6194" prefix=" " category="inline-code"></block> , für jedes Volumen in der<block ref="642542e40351edbd731ebad352b31317" prefix=" " category="inline-code"></block> Liste, ändern Sie die<block ref="556f4fe5afbf7b3614f70dcf9e38c44c" prefix=" " category="inline-code"></block> Zu<block ref="caa8dc1f4bb28d2d11226494cd05a123" prefix=" " category="inline-code"></block> .</block>
  <block id="edad21c5950d7e773534103192f18dd8" category="section-title">(Optional) Deaktivieren Sie die SSL-Zertifikatüberprüfung</block>
  <block id="6aaadab147a2227d76985e7ef0fc2680" category="paragraph">Wenn Sie beim Aktivieren des S3-Zugriffs für Ihre SVM ein selbstsigniertes Zertifikat verwendet haben, müssen Sie die SSL-Zertifikatsüberprüfung deaktivieren.  Wenn Sie ein Zertifikat verwendet haben, das von einer öffentlich vertrauenswürdigen Zertifizierungsstelle signiert ist, können Sie diesen Schritt überspringen.</block>
  <block id="2bb2c1d3d614a1de0e2e1e97fe3ac3c1" category="paragraph">Um die SSL-Zertifikatsüberprüfung zu deaktivieren, legen Sie die folgenden Werte fest in<block ref="84bfd070139b7efc56f8e85ce50bc0b4" prefix=" " category="inline-code"></block></block>
  <block id="dd88285a7105f2f3e6756070ae0535e2" category="section-title">Greifen Sie auf OPEA für Intel AI für Enterprise RAG UI zu</block>
  <block id="123b51539e81bc36af05f29733939680" category="inline-link">Intel AI for Enterprise RAG-Bereitstellungsdokumentation</block>
  <block id="c1b501f6d4c8c6a8616b9ca35cd2fc45" category="paragraph">Greifen Sie auf die OPEA für die Intel AI for Enterprise RAG-Benutzeroberfläche zu.  Weitere Informationen finden Sie im<block ref="746fad554462625e79393992880c7bc6" category="inline-link-rx"></block> für Details.</block>
  <block id="922ca547bcfcab30994177a3c1d383ae" category="paragraph">Abbildung 8 – OPEA für Intel AI für Enterprise RAG-Benutzeroberfläche.<block ref="4cedb9bc094b7a9f8925870620118f64" category="inline-image-macro-rx" type="image"></block></block>
  <block id="71b202e61cbdf7d879691cc22fff5944" category="section-title">Daten für RAG aufnehmen</block>
  <block id="1e5926c65c9a0919b7d73b19b2df9d53" category="paragraph">Sie können jetzt Dateien zur Einbeziehung in die RAG-basierte Abfrageerweiterung aufnehmen.  Es gibt mehrere Optionen zum Einlesen von Dateien.  Wählen Sie die passende Option für Ihre Anforderungen.</block>
  <block id="36dc767aab6b2ad698f45815826a1a29" category="paragraph">Hinweis: Nachdem eine Datei aufgenommen wurde, sucht die OPEA für Intel AI for Enterprise RAG-Anwendung automatisch nach Aktualisierungen der Datei und nimmt die Aktualisierungen entsprechend auf.</block>
  <block id="39ba5d380c5ff87759539eee68e65d99" category="paragraph">*Option 1: Direkt in Ihren S3-Bucket hochladen. Um viele Dateien auf einmal aufzunehmen, empfehlen wir, die Dateien mit dem S3-Client Ihrer Wahl in Ihren S3-Bucket (den Bucket, den Sie zuvor erstellt haben) hochzuladen.  Zu den beliebten S3-Clients gehören die AWS CLI, das Amazon SDK für Python (Boto3), s3cmd, S3 Browser, Cyberduck und Commander One.  Wenn es sich bei den Dateien um einen unterstützten Typ handelt, werden alle Dateien, die Sie in Ihren S3-Bucket hochladen, automatisch von der OPEA für die Intel AI for Enterprise RAG-Anwendung aufgenommen.</block>
  <block id="e8c9e1c06420b69e589d260def731d88" category="paragraph">Hinweis: Zum Zeitpunkt der Erstellung dieses Dokuments werden die folgenden Dateitypen unterstützt: PDF, HTML, TXT, DOC, DOCX, PPT, PPTX, MD, XML, JSON, JSONL, YAML, XLS, XLSX, CSV, TIFF, JPG, JPEG, PNG und SVG.</block>
  <block id="bc974fb6199b9073fbf1026bd2d236d2" category="paragraph">Sie können die OPEA für die Intel AI for Enterprise RAG-Benutzeroberfläche verwenden, um zu bestätigen, dass Ihre Dateien ordnungsgemäß aufgenommen wurden.  Weitere Informationen finden Sie in der Intel AI for Enterprise RAG UI-Dokumentation.  Beachten Sie, dass es einige Zeit dauern kann, bis die Anwendung eine große Anzahl von Dateien aufgenommen hat.</block>
  <block id="25ce0ebd12d3573d98440a5151efd06e" category="paragraph">*Option 2: Hochladen über die Benutzeroberfläche. Wenn Sie nur eine kleine Anzahl von Dateien aufnehmen müssen, können Sie diese über die OPEA für Intel AI for Enterprise RAG-Benutzeroberfläche aufnehmen.  Weitere Informationen finden Sie in der Intel AI for Enterprise RAG UI-Dokumentation.</block>
  <block id="aad57997fffb9169edca9049f6c408fc" category="paragraph">Abbildung 9 – Benutzeroberfläche zur Datenaufnahme.<block ref="55969be455b6eb9c434a32c9edf9a19f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1aab14042462d545cbc81ccbd5144183" category="section-title">Chat-Abfragen ausführen</block>
  <block id="37afbf2924fcb8ec313cd060eae9317c" category="paragraph">Sie können jetzt mit der OPEA für die Intel AI for Enterprise RAG-Anwendung „chatten“, indem Sie die enthaltene Chat-Benutzeroberfläche verwenden.  Bei der Beantwortung Ihrer Anfragen führt die Anwendung RAG mithilfe Ihrer aufgenommenen Dateien durch.  Dies bedeutet, dass die Anwendung automatisch nach relevanten Informationen in Ihren aufgenommenen Dateien sucht und diese Informationen bei der Beantwortung Ihrer Anfragen berücksichtigt.</block>
  <block id="2ed19e65997a81f69c25a47d5bf28407" category="paragraph">Im Rahmen unserer Validierungsbemühungen haben wir in Abstimmung mit Intel Leistungstests durchgeführt.  Das Ergebnis dieser Tests sind die in der folgenden Tabelle aufgeführten Größenrichtlinien.</block>
  <block id="b0e166baec472090eb9b8fe69dd5736a" category="cell">Charakterisierungen</block>
  <block id="689202409e48743b914713f96d93947c" category="cell">Wert</block>
  <block id="a48c8e3a66454b67fa81ad9e940c8b27" category="cell">Modellgröße</block>
  <block id="4f4ccdf1d741c3c95db91bbc2930fb82" category="cell">20 Milliarden Parameter</block>
  <block id="9be9211aab4b7a1e7b93895b22cac265" category="cell">Llama-8B, Llama-13B, Mistral 7B, Qwen 14B, DeepSeek Distill 8B</block>
  <block id="5b176800a4fa5f818733bbc47bf50c58" category="cell">Eingabegröße</block>
  <block id="5da438d3d127ea08ac04b3ad27565f86" category="cell">~2.000 Token</block>
  <block id="ec110f5087b1200011dcf2f34914001b" category="cell">~4 Seiten</block>
  <block id="2e422b9da98e2d0a7b8c31aa22986312" category="cell">Ausgabegröße</block>
  <block id="0de7dbc3b2f780207078fda7fe5f5312" category="cell">Gleichzeitige Benutzer</block>
  <block id="2dda44ea1754f4e550f1a5cc97bd2f88" category="cell">„Gleichzeitige Benutzer“ bezieht sich auf Eingabeaufforderungen, die gleichzeitig Abfragen übermitteln.</block>
  <block id="e8d9bc5e8e6b28217a5661b56a0ce38d" category="paragraph">_Hinweis: Die oben aufgeführten Größenrichtlinien basieren auf Leistungsvalidierungen und Testergebnissen, die mit Intel Xeon 6-Prozessoren mit 96 Kernen gesammelt wurden.  Für Kunden mit ähnlichen Anforderungen an E/A-Token und Modellgröße empfehlen wir die Verwendung von Servern mit Xeon 6-Prozessoren mit 96 oder 128 Kernen._</block>
  <block id="d83a33143fe76973b5528ae0d2b5750c" category="paragraph">Enterprise-RAG-Systeme und LLMs sind Technologien, die zusammenarbeiten, um Unternehmen dabei zu helfen, genaue und kontextbezogene Antworten zu geben.  Diese Antworten beinhalten die Informationsbeschaffung auf der Grundlage einer umfangreichen Sammlung privater und interner Unternehmensdaten.  Durch die Verwendung von RAG, APIs, Vektoreinbettungen und Hochleistungsspeichersystemen zum Abfragen von Dokumentenspeichern, die Unternehmensdaten enthalten, werden die Daten schneller und sicherer verarbeitet.  Der NetApp AIPod Mini kombiniert die intelligente Dateninfrastruktur von NetApp mit ONTAP Datenverwaltungsfunktionen und Intel Xeon 6-Prozessoren, Intel AI für Enterprise RAG und dem OPEA-Software-Stack, um die Bereitstellung leistungsstarker RAG-Anwendungen zu unterstützen und Unternehmen auf den Weg zur KI-Führung zu bringen.</block>
  <block id="37bea4d3bbce78210e52efa42aff98fc" category="section-title">Anerkennung</block>
  <block id="9d17f4dbd111838ecf2ecb0306f6c255" category="paragraph">Dieses Dokument ist das Werk von Sathish Thyagarajan und Michael Ogelsby, Mitgliedern des NetApp Solutions Engineering-Teams.  Die Autoren möchten sich außerdem beim Enterprise AI-Produktteam bei Intel – Ajay Mungara, Mikolaj Zyczynski, Igor Konopko, Ramakrishna Karamsetty, Michal Prostko, Shreejan Mistry und Ned Fiori – und den anderen Teammitgliedern bei NetApp– Lawrence Bunka, Bobby Oommen und Jeff Liborio – für ihre kontinuierliche Unterstützung und Hilfe während der Validierung dieser Lösung bedanken.</block>
  <block id="638409a97591a74cbaf8ecaac7bc356a" category="section-title">Stückliste</block>
  <block id="faf3c2849bae24ab9045ae5add024400" category="paragraph">Die folgende Stückliste wurde für die Funktionsvalidierung dieser Lösung verwendet und kann als Referenz verwendet werden.  Es kann jeder Server oder jede Netzwerkkomponente (oder sogar ein vorhandenes Netzwerk mit vorzugsweise 100 GbE Bandbreite) verwendet werden, die mit der folgenden Konfiguration übereinstimmt.</block>
  <block id="74953ad13674266e8135ca232d6d7d5d" category="paragraph">Für den App-Server:</block>
  <block id="6737192650f0c3a81629128ea7774174" category="cell">*Teilenummer*</block>
  <block id="eb6fa4e6fed41e388b4d654a174c1b82" category="cell">*Produktbeschreibung*</block>
  <block id="a3b91229cc5a5eb0d50908cc956824b3" category="cell">222HA-TN-OTO-37</block>
  <block id="2302a4ae44cddff506100b112f4645c6" category="cell">Hyper SuperServer SYS-222HA-TN /2U</block>
  <block id="f6c89f7ba30cbd887804a4308bd66add" category="cell">P4X-GNR6972P-SRPL2-UCC</block>
  <block id="68a721cd66b4e182958e8b3ba088ae78" category="cell">Intel Xeon 6972P 2P 128C 2G 504M 500W SGX512</block>
  <block id="e53619c1fe611a51eeeb8d148ba6e532" category="cell">RAM</block>
  <block id="673b9923dda6787459c6a0ae7f711593" category="cell">MEM-DR564MC-ER64(x16)64GB DDR5-6400 2RX4 (16Gb) ECC RDIMM</block>
  <block id="0be247e8eaad16189d4e7ce0829add7a" category="cell">HDS-M2N4-960G0-E1-TXD-NON-080(x2) SSD M.2 NVMe PCIe4 960GB 1DWPD TLC D, 80mm</block>
  <block id="c3ca791a9361b57a8fa217067084b891" category="cell">WS-1K63A-1R(x2)1U 692W/1600W redundantes Netzteil mit Einzelausgang.  Wärmeableitung von 2361 BTU/h bei einer maximalen Temperatur von 59 °C (ca.)</block>
  <block id="7d83e48371fe2b2bd396527bf08497f1" category="paragraph">Für den Kontrollserver:</block>
  <block id="4bf51ddd79708218d2ca40addbf3f2fb" category="cell">511R-M-OTO-17</block>
  <block id="870f227b084b6f0c047a533d218e9874" category="cell">OPTIMIERT UP 1U X13SCH-SYS, CSE-813MF2TS-R0RCNBP, PWS-602A-1R</block>
  <block id="3a3c852894f27ec7f0e61dfb46110539" category="cell">P4D-G7400-SRL66(x1) ADL Pentium G7400</block>
  <block id="7c3e6ed807c306444b3bddd7fc90cb2a" category="cell">MEM-DR516MB-EU48(x2)16GB DDR5-4800 1Rx8 (16Gb) ECC UDIMM</block>
  <block id="c104b47ab1794697f8c929d251599740" category="paragraph">Für den Netzwerk-Switch:</block>
  <block id="1bf595c07879a3e4909b5196570ee253" category="cell">DCS-7280CR3A</block>
  <block id="60e4b729f0a2b5471a6c6209bc49aac5" category="cell">Arista 7280R3A 28x100 GbE</block>
  <block id="40f46282e86b9c228e0cce6e2011f35c" category="paragraph">NetApp AFF -Speicher:</block>
  <block id="39ff721f18a3edbb373a8c8f54cd3f14" category="cell">AFF-A20A-100-C</block>
  <block id="c133ed5a1928378c2f6a29bf6b6f1135" category="cell">AFF A20 HA System, -C</block>
  <block id="52b142796a871ab98369e293ae4d91c2" category="cell">X800-42U-R6-C</block>
  <block id="c6b0cc56d77c17a08efb3742ab92e776" category="cell">Überbrückungsbatterie, In-Cab, C13-C14, -C</block>
  <block id="128bdeded7a535e68b0f98e463111407" category="cell">X97602A-C</block>
  <block id="f14bf71f2d74fbf0d0560b5a355bbf63" category="cell">Netzteil, 1600 W, Titan, -C</block>
  <block id="2a0cfc5d71abb55759a510240510f87a" category="cell">X66211B-2-N-C</block>
  <block id="d50feb7d1470a9fb63d75f5a39b4b8bd" category="cell">Kabel, 100GbE, QSFP28-QSFP28, Cu, 2m, -C</block>
  <block id="9d4b1f9c3df948f2260e6332be9d5aed" category="cell">X66240A-05-N-C</block>
  <block id="7229ff7ba1f700db7ec3bd4b5221db26" category="cell">Kabel, 25GbE, SFP28-SFP28, Cu, 0,5m, -C</block>
  <block id="1ab2d2badc8592e1d029782bd25632a5" category="cell">X5532A-N-C</block>
  <block id="4688dd909d449010ca4b23347351a707" category="cell">Schiene, 4-Pfosten, dünn, rund/quadratisch, klein, verstellbar, 24–32, -C</block>
  <block id="b24ac50247ba189d666fdae929cede64" category="cell">X4024A-2-A-C</block>
  <block id="25630a46b821a822994c9b1e0dd238d5" category="cell">Laufwerkspaket 2 x 1,92 TB, NVMe4, SED, -C</block>
  <block id="326b6bb4ee61f9700e237d78e0a70b27" category="cell">X60130A-C</block>
  <block id="f2acaac754bf0c08463a09096b25ebd5" category="cell">IO-Modul, 2PT, 100GbE, -C</block>
  <block id="826f0d850b56b5bcd6026118ee4048b5" category="cell">X60132A-C</block>
  <block id="f567279f3d616d5bcfbd134b1e39b047" category="cell">IO-Modul, 4PT, 10/25GbE, -C</block>
  <block id="7090ee7c22ea0bf45e028538870d276f" category="cell">SW-ONTAPB-FLASH-A20-C</block>
  <block id="c2375e9a630d78f92c99f36859f2dc63" category="cell">SW, ONTAP -Basispaket, pro TB, Flash, A20, -C</block>
  <block id="37693cfc748049e45d87b8c7d8b9aacd" category="cell">23</block>
  <block id="1006bcc3d9e9f1297760c57c62541267" category="paragraph"><block ref="1006bcc3d9e9f1297760c57c62541267" category="inline-link-rx"></block></block>
  <block id="9bf497d692d0e146d05a76e3a34ae95f" category="inline-link-macro">OPEA-Projekt</block>
  <block id="feeb32cac2847bc01bfab8eb7dfbbbfe" category="paragraph"><block ref="feeb32cac2847bc01bfab8eb7dfbbbfe" category="inline-link-macro-rx"></block></block>
  <block id="a64127d2271b6c8ff07ae84c3a53c90c" category="inline-link">Playbook zur OPEA Enterprise RAG-Bereitstellung</block>
  <block id="3d766654d6f2d85f314e655c63e91d81" category="paragraph"><block ref="3d766654d6f2d85f314e655c63e91d81" category="inline-link-rx"></block></block>
  <block id="a5e99aa2ffae2218fdcf2038b1b3fd1b" category="doc">TR-4851: NetApp StorageGRID -Datensee für Workloads beim autonomen Fahren – Lösungsdesign</block>
  <block id="981ed5a5ebc4fbc2a64f69a42d9ef36c" category="paragraph">David Arnette, NetApp</block>
  <block id="0e2b7ed1591c52ac15ea956ecb6a5701" category="paragraph">TR-4851 demonstriert die Verwendung des NetApp StorageGRID Objektspeichers als Datenspeicher und Verwaltungssystem für die Softwareentwicklung für maschinelles Lernen (ML) und Deep Learning (DL).  In diesem Dokument werden der Datenfluss und die Anforderungen bei der Entwicklung autonomer Fahrzeugsoftware sowie die StorageGRID -Funktionen beschrieben, die den Datenlebenszyklus optimieren.  Diese Lösung gilt für jeden mehrstufigen Datenpipeline-Workflow, der in ML- und DL-Entwicklungsprozessen typisch ist.</block>
  <block id="ba9a0dcacc73fb54c527ad33eceb30c1" category="paragraph"><block ref="ba9a0dcacc73fb54c527ad33eceb30c1" category="inline-link-macro-rx"></block></block>
  <block id="30d965eef5ba25c6b9998ae38270b43e" category="doc">Rechtliche Hinweise</block>
  <block id="e9c44bbfd795a5d63d74c6a77afee70d" category="paragraph">Rechtliche Hinweise bieten Zugriff auf Urheberrechtserklärungen, Marken, Patente und mehr.</block>
  <block id="6016a2b341113bf496b719905398ecd2" category="section-title">Copyright</block>
  <block id="52009bb7ee17227f566cd26a02caee56" category="inline-link-macro"><block ref="52009bb7ee17227f566cd26a02caee56" category="inline-link-rx"></block></block>
  <block id="a1a9afcf552a769c282769271829889a" category="paragraph"><block ref="a1a9afcf552a769c282769271829889a" category="inline-link-macro-rx"></block></block>
  <block id="126a02652da6de02962cf1b654fd6376" category="section-title">Marken</block>
  <block id="c4ce4761e466527d26b3e3d5ed1006fd" category="paragraph">NETAPP, das NETAPP-Logo und die auf der NetApp -Markenseite aufgeführten Marken sind Marken von NetApp, Inc. Andere Firmen- und Produktnamen können Marken ihrer jeweiligen Eigentümer sein.</block>
  <block id="f99aa604031e5049799e73b5c3748a98" category="inline-link-macro"><block ref="f99aa604031e5049799e73b5c3748a98" category="inline-link-rx"></block></block>
  <block id="5d545fe5152641e2ebe654e336e520e5" category="paragraph"><block ref="5d545fe5152641e2ebe654e336e520e5" category="inline-link-macro-rx"></block></block>
  <block id="be89498d2f8a22ce47c02ba9795fe2af" category="section-title">Patente</block>
  <block id="d0b19d36be2c5f16e9aef46c8a452d3d" category="paragraph">Eine aktuelle Liste der Patente im Besitz von NetApp finden Sie unter:</block>
  <block id="88e5eabd3917048b6927c42496b98f86" category="inline-link-macro"><block ref="88e5eabd3917048b6927c42496b98f86" category="inline-link-rx"></block></block>
  <block id="dd38f906b37d412de7d1c1dcf4cbf31c" category="paragraph"><block ref="dd38f906b37d412de7d1c1dcf4cbf31c" category="inline-link-macro-rx"></block></block>
  <block id="56c34c6410dd45c5cec44149ad0ce037" category="section-title">Datenschutzrichtlinie</block>
  <block id="8acb58cbd50ef1b468a020ee0bd351d3" category="inline-link-macro"><block ref="8acb58cbd50ef1b468a020ee0bd351d3" category="inline-link-rx"></block></block>
  <block id="2352c4e1f4d0024ade0869e00e6243f4" category="paragraph"><block ref="2352c4e1f4d0024ade0869e00e6243f4" category="inline-link-macro-rx"></block></block>
  <block id="91bc87f1c8c087219cec868bb9eec3e7" category="summary">Für diese Validierung haben wir mithilfe einer Reihe von Rohbildern eine Inferenz für einen Anwendungsfall zur Bilderkennung durchgeführt.  Anschließend haben wir dieselbe Inferenzaufgabe mit demselben Satz von Bildern durchgeführt, wobei wir vor der Inferenz die Protopia-Verschleierung hinzugefügt haben.  Wir haben die Aufgabe mit unterschiedlichen ALPHA-Werten für die Protopia-Verschleierungskomponente wiederholt.</block>
  <block id="f63c4677c27e0489f346c0711720cc39" category="doc">Vergleich der Inferenzgenauigkeit</block>
  <block id="0c71eb4e1fba60fba81db988197da57d" category="paragraph">Für diese Validierung haben wir mithilfe einer Reihe von Rohbildern eine Inferenz für einen Anwendungsfall zur Bilderkennung durchgeführt.  Anschließend haben wir dieselbe Inferenzaufgabe mit demselben Satz von Bildern durchgeführt, wobei wir vor der Inferenz die Protopia-Verschleierung hinzugefügt haben.  Wir haben die Aufgabe mit unterschiedlichen ALPHA-Werten für die Protopia-Verschleierungskomponente wiederholt.  Im Kontext der Protopia-Verschleierung stellt der ALPHA-Wert den Grad der angewendeten Verschleierung dar, wobei ein höherer ALPHA-Wert einen höheren Grad der Verschleierung darstellt.  Anschließend haben wir die Inferenzgenauigkeit dieser verschiedenen Läufe verglichen.</block>
  <block id="93d52a2c23957d4188c7b2ce8b2ae884" category="paragraph">Die folgenden beiden Tabellen liefern Details zu unserem Anwendungsfall und skizzieren die Ergebnisse.</block>
  <block id="65a3419ae19e457df9db4c0e110b2538" category="paragraph">Protopia arbeitet direkt mit Kunden zusammen, um den geeigneten ALPHA-Wert für einen bestimmten Anwendungsfall zu bestimmen.</block>
  <block id="e558777bd1568637c97294a33389e930" category="cell">FaceBoxen (PyTorch) –</block>
  <block id="20172a059ee71423ad0d94393e819e10" category="cell">FDDB-Datensatz</block>
  <block id="06a8fb4576a28a6488c929097c870fe1" category="cell">Protopia-Verschleierung</block>
  <block id="002101f8725e5c78d9f30d87f3fa4c87" category="cell">ALPHA</block>
  <block id="d78f1fb7e69f7cddcf3e168f2663db20" category="cell">Genauigkeit</block>
  <block id="bafd7322c6e97d25b6299b5d6fe8920b" category="cell">Nein</block>
  <block id="382b0f5185773fa0f67a8ed8056c7759" category="cell">k. A.</block>
  <block id="646738dcd35eaf5c3f3c9bfdc6a90b78" category="cell">0,9337148153739079</block>
  <block id="93cba07454f06a4a960172bbd6e2a435" category="cell">Ja</block>
  <block id="b14399cbaac6da4b5b733b483106383f" category="cell">0,05</block>
  <block id="bcf8c22771ff8c7065180f5a6526d4a6" category="cell">0,9028766627325002</block>
  <block id="cb5ae17636e975f9bf71ddf5bc542075" category="cell">0,1</block>
  <block id="1336b1cb08d93aa0a453c53e27efa594" category="cell">0,9024301009661478</block>
  <block id="3d522deaf85577451c01974654b36ad3" category="cell">0,2</block>
  <block id="b1cb1b288bfae3850c74795f5691dc4e" category="cell">0,9081836283186224</block>
  <block id="54fbf38cf649866815e0fefc46a1f6c7" category="cell">0,4</block>
  <block id="b9e8c964d5c5d3e7c815896cd6235239" category="cell">0,9073066107482036</block>
  <block id="e95e1ca27d0e39aa03eb5a611ce4122f" category="cell">0,6</block>
  <block id="57489d9101ec373d9e2841292a5b3af9" category="cell">0,8847816568680239</block>
  <block id="57eeec0a6974ecb4e9fcf68fab052f7b" category="cell">0,8</block>
  <block id="8ab8d7756b82eb70d635bc66c1bc532b" category="cell">0,8841195749171925</block>
  <block id="a894124cc6d5c5c71afe060d5dde0762" category="cell">0,9</block>
  <block id="226cc0951c1f30973a4c71f0f567936a" category="cell">0,8455427675252052</block>
  <block id="248a7444f08189bb31ba143eabebe4e5" category="cell">0,95</block>
  <block id="cf285ec96f684d6597b7ffbbfcf16197" category="doc">Wo Sie weitere Informationen und Danksagungen finden</block>
  <block id="89f170193efdf8434f549c8e91adf860" category="list-text">Protopia AI – Vertrauliche Schlussfolgerung</block>
  <block id="62faa8d62bfb6098877b809cce925de5" category="inline-link"><block ref="62faa8d62bfb6098877b809cce925de5" category="inline-link-rx"></block></block>
  <block id="45b79877f4c11139882c88df94d50fa6" category="paragraph"><block ref="45b79877f4c11139882c88df94d50fa6" category="inline-link-rx"></block></block>
  <block id="2c5e74d45708e2fae638e03f88353b75" category="list-text">NVIDIA Triton Inference Server</block>
  <block id="2c54e28a12ce15452929a28550a30a96" category="inline-link"><block ref="2c54e28a12ce15452929a28550a30a96" category="inline-link-rx"></block></block>
  <block id="bc5345c4517d46bdf8a87f10d404839f" category="paragraph"><block ref="bc5345c4517d46bdf8a87f10d404839f" category="inline-link-rx"></block></block>
  <block id="fba4b133e329411c361e02e05efed0b9" category="list-text">NVIDIA Triton Inference Server-Dokumentation</block>
  <block id="cce40efbd4a717916ccbab694b676e9c" category="inline-link"><block ref="cce40efbd4a717916ccbab694b676e9c" category="inline-link-rx"></block></block>
  <block id="170ba65f4e4807f3643de39afb3f2e16" category="paragraph"><block ref="170ba65f4e4807f3643de39afb3f2e16" category="inline-link-rx"></block></block>
  <block id="ba1d5cc71378020998752955821460b2" category="list-text">FaceBoxen in PyTorch</block>
  <block id="ace8d80d2ede0fadf07325408b376b83" category="inline-link"><block ref="ace8d80d2ede0fadf07325408b376b83" category="inline-link-rx"></block></block>
  <block id="a688d324b63c4f882d06673058aa2f61" category="paragraph"><block ref="a688d324b63c4f882d06673058aa2f61" category="inline-link-rx"></block></block>
  <block id="121ef407a6a3c08ce9fa247e382d7637" category="list-text">Mark Cates, Principal Product Manager, NetApp</block>
  <block id="fb345adb43ea24ffc891d20327bdca09" category="list-text">Sufian Ahmad, technischer Marketingingenieur, NetApp</block>
  <block id="711ba3fec382e550526a6ab0f49bdf3a" category="list-text">Hadi Esmaeilzadeh, Chief Technology Officer und Professor, Protopia AI</block>
  <block id="cd24a85c5cf2d1a7af0bade6066be0aa" category="summary">Daten existieren in drei Zuständen: im Ruhezustand, während der Übertragung und in der Berechnung.  Ein wichtiger Teil jedes KI-Inferenzdienstes sollte der Schutz der Daten vor Bedrohungen während des gesamten Prozesses sein.  Der Schutz der Daten während der Inferenz ist von entscheidender Bedeutung, da durch den Prozess private Informationen sowohl über externe Kunden als auch über das Unternehmen, das den Inferenzdienst bereitstellt, preisgegeben werden können.</block>
  <block id="cd9ef21e97d9c9e701bfc6d1a77634d5" category="paragraph">Daten existieren in drei Zuständen: im Ruhezustand, während der Übertragung und in der Berechnung.  Ein wichtiger Teil jedes KI-Inferenzdienstes sollte der Schutz der Daten vor Bedrohungen während des gesamten Prozesses sein.  Der Schutz der Daten während der Inferenz ist von entscheidender Bedeutung, da durch den Prozess private Informationen sowohl über externe Kunden als auch über das Unternehmen, das den Inferenzdienst bereitstellt, preisgegeben werden können.  Protopia AI ist eine unaufdringliche reine Softwarelösung für vertrauliche KI-Inferenz auf dem heutigen Markt.  Mit Protopia erhält die KI nur die transformierten Informationen in den Datensätzen, die für die Ausführung der vorliegenden KI/ML-Aufgabe wesentlich sind, und nichts weiter.  Diese stochastische Transformation ist keine Form der Maskierung und basiert auf der mathematischen Änderung der Datendarstellung durch die Verwendung kuratierten Rauschens.</block>
  <block id="945691f1b395ce7af4d5e818b4e62b9b" category="paragraph">NetApp Storage-Systeme mit ONTAP -Funktionen bieten die gleiche oder eine bessere Leistung als lokaler SSD-Speicher und bieten in Kombination mit dem NetApp DataOps Toolkit die folgenden Vorteile für Datenwissenschaftler, Dateningenieure, KI/ML-Entwickler und IT-Entscheidungsträger in Unternehmen oder Großunternehmen:</block>
  <block id="2d1d64cb5768a8ce2a6d6bda322d2ecd" category="list-text">Unternehmensweiter Datenschutz und Datenverwaltung für Notfallwiederherstellung, Geschäftskontinuität und gesetzliche Anforderungen.</block>
  <block id="58b8e67477c25a96d3b430f4ee8d75cf" category="list-text">Vereinfachter Aufruf von Datenverwaltungsvorgängen; Erstellen Sie schnell Snapshot-Kopien von Data Scientist-Arbeitsbereichen zur Sicherung und Rückverfolgbarkeit vom NetApp DataOps Toolkit in Jupyter-Notebooks.</block>
  <block id="57e858ddb0a3e1c340cfe4ba7d5c3a14" category="paragraph">Die Lösung von NetApp und Protopia bietet eine flexible, skalierbare Architektur, die sich ideal für KI-Inferenzbereitstellungen auf Unternehmensebene eignet.  Es ermöglicht Datenschutz und bietet Schutz für vertrauliche Informationen, wobei vertrauliche KI-Inferenzanforderungen mit verantwortungsvollen KI-Praktiken sowohl in lokalen als auch in hybriden Cloud-Bereitstellungen erfüllt werden können.</block>
  <block id="a41206687a4ac62c15fc883554a75883" category="summary">In diesem Abschnitt wird die Validierungsumgebung für das Lösungsdesign beschrieben.</block>
  <block id="0d013965bb31fe1cc0ba44ef3b846d09" category="paragraph">Die folgende Tabelle skizziert die Validierungsumgebung für das Lösungsdesign.</block>
  <block id="30136395f01879792198317c11831ea4" category="cell">Kubernetes</block>
  <block id="32f014d18e1f60596057834de2864322" category="cell">1.21.6</block>
  <block id="8b2b11d27dd7d347de30cae2db2ab86d" category="cell">NetApp Trident CSI-Treiber</block>
  <block id="8e232cd005846e0f66f39f19aa03103c" category="cell">22.01.0</block>
  <block id="297924c1d3fec9d97f9a1f3b49ee0709" category="cell">NetApp DataOps Toolkit für Kubernetes</block>
  <block id="70e2b24f7d348efe6b30b41469d5070c" category="cell">2.3.0</block>
  <block id="099d96b4d8f70fb73f1d4661f98c337a" category="cell">21.11-py3</block>
  <block id="6d01d0026564c98aa0d6274cd39c586a" category="summary">Dieses Dokument beschreibt eine validierte Designlösung für drei verschiedene Szenarien mit und ohne Bildverschleierung, die für den Schutz der Privatsphäre und die Bereitstellung einer verantwortungsvollen KI-Lösung relevant ist.</block>
  <block id="236e54165aafef697c2c82c667e05d36" category="doc">TR-4928: Verantwortungsvolle KI und vertrauliche Inferenz – NetApp KI mit Protopia Image- und Datentransformation</block>
  <block id="0bbb7f0a0d464779fc0832c366f3a4e7" category="paragraph">Sathish Thyagarajan, Michael Oglesby, NetApp Byung Hoon Ahn, Jennifer Cwagenberg, Protopia</block>
  <block id="c110f3156d66710a207ebd7135164ec1" category="paragraph">Visuelle Interpretationen sind mit dem Aufkommen der Bilderfassung und Bildverarbeitung zu einem integralen Bestandteil der Kommunikation geworden.  Künstliche Intelligenz (KI) in der digitalen Bildverarbeitung eröffnet neue Geschäftsmöglichkeiten, etwa im medizinischen Bereich zur Erkennung von Krebs und anderen Krankheiten, in der georäumlichen visuellen Analyse zur Untersuchung von Umweltgefahren, in der Mustererkennung, in der Videoverarbeitung zur Verbrechensbekämpfung usw.  Allerdings bringt diese Chance auch außergewöhnliche Verantwortung mit sich.</block>
  <block id="0159205b6d54375adfabd56a2258fcb9" category="paragraph">Je mehr Entscheidungen Unternehmen in die Hände von KI legen, desto mehr Risiken gehen sie hinsichtlich Datenschutz und -sicherheit sowie rechtlicher, ethischer und regulatorischer Fragen ein.  Verantwortungsvolle KI ermöglicht eine Praxis, die es Unternehmen und Regierungsorganisationen erlaubt, Vertrauen und Governance aufzubauen, was für KI im großen Maßstab in großen Unternehmen von entscheidender Bedeutung ist.  Dieses Dokument beschreibt eine von NetApp in drei verschiedenen Szenarien validierte KI-Inferenzlösung. Dabei kommen NetApp Datenverwaltungstechnologien mit der Datenverschleierungssoftware Protopia zum Einsatz, um sensible Daten zu privatisieren und Risiken und ethische Bedenken zu reduzieren.</block>
  <block id="fade8b24490b0ba74a7ffa05d3f8631a" category="paragraph">Täglich werden von Verbrauchern und Unternehmen mit verschiedenen digitalen Geräten Millionen von Bildern erstellt.  Die daraus resultierende massive Explosion der Datenmengen und der Rechenlast führt dazu, dass Unternehmen aus Gründen der Skalierbarkeit und Effizienz auf Cloud-Computing-Plattformen zurückgreifen.  Gleichzeitig treten bei der Übertragung in eine öffentliche Cloud Datenschutzbedenken hinsichtlich der in den Bilddaten enthaltenen sensiblen Informationen auf.  Der Mangel an Sicherheits- und Datenschutzgarantien wird zum Haupthindernis für den Einsatz von KI-Systemen zur Bildverarbeitung.</block>
  <block id="e9ac7ec9dd27fe52477986ab1dccbcae" category="inline-link">Recht auf Löschung</block>
  <block id="49dca35d3e0662046425327194fd8965" category="inline-link">Datenschutzgesetz</block>
  <block id="f615b294f87bd53494e01691ab95c654" category="paragraph">Darüber hinaus gibt es die<block ref="ac9ac606204db63758cb1efd6e89e43e" category="inline-link-rx"></block> durch die DSGVO das Recht einer Einzelperson, von einer Organisation die Löschung aller ihrer personenbezogenen Daten zu verlangen.  Es gibt auch die<block ref="fd57f794f9c27951b4a5b543db96bdb6" category="inline-link-rx"></block> , das einen Kodex für faire Informationspraktiken festlegt.  Digitale Bilder wie Fotos können personenbezogene Daten im Sinne der DSGVO darstellen, die regelt, wie Daten erhoben, verarbeitet und gelöscht werden müssen.  Andernfalls verstoßen Sie gegen die DSGVO und können wegen Verstößen gegen die Vorschriften mit hohen Geldstrafen belegt werden, die für Unternehmen ernsthaften Schaden verursachen können.  Datenschutzgrundsätze bilden das Rückgrat der Implementierung verantwortungsvoller KI, die Fairness bei den Modellvorhersagen für maschinelles Lernen (ML) und Deep Learning (DL) gewährleisten und die mit der Verletzung des Datenschutzes oder der Einhaltung gesetzlicher Vorschriften verbundenen Risiken senken.</block>
  <block id="d365f4ef3ed2b414236f81df850880a3" category="paragraph">Dieses Dokument beschreibt eine validierte Designlösung für drei verschiedene Szenarien mit und ohne Bildverschleierung, die für den Schutz der Privatsphäre und die Bereitstellung einer verantwortungsvollen KI-Lösung relevant sind:</block>
  <block id="bd12a6b0ed0be7808c1e30b1e360bee6" category="list-text">*Szenario 1.*  On-Demand-Inferenz innerhalb des Jupyter-Notebooks.</block>
  <block id="bf93b5af78256f2e49d2c0351133b08d" category="list-text">*Szenario 2.*  Batch-Inferenz auf Kubernetes.</block>
  <block id="d5a10e810e1d293a064388e4980bde15" category="list-text">*Szenario 3.*  NVIDIA Triton-Inferenzserver.</block>
  <block id="870f1cf4b101c66b438e8dd024f24118" category="paragraph">Für diese Lösung verwenden wir den Face Detection Data Set and Benchmark (FDDB), einen Datensatz von Gesichtsregionen, der für die Untersuchung des Problems der uneingeschränkten Gesichtserkennung entwickelt wurde, kombiniert mit dem PyTorch-Framework für maschinelles Lernen zur Implementierung von FaceBoxes.  Dieser Datensatz enthält die Anmerkungen zu 5171 Gesichtern in einem Satz von 2845 Bildern mit unterschiedlichen Auflösungen.  Darüber hinaus stellt dieser technische Bericht einige der Lösungsbereiche und relevanten Anwendungsfälle vor, die von NetApp -Kunden und Außendiensttechnikern in Situationen gesammelt wurden, in denen diese Lösung anwendbar ist.</block>
  <block id="e28a169eb64ee1d32c878a26595922f0" category="paragraph">Dieser technische Bericht richtet sich an folgende Zielgruppen:</block>
  <block id="167e9693dfa764051f26b64ec22356a9" category="list-text">Führungskräfte und Unternehmensarchitekten, die verantwortungsvolle KI entwickeln und einsetzen und sich mit Datenschutz- und Privatsphäreproblemen im Zusammenhang mit der Gesichtsbildverarbeitung im öffentlichen Raum befassen möchten.</block>
  <block id="304e871b0b1ea55fe3e4f07ead7a7d42" category="list-text">Datenwissenschaftler, Dateningenieure, KI-/Maschinelles-Lernen-(ML-)Forscher und Entwickler von KI-/ML-Systemen, die den Schutz und die Wahrung der Privatsphäre zum Ziel haben.</block>
  <block id="dcf26996b3ab9f385a95f72c1d0a0dce" category="list-text">Unternehmensarchitekten, die Datenverschleierungslösungen für KI/ML-Modelle und -Anwendungen entwerfen, die regulatorischen Standards wie der DSGVO, dem CCPA oder dem Datenschutzgesetz des Verteidigungsministeriums (DoD) und von Regierungsorganisationen entsprechen.</block>
  <block id="bb6887ed7c7b07cbb7bd3ec71f951e6f" category="list-text">Datenwissenschaftler und KI-Ingenieure suchen nach effizienten Möglichkeiten zum Einsatz von Deep Learning (DL) und KI/ML/DL-Inferenzmodellen, die vertrauliche Informationen schützen.</block>
  <block id="69adf8f52a6229e7062bda4b2b9679fb" category="paragraph">Diese Lösung ist für die Verarbeitung von KI-Workloads mit Echtzeit- und Batch-Inferenz auf großen Datensätzen konzipiert, indem sie die Verarbeitungsleistung von GPUs neben herkömmlichen CPUs nutzt.  Diese Validierung demonstriert die datenschutzkonforme Schlussfolgerung für ML und optimales Datenmanagement, die für Organisationen erforderlich sind, die verantwortungsvolle KI-Bereitstellungen anstreben.  Diese Lösung bietet eine Architektur, die für eine Kubernetes-Plattform mit einem oder mehreren Knoten für Edge- und Cloud-Computing geeignet ist, die mit NetApp ONTAP AI im Kern vor Ort, NetApp DataOps Toolkit und Protopia-Verschleierungssoftware unter Verwendung von Jupyter Lab und CLI-Schnittstellen verbunden ist.  Die folgende Abbildung zeigt die Übersicht über die logische Architektur des Data Fabric, das von NetApp mit DataOps Toolkit und Protopia betrieben wird.</block>
  <block id="28afcbd6e097b781313de9c75adccb13" category="paragraph"><block ref="28afcbd6e097b781313de9c75adccb13" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7dfea85fd355e4966805c3504348aa8b" category="paragraph">Die Verschleierungssoftware Protopia läuft nahtlos auf dem NetApp DataOps Toolkit und transformiert die Daten, bevor sie den Speicherserver verlassen.</block>
  <block id="46ded0be5f6c48090d38435b6dafa3e2" category="summary">Dieser Abschnitt bietet einen Überblick über die drei in dieser Lösung validierten Szenarien.</block>
  <block id="71446ef316489c70b5279867eb81a86b" category="doc">Test- und Validierungsplan</block>
  <block id="68cdc250e271cc43502e5f009d0ebec7" category="paragraph">Für diesen Lösungsentwurf wurden die folgenden drei Szenarien validiert:</block>
  <block id="83c38d8dc6bc37fe6bb9691e75d0f881" category="list-text">Eine Inferenzaufgabe mit und ohne Protopia-Verschleierung innerhalb eines JupyterLab-Arbeitsbereichs, der mithilfe des NetApp DataOps Toolkit für Kubernetes orchestriert wurde.</block>
  <block id="da4ec54ac3b4b67b77d52ccf0ebaefc0" category="list-text">Ein Batch-Inferenzjob mit und ohne Protopia-Verschleierung auf Kubernetes mit einem Datenvolumen, das mithilfe des NetApp DataOps Toolkit für Kubernetes orchestriert wurde.</block>
  <block id="5526e24c695504cfa8b2187b0a3da212" category="list-text">Eine Inferenzaufgabe unter Verwendung einer NVIDIA Triton Inference Server-Instanz, die mithilfe des NetApp DataOps Toolkit für Kubernetes orchestriert wurde.  Wir haben die Protopia-Verschleierung auf das Bild angewendet, bevor wir die Triton-Inferenz-API aufgerufen haben, um die allgemeine Anforderung zu simulieren, dass alle über das Netzwerk übertragenen Daten verschleiert werden müssen.  Dieser Workflow ist auf Anwendungsfälle anwendbar, in denen Daten innerhalb einer vertrauenswürdigen Zone erfasst werden, aber zur Inferenzierung außerhalb dieser vertrauenswürdigen Zone weitergeleitet werden müssen.  Ohne die Verschleierung durch Protopia ist es nicht möglich, diese Art von Workflow zu implementieren, ohne dass vertrauliche Daten die vertrauenswürdige Zone verlassen.</block>
  <block id="6bee97571af49e4c38ff85a4abbbe0e9" category="summary">In diesem Abschnitt werden die Aufgaben beschrieben, die zum Abschließen der Validierung erforderlich sind.</block>
  <block id="ee68e5b99222bbc29a480fcb0d1d6ee2" category="section-title">Voraussetzungen</block>
  <block id="df06a8aa3d194f798e70c253c55d915c" category="paragraph">Um die in diesem Abschnitt beschriebenen Aufgaben auszuführen, müssen Sie Zugriff auf einen Linux- oder macOS-Host haben, auf dem die folgenden Tools installiert und konfiguriert sind:</block>
  <block id="c0ffe26d3756a5c964ff9bc591e1fc16" category="list-text">Kubectl (konfiguriert für den Zugriff auf einen vorhandenen Kubernetes-Cluster)</block>
  <block id="e436fe7c4ecfcca0f0327b41471955df" category="list-text">Installations- und Konfigurationsanweisungen finden Sie<block ref="f6d4f9e359e394de0cb3015a4518672c" category="inline-link-rx"></block> .</block>
  <block id="e3e34254666d96b8967227676b54e135" category="list-text">Installationsanweisungen finden Sie<block ref="9535953c30e005e9672e48b24a3ac733" category="inline-link-rx"></block> .</block>
  <block id="1a66086f406852b100e9d8f85d007b87" category="section-title">Szenario 1 – On-Demand-Inferenz in JupyterLab</block>
  <block id="28876e2d40a33fcbc3630d7408b14046" category="list-text">Erstellen Sie einen Kubernetes-Namespace für AI/ML-Inferenz-Workloads.</block>
  <block id="1464ad61957a8ed3db5f67edbc20cc41" category="list-text">Verwenden Sie das NetApp DataOps Toolkit, um ein persistentes Volume zum Speichern der Daten bereitzustellen, auf denen Sie die Inferenz durchführen.</block>
  <block id="da33a6119aa0b49526bd284e9a865ed5" category="list-text">Verwenden Sie das NetApp DataOps Toolkit, um einen neuen JupyterLab-Arbeitsbereich zu erstellen.  Mounten Sie das im vorherigen Schritt erstellte persistente Volume mithilfe des<block ref="49477e975a03ac8fbc68aea44a67d49d" prefix=" " category="inline-code"></block> Option.  Weisen Sie dem Arbeitsbereich nach Bedarf NVIDIA -GPUs zu, indem Sie die<block ref="dfc4755b60ee7dfab3c1e88693efd099" prefix=" " category="inline-code"></block> Option.</block>
  <block id="810e88d69a6b7f454f24db3a25ba375a" category="paragraph">Im folgenden Beispiel wird das persistente Volume<block ref="682303bbf677ac9a205caf2d086b33d3" prefix=" " category="inline-code"></block> wird im JupyterLab-Arbeitsbereichscontainer unter<block ref="a88bf20c35f897f8c2c3a03189e90c09" prefix=" " category="inline-code"></block> .  Bei Verwendung offizieller Project Jupyter-Container-Images<block ref="3b8e9b793a1a95056575343e279719df" prefix=" " category="inline-code"></block> wird als oberstes Verzeichnis innerhalb der JupyterLab-Weboberfläche angezeigt.</block>
  <block id="ecca64929aad192e0cdba66d89af6fc2" category="list-text">Greifen Sie auf den JupyterLab-Arbeitsbereich zu, indem Sie die URL verwenden, die in der Ausgabe des<block ref="d9eb9b67c69b49a1b002e09de33d9ed9" prefix=" " category="inline-code"></block> Befehl.  Das Datenverzeichnis stellt das persistente Volume dar, das im Arbeitsbereich bereitgestellt wurde.</block>
  <block id="87209231def3204e4e4d9a18544294dd" category="paragraph"><block ref="87209231def3204e4e4d9a18544294dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b5989087fa6f30a7b2ad79b3b28f4f68" category="list-text">Öffnen Sie die<block ref="8d777f385d3dfec8815d20f7496026dc" prefix=" " category="inline-code"></block> Verzeichnis und laden Sie die Dateien hoch, für die die Inferenz durchgeführt werden soll.  Wenn Dateien in das Datenverzeichnis hochgeladen werden, werden sie automatisch auf dem persistenten Volume gespeichert, das im Arbeitsbereich bereitgestellt wurde.  Um Dateien hochzuladen, klicken Sie auf das Symbol „Dateien hochladen“, wie im folgenden Bild gezeigt.</block>
  <block id="e3b5f0c1efdf69526c759b1d33d05e5b" category="paragraph"><block ref="e3b5f0c1efdf69526c759b1d33d05e5b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c6da42e23b9d4e193c2fb146b8189581" category="list-text">Kehren Sie zum obersten Verzeichnis zurück und erstellen Sie ein neues Notizbuch.</block>
  <block id="8c8d84a9a1e17bebaa40920247f46e13" category="paragraph"><block ref="8c8d84a9a1e17bebaa40920247f46e13" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d6d5c0ae1c38484d2d4fd513ff80f90" category="list-text">Fügen Sie dem Notebook Inferenzcode hinzu.  Das folgende Beispiel zeigt Inferenzcode für einen Anwendungsfall zur Bilderkennung.</block>
  <block id="cf7a1e02f4be1c22e175847fae951746" category="paragraph"><block ref="cf7a1e02f4be1c22e175847fae951746" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9fa1b8c326d7c59c16ba99f22361e9e4" category="paragraph"><block ref="9fa1b8c326d7c59c16ba99f22361e9e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="296d40736553e2033f5cf8817174bc7c" category="list-text">Fügen Sie Ihrem Inferenzcode die Protopia-Verschleierung hinzu.  Protopia arbeitet direkt mit Kunden zusammen, um anwendungsfallspezifische Dokumentation bereitzustellen, und liegt außerhalb des Geltungsbereichs dieses technischen Berichts.  Das folgende Beispiel zeigt Inferenzcode für einen Anwendungsfall zur Bilderkennung mit hinzugefügter Protopia-Verschleierung.</block>
  <block id="a782d09a204dcf45c8852abf7684c340" category="paragraph"><block ref="a782d09a204dcf45c8852abf7684c340" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b937401d5d173ae3750bccadcff9481e" category="paragraph"><block ref="b937401d5d173ae3750bccadcff9481e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9d5709eb5c3d3d4a700397ee447f9818" category="section-title">Szenario 2 – Batch-Inferenz auf Kubernetes</block>
  <block id="77b69d61f1889c8321dce66f3c3e2e1a" category="list-text">Füllen Sie das neue persistente Volume mit den Daten, für die Sie die Inferenz durchführen möchten.</block>
  <block id="8b6983cc7986c7b0553983d8ab669289" category="inline-link">NetApp DataOps Toolkit S3 Data Mover-Funktionen</block>
  <block id="685f44c17611b1391b579c696f310b98" category="paragraph">Es gibt mehrere Methoden zum Laden von Daten auf ein PVC.  Wenn Ihre Daten derzeit in einer S3-kompatiblen Objektspeicherplattform wie NetApp StorageGRID oder Amazon S3 gespeichert sind, können Sie<block ref="5d1617256d53e0547b237f3cf3fda5b0" category="inline-link-rx"></block> .  Eine weitere einfache Methode besteht darin, einen JupyterLab-Arbeitsbereich zu erstellen und dann Dateien über die JupyterLab-Weboberfläche hochzuladen, wie in den Schritten 3 bis 5 im Abschnitt „<block ref="db54c391b2f7c3a38c2e40a69aa744e3" category="inline-xref-macro-rx"></block> ."</block>
  <block id="a62147e18dbac7ad5eab17791c371ad4" category="list-text">Erstellen Sie einen Kubernetes-Job für Ihre Batch-Inferenzaufgabe.  Das folgende Beispiel zeigt einen Batch-Inferenzjob für einen Anwendungsfall zur Bilderkennung.  Dieser Job führt für jedes Bild in einem Satz von Bildern eine Inferenz durch und schreibt Metriken zur Inferenzgenauigkeit in die Standardausgabe.</block>
  <block id="a883fb9f7bda67c6fbcab6dfb8f091ce" category="list-text">Bestätigen Sie, dass der Inferenzauftrag erfolgreich abgeschlossen wurde.</block>
  <block id="590888c60942c47f5268c19f273109ee" category="list-text">Fügen Sie Ihrem Inferenzjob die Protopia-Verschleierung hinzu.  Anwendungsfallspezifische Anweisungen zum Hinzufügen der Protopia-Verschleierung finden Sie direkt bei Protopia, was jedoch nicht in den Rahmen dieses technischen Berichts fällt.  Das folgende Beispiel zeigt einen Batch-Inferenzjob für einen Anwendungsfall zur Gesichtserkennung mit hinzugefügter Protopia-Verschleierung unter Verwendung eines ALPHA-Werts von 0,8.  Dieser Job wendet die Protopia-Verschleierung an, bevor er für jedes Bild in einem Satz von Bildern eine Inferenz durchführt, und schreibt dann die Inferenzgenauigkeitsmetriken in die Standardausgabe.</block>
  <block id="babeb9cd0280f29f38c9a4c3029f7ba0" category="inline-link-macro">Vergleich der Inferenzgenauigkeit.</block>
  <block id="f4d99d417d0adde7f8d0f1a70caac126" category="paragraph">Wir haben diesen Schritt für die ALPHA-Werte 0,05, 0,1, 0,2, 0,4, 0,6, 0,8, 0,9 und 0,95 wiederholt.  Die Ergebnisse können Sie in<block ref="b3380bdc8f9311566c95bcb62c7aea42" category="inline-link-macro-rx"></block></block>
  <block id="76d6540fbdbbcd913fb6272a50d0e3f2" category="section-title">Szenario 3 – NVIDIA Triton Inference Server</block>
  <block id="c470d7124546c64e8539c39ced806428" category="list-text">Verwenden Sie das NetApp DataOps Toolkit, um ein persistentes Volume bereitzustellen, das als Modell-Repository für den NVIDIA Triton Inference Server verwendet werden kann.</block>
  <block id="1ddcb92ade31c8fbd370001f9b29a7d9" category="inline-link">Format</block>
  <block id="898dfcda591317ac60dd8d6af3aff189" category="list-text">Speichern Sie Ihr Modell auf dem neuen persistenten Datenträger in einem<block ref="2001a6caf72de652d98c6c64bc75a4e8" category="inline-link-rx"></block> das vom NVIDIA Triton Inference Server erkannt wird.</block>
  <block id="23ed8d1b8cbc461ebdbedcdb67ee7718" category="paragraph">Es gibt mehrere Methoden zum Laden von Daten auf ein PVC.  Eine einfache Methode besteht darin, einen JupyterLab-Arbeitsbereich zu erstellen und dann Dateien über die JupyterLab-Weboberfläche hochzuladen, wie in den Schritten 3 bis 5 in "<block ref="db54c391b2f7c3a38c2e40a69aa744e3" category="inline-xref-macro-rx"></block> .  "</block>
  <block id="fc35606f82a544f9c79f09561d7a234d" category="list-text">Verwenden Sie das NetApp DataOps Toolkit, um eine neue NVIDIA Triton Inference Server-Instanz bereitzustellen.</block>
  <block id="27a920b35a8f949700a98b22803c70fc" category="list-text">Verwenden Sie ein Triton-Client-SDK, um eine Inferenzaufgabe auszuführen.  Der folgende Python-Codeauszug verwendet das Triton Python-Client-SDK, um eine Inferenzaufgabe für einen Anwendungsfall zur Gesichtserkennung auszuführen.  Dieses Beispiel ruft die Triton-API auf und übergibt ein Bild zur Inferenz.  Der Triton Inference Server empfängt dann die Anfrage, ruft das Modell auf und gibt die Inferenzausgabe als Teil der API-Ergebnisse zurück.</block>
  <block id="7b5e296090a5d063fdbd3ebb69fc6547" category="list-text">Fügen Sie Ihrem Inferenzcode die Protopia-Verschleierung hinzu.  Anwendungsfallspezifische Anweisungen zum Hinzufügen der Protopia-Verschleierung finden Sie direkt von Protopia aus. Dieser Vorgang liegt jedoch außerhalb des Rahmens dieses technischen Berichts.  Das folgende Beispiel zeigt denselben Python-Code wie im vorherigen Schritt 5, jedoch mit hinzugefügter Protopia-Verschleierung.</block>
  <block id="c3069165ee6fb9d5dde8d8472d8b4602" category="paragraph">Beachten Sie, dass die Protopia-Verschleierung auf das Bild angewendet wird, bevor es an die Triton-API übergeben wird.  Somit verlässt das nicht verschleierte Bild nie die lokale Maschine.  Nur das verschleierte Bild wird über das Netzwerk übertragen.  Dieser Workflow ist auf Anwendungsfälle anwendbar, in denen Daten innerhalb einer vertrauenswürdigen Zone erfasst werden, dann aber zur Inferenz außerhalb dieser vertrauenswürdigen Zone weitergeleitet werden müssen.  Ohne die Verschleierung durch Protopia ist es nicht möglich, diese Art von Workflow zu implementieren, ohne dass vertrauliche Daten jemals die vertrauenswürdige Zone verlassen.</block>
  <block id="fb0e25ed6b061ae8d5a55a94457e445e" category="summary">Für diese Validierung haben wir die Protopia-Verschleierung fünfmal auf ein 1920 x 1080 Pixel großes Bild angewendet und die Zeit gemessen, die jedes Mal für den Abschluss des Verschleierungsschritts benötigt wurde.</block>
  <block id="9c6852dd5556b48ff70dd2583a5d3aa0" category="doc">Verschleierungsgeschwindigkeit</block>
  <block id="6977bb3543f8de6dcfa78f7970349ba1" category="paragraph">Wir haben PyTorch auf einer einzelnen NVIDIA V100-GPU verwendet, um die Verschleierung anzuwenden, und wir haben den GPU-Cache zwischen den Läufen geleert.  Der Verschleierungsschritt dauerte bei den fünf Durchläufen jeweils 5,47 ms, 5,27 ms, 4,54 ms, 5,24 ms und 4,84 ms.  Die Durchschnittsgeschwindigkeit betrug 5,072 ms.</block>
  <block id="4c787c1632a0a940cb0b44706b1d24c6" category="summary">Dieser Abschnitt bietet einen Überblick über die verschiedenen technischen Komponenten, die zur Vervollständigung dieser Lösung erforderlich sind.</block>
  <block id="a6d48b22bcf266404bdb8c57102c14a4" category="section-title">Protopia</block>
  <block id="b2cbc1ff8afd6c872961a852572e1782" category="paragraph">Protopia AI bietet heute auf dem Markt eine unaufdringliche, reine Softwarelösung für vertrauliche Inferenz.  Die Protopia-Lösung bietet beispiellosen Schutz für Inferenzdienste, indem sie die Offenlegung vertraulicher Informationen minimiert.  Der KI werden nur die Informationen aus dem Datensatz zugeführt, die für die Ausführung der jeweiligen Aufgabe wirklich notwendig sind, und nicht mehr.  Die meisten Inferenzaufgaben verwenden nicht alle Informationen, die in jedem Datensatz vorhanden sind.  Unabhängig davon, ob Ihre KI Bilder, Sprache, Videos oder sogar strukturierte Tabellendaten verarbeitet, liefert Protopia nur das, was der Inferenzdienst benötigt.  Die patentierte Kerntechnologie verwendet mathematisch kuratiertes Rauschen, um die Daten stochastisch zu transformieren und die Informationen zu verfälschen, die von einem bestimmten ML-Dienst nicht benötigt werden.  Diese Lösung maskiert die Daten nicht, sondern ändert die Datendarstellung durch die Verwendung kuratierten Zufallsrauschens.</block>
  <block id="46ce082967eab6fe2e33798614d50861" category="paragraph">Die Protopia-Lösung formuliert das Problem der Änderung der Darstellung als gradientenbasierte Methode zur Störungsmaximierung, die im Hinblick auf die Funktionalität des Modells immer noch die relevanten Informationen im Eingabemerkmalsraum beibehält.  Dieser Erkennungsprozess wird als Feinabstimmungsdurchgang am Ende des Trainings des ML-Modells ausgeführt.  Nachdem der Durchlauf automatisch eine Reihe von Wahrscheinlichkeitsverteilungen generiert hat, wendet eine Datentransformation mit geringem Aufwand Rauschproben aus diesen Verteilungen auf die Daten an und verschleiert sie, bevor sie zur Inferenz an das Modell übergeben werden.</block>
  <block id="af2063646dcea30a4bac90a1c51b14aa" category="section-title">NetApp ONTAP AI</block>
  <block id="4fb9892dc0183c3142a3629cecc3104a" category="paragraph">Die NetApp ONTAP AI-Referenzarchitektur, die auf DGX A100-Systemen und mit der NetApp Cloud verbundenen Speichersystemen basiert, wurde von NetApp und NVIDIA entwickelt und verifiziert.  Es bietet IT-Organisationen eine Architektur, die folgende Vorteile bietet:</block>
  <block id="9c6bd300c8cf3ca98c8548bbb27cc34a" category="list-text">Eliminiert Designkomplexitäten</block>
  <block id="cee5abf75433f502c31530bc72eecd6a" category="list-text">Ermöglicht die unabhängige Skalierung von Rechenleistung und Speicher</block>
  <block id="eccaf37681e446d183db0332d1e50552" category="list-text">Ermöglicht Kunden, klein anzufangen und nahtlos zu skalieren</block>
  <block id="410a2fbd85ad3d74051034eac2b94889" category="list-text">Bietet eine Reihe von Speicheroptionen für verschiedene Leistungs- und Kostenpunkte</block>
  <block id="988d7b305f79b990bbacdaed46f4b2bf" category="paragraph">ONTAP AI integriert DGX A100-Systeme und NetApp AFF A800 -Speichersysteme nahtlos in modernste Netzwerke.  ONTAP AI vereinfacht KI-Bereitstellungen, indem es die Designkomplexität und das Rätselraten eliminiert.  Kunden können klein anfangen und unterbrechungsfrei wachsen, während sie Daten vom Rand über den Kern bis zur Cloud und zurück intelligent verwalten.</block>
  <block id="57e22b018aa5130ece9890cd6b45e779" category="paragraph">Die folgende Abbildung zeigt mehrere Varianten der ONTAP AI-Lösungsfamilie mit DGX A100-Systemen.  Die Leistung des AFF A800 -Systems wird mit bis zu acht DGX A100-Systemen überprüft.  Durch das Hinzufügen von Speichercontrollerpaaren zum ONTAP Cluster kann die Architektur auf mehrere Racks skaliert werden, um viele DGX A100-Systeme und Petabyte an Speicherkapazität mit linearer Leistung zu unterstützen.  Dieser Ansatz bietet die Flexibilität, das Verhältnis von Rechenleistung zu Speicherleistung unabhängig voneinander zu ändern, basierend auf der Größe der verwendeten DL-Modelle und den erforderlichen Leistungskennzahlen.</block>
  <block id="a28d0dc585dd816bf7bcce4c5f5f6dd9" category="paragraph"><block ref="a28d0dc585dd816bf7bcce4c5f5f6dd9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ecc164061fb57b585c892f0faa6f4dcf" category="inline-link">NVA-1153: NetApp ONTAP AI mit NVIDIA DGX A100-Systemen und Mellanox Spectrum Ethernet-Switches.</block>
  <block id="3046083f382853b50c004323f2cda8f9" category="paragraph">Weitere Informationen zu ONTAP AI finden Sie unter<block ref="2c1616ab9baa55036487e7ef75b3821d" category="inline-link-rx"></block></block>
  <block id="862dcadd0f2887701abaa60bf59d5aa5" category="paragraph">ONTAP 9.11, die neueste Generation der Speicherverwaltungssoftware von NetApp, ermöglicht Unternehmen die Modernisierung ihrer Infrastruktur und den Übergang zu einem Cloud-fähigen Rechenzentrum.  Durch die Nutzung branchenführender Datenverwaltungsfunktionen ermöglicht ONTAP die Verwaltung und den Schutz von Daten mit einem einzigen Satz von Tools, unabhängig davon, wo sich diese Daten befinden.  Sie können Daten auch frei dorthin verschieben, wo sie benötigt werden: an den Rand, in den Kern oder in die Cloud.  ONTAP 9.11 umfasst zahlreiche Funktionen, die die Datenverwaltung vereinfachen, kritische Daten beschleunigen und schützen und Infrastrukturfunktionen der nächsten Generation in Hybrid-Cloud-Architekturen ermöglichen.</block>
  <block id="94c4b42bd5bfaa12f328387b161a1686" category="paragraph">NetApp DataOps Toolkit ist eine Python-Bibliothek, die Entwicklern, Datenwissenschaftlern, DevOps-Ingenieuren und Dateningenieuren die Durchführung verschiedener Datenverwaltungsaufgaben erleichtert, z. B. die nahezu sofortige Bereitstellung eines neuen Datenvolumens oder JupyterLab-Arbeitsbereichs, das nahezu sofortige Klonen eines Datenvolumens oder JupyterLab-Arbeitsbereichs und das nahezu sofortige Erstellen von Snapshots eines Datenvolumens oder JupyterLab-Arbeitsbereichs zur Rückverfolgbarkeit oder zum Erstellen einer Baseline.  Diese Python-Bibliothek kann entweder als Befehlszeilenprogramm oder als Funktionsbibliothek fungieren, die Sie in jedes Python-Programm oder Jupyter-Notebook importieren können.</block>
  <block id="2dcb054d023d8770b9ba0125434b8f20" category="paragraph">NVIDIA Triton Inference Server ist eine Open-Source-Inferenzsoftware, die die Standardisierung der Modellbereitstellung und -ausführung unterstützt, um schnelle und skalierbare KI in der Produktion bereitzustellen.  Triton Inference Server optimiert die KI-Inferenz, indem es Teams ermöglicht, trainierte KI-Modelle aus jedem Framework auf jeder GPU- oder CPU-basierten Infrastruktur bereitzustellen, auszuführen und zu skalieren.  Triton Inference Server unterstützt alle wichtigen Frameworks wie TensorFlow, NVIDIA TensorRT, PyTorch, MXNet, OpenVINO usw.  Triton lässt sich zur Orchestrierung und Skalierung in Kubernetes integrieren, sodass Sie es in allen wichtigen öffentlichen Cloud-KI- und Kubernetes-Plattformen verwenden können.  Es ist auch in viele MLOps-Softwarelösungen integriert.</block>
  <block id="6532191b754c006509ce4006a972990e" category="paragraph"><block ref="7b17fc2d2143dfdbd3bff6783f73e17c" category="inline-link-rx"></block>ist ein Open-Source-ML-Framework.  Es handelt sich um eine optimierte Tensorbibliothek für Deep Learning, die GPUs und CPUs verwendet.  Das PyTorch-Paket enthält Datenstrukturen für mehrdimensionale Tensoren, die neben anderen nützlichen Dienstprogrammen viele Dienstprogramme für die effiziente Serialisierung von Tensoren bereitstellen.  Es verfügt außerdem über ein CUDA-Gegenstück, mit dem Sie Ihre Tensorberechnungen auf einer NVIDIA GPU mit Rechenkapazität ausführen können.  Bei dieser Validierung verwenden wir die OpenCV-Python-Bibliothek (cv2), um unser Modell zu validieren und gleichzeitig die intuitivsten Computer-Vision-Konzepte von Python zu nutzen.</block>
  <block id="cdea8196113c492688981e0a035baa29" category="list-text">Leistung und geringere Latenz.  ONTAP bietet den höchstmöglichen Durchsatz bei der geringstmöglichen Latenz.</block>
  <block id="fa126db4297464dd03b3ceef190df0d0" category="list-text">Datenschutz.  ONTAP bietet integrierte Datenschutzfunktionen mit gemeinsamer Verwaltung auf allen Plattformen.</block>
  <block id="1f17e94c6f48114ff29ad3267277420c" category="list-text">Mandantenfähigkeit und Multifaktor-Authentifizierung.  ONTAP ermöglicht die gemeinsame Nutzung von Infrastrukturressourcen mit höchster Sicherheit.</block>
  <block id="b816bfff9511bcd88a9aa06fe0fd6389" category="list-text">Nahtlose Skalierung und unterbrechungsfreier Betrieb.  ONTAP unterstützt die unterbrechungsfreie Kapazitätserweiterung bestehender Controller und Scale-Out-Cluster.  Kunden können ohne kostspielige Datenmigrationen oder Ausfälle auf die neuesten Technologien wie NVMe und 32 GB FC upgraden.</block>
  <block id="377c9a91b43c5423691b5ce75db91350" category="section-title">NetApp Astra Control</block>
  <block id="35b46e301702b6fcb16192f9f4cf4533" category="inline-link">Astra Control Service</block>
  <block id="eb75cc706ac8cc6c0f4cb17f4fb073dd" category="paragraph">Die NetApp Astra Produktfamilie bietet Speicher- und anwendungsorientierte Datenverwaltungsdienste für Kubernetes-Anwendungen vor Ort und in der öffentlichen Cloud, unterstützt durch NetApp -Speicher- und Datenverwaltungstechnologien.  Damit können Sie Kubernetes-Anwendungen einfach sichern, Daten in einen anderen Cluster migrieren und sofort funktionierende Anwendungsklone erstellen.  Wenn Sie Kubernetes-Anwendungen verwalten müssen, die in einer öffentlichen Cloud ausgeführt werden, lesen Sie die Dokumentation für<block ref="6d442ad773e9d31651277931acd1583a" category="inline-link-rx"></block> .  Astra Control Service ist ein von NetApp verwalteter Dienst, der anwendungsbewusstes Datenmanagement von Kubernetes-Clustern in Google Kubernetes Engine (GKE) und Azure Kubernetes Service (AKS) bietet.</block>
  <block id="545b3003eeeed3a05db492712188eaa8" category="paragraph">Astra<block ref="b792e70a7bbe82fe69049fd18abe3c18" category="inline-link-rx"></block> von NetApp ist ein Open-Source-Orchestrator für dynamischen Speicher für Docker und Kubernetes, der die Erstellung, Verwaltung und Nutzung von persistentem Speicher vereinfacht.  Trident, eine Kubernetes-native Anwendung, läuft direkt in einem Kubernetes-Cluster.  Trident ermöglicht Kunden die nahtlose Bereitstellung von DL-Container-Images auf NetApp Speicher und bietet eine unternehmenstaugliche Erfahrung für die Bereitstellung von KI-Containern.  Kubernetes-Benutzer (ML-Entwickler, Datenwissenschaftler usw.) können Orchestrierung und Klonen erstellen, verwalten und automatisieren, um die erweiterten Datenverwaltungsfunktionen der NetApp Technologie zu nutzen.</block>
  <block id="45a189f17e7eec44ce720f6a979e501e" category="paragraph"><block ref="9f25cf06e22037e38bb7442b4d301b6c" category="inline-link-rx"></block>ist ein NetApp -Dienst für die schnelle und sichere Datensynchronisierung.  Unabhängig davon, ob Sie Dateien zwischen lokalen NFS- oder SMB-Dateifreigaben, NetApp StorageGRID, NetApp ONTAP S3, Google Cloud NetApp Volumes, Azure NetApp Files, Amazon Simple Storage Service (Amazon S3), Amazon Elastic File System (Amazon EFS), Azure Blob, Google Cloud Storage oder IBM Cloud Object Storage übertragen müssen, verschiebt BlueXP Copy and Sync die Dateien schnell und sicher dorthin, wo Sie sie benötigen.  Nachdem Ihre Daten übertragen wurden, stehen sie sowohl auf der Quelle als auch auf dem Ziel vollständig zur Verwendung zur Verfügung.  BlueXP Copy and Syncc synchronisiert die Daten kontinuierlich basierend auf Ihrem vordefinierten Zeitplan und verschiebt nur die Deltas, sodass der Zeit- und Kostenaufwand für die Datenreplikation minimiert wird.  BlueXP Copy and Sync ist ein Software-as-a-Service-Tool (SaaS), das extrem einfach einzurichten und zu verwenden ist.  Datenübertragungen, die durch BlueXP Copy and Sync ausgelöst werden, werden von Datenbrokern durchgeführt.  Sie können BlueXP Copy and Sync-Datenbroker in AWS, Azure, Google Cloud Platform oder vor Ort bereitstellen.</block>
  <block id="b8bc3287c1345ab1a36c796d2de0aaa2" category="section-title">NetApp BlueXP Klassifizierung</block>
  <block id="196f1872673d3381d912260929325605" category="paragraph">Angetrieben von leistungsstarken KI-Algorithmen,<block ref="860dd213c65646bc2292a7454f4cfbac" category="inline-link-rx"></block> bietet automatisierte Kontrollen und Datenverwaltung für Ihren gesamten Datenbestand.  Sie können Kosteneinsparungen leicht ermitteln, Compliance- und Datenschutzbedenken erkennen und Optimierungsmöglichkeiten finden.  Das BlueXP -Klassifizierungs-Dashboard bietet Ihnen die nötigen Einblicke, um doppelte Daten zu identifizieren und Redundanzen zu vermeiden, persönliche, nicht persönliche und vertrauliche Daten zuzuordnen und Warnmeldungen für vertrauliche Daten und Anomalien zu aktivieren.</block>
  <block id="c46aabfbeb0af662ede62f7325853fa2" category="summary">Die digitale Bildverarbeitung bietet zahlreiche Vorteile und ermöglicht vielen Unternehmen, die mit visuellen Darstellungen verbundenen Daten optimal zu nutzen.  Diese Lösung von NetApp und Protopia bietet ein einzigartiges KI-Inferenzdesign zum Schutz und zur Privatisierung von KI-/ML-Daten über den gesamten ML/DL-Lebenszyklus hinweg.  Es ermöglicht Kunden, das Eigentum an sensiblen Daten zu behalten, öffentliche oder hybride Cloud-Bereitstellungsmodelle für Skalierbarkeit und Effizienz zu verwenden, indem Datenschutzbedenken ausgeräumt werden, und KI-Inferenz am Rand einzusetzen.</block>
  <block id="55ece983a5251583397e3db1cd3926ec" category="section-title">Umweltintelligenz</block>
  <block id="d0f24bc92f5b7838f03e893b41066a90" category="paragraph">Es gibt viele Möglichkeiten, wie die Industrie im Bereich Umweltgefahren von Geodatenanalysen profitieren kann.  Regierungen und das Ministerium für öffentliche Arbeiten können daraus umsetzbare Erkenntnisse zur öffentlichen Gesundheit und zu den Wetterbedingungen gewinnen, um die Öffentlichkeit während einer Pandemie oder einer Naturkatastrophe wie Waldbränden besser beraten zu können.  Sie können beispielsweise einen COVID-positiven Patienten in öffentlichen Räumen wie Flughäfen oder Krankenhäusern identifizieren, ohne die Privatsphäre der betroffenen Person zu verletzen, und die entsprechenden Behörden und die Öffentlichkeit in der Umgebung über die erforderlichen Sicherheitsmaßnahmen informieren.</block>
  <block id="4f9352e4f65872238d755155cd23edec" category="section-title">Edge-Geräte-Wearables</block>
  <block id="315a1bbca88dbcbdc95471a0061c333f" category="paragraph">Beim Militär und auf Schlachtfeldern können Sie KI-Inferenz am Rande als tragbare Geräte nutzen, um den Gesundheitszustand von Soldaten zu verfolgen, das Verhalten von Fahrern zu überwachen und die Behörden auf die Sicherheit und die damit verbundenen Risiken bei der Annäherung an Militärfahrzeuge aufmerksam zu machen und gleichzeitig die Privatsphäre der Soldaten zu wahren und zu schützen.  Die Zukunft des Militärs wird Hightech mit dem Internet of Battlefield Things (IoBT) und dem Internet of Military Things (IoMT) für tragbare Kampfausrüstung, die Soldaten dabei hilft, Feinde zu identifizieren und im Kampf durch den Einsatz von schnellem Edge Computing bessere Leistungen zu erbringen.  Der Schutz und die Aufbewahrung visueller Daten, die von Edge-Geräten wie Drohnen und tragbaren Geräten erfasst werden, ist von entscheidender Bedeutung, um Hacker und Feinde in Schach zu halten.</block>
  <block id="d6dded41a42f767150e641793fc0c929" category="section-title">Evakuierungsoperationen für Nichtkombattanten</block>
  <block id="c5b381de9b2a4ee73bcc524aa380d725" category="paragraph">Das US-Verteidigungsministerium führt Evakuierungsoperationen für Nichtkombattanten (NEOs) durch, um die Evakuierung von US-Bürgern und -Staatsangehörigen, zivilem Personal des Verteidigungsministeriums und bestimmten Personen (Staatsangehörige des Gastlandes (HN) und Drittstaatsangehörige (TCN)), deren Leben in Gefahr ist, in einen geeigneten sicheren Hafen zu unterstützen.  Die bestehenden Verwaltungskontrollen basieren größtenteils auf manuellen Überprüfungsprozessen für Evakuierte.  Die Genauigkeit, Sicherheit und Geschwindigkeit der Identifizierung und Verfolgung von Evakuierten sowie der Bedrohungsüberprüfung könnten jedoch möglicherweise durch den Einsatz hochautomatisierter KI/ML-Tools in Kombination mit KI/ML-Videoverschleierungstechnologien verbessert werden.</block>
  <block id="19c95c19bd7c939577775cd0ecce3df1" category="section-title">Gesundheitswesen und biomedizinische Forschung</block>
  <block id="a047c61461aba5a84a0a221900c33984" category="paragraph">Mittels Bildverarbeitung werden Pathologien für die Operationsplanung anhand von 3D-Bildern aus der Computertomographie (CT) oder Magnetresonanztomographie (MRT) diagnostiziert.  Die HIPAA-Datenschutzbestimmungen regeln, wie Organisationen alle personenbezogenen Daten und digitalen Bilder wie Fotos erfassen, verarbeiten und löschen müssen.  Damit Daten gemäß den HIPAA Safe Harbor-Bestimmungen als gemeinsam nutzbar gelten, müssen vollständige Gesichtsfotos und alle vergleichbaren Bilder entfernt werden.  Automatisierte Techniken wie De-Identifizierung oder Algorithmen zur Schädelentfernung, die zum Verbergen der Gesichtszüge einer Person auf strukturellen CT-/MR-Bildern verwendet werden, sind zu einem wesentlichen Bestandteil des Datenaustauschprozesses für biomedizinische Forschungseinrichtungen geworden.</block>
  <block id="2d930616ec617ae047b7b7eaefb0822c" category="section-title">Cloud-Migration von KI/ML-Analysen</block>
  <block id="073395e7b5fc53b602884ac0aaf757fb" category="inline-link">Datenschutz</block>
  <block id="2c5c3872e94de8a36eac45213c5bf2e6" category="paragraph">Unternehmenskunden haben KI/ML-Modelle traditionell vor Ort trainiert und bereitgestellt.  Aus Skalen- und Effizienzgründen expandieren diese Kunden, um KI-/ML-Funktionen in öffentliche, hybride oder Multi-Cloud-Bereitstellungen zu verlagern.  Sie sind jedoch daran gebunden, welche Daten anderen Infrastrukturen zugänglich gemacht werden können.  NetApp Lösungen adressieren eine breite Palette von Cybersicherheitsbedrohungen, die für<block ref="9da3a9a08c9461b229d33f221e8caa37" category="inline-link-rx"></block> und Sicherheitsbewertung und minimieren in Kombination mit der Protopia-Datentransformation die Risiken, die mit der Migration von KI/ML-Workloads zur Bildverarbeitung in die Cloud verbunden sind.</block>
  <block id="c9f2e6462caf995f1d336ab4bb33a7c2" category="inline-link-macro">TR-4886 KI-Inferenzierung am Rand</block>
  <block id="ae1b6ac445119145d739025d55fe616f" category="inline-link">Intelligenz versus Privatsphäre</block>
  <block id="7c93429acdde399d280f2e20425ac745" category="paragraph">Weitere Anwendungsfälle für Edge Computing und KI-Inferenz in anderen Branchen finden Sie unter<block ref="c2ef3f1fa710d59c08d58b9025616182" category="inline-link-macro-rx"></block> und dem NetApp AI-Blog,<block ref="bc130be57ffb0325128dc7274bbdbc64" category="inline-link-rx"></block> .</block>
  <block id="59a6ec9eb2075dc5ac847799c3c9b4e0" category="summary">Hybrid Multicloud MLOps mit Domino Data Lab und NetApp – Wo Sie weitere Informationen finden</block>
  <block id="3887d417240a72ab69f6d0301efd3b2b" category="doc">Wo Sie weitere Informationen finden</block>
  <block id="44997fb529c7b7d20853c30af9ad918a" category="list-text">Domino Data Lab</block>
  <block id="1182c61de35b31af3e72f77e61442c77" category="inline-link-macro"><block ref="1182c61de35b31af3e72f77e61442c77" category="inline-link-rx"></block></block>
  <block id="bd0007c3dcc92207ee01f0427da0a4be" category="paragraph"><block ref="bd0007c3dcc92207ee01f0427da0a4be" category="inline-link-macro-rx"></block></block>
  <block id="d7574cd2803b94ddaa90cab193a19ba2" category="list-text">Domino Nexus</block>
  <block id="2703dd45bd40545fb60997c2d3afe208" category="inline-link-macro"><block ref="2703dd45bd40545fb60997c2d3afe208" category="inline-link-rx"></block></block>
  <block id="14a3e5a8d5046236b5959a8860c405eb" category="paragraph"><block ref="14a3e5a8d5046236b5959a8860c405eb" category="inline-link-macro-rx"></block></block>
  <block id="1273c8a63109161e6fd1f18d6998523f" category="list-text">NetApp BlueXP</block>
  <block id="43e196fd7d1a86adce26084a27e3d664" category="inline-link-macro"><block ref="43e196fd7d1a86adce26084a27e3d664" category="inline-link-rx"></block></block>
  <block id="2edabab990aa6b9914f978e6885781f2" category="paragraph"><block ref="2edabab990aa6b9914f978e6885781f2" category="inline-link-macro-rx"></block></block>
  <block id="5339d389f2f896062fb28b05454dc94a" category="list-text">NetApp ONTAP Datenmanagementsoftware</block>
  <block id="5b8aea48f614361f60f00e194e1b0976" category="inline-link-macro"><block ref="5b8aea48f614361f60f00e194e1b0976" category="inline-link-rx"></block></block>
  <block id="59f3782142c74894e9aa57873085e394" category="paragraph"><block ref="59f3782142c74894e9aa57873085e394" category="inline-link-macro-rx"></block></block>
  <block id="13ed1686110be86a2aeef6d76d4ec65e" category="list-text">NetApp KI-Lösungen</block>
  <block id="91fc02253adb6a9eea2156b684aa70f5" category="inline-link-macro"><block ref="91fc02253adb6a9eea2156b684aa70f5" category="inline-link-rx"></block></block>
  <block id="501b3e03ab68e967ec7e74647ece575b" category="paragraph"><block ref="501b3e03ab68e967ec7e74647ece575b" category="inline-link-macro-rx"></block></block>
  <block id="5acaa2031a97473b7a185dc30ce9e62d" category="list-text">Josh Mineroff, Direktor von SA für Tech Alliances, Domino Data Lab</block>
  <block id="ed2311020217442776d108d1f99b7521" category="list-text">Nicholas Jablonski, Field CTO, Domino Data Lab</block>
  <block id="5c38b0c6106b026873b5212202e5eb20" category="list-text">Prabu Arjunan, Lösungsarchitekt, NetApp</block>
  <block id="958996b71437140af7dadceec3c0acf1" category="list-text">Brian Young, Global Alliance Director, Technology Alliance Partners, NetApp</block>
  <block id="182f685e8ff46f3bde7c8c63a6d3e8eb" category="summary">Hybrid Multicloud MLOps mit Domino Data Lab und NetApp – Architektur</block>
  <block id="22a02f1b77fcd49462c4d58a6e2425fb" category="paragraph">Diese Lösung kombiniert die hybriden Multicloud-Workload-Scheduling-Funktionen von Domino Nexus mit NetApp -Datendiensten, um eine einheitliche Hybrid-Cloud-MLOps-Plattform zu erstellen.  Einzelheiten finden Sie in der folgenden Tabelle.</block>
  <block id="0ba29c6a1afacf586b03a26162c72274" category="cell">Umfeld</block>
  <block id="1a01eb6a884a288b667e023501d09eea" category="cell">MLOps-Steuerebene</block>
  <block id="51c0d15bebbbdb19d5e1bde9bf2bc1ba" category="inline-link-macro">Domino Enterprise AI-Plattform mit Domino Nexus</block>
  <block id="a0133d74aa4167bee7ec6bb2830b32ab" category="cell"><block ref="a0133d74aa4167bee7ec6bb2830b32ab" category="inline-link-macro-rx"></block></block>
  <block id="4847e034bb0a55fcbc8a3380d6a3ab80" category="cell">AWS</block>
  <block id="dedb71b645ad83baa13a64e834ea32a3" category="cell">Rechenumgebungen der MLOps-Plattform</block>
  <block id="1f26213ee3d03d1bce28558ef8ff15ff" category="inline-link-macro">Domino Nexus-Datenebenen</block>
  <block id="f2d3c460a5a76b316899ec775650d7ea" category="cell"><block ref="f2d3c460a5a76b316899ec775650d7ea" category="inline-link-macro-rx"></block></block>
  <block id="89f5a1a21bf30d5f2db943911b2d22f2" category="cell">AWS, lokales Rechenzentrum</block>
  <block id="1698863d644408b6fdc41803a6a1c234" category="cell">Lokale Rechenplattform</block>
  <block id="2c02a900da9ea696e0b13c405974ca0b" category="cell"><block ref="e08fa5b25dd32bed0a8727bee0e3fdd0" category="inline-link-macro-rx"></block>mit<block ref="c8e9826c7461e34f8a6ee68d2d629f27" category="inline-link-macro-rx"></block></block>
  <block id="59f10558cba0587bc03fb56826f8cd4b" category="cell">Rechenzentrum vor Ort</block>
  <block id="29e13ea538f81a8bf3cea3900519c8a1" category="cell">Cloud-Computing-Plattform</block>
  <block id="480c9b5f979d1ce95ea2a58b09826d1b" category="inline-link-macro">Amazon Elastic Kubernetes Service (EKS)</block>
  <block id="ff969739d0750911a50d47ea892fad80" category="cell"><block ref="4ecdb2c4c840fbc0e496687cc8bf58fe" category="inline-link-macro-rx"></block>mit<block ref="c8e9826c7461e34f8a6ee68d2d629f27" category="inline-link-macro-rx"></block></block>
  <block id="cd3aefaae18f11e3ecc3de62739183f3" category="cell">On-Premise-Datenplattform</block>
  <block id="e16a11bc6041db3c2b26ef054c8b8847" category="inline-link-macro">NetApp Speichergerät</block>
  <block id="b331d50869bea7c3b019d322cffc1f03" category="cell"><block ref="ea0807fcd7c8182254e93c3bfdf94abc" category="inline-link-macro-rx"></block>angetrieben von<block ref="1c317db419d669c4b6473c6d462e881e" category="inline-link-macro-rx"></block></block>
  <block id="0c9ae535d9e81d6e268c0ea087be535f" category="cell">Cloud-Datenplattform</block>
  <block id="35f7c29efc923e8a7920a0b331095d71" category="inline-link-macro">Amazon FSx ONTAP</block>
  <block id="2a9165a68b73a53b924deda7b9ec0251" category="cell"><block ref="2a9165a68b73a53b924deda7b9ec0251" category="inline-link-macro-rx"></block></block>
  <block id="b497a71f092b521e07c06ade7296c159" category="paragraph"><block ref="b497a71f092b521e07c06ade7296c159" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f92651ef1a171bf24e3a0279a4f656f" category="summary">Hybrid Multicloud MLOps mit Domino Data Lab und NetApp – Zugriff auf dieselben Daten in verschiedenen Umgebungen</block>
  <block id="2167fcd754f38c037a8a5fc219634638" category="doc">Greifen Sie in verschiedenen Umgebungen auf dieselben Daten zu</block>
  <block id="2b2213cc89a71238bd2629046704d311" category="paragraph">In diesem Abschnitt werden die Aufgaben beschrieben, die ausgeführt werden müssen, um in verschiedenen Computerumgebungen auf dieselben Daten zuzugreifen.  In der Domino MLOps-Plattform werden Rechenumgebungen als „Datenebenen“ bezeichnet.  Befolgen Sie die in diesem Abschnitt beschriebenen Aufgaben, wenn sich Ihre Daten auf einem NetApp -Volume in einer Datenebene befinden, Sie aber in einer anderen Datenebene darauf zugreifen müssen.  Diese Art von Szenario wird oft als „Bursting“ oder, wenn die Zielumgebung die Cloud ist, als „Cloud Bursting“ bezeichnet.  Diese Funktion wird häufig benötigt, wenn es um eingeschränkte oder überbelegte Rechenressourcen geht.  Wenn Ihr lokaler Computercluster beispielsweise überbucht ist, möchten Sie möglicherweise Workloads in die Cloud verschieben, wo sie sofort gestartet werden können.</block>
  <block id="8e259831056b970e9e9ad97044e756ea" category="paragraph">Für den Zugriff auf ein NetApp -Volume, das sich in einer anderen Datenebene befindet, gibt es zwei empfohlene Optionen.  Diese Optionen werden in den folgenden Unterabschnitten beschrieben.  Wählen Sie je nach Ihren spezifischen Anforderungen eine dieser Optionen.  Die Vor- und Nachteile der beiden Optionen werden in der folgenden Tabelle beschrieben.</block>
  <block id="054b4f3ea543c990f6b125f41af6ebf7" category="cell">Option</block>
  <block id="e654f7a86a4458b9cd662267e0f29b52" category="cell">Vorteile</block>
  <block id="0cfc0523189294ac086e11c8e286ba2d" category="cell">Nachteile</block>
  <block id="a5a315a3bc09fc65d5b92a61203e604b" category="cell">Option 1 – Cache</block>
  <block id="542d0200f163f8f3533463dd59fe0270" category="cell">- Einfacherer Arbeitsablauf - Möglichkeit, eine Teilmenge der Daten je nach Bedarf zwischenzuspeichern - Möglichkeit, Daten zurück in die Quelle zu schreiben - Keine Remote-Kopie zu verwalten</block>
  <block id="7426e3bde1c62fb806a70f18c6134316" category="cell">- Erhöhte Latenz beim ersten Datenzugriff, da der Cache hydratisiert wird.</block>
  <block id="aaa4d30d61e64cea712b7c05c68eb117" category="cell">Option 2 – Spiegel</block>
  <block id="cbefd7ef29f92291b21681c43ba469b7" category="cell">- Vollständige Kopie des Quellvolumes - Keine erhöhte Latenz durch Cache-Hydration (nach Abschluss des Spiegelvorgangs)</block>
  <block id="03dab0d003c274e0f366cd0df3efb059" category="cell">- Vor dem Zugriff auf die Daten muss auf den Abschluss des Spiegelvorgangs gewartet werden. - Eine Remote-Kopie muss verwaltet werden. - Keine Möglichkeit, in die Quelle zurückzuschreiben.</block>
  <block id="f794ea935b3f3b976964bf0990d05005" category="section-title">Option 1 – Erstellen Sie einen Cache eines Volumes, das sich in einer anderen Datenebene befindet</block>
  <block id="79849c69657d54d5bfdd901f71375897" category="inline-link-macro">NetApp FlexCache -Technologie</block>
  <block id="a816bf9775484a9a7049d55ece7f5396" category="paragraph">Mit<block ref="bb0419306e9b544a3e597acbf1d444f1" category="inline-link-macro-rx"></block> können Sie einen Cache eines NetApp -Volumes erstellen, das sich in einer anderen Datenebene befindet.  Wenn Sie beispielsweise ein NetApp Volume in Ihrer lokalen Datenebene haben und auf dieses Volume in Ihrer AWS-Datenebene zugreifen müssen, können Sie einen Cache des Volumes in AWS erstellen.  In diesem Abschnitt werden die Aufgaben beschrieben, die ausgeführt werden müssen, um einen Cache für ein NetApp -Volume zu erstellen, das sich in einer anderen Datenebene befindet.</block>
  <block id="d93488703b54616875bcacc4afd140a7" category="section-title">Erstellen Sie ein FlexCache -Volume in der Zielumgebung</block>
  <block id="5d03f3f921e1e11afbd6bc02646a4b6f" category="admonition">Wenn die Zielumgebung Ihr lokales Rechenzentrum ist, erstellen Sie das FlexCache Volume auf Ihrem lokalen ONTAP System.  Wenn die Zielumgebung AWS ist, erstellen Sie das FlexCache Volume auf Ihrer Amazon FSx ONTAP Instance.</block>
  <block id="a53f62411ee21cbe84822e3eba531ca4" category="paragraph">Zuerst müssen Sie in der Zielumgebung ein FlexCache -Volume erstellen.</block>
  <block id="671e0b00bec7311fe1a27ae3b1374868" category="inline-link-macro">BlueXP volume caching Dokumentation</block>
  <block id="25d1d7fbc173abf20974acc2fd19014b" category="paragraph">Wir empfehlen die Verwendung von BlueXP zum Erstellen des FlexCache -Volumes.  Um ein FlexCache Volume mit BlueXP zu erstellen, folgen Sie den Anweisungen im<block ref="13882193b90946980fb2e14f0dc3f833" category="inline-link-macro-rx"></block> .</block>
  <block id="597fd5f01aeae294735b75c08203b6dd" category="paragraph">Wenn Sie BlueXP nicht verwenden möchten, können Sie zum Erstellen des FlexCache Volumes ONTAP System Manager oder die ONTAP CLI verwenden.  Um ein FlexCache Volume mit System Manager zu erstellen, befolgen Sie die Anweisungen im<block ref="01bbf1f7353a360c52874272bfd82e21" category="inline-link-macro-rx"></block> .  Informationen zum Erstellen eines FlexCache Volumes mit der ONTAP CLI finden Sie in den Anweisungen im<block ref="91e4088944fb7c016c63d36e00422b16" category="inline-link-macro-rx"></block> .</block>
  <block id="e4de6f9df9cd48ef525131de3cb21481" category="inline-link-macro">BlueXP -API</block>
  <block id="0ec641cfacd36c8e22a334135e2abdac" category="inline-link-macro">ONTAP REST API</block>
  <block id="ebf440be7bdce857e55ec25910ae837b" category="inline-link-macro">ONTAP Ansible-Sammlung</block>
  <block id="dd7a007ea7e610e168238b6d6ab542a1" category="paragraph">Wenn Sie diesen Prozess automatisieren möchten, können Sie die<block ref="f07bcb7e875f8bb20680b339fb58364a" category="inline-link-macro-rx"></block> , Die<block ref="0966e902a53f3a5becbd165bbdc18e79" category="inline-link-macro-rx"></block> oder die<block ref="62c3d824298cc8f488bda82279b91e73" category="inline-link-macro-rx"></block> .</block>
  <block id="2f37e297d79532f437d3ab48727a61c0" category="admonition">System Manager ist in Amazon FSx ONTAP nicht verfügbar.</block>
  <block id="20f99b2a7f22945f3d769fa1def1e403" category="section-title">FlexCache -Volume für Domino verfügbar machen</block>
  <block id="c9743d6f9b7fcd7047ce3eb9d1f2a273" category="inline-link-macro">Abschnitt „Vorhandene NetApp -Volumes für Domino verfügbar machen“</block>
  <block id="82a25bd099304632e33529b36f2ac5de" category="paragraph">Als Nächstes müssen Sie das FlexCache Volume der Domino MLOps-Plattform zugänglich machen.  Um das FlexCache -Volume für Domino verfügbar zu machen, folgen Sie den Anweisungen im Unterabschnitt „Existierende NFS-Volumes verfügbar machen, die nicht von Trident bereitgestellt wurden“ des<block ref="37f39ecc5e06a679f4975effd49fb9b8" category="inline-link-macro-rx"></block> dieser Lösung.</block>
  <block id="1d25e828bd3386ce7ef8b97572c88781" category="paragraph">Jetzt können Sie das FlexCache -Volume mounten, wenn Sie Jobs und Arbeitsbereiche in der Zieldatenebene starten, wie in den folgenden Screenshots gezeigt.</block>
  <block id="edaa69742537cd645340e6ec55f0e7c2" category="section-title">Vor dem Erstellen des FlexCache -Volumes</block>
  <block id="7708950a83e2f559b43ad1d7bc08a440" category="paragraph"><block ref="7708950a83e2f559b43ad1d7bc08a440" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c7bf27913e6097a43d318c500146c1e1" category="section-title">Nach der Bereitstellung des FlexCache -Volumes für Domino</block>
  <block id="acacf35ed5b32878a29f6d32e6a11ffe" category="paragraph"><block ref="acacf35ed5b32878a29f6d32e6a11ffe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9be78ccf5bdf4dc10f0e5d25b893eeb" category="section-title">Option 2 – Replizieren eines Volumes, das sich in einer anderen Datenebene befindet</block>
  <block id="0e6ab030c4eacec9efa80d3df6cd643b" category="inline-link-macro">NetApp SnapMirror Datenreplikationstechnologie</block>
  <block id="124468d30e8b5047c5fe1b160b4fcbd2" category="paragraph">Mit<block ref="ebe914c00393f99bd92af5cffa8376b0" category="inline-link-macro-rx"></block> können Sie eine Kopie eines NetApp -Volumes erstellen, das sich in einer anderen Datenebene befindet.  Wenn Sie beispielsweise ein NetApp Volume in Ihrer lokalen Datenebene haben und auf dieses Volume in Ihrer AWS-Datenebene zugreifen müssen, können Sie eine Kopie des Volumes in AWS erstellen.  In diesem Abschnitt werden die Aufgaben beschrieben, die ausgeführt werden müssen, um eine Kopie eines NetApp -Volumes zu erstellen, das sich in einer anderen Datenebene befindet.</block>
  <block id="050a227810327b3bcfd311be38b7d202" category="section-title">SnapMirror -Beziehung erstellen</block>
  <block id="fef6b7d4f88331bab85d2eb944d43e9b" category="paragraph">Zuerst müssen Sie eine SnapMirror -Beziehung zwischen Ihrem Quellvolume und einem neuen Zielvolume in der Zielumgebung erstellen.  Beachten Sie, dass das Zielvolume im Rahmen des Prozesses zum Erstellen der SnapMirror -Beziehung erstellt wird.</block>
  <block id="62390de09bd56fbb6d4533a188f4f201" category="inline-link-macro">BlueXP replication</block>
  <block id="6fbd84bba212db826d8a94b992bd6324" category="paragraph">Wir empfehlen die Verwendung von BlueXP zum Erstellen der SnapMirror -Beziehung.  Um eine SnapMirror -Beziehung mit BlueXP zu erstellen, folgen Sie den Anweisungen in der<block ref="b08e4ece79f7d1aa7f110b298b659fae" category="inline-link-macro-rx"></block> .</block>
  <block id="052be79cbb457a1391bb0a6839e610d3" category="paragraph">Wenn Sie BlueXP nicht verwenden möchten, können Sie die SnapMirror -Beziehung mit dem ONTAP System Manager oder der ONTAP CLI erstellen.  Um eine SnapMirror -Beziehung mit System Manager zu erstellen, beachten Sie die Anweisungen im<block ref="665d2354c4ea508e65993c5ec9dc3fa1" category="inline-link-macro-rx"></block> .  Um eine SnapMirror -Beziehung mit der ONTAP CLI zu erstellen, beachten Sie die Anweisungen im<block ref="bf03311f5c6980a3d817528b27741438" category="inline-link-macro-rx"></block> .</block>
  <block id="805b58c51fa6bf98d530bbc76f317e74" category="section-title">SnapMirror Beziehung unterbrechen</block>
  <block id="9ee42869e01344256cee7824a61c3f00" category="paragraph">Als Nächstes müssen Sie die SnapMirror -Beziehung aufheben, um das Zielvolume für den Datenzugriff zu aktivieren.  Warten Sie, bis die erste Replikation abgeschlossen ist, bevor Sie diesen Schritt ausführen.</block>
  <block id="c16b6b1cdf70d97ab9f143b23f304ee5" category="admonition">Sie können feststellen, ob die Replikation abgeschlossen ist, indem Sie den Spiegelstatus in BlueXP, ONTAP System Manager oder der ONTAP CLI überprüfen.  Wenn die Replikation abgeschlossen ist, lautet der Spiegelstatus „snapmirrored“.</block>
  <block id="acab4369131a8c646dc85deedc5c4abb" category="paragraph">Wir empfehlen die Verwendung von BlueXP , um die SnapMirror -Beziehung zu unterbrechen.  Um eine SnapMirror -Beziehung mit BlueXP zu beenden, folgen Sie den Anweisungen in der<block ref="eb8fade3a2fe398b39f82043fade1a22" category="inline-link-macro-rx"></block> .</block>
  <block id="96009cd50e3918957734c7c1dbe9bbb1" category="paragraph">Wenn Sie BlueXP nicht verwenden möchten, können Sie die SnapMirror -Beziehung mit dem ONTAP System Manager oder der ONTAP CLI aufheben.  Um eine SnapMirror -Beziehung mit System Manager zu beenden, beachten Sie die Anweisungen im<block ref="2feb8ad9799acf2d659fb0cab9f5c802" category="inline-link-macro-rx"></block> .  Um eine SnapMirror -Beziehung mit der ONTAP CLI zu unterbrechen, beachten Sie die Anweisungen im<block ref="a5d68b350f5308762130d0f350fbb93c" category="inline-link-macro-rx"></block> .</block>
  <block id="67a1a8de2d55c1b2a31ec40db952c0cf" category="section-title">Zielvolume für Domino verfügbar machen</block>
  <block id="0de56c363db9af31c3fe36cd53b5deaf" category="paragraph">Als Nächstes müssen Sie das Zielvolume der Domino MLOps-Plattform zugänglich machen.  Um das Zielvolume für Domino freizugeben, folgen Sie den Anweisungen im Unterabschnitt „Existierende NFS-Volumes freigeben, die nicht von Trident bereitgestellt wurden“ des<block ref="37f39ecc5e06a679f4975effd49fb9b8" category="inline-link-macro-rx"></block> dieser Lösung.</block>
  <block id="aa4e6b2b0a9165bbe6adb64ff972dbb0" category="paragraph">Jetzt können Sie das Zielvolume mounten, wenn Sie Jobs und Arbeitsbereiche in der Zieldatenebene starten, wie in den folgenden Screenshots gezeigt.</block>
  <block id="6c2d9f4c43e6e539a1b0bf3be24de513" category="section-title">Vor dem Erstellen einer SnapMirror Beziehung</block>
  <block id="800f74671431bfc6b9efb2f7e294020f" category="section-title">Nach der Freigabe des Zielvolumes für Domino</block>
  <block id="a2207225ebdd3d675188d927e34ace5a" category="summary">Domino Nexus ist eine zentrale Oberfläche, mit der Sie Data-Science- und Machine-Learning-Workloads in jedem beliebigen Computercluster ausführen können – in jeder Cloud, Region oder vor Ort.</block>
  <block id="1882311bf64ae464a0b9653b463c8584" category="doc">Hybrid Multicloud MLOps mit Domino Data Lab und NetApp</block>
  <block id="f0829d8f9d70b9de9de7beae86dc2129" category="paragraph">Mike Oglesby, NetApp</block>
  <block id="c716184d878cbe2fda94903e01c21291" category="paragraph">Organisationen auf der ganzen Welt setzen derzeit KI ein, um ihre Geschäfte und Prozesse zu transformieren.  Aus diesem Grund ist eine KI-fähige Computerinfrastruktur oft Mangelware.  Unternehmen setzen auf hybride Multicloud-MLOps-Architekturen, um die Vorteile der verfügbaren Rechenumgebungen in verschiedenen Regionen, Rechenzentren und Clouds zu nutzen und so Kosten, Verfügbarkeit und Leistung in Einklang zu bringen.</block>
  <block id="542493ebb9768d33d834c6edcade57dc" category="paragraph">Domino Nexus von Domino Data Lab ist eine einheitliche MLOps-Steuerungsebene, mit der Sie Data-Science- und Machine-Learning-Workloads in jedem Computercluster ausführen können – in jeder Cloud, Region oder vor Ort.  Es vereinheitlicht Data-Science-Silos im gesamten Unternehmen, sodass Sie Modelle an einem Ort erstellen, bereitstellen und überwachen können.  Ebenso ermöglichen Ihnen die Hybrid-Cloud-Datenverwaltungsfunktionen von NetApp, Ihre Daten zu Ihren Jobs und Arbeitsbereichen zu bringen, unabhängig davon, wo diese ausgeführt werden.  Wenn Sie Domino Nexus mit NetApp koppeln, haben Sie die Flexibilität, Workloads umgebungsübergreifend zu planen, ohne sich um die Datenverfügbarkeit sorgen zu müssen.  Mit anderen Worten: Sie haben die Möglichkeit, Ihre Workloads und Daten an die entsprechende Rechenumgebung zu senden. So können Sie Ihre KI-Bereitstellungen beschleunigen und gleichzeitig die Vorschriften zum Datenschutz und zur Datensouveränität einhalten.</block>
  <block id="3eb3ace35104f92d82777b3219f769d7" category="paragraph">Diese Lösung demonstriert die Bereitstellung einer einheitlichen MLOps-Steuerungsebene, die einen lokalen Kubernetes-Cluster und einen Elastic Kubernetes Service (EKS)-Cluster umfasst, der in Amazon Web Services (AWS) ausgeführt wird.</block>
  <block id="5be0395276ff3840daa0a0cb7643b68d" category="summary">Hybrid Multicloud MLOps mit Domino Data Lab und NetApp – Ersteinrichtung</block>
  <block id="6641666d7bc2748bab0ac80cdec3a2a3" category="doc">Ersteinrichtung</block>
  <block id="ef81709626b455fffcd99d9f67085d18" category="paragraph">In diesem Abschnitt werden die anfänglichen Einrichtungsaufgaben beschrieben, die ausgeführt werden müssen, um Domino Nexus mit NetApp -Datendiensten in einer Hybridumgebung zu nutzen, die ein lokales Rechenzentrum und AWS umfasst.</block>
  <block id="87b13b0a04193ccc830f23d041d6f3ba" category="paragraph">Bevor Sie die in diesem Abschnitt beschriebenen Schritte ausführen, gehen wir davon aus, dass Sie die folgenden Aufgaben bereits ausgeführt haben:</block>
  <block id="677ae9330aedf715db07a33be39cbbeb" category="list-text">Sie haben Ihre lokale NetApp ONTAP Speicherplattform bereits bereitgestellt und konfiguriert. Weitere Informationen finden Sie im <block ref="077b296918e9131d07388450dbd7a243" category="inline-link-macro-rx"></block> .</block>
  <block id="8f117f8e1e04a7113b95048bd0077b28" category="inline-link-macro">Amazon FSx ONTAP -Produktseite</block>
  <block id="837adf3f87eb8a7f5893e4b6a6f7cee5" category="list-text">Sie haben bereits eine Amazon FSx ONTAP Instanz in AWS bereitgestellt. Weitere Informationen finden Sie im <block ref="88e07f6417e37f8ff711e34864e5d89c" category="inline-link-macro-rx"></block> .</block>
  <block id="6bd1aa1204077ccb610d72dbc07f11b1" category="inline-link-macro">Domino-Administratorhandbuch</block>
  <block id="83a12488d43dae9419d61f6f83fa014a" category="list-text">Sie haben bereits einen Kubernetes-Cluster in Ihrem lokalen Rechenzentrum bereitgestellt. Weitere Informationen finden Sie im <block ref="ae2d81862ffd2c0afcf7ba06af1fbd2e" category="inline-link-macro-rx"></block> .</block>
  <block id="6b59c41a4554c4e0f63a7da5ad17b347" category="list-text">Sie haben bereits einen Amazon EKS-Cluster in AWS bereitgestellt. Weitere Informationen finden Sie im <block ref="ae2d81862ffd2c0afcf7ba06af1fbd2e" category="inline-link-macro-rx"></block> .</block>
  <block id="be3455a34c69a26df1a5f04a6245249b" category="inline-link-macro">NetApp Trident -Dokumentation</block>
  <block id="1ac8e4f74be6c2aad80e2d33e0bdef83" category="list-text">Sie haben NetApp Trident in Ihrem lokalen Kubernetes-Cluster installiert.  Darüber hinaus haben Sie diese Trident -Instanz so konfiguriert, dass sie beim Bereitstellen und Verwalten von Speicherressourcen Ihre lokale NetApp ONTAP -Speicherplattform verwendet. Weitere Informationen finden Sie im <block ref="eaacbbbc0da023a88cdd2b5800b9ea3b" category="inline-link-macro-rx"></block> .</block>
  <block id="6c45529675023ab110b59c01a71b6038" category="list-text">Sie haben NetApp Trident in Ihrem Amazon EKS-Cluster installiert.  Darüber hinaus haben Sie diese Trident -Instanz so konfiguriert, dass sie Ihre Amazon FSx ONTAP -Instanz beim Bereitstellen und Verwalten von Speicherressourcen verwendet. Weitere Informationen finden Sie im <block ref="eaacbbbc0da023a88cdd2b5800b9ea3b" category="inline-link-macro-rx"></block> .</block>
  <block id="f8090d27d981a98d65c4401bdd84b3bf" category="inline-link-macro">Amazon Virtual Private Network (VPN)-Dokumentation</block>
  <block id="c09961db559c7c906d851ebf8ba40ac5" category="list-text">Sie müssen über eine bidirektionale Netzwerkverbindung zwischen Ihrem lokalen Rechenzentrum und Ihrer Virtual Private Cloud (VPC) in AWS verfügen.  Nähere Einzelheiten zu den verschiedenen Möglichkeiten der Umsetzung finden Sie im<block ref="f5c50c4f502917d968e827ba0a3b9d8e" category="inline-link-macro-rx"></block> .</block>
  <block id="077b7144cc60353e8c8fdc9663398f24" category="section-title">Installieren Sie die Domino Enterprise AI Platform in AWS</block>
  <block id="5e1251e5d0134550a0ea5f1f02c14c3a" category="paragraph">Um die Domino Enterprise MLOps-Plattform in AWS zu installieren, folgen Sie den Anweisungen in<block ref="7ebd1f818144f08a887fe5d8dbad016a" category="inline-link-macro-rx"></block> .  Sie müssen Domino im selben Amazon EKS-Cluster bereitstellen, den Sie zuvor bereitgestellt haben.  Darüber hinaus muss NetApp Trident bereits in diesem EKS-Cluster installiert und konfiguriert sein, und Sie müssen in Ihrer Installationskonfigurationsdatei domino.yml eine von Trident verwaltete Speicherklasse als gemeinsam genutzte Speicherklasse angeben.</block>
  <block id="feee67bbfd0f30a09eeb08ca21cdf38d" category="inline-link-macro">Referenzhandbuch zur Domino-Installationskonfiguration</block>
  <block id="8facc83d9ba07b807b37a1cf4c7f8a74" category="admonition">Weitere Informationen finden Sie im<block ref="ace9eaa491d11b57c3774d7e21b1cd72" category="inline-link-macro-rx"></block> Weitere Informationen zum Angeben einer gemeinsam genutzten Speicherklasse in Ihrer Installationskonfigurationsdatei domino.yml.</block>
  <block id="11f21d6309deb4cfcdc7f2cdb4fd0839" category="inline-link-macro">Technischer Bericht TR-4952</block>
  <block id="78dd0d0a7a9f103f53daa672d459adb9" category="admonition"><block ref="3de90155c2505cad82b61f16af3049bc" category="inline-link-macro-rx"></block>führt durch die Bereitstellung von Domino in AWS mit Amazon FSx ONTAP und kann eine nützliche Referenz für die Behebung auftretender Probleme sein.</block>
  <block id="aa2a36e425ea068322a0e37b07481ba8" category="section-title">Domino Nexus aktivieren</block>
  <block id="1a942f929d8ad029b828b8e738a86a07" category="paragraph">Als Nächstes müssen Sie Domino Nexus aktivieren. Weitere Informationen finden Sie im<block ref="31b0fd9bf4991ddcfdb80d02c1415fe4" category="inline-link-macro-rx"></block> für Details.</block>
  <block id="fa64dcf7a96dbbcd90b8729d4d59ab2f" category="section-title">Stellen Sie eine Domino-Datenebene in Ihrem lokalen Rechenzentrum bereit</block>
  <block id="4ad85753a09f6b6e21cf6089aa28f2b2" category="paragraph">Als Nächstes müssen Sie eine Domino-Datenebene in Ihrem lokalen Rechenzentrum bereitstellen.  Sie müssen diese Datenebene im lokalen Kubernetes-Cluster bereitstellen, den Sie zuvor bereitgestellt haben.  Darüber hinaus muss NetApp Trident in diesem Kubernetes-Cluster bereits installiert und konfiguriert sein. Weitere Informationen finden Sie im<block ref="d46974ff7fcd2c0e55b6b55f2aa698e1" category="inline-link-macro-rx"></block> für Details.</block>
  <block id="9fac4fc4e1be67e589c110f0c4647f2e" category="summary">Hybrid Multicloud MLOps mit Domino Data Lab und NetApp – Technologieübersicht</block>
  <block id="d8b778c81ae11eb5edbd4291a3cf8fff" category="doc">Technologieübersicht</block>
  <block id="f0bbbdb43782a17fdb1b5541f4c2d25f" category="paragraph">Dieser Abschnitt bietet einen Technologieüberblick für Hybrid Multicloud MLOps mit Domino Data Lab und NetApp.</block>
  <block id="4e00c35efcd0578992f4821557db1c9e" category="paragraph">Domino Data Lab unterstützt modellbasierte Unternehmen mit seiner führenden Enterprise-KI-Plattform, der über 20 % der Fortune 100-Unternehmen vertrauen.  Domino beschleunigt die Entwicklung und Bereitstellung von Data-Science-Arbeiten und verbessert gleichzeitig die Zusammenarbeit und Governance.  Mit Domino können Unternehmen weltweit bessere Medikamente entwickeln, ertragreichere Pflanzen anbauen, bessere Autos bauen und vieles mehr.  Domino wurde 2013 gegründet und wird von Coatue Management, Great Hill Partners, Highland Capital, Sequoia Capital und anderen führenden Investoren unterstützt.</block>
  <block id="582cc4e2654a5d265b3a9c8960a43e88" category="paragraph">Mit Domino können Unternehmen und ihre Datenwissenschaftler KI auf einer einheitlichen End-to-End-Plattform erstellen, bereitstellen und verwalten – schnell, verantwortungsvoll und kostengünstig.  Teams können in jeder Umgebung auf alle Daten, Tools, Berechnungen, Modelle und Projekte zugreifen, die sie benötigen. So können sie zusammenarbeiten, frühere Arbeiten wiederverwenden, Modelle in der Produktion verfolgen, um die Genauigkeit zu verbessern, mit Best Practices standardisieren und KI verantwortungsvoll und kontrolliert einsetzen.</block>
  <block id="79aba99e2c2c50a4d5627b787bde8eae" category="list-text">*Offen und flexibel:* Greifen Sie auf das breiteste Ökosystem aus Open Source- und kommerziellen Tools und Infrastrukturen zu, um die besten Innovationen zu nutzen und sich nicht an einen bestimmten Anbieter zu binden.</block>
  <block id="720b80ab9ad18c5e500ae8203bb712f2" category="list-text">*System of Record:* Zentraler Hub für KI-Operationen und -Wissen im gesamten Unternehmen, der Best Practices, funktionsübergreifende Zusammenarbeit, schnellere Innovation und Effizienz ermöglicht.</block>
  <block id="8d89627678490a8b88c851ea2fac357d" category="list-text">*Integriert:* Integrierte Workflows und Automatisierung – entwickelt für Unternehmensprozesse, -kontrollen und -governance – erfüllen Ihre Compliance- und Regulierungsanforderungen.</block>
  <block id="9e390a9660aa9f11963ef8d4ebe9b58a" category="list-text">*Hybrid Multicloud:* Führen Sie KI-Workloads überall in der Nähe Ihrer Daten aus – vor Ort, hybrid, in jeder Cloud oder Multi-Cloud – für geringere Kosten, optimale Leistung und Compliance.</block>
  <block id="5bfd375703bc2df982ba9c5193150b90" category="paragraph"><block ref="5bfd375703bc2df982ba9c5193150b90" category="inline-image-macro-rx" type="image"></block></block>
  <block id="80603873e677eebf28ec5645b40f7453" category="paragraph">Domino Nexus ist eine zentrale Oberfläche, mit der Sie Data-Science- und Machine-Learning-Workloads in jedem beliebigen Computercluster ausführen können – in jeder Cloud, Region oder vor Ort.  Es vereinheitlicht Data-Science-Silos im gesamten Unternehmen, sodass Sie Modelle an einem Ort erstellen, bereitstellen und überwachen können.</block>
  <block id="991a53642be15661dc9369ee1ae2085c" category="paragraph">NetApp BlueXP vereint alle Speicher- und Datendienste von NetApp in einem einzigen Tool, mit dem Sie Ihren hybriden Multicloud-Datenbestand erstellen, schützen und verwalten können.  Es bietet eine einheitliche Erfahrung für Speicher- und Datendienste in lokalen und Cloud-Umgebungen und ermöglicht durch die Leistungsfähigkeit von AIOps eine einfache Bedienung mit den flexiblen Verbrauchsparametern und dem integrierten Schutz, die für die heutige Cloud-basierte Welt erforderlich sind.</block>
  <block id="8814f8d780d4b85a940aa27445d68549" category="list-text">Cloud-Verbindung.  ONTAP ist die Speicherverwaltungssoftware mit der stärksten Cloud-Anbindung und bietet Optionen für softwaredefinierten Speicher und Cloud-native Instanzen in allen öffentlichen Clouds.</block>
  <block id="5dbf44a3195cc10e2873e76a30df05ac" category="section-title">Amazon FSx for NetApp ONTAP (FSx ONTAP)</block>
  <block id="bca10fd5d70f83556ba989ecf392df97" category="paragraph">Amazon FSx ONTAP ist ein vollständig verwalteter AWS-Service eines Erstanbieters, der äußerst zuverlässigen, skalierbaren, leistungsstarken und funktionsreichen Dateispeicher bietet, der auf dem beliebten ONTAP Dateisystem von NetApp basiert. FSx ONTAP kombiniert die vertrauten Funktionen, Leistung, Fähigkeiten und API-Operationen von NetApp Dateisystemen mit der Agilität, Skalierbarkeit und Einfachheit eines vollständig verwalteten AWS-Dienstes.</block>
  <block id="193e0bb6f3a76822b629d0fae08bdb7e" category="paragraph">Trident ermöglicht die Nutzung und Verwaltung von Speicherressourcen auf allen gängigen NetApp Speicherplattformen, in der öffentlichen Cloud oder vor Ort, einschließlich ONTAP (AFF, FAS, Select, Cloud, Amazon FSx ONTAP), Element-Software (NetApp HCI, SolidFire), Azure NetApp Files -Dienst und Google Cloud NetApp Volumes auf Google Cloud.  Trident ist ein Container Storage Interface (CSI)-kompatibler dynamischer Speicher-Orchestrator, der nativ in Kubernetes integriert ist.</block>
  <block id="978ecccb92a71c90363dfd222ebdfe77" category="paragraph">Kubernetes ist eine Open-Source-Plattform zur verteilten Container-Orchestrierung, die ursprünglich von Google entwickelt wurde und jetzt von der Cloud Native Computing Foundation (CNCF) gepflegt wird.  Kubernetes ermöglicht die Automatisierung von Bereitstellungs-, Verwaltungs- und Skalierungsfunktionen für containerisierte Anwendungen und ist die dominierende Container-Orchestrierungsplattform in Unternehmensumgebungen.</block>
  <block id="b2a7a79ed7fe83cbfb6fe2140e6fb60a" category="paragraph">Amazon Elastic Kubernetes Service (Amazon EKS) ist ein verwalteter Kubernetes-Dienst in der AWS-Cloud.  Amazon EKS verwaltet automatisch die Verfügbarkeit und Skalierbarkeit der Kubernetes-Steuerebenenknoten, die für die Planung von Containern, die Verwaltung der Anwendungsverfügbarkeit, die Speicherung von Clusterdaten und andere wichtige Aufgaben verantwortlich sind.  Mit Amazon EKS können Sie die gesamte Leistung, Skalierbarkeit, Zuverlässigkeit und Verfügbarkeit der AWS-Infrastruktur sowie die Integrationen mit AWS-Netzwerk- und Sicherheitsdiensten nutzen.</block>
  <block id="7bdb77faa0d23db500f55d38c7812837" category="summary">Hybrid Multicloud MLOps mit Domino Data Lab und NetApp – Vorhandene NetApp Volumes für Domino verfügbar machen</block>
  <block id="5f385895d8f69d19670414fea115c17e" category="doc">Vorhandene NetApp -Volumes für Domino verfügbar machen</block>
  <block id="012942ee2856a3a30e386d999ab4decd" category="paragraph">In diesem Abschnitt werden die Aufgaben beschrieben, die ausgeführt werden müssen, um vorhandene NetApp ONTAP NFS-Volumes für die Domino MLOps-Plattform verfügbar zu machen.  Dieselben Schritte gelten sowohl vor Ort als auch in AWS.</block>
  <block id="216745145dbb2663dd8ef64d1e7b70ce" category="section-title">Warum NetApp ONTAP -Volumes für Domino freigeben?</block>
  <block id="4f49bbf1791537d3f9cea32729bcf171" category="paragraph">Die Verwendung von NetApp -Volumes in Verbindung mit Domino bietet die folgenden Vorteile:</block>
  <block id="bdf339cbdff188396b615acb6642682f" category="list-text">Sie können Workloads für extrem große Datensätze ausführen, indem Sie die Scale-Out-Funktionen von NetApp ONTAP nutzen.</block>
  <block id="ad859808af9509052afa68845ee13abf" category="list-text">Sie können Workloads über mehrere Compute-Knoten hinweg ausführen, ohne Ihre Daten auf die einzelnen Knoten kopieren zu müssen.</block>
  <block id="3019efb93cfae9d2074cee3ecba248ce" category="list-text">Sie können die Vorteile der hybriden Multicloud-Datenverschiebungs- und Synchronisierungsfunktionen von NetApp nutzen, um über mehrere Rechenzentren und/oder Clouds hinweg auf Ihre Daten zuzugreifen.</block>
  <block id="72410fa7689169a336be6540fbab04cb" category="list-text">Sie möchten schnell und einfach einen Cache Ihrer Daten in einem anderen Rechenzentrum oder einer anderen Cloud erstellen können.</block>
  <block id="6d4734babb6928dd0a6f21c21a95be6a" category="section-title">Vorhandene NFS-Volumes verfügbar machen, die nicht von Trident bereitgestellt wurden</block>
  <block id="908d8e50ed4f87ffd16293ce7689ffa3" category="paragraph">Wenn Ihr vorhandenes NetApp ONTAP NFS-Volume nicht von Trident bereitgestellt wurde, befolgen Sie die in diesem Unterabschnitt beschriebenen Schritte.</block>
  <block id="b0604699a0737b4da7a79ed81a611605" category="section-title">Erstellen Sie PV und PVC in Kubernetes</block>
  <block id="0b8e803956828c77b5f9c0745c726ca8" category="admonition">Erstellen Sie für lokale Volumes das PV und PVC in Ihrem lokalen Kubernetes-Cluster.  Erstellen Sie für Amazon FSx ONTAP -Volumes PV und PVC in Amazon EKS.</block>
  <block id="7ea686752cd0065765a1f236f52b6a86" category="inline-link-macro">NFS PV/PVC-Beispiel</block>
  <block id="21daa905ac0fe45b36e98c4b7c6cbfaf" category="paragraph">Zuerst müssen Sie in Ihrem Kubernetes-Cluster ein persistentes Volume (PV) und einen persistenten Volume-Claim (PVC) erstellen.  Um PV und PVC zu erstellen, verwenden Sie die<block ref="a25b642a6322d7659714e6bd71e7cd4f" category="inline-link-macro-rx"></block> aus dem Domino-Administratorhandbuch und aktualisieren Sie die Werte, damit sie Ihrer Umgebung entsprechen.  Geben Sie unbedingt die richtigen Werte für die<block ref="89801e9e98979062e84647433a8ed3e9" prefix=" " category="inline-code"></block> ,<block ref="0a087fd97387c110f029a7a2550ff280" prefix=" " category="inline-code"></block> , Und<block ref="34ae7d3a708b57f81af8fcfcd13c7a55" prefix=" " category="inline-code"></block> Felder.  Darüber hinaus empfehlen wir, Ihrem PV und PVC eindeutige Namen zu geben, die die Art der Daten darstellen, die auf dem entsprechenden ONTAP NFS-Volume gespeichert sind.  Wenn der Band beispielsweise Bilder von Herstellungsfehlern enthält, können Sie den PV benennen,<block ref="7146834334002e1c2c8bbb00348a951c" prefix=" " category="inline-code"></block> , und das PVC,<block ref="2d04ce24c553ffe8e7f9b69269696618" prefix=" " category="inline-code"></block> .</block>
  <block id="3a0e23ff2bfd7dc5b55c1aeb14b0ce33" category="section-title">Externes Datenvolumen in Domino registrieren</block>
  <block id="cbde2df6a7c89370edc449dc5705d30c" category="inline-link-macro">Anweisungen</block>
  <block id="6d38ad9604bf23123ad6f1505f8f64ce" category="paragraph">Als nächstes müssen Sie ein externes Datenvolumen in Domino registrieren.  Informationen zur Registrierung eines externen Datenvolumens finden Sie im<block ref="1b56e73c8083d7259fd3343f2f8d6ce6" category="inline-link-macro-rx"></block> im Domino-Administratorhandbuch.  Achten Sie beim Registrieren des Volumes darauf, „NFS“ aus dem Dropdown-Menü „Volume-Typ“ auszuwählen.  Nachdem Sie „NFS“ ausgewählt haben, sollte Ihr PVC in der Liste „Verfügbare Volumes“ angezeigt werden.</block>
  <block id="f759d0a96176c0ce67a4269c5b45bc42" category="paragraph"><block ref="f759d0a96176c0ce67a4269c5b45bc42" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f91c183558f2466e2e75a92424f7a3bf" category="section-title">Vorhandene Volumes verfügbar machen, die von Trident bereitgestellt wurden</block>
  <block id="733e83e8c2052942f7f0e96fcd19e8a4" category="paragraph">Wenn Ihr vorhandenes Volume von Trident bereitgestellt wurde, befolgen Sie die in diesem Unterabschnitt beschriebenen Schritte.</block>
  <block id="57a045b809f3298056d203360becbd66" category="section-title">Vorhandenes PVC bearbeiten</block>
  <block id="aaf6f0a313e2fa37d3584aa97603489a" category="paragraph">Wenn Ihr Volume von Trident bereitgestellt wurde, verfügen Sie bereits über einen Persistent Volume Claim (PVC), der Ihrem Volume entspricht.  Um dieses Volume für Domino verfügbar zu machen, müssen Sie den PVC bearbeiten und der Liste der Labels im<block ref="9cc59534218c9b00f7eb481861d14401" prefix=" " category="inline-code"></block> Feld:</block>
  <block id="d2790ed8ab25c08ee1efd69f0773cade" category="paragraph">Als nächstes müssen Sie ein externes Datenvolumen in Domino registrieren.  Informationen zur Registrierung eines externen Datenvolumens finden Sie im<block ref="1b56e73c8083d7259fd3343f2f8d6ce6" category="inline-link-macro-rx"></block> im Domino-Administratorhandbuch.  Achten Sie beim Registrieren des Volumes darauf, im Dropdown-Menü „Volume-Typ“ die Option „Allgemein“ auszuwählen.  Nachdem Sie „Generic“ ausgewählt haben, sollte Ihr PVC in der Liste „Verfügbare Volumes“ angezeigt werden.</block>
  <block id="922b9696b39b06f6a4d313569231a446" category="summary">NVIDIA AI Enterprise mit NetApp und VMware – Wo Sie weitere Informationen finden</block>
  <block id="913e298a14c5b49185ced898ccea22bd" category="list-text">NVIDIA AI Enterprise mit VMware</block>
  <block id="c85cb3eda6d429393778efbed7420a50" category="list-text">Bobby Oommen, Senior Manager, NetApp</block>
  <block id="c4321e9f60724f09a097b4d8b79c6e7b" category="list-text">Ramesh Isaac, Systemadministrator, NetApp</block>
  <block id="cf4995eac87d7ce5351e1043fe85683c" category="list-text">Roney Daniel, Technischer Marketingingenieur, NetApp</block>
  <block id="d8299632c247aca8f771d7368ee36f9d" category="summary">NVIDIA AI Enterprise mit NetApp und VMware – Architektur</block>
  <block id="37810ec69b6e321b4b377d835e7d84ac" category="paragraph">Diese Lösung baut auf einer bewährten und vertrauten Architektur mit zertifizierten Systemen von NetApp, VMware und NVIDIA auf.  Einzelheiten finden Sie in der folgenden Tabelle.</block>
  <block id="95a502ec0ddaf3352c2540e3e9f65a1b" category="cell">KI- und Datenanalysesoftware</block>
  <block id="61da586210da33a8abab150a7d7d0972" category="inline-link-macro">NVIDIA AI Enterprise für VMware</block>
  <block id="7865e440c1b499e7942ca9b659d737d6" category="cell"><block ref="7865e440c1b499e7942ca9b659d737d6" category="inline-link-macro-rx"></block></block>
  <block id="102995a1cdd2c719d7d0aa4d888fa019" category="cell">Virtualisierungsplattform</block>
  <block id="8887a9a417a1629326acdb917d224337" category="inline-link-macro">VMware vSphere</block>
  <block id="4ce5f3794d6e351daaaaa4f211e419ee" category="cell"><block ref="4ce5f3794d6e351daaaaa4f211e419ee" category="inline-link-macro-rx"></block></block>
  <block id="8cf5fbd26a1d5d924600d38015860908" category="cell">Rechenplattform</block>
  <block id="aee87e9fe5cc4cf9193cd27c74a0a6e7" category="inline-link-macro">NVIDIA-zertifizierte Systeme</block>
  <block id="b3cdb2e0e953c1639ad63fe06b8c7a37" category="cell"><block ref="b3cdb2e0e953c1639ad63fe06b8c7a37" category="inline-link-macro-rx"></block></block>
  <block id="ddca712fc3b0dad3d85e423eb97d58ea" category="cell">Datenmanagement-Plattform</block>
  <block id="1c317db419d669c4b6473c6d462e881e" category="cell"><block ref="1c317db419d669c4b6473c6d462e881e" category="inline-link-macro-rx"></block></block>
  <block id="3e549e3b22de98c96646fb0586a93db3" category="paragraph"><block ref="3e549e3b22de98c96646fb0586a93db3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69e8c6aef5e50150d499e7fa39f846ed" category="summary">NVIDIA AI Enterprise ist eine durchgängige, Cloud-native Suite von KI- und Datenanalysesoftware, die optimiert ist, damit jedes Unternehmen mit KI erfolgreich sein kann.</block>
  <block id="68cdb7bf3dabd26e338e1ba72b549c69" category="doc">NVIDIA AI Enterprise mit NetApp und VMware</block>
  <block id="61cb0c1b4a32d4815eb2a785c0c84cb8" category="paragraph">Für IT-Architekten und -Administratoren können KI-Tools kompliziert und ungewohnt sein.  Darüber hinaus sind viele KI-Plattformen nicht unternehmensbereit.  NVIDIA AI Enterprise, unterstützt von NetApp und VMware, wurde entwickelt, um eine optimierte KI-Architektur der Enterprise-Klasse bereitzustellen.</block>
  <block id="eb7e5009de0ce355dc9131d958a1541e" category="paragraph"><block ref="eb7e5009de0ce355dc9131d958a1541e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d6b1f830356956d1f4b73438f8604232" category="summary">NVIDIA AI Enterprise mit NetApp und VMware – NVIDIA NGC-Software nutzen – Setup</block>
  <block id="ad2376beebecdcf7846ba973fa1a005b" category="doc">Aufstellen</block>
  <block id="7bb37c1d3fb64e908e6704f53b5fe4a8" category="paragraph">In diesem Abschnitt werden die anfänglichen Einrichtungsaufgaben beschrieben, die durchgeführt werden müssen, um die NVIDIA NGC-Unternehmenssoftware in einer NVIDIA AI Enterprise-Umgebung zu nutzen.</block>
  <block id="1eb5d19d2c5071a5a7a569f58f2c9613" category="paragraph">Bevor Sie die in diesem Abschnitt beschriebenen Schritte ausführen, gehen wir davon aus, dass Sie die NVIDIA AI Enterprise-Hostsoftware bereits bereitgestellt haben, indem Sie die Anweisungen auf der<block ref="b97b75086b5941ac63fab1eee89b4777" category="inline-link-macro-rx"></block> Seite.</block>
  <block id="c23799b3650257af14b8af5acb107354" category="section-title">Erstellen Sie eine Ubuntu-Gast-VM mit vGPU</block>
  <block id="0271f6ade1f60c92c6548f0e5c440e4e" category="inline-link-macro">NVIDIA AI Enterprise-Bereitstellungshandbuch</block>
  <block id="4be8ecb3320915437222a84e9761bcec" category="paragraph">Zuerst müssen Sie eine Ubuntu 20.04-Gast-VM mit vGPU erstellen.  Um eine Ubuntu 20.04-Gast-VM mit vGPU zu erstellen, folgen Sie den Anweisungen im<block ref="2009ba36309e23fc0bb68cec4d4a3e0d" category="inline-link-macro-rx"></block> .</block>
  <block id="70c95294a49e1475adbde86d8eae754e" category="section-title">Laden Sie die NVIDIA Gastsoftware herunter und installieren Sie sie</block>
  <block id="6148d2809a69d7225df7c6dcc1b5f94f" category="inline-link-macro">NVIDIA AI Enterprise-Kurzanleitung</block>
  <block id="8f3d19df984dedd40b9998136343e036" category="paragraph">Als Nächstes müssen Sie die erforderliche NVIDIA Gastsoftware in der Gast-VM installieren, die Sie im vorherigen Schritt erstellt haben.  Um die erforderliche NVIDIA Gastsoftware herunterzuladen und in der Gast-VM zu installieren, folgen Sie den Anweisungen in den Abschnitten 5.1-5.4 im<block ref="d00914f6db2027b3a594dc7a64e68b3c" category="inline-link-macro-rx"></block> .</block>
  <block id="15186686bd7e9c36683658388b6865b0" category="admonition">Beim Ausführen der in Abschnitt 5.4 beschriebenen Überprüfungsaufgaben müssen Sie möglicherweise ein anderes Versionstag für das CUDA-Container-Image verwenden, da das CUDA-Container-Image seit dem Verfassen dieses Handbuchs aktualisiert wurde.  Bei unserer Validierung haben wir „nvidia/cuda:11.0.3-base-ubuntu20.04“ verwendet.</block>
  <block id="f43e7f8a79b8984748fff81eeb0f8c5f" category="section-title">AI/Analytics Framework-Container herunterladen</block>
  <block id="939ac3b79a18fc027a13bea0aeebcd3c" category="paragraph">Als Nächstes müssen Sie die benötigten Container-Images für KI- oder Analyse-Frameworks von NVIDIA NGC herunterladen, damit sie in Ihrer Gast-VM verfügbar sind.  Um Framework-Container innerhalb der Gast-VM herunterzuladen, folgen Sie den Anweisungen im<block ref="7ea494a5b1819fa63a0ad0f42cf94b43" category="inline-link-macro-rx"></block> .</block>
  <block id="5a8b2b886d790892b5beca474e789276" category="section-title">Installieren und Konfigurieren des NetApp DataOps Toolkit</block>
  <block id="a225239f36328db667324928281cd834" category="paragraph">Als Nächstes müssen Sie das NetApp DataOps Toolkit für traditionelle Umgebungen innerhalb der Gast-VM installieren.  Mit dem NetApp DataOps Toolkit können Sie Scale-Out-Datenvolumes auf Ihrem ONTAP -System direkt vom Terminal innerhalb der Gast-VM aus verwalten.  Um das NetApp DataOps Toolkit innerhalb der Gast-VM zu installieren, führen Sie die folgenden Aufgaben aus.</block>
  <block id="e0288a23fbe1bfdb5f5b06d39e315992" category="list-text">Installieren Sie pip.</block>
  <block id="bb5f723fd408b79a93de1e726de66dd1" category="list-text">Melden Sie sich vom Gast-VM-Terminal ab und dann wieder an.</block>
  <block id="c456f18c285a54b87c3bc96f0ee32ebb" category="list-text">Konfigurieren Sie das NetApp DataOps Toolkit.  Um diesen Schritt abzuschließen, benötigen Sie API-Zugriffsdaten für Ihr ONTAP -System.  Möglicherweise müssen Sie diese von Ihrem Speicheradministrator erhalten.</block>
  <block id="defe5f6be79f86b85d956d3e53c7ac4d" category="section-title">Erstellen einer Gast-VM-Vorlage</block>
  <block id="d5d979be97f5a76cf2676ef5a9c7f071" category="paragraph">Zuletzt müssen Sie eine VM-Vorlage basierend auf Ihrer Gast-VM erstellen.  Mit dieser Vorlage können Sie schnell Gast-VMs zur Nutzung der NVIDIA NGC-Software erstellen.</block>
  <block id="fec1fe0b41ba3927cfb9ac7c0507a1f5" category="paragraph">Um eine VM-Vorlage basierend auf Ihrer Gast-VM zu erstellen, melden Sie sich bei VMware vSphere an, klicken Sie mit der rechten Maustaste auf den Namen der Gast-VM, wählen Sie „Klonen“, wählen Sie „In Vorlage klonen …“ und folgen Sie dann dem Assistenten.</block>
  <block id="ae46b5fec5e9fa6540317c6aff2886d0" category="paragraph"><block ref="ae46b5fec5e9fa6540317c6aff2886d0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54d7050762b4d8c4af04f27ce33f1f9b" category="summary">NVIDIA AI Enterprise mit NetApp und VMware – Ersteinrichtung</block>
  <block id="cb8b0bf52601ee3b7c48b31850f1a45a" category="paragraph">In diesem Abschnitt werden die anfänglichen Einrichtungsaufgaben beschrieben, die durchgeführt werden müssen, um NVIDIA AI Enterprise mit NetApp und VMware zu nutzen.</block>
  <block id="5600e01753ba1c962c6d52ee6f0bdc72" category="inline-link-macro">NVIDIA AI Enterprise-Produktsupportmatrix</block>
  <block id="b46df8af05863c37f3cd1fd611e5d2d9" category="inline-link-macro">Dokumentation zu NetApp und VMware-Lösungen</block>
  <block id="06a8848af5cbb48d04a6b9d27ea22cae" category="paragraph">Bevor Sie die in diesem Abschnitt beschriebenen Schritte ausführen, gehen wir davon aus, dass Sie VMware vSphere und NetApp ONTAP bereits bereitgestellt haben.  Weitere Informationen finden Sie im<block ref="fca8480728eb091fdea60a7b3cdc16f7" category="inline-link-macro-rx"></block> für Details zu unterstützten vSphere-Versionen.  Weitere Informationen finden Sie im<block ref="dde322875ea0d7cfe426ecec0c0dad4c" category="inline-link-macro-rx"></block> Weitere Informationen zur Bereitstellung von VMware vSphere mit NetApp ONTAP.</block>
  <block id="a067b320746c7952a2b152f5a3af42b4" category="section-title">Installieren Sie die NVIDIA AI Enterprise Host-Software</block>
  <block id="ee9d732a57ce821e52e753e2b4bd4a84" category="paragraph">Um die NVIDIA AI Enterprise Host-Software zu installieren, folgen Sie den Anweisungen in den Abschnitten 1-4 im<block ref="d00914f6db2027b3a594dc7a64e68b3c" category="inline-link-macro-rx"></block> .</block>
  <block id="f0de4adaf6568678921cef0d0e69b81f" category="summary">NVIDIA AI Enterprise mit NetApp und VMware – Technologieübersicht</block>
  <block id="d54433e43cda21e1ff5ab715c73883de" category="paragraph">Dieser Abschnitt bietet einen Technologieüberblick für NVIDIA AI Enterprise mit NetApp und VMware.</block>
  <block id="0719941ec04c59670033b3b1f0e3c239" category="paragraph">NVIDIA AI Enterprise ist eine durchgängige, Cloud-native Suite von KI- und Datenanalysesoftware, die von NVIDIA für die Ausführung auf VMware vSphere mit NVIDIA-zertifizierten Systemen optimiert, zertifiziert und unterstützt wird.  Diese Software ermöglicht die einfache und schnelle Bereitstellung, Verwaltung und Skalierung von KI-Workloads in der modernen Hybrid-Cloud-Umgebung.</block>
  <block id="cbd4c44d2b7fc45943b834d2a03f2a63" category="paragraph">NVIDIA NGC hostet einen Katalog mit GPU-optimierter Software für KI-Praktiker zur Entwicklung ihrer KI-Lösungen.  Es bietet außerdem Zugriff auf verschiedene KI-Dienste, darunter NVIDIA Base Command für das Modelltraining, NVIDIA Fleet Command zum Bereitstellen und Überwachen von Modellen und das NGC Private Registry für den sicheren Zugriff auf und die Verwaltung proprietärer KI-Software.  Darüber hinaus können NVIDIA AI Enterprise-Kunden über das NGC-Portal Support anfordern.</block>
  <block id="7ee50a783ac86f99c7b7db29b77e7a2a" category="paragraph">VMware vSphere ist die Virtualisierungsplattform von VMware, die Rechenzentren in aggregierte Computing-Infrastrukturen mit CPU-, Speicher- und Netzwerkressourcen verwandelt. vSphere verwaltet diese Infrastrukturen als einheitliche Betriebsumgebung und bietet Administratoren die Tools zur Verwaltung der an dieser Umgebung beteiligten Rechenzentren.</block>
  <block id="a8b821c11b6c83cd7165137d4f68a45b" category="paragraph">Die beiden Kernkomponenten von vSphere sind ESXi und vCenter Server.  ESXi ist die Virtualisierungsplattform, auf der Administratoren virtuelle Maschinen und virtuelle Appliances erstellen und ausführen. vCenter Server ist der Dienst, über den Administratoren mehrere in einem Netzwerk verbundene Hosts verwalten und Hostressourcen bündeln.</block>
  <block id="7cc4f632835e2377fd90f38601a3e0eb" category="paragraph">Das NetApp DataOps Toolkit ist ein Python-basiertes Tool, das die Verwaltung von Entwicklungs-/Schulungsarbeitsbereichen und Inferenzservern vereinfacht, die durch leistungsstarken, skalierbaren NetApp -Speicher unterstützt werden.  Zu den wichtigsten Funktionen gehören:</block>
  <block id="23b97f551923a166ae2d3223b0ed84cc" category="list-text">Klonen Sie JupyterLab-Arbeitsbereiche mit hoher Kapazität nahezu sofort, um Experimente oder schnelle Iterationen zu ermöglichen.</block>
  <block id="27c7d5bdafd6a9d64ad337b08e104c87" category="list-text">Speichern Sie nahezu sofort Snapshots von JupyterLab-Arbeitsbereichen mit hoher Kapazität für Backups und/oder Rückverfolgbarkeit/Baselining.</block>
  <block id="86f28dd8fdffc90314bf94c94e1b3c1c" category="list-text">Stellen Sie Datenvolumes mit hoher Kapazität und hoher Leistung nahezu sofort bereit, klonen Sie sie und erstellen Sie Snapshots davon.</block>
  <block id="e4f8ad54c095217d5da72f9ba2ad87d4" category="summary">NVIDIA AI Enterprise mit NetApp und VMware – NVIDIA NGC-Software nutzen – Beispiel-Anwendungsfall – TensorFlow-Schulungsjob</block>
  <block id="b26247c1865d93ea590ef10d1150c2ae" category="doc">Beispiel-Anwendungsfall – TensorFlow-Trainingsjob</block>
  <block id="ff35b7c65e31b6103dee61bd8d89ee4f" category="paragraph">In diesem Abschnitt werden die Aufgaben beschrieben, die ausgeführt werden müssen, um einen TensorFlow-Trainingsjob in einer NVIDIA AI Enterprise-Umgebung auszuführen.</block>
  <block id="0733928d94b0eba77ac6cf7f3c950257" category="paragraph">Bevor Sie die in diesem Abschnitt beschriebenen Schritte ausführen, gehen wir davon aus, dass Sie bereits eine Gast-VM-Vorlage erstellt haben, indem Sie die Anweisungen auf der<block ref="ad0d852572366b07cdb7f9f854b3aedf" category="inline-link-macro-rx"></block> Seite.</block>
  <block id="c8281ef65e7f967dfd74821eada0aed1" category="section-title">Gast-VM aus Vorlage erstellen</block>
  <block id="8f195db6a3d092a2d990de535475fb82" category="paragraph">Zuerst müssen Sie eine neue Gast-VM aus der Vorlage erstellen, die Sie im vorherigen Abschnitt erstellt haben.  Um eine neue Gast-VM aus Ihrer Vorlage zu erstellen, melden Sie sich bei VMware vSphere an, klicken Sie mit der rechten Maustaste auf den Vorlagennamen, wählen Sie „Neue VM aus dieser Vorlage …“ und folgen Sie dann dem Assistenten.</block>
  <block id="d31d5f91fee0f03911daa3d20a90e607" category="paragraph"><block ref="d31d5f91fee0f03911daa3d20a90e607" category="inline-image-macro-rx" type="image"></block></block>
  <block id="229fea3a8aa56b262dc3dbb996d81052" category="section-title">Datenvolume erstellen und bereitstellen</block>
  <block id="bbdc3bf8e16f6c828df2941c605e4ef3" category="paragraph">Als Nächstes müssen Sie ein neues Datenvolumen erstellen, auf dem Sie Ihren Trainingsdatensatz speichern.  Mit dem NetApp DataOps Toolkit können Sie schnell ein neues Datenvolumen erstellen.  Der folgende Beispielbefehl zeigt die Erstellung eines Volumes namens „imagenet“ mit einer Kapazität von 2 TB.</block>
  <block id="bed0c39c2a853526e026bbd1d13b0a29" category="paragraph">Bevor Sie Ihr Datenvolumen mit Daten füllen können, müssen Sie es in der Gast-VM mounten.  Mit dem NetApp DataOps Toolkit können Sie schnell ein Datenvolumen bereitstellen.  Der folgende Beispielbefehl zeigt das Mounten des im vorherigen Schritt erstellten Volumes.</block>
  <block id="3418ebfa9c3ff38c1bfcd27521d4e641" category="section-title">Datenvolumen auffüllen</block>
  <block id="ec123d1ef57b0ab158b8c891c6b936da" category="paragraph">Nachdem das neue Volume bereitgestellt und gemountet wurde, kann der Trainingsdatensatz vom Quellspeicherort abgerufen und auf dem neuen Volume platziert werden.  Dies beinhaltet normalerweise das Abrufen der Daten aus einem S3- oder Hadoop-Datensee und manchmal die Unterstützung eines Dateningenieurs.</block>
  <block id="d3e84e47f561be23742b30b8c3dd7d10" category="section-title">TensorFlow-Trainingsjob ausführen</block>
  <block id="f6a0596efc5c96edbcbffd2d19e48f41" category="paragraph">Jetzt können Sie Ihren TensorFlow-Trainingsjob ausführen.  Führen Sie die folgenden Aufgaben aus, um Ihren TensorFlow-Trainingsjob auszuführen.</block>
  <block id="83c4072e784e0048974a7fbaef9e7567" category="list-text">Rufen Sie das NVIDIA NGC Enterprise TensorFlow-Containerimage ab.</block>
  <block id="26857c717c90aa9ca7c999304a47e6ad" category="list-text">Starten Sie eine Instanz des NVIDIA NGC Enterprise TensorFlow-Containers.  Verwenden Sie die Option „-v“, um Ihr Datenvolumen an den Container anzuhängen.</block>
  <block id="c8dc137f2972d72ed031b7e9000c2b58" category="list-text">Führen Sie Ihr TensorFlow-Trainingsprogramm innerhalb des Containers aus.  Der folgende Beispielbefehl zeigt die Ausführung eines beispielhaften ResNet-50-Trainingsprogramms, das im Container-Image enthalten ist.</block>
  <block id="9dd88053035e8518106da3a40ce3aa3b" category="summary">Open Source MLOps mit NetApp – Apache Airflow-Bereitstellung</block>
  <block id="7d2a9e50f39ee00c2b180900e7bacc92" category="doc">Apache Airflow-Bereitstellung</block>
  <block id="c2ae2e58baf01933984b63bbfd58c6c2" category="paragraph">In diesem Abschnitt werden die Aufgaben beschrieben, die Sie ausführen müssen, um Airflow in Ihrem Kubernetes-Cluster bereitzustellen.</block>
  <block id="1874d60ac69d2a867825b1b7ab0f9297" category="admonition">Es ist möglich, Airflow auf anderen Plattformen als Kubernetes bereitzustellen.  Die Bereitstellung von Airflow auf anderen Plattformen als Kubernetes liegt außerhalb des Umfangs dieser Lösung.</block>
  <block id="e5595c75c723712666f834213ee6568f" category="paragraph">Bevor Sie die in diesem Abschnitt beschriebene Bereitstellungsübung durchführen, gehen wir davon aus, dass Sie die folgenden Aufgaben bereits ausgeführt haben:</block>
  <block id="c7a7dda60a4edd19d3b5bad13d43d605" category="list-text">Sie verfügen bereits über einen funktionierenden Kubernetes-Cluster.</block>
  <block id="40ef3fb23e015d9b4b46a16fa50f10d3" category="inline-link-macro">Trident -Dokumentation</block>
  <block id="85dd9fb465515fcb64ad8d6b67591898" category="list-text">Sie haben NetApp Trident bereits in Ihrem Kubernetes-Cluster installiert und konfiguriert.  Weitere Einzelheiten zu Trident finden Sie im<block ref="6bc4e9e49caf522f01de7c1314cd2006" category="inline-link-macro-rx"></block> .</block>
  <block id="ead9806c164633fcb334dc844a3d588f" category="section-title">Helm installieren</block>
  <block id="7586dbf5f3ac1a66383f6c201a17a341" category="inline-link">Installationsanweisungen</block>
  <block id="f9093f3279eca680041e957a2a0505dd" category="paragraph">Airflow wird mit Helm bereitgestellt, einem beliebten Paketmanager für Kubernetes.  Bevor Sie Airflow bereitstellen, müssen Sie Helm auf dem Bereitstellungs-Jump-Host installieren.  Um Helm auf dem Bereitstellungs-Jump-Host zu installieren, folgen Sie den<block ref="cf3f65305f288242c9d49061d26ec8ec" category="inline-link-rx"></block> in der offiziellen Helm-Dokumentation.</block>
  <block id="72727333279dd1f9e8b63f969075bca8" category="section-title">Standardmäßige Kubernetes-Speicherklasse festlegen</block>
  <block id="124793fd2a85b1699a94b12bf4661758" category="inline-link-macro">Kubeflow-Bereitstellung</block>
  <block id="53b8c224038ee8370989019811dd9379" category="paragraph">Bevor Sie Airflow bereitstellen, müssen Sie eine Standard-StorageClass in Ihrem Kubernetes-Cluster festlegen.  Der Airflow-Bereitstellungsprozess versucht, neue persistente Volumes mithilfe der Standard-StorageClass bereitzustellen.  Wenn keine StorageClass als Standard-StorageClass festgelegt ist, schlägt die Bereitstellung fehl.  Um eine Standard-StorageClass innerhalb Ihres Clusters festzulegen, folgen Sie den Anweisungen im<block ref="a8e87de8c7ac570587ad7744774f8330" category="inline-link-macro-rx"></block> Abschnitt.  Wenn Sie in Ihrem Cluster bereits eine Standard-StorageClass festgelegt haben, können Sie diesen Schritt überspringen.</block>
  <block id="c7feb8d7350bb5372c4dd0dfc1383865" category="section-title">Verwenden Sie Helm, um Airflow bereitzustellen</block>
  <block id="a781e1f3dbd7b5f15c3257febe820528" category="paragraph">Um Airflow mithilfe von Helm in Ihrem Kubernetes-Cluster bereitzustellen, führen Sie die folgenden Aufgaben vom Bereitstellungs-Jump-Host aus:</block>
  <block id="014e85e7f3bbdad1ad6f193e82d21755" category="inline-link">Bereitstellungsanweisungen</block>
  <block id="fe1b26293aba127732d69bdc90866794" category="list-text">Stellen Sie Airflow mit Helm bereit, indem Sie den Anweisungen folgen<block ref="e4140084ec840191180d755827375d89" category="inline-link-rx"></block> für das offizielle Airflow-Diagramm im Artifact Hub.  Die folgenden Beispielbefehle zeigen die Bereitstellung von Airflow mit Helm.  Ändern, Hinzufügen und/oder Entfernen von Werten in der<block ref="b03054dec41b4d504351d411d8221d7f" prefix=" " category="inline-code"></block> Datei nach Bedarf, abhängig von Ihrer Umgebung und der gewünschten Konfiguration.</block>
  <block id="fa7edbfc4d9facbb8db918116ff0ae46" category="list-text">Bestätigen Sie, dass alle Airflow-Pods betriebsbereit sind.  Es kann einige Minuten dauern, bis alle Pods gestartet sind.</block>
  <block id="9bb040ffef8c89d0861be81732ca17de" category="list-text">Rufen Sie die URL des Airflow-Webdienstes ab, indem Sie den Anweisungen folgen, die auf der Konsole angezeigt wurden, als Sie Airflow in Schritt 1 mit Helm bereitgestellt haben.</block>
  <block id="0db6a8f601b49c6c3780b668eac398a8" category="list-text">Bestätigen Sie, dass Sie auf den Airflow-Webdienst zugreifen können.</block>
  <block id="ae954beef496ebe087806e1ce5f985b1" category="paragraph"><block ref="ae954beef496ebe087806e1ce5f985b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1358ee6f6793d8ad5c774e77af0ef2f8" category="summary">Open Source MLOps mit NetApp – Verwenden Sie das NetApp DataOps Toolkit mit Airflow</block>
  <block id="a6341ca5ab25e7d3076dec050c9e5a97" category="doc">Verwenden Sie das NetApp DataOps Toolkit mit Airflow</block>
  <block id="a408a973f45f990bcd545653e35109ff" category="paragraph">Der<block ref="d2f8e20a78f43c00804244e7ccbfa516" category="inline-link-rx"></block> kann in Verbindung mit Airflow verwendet werden.  Durch die Verwendung des NetApp DataOps Toolkit mit Airflow können Sie NetApp Datenverwaltungsvorgänge, wie das Erstellen von Snapshots und Klonen, in automatisierte Workflows integrieren, die von Airflow orchestriert werden.</block>
  <block id="dee957e8ec77b256b931e812220f0553" category="inline-link">Beispiele für Luftströme</block>
  <block id="b6cc356bf5062501529145b3a4643413" category="paragraph">Weitere Informationen finden Sie im<block ref="7c367129528d87aa1adf73a57a51aa4d" category="inline-link-rx"></block> Weitere Informationen zur Verwendung des Toolkits mit Airflow finden Sie im Abschnitt „NetApp DataOps Toolkit GitHub-Repository“.</block>
  <block id="95cd1b9d487589b619592ac7a94f1001" category="summary">Open Source MLOps mit NetApp – Architektur</block>
  <block id="21d5dd37b5f077a36d22ba32af4054e6" category="paragraph">Diese Lösung ist nicht von bestimmter Hardware abhängig.  Die Lösung ist mit allen physischen Speichergeräten, softwaredefinierten Instanzen und Cloud-Diensten von NetApp kompatibel, die von NetApp Trident unterstützt werden.  Beispiele hierfür sind ein NetApp AFF Speichersystem, Amazon FSx ONTAP, Azure NetApp Files, Google Cloud NetApp Volumes oder eine NetApp Cloud Volumes ONTAP -Instanz.  Darüber hinaus kann die Lösung auf jedem Kubernetes-Cluster implementiert werden, solange die verwendete Kubernetes-Version von NetApp Trident und den anderen implementierten Lösungskomponenten unterstützt wird.  Eine Liste der von Trident unterstützten Kubernetes-Versionen finden Sie im<block ref="7e5b92b70f9fb8a6ea9680492953995f" category="inline-link-rx"></block> .  In den folgenden Tabellen finden Sie Einzelheiten zu den Umgebungen, die zur Validierung der verschiedenen Komponenten dieser Lösung verwendet wurden.</block>
  <block id="f9004e284a207cf92c8642965dc258f6" category="section-title">Apache Airflow-Validierungsumgebung</block>
  <block id="68782f72ebeb2cac06f03226a6e941bb" category="cell">Softwarekomponente</block>
  <block id="385904ba8ac27bcacafadf2113386df4" category="cell">Apache Airflow</block>
  <block id="78fd3ce4c7835c8336b8c4f52bbd8570" category="inline-link-macro">Apache Airflow Helm-Diagramm</block>
  <block id="923fc06abfe0b856f72313cb88706558" category="cell">2.0.1, bereitgestellt über<block ref="d1ea82e80be31e00d2b939c38f87e0a0" category="inline-link-macro-rx"></block> 8.0.8</block>
  <block id="836eb480bf66641d4fb44675e000d22b" category="cell">1,18</block>
  <block id="d029b605d0129cdb050642645b32b1db" category="cell">21,01</block>
  <block id="44ce1bc6a7380dccbb311f0fa6cd1972" category="section-title">JupyterHub-Validierungsumgebung</block>
  <block id="6a1bd94b05289cc97fd96ec055920439" category="cell">JupyterHub</block>
  <block id="263ec1d326c1f5a1bfd24b88cb972a38" category="inline-link-macro">JupyterHub Helm-Diagramm</block>
  <block id="6af30397902bd26914df2ae5955c4be8" category="cell">4.1.5, bereitgestellt über<block ref="26830a1e301761faef592d8e74481ce6" category="inline-link-macro-rx"></block> 3.3.7</block>
  <block id="c272116b61605b9462784a01f5899785" category="cell">1,29</block>
  <block id="4e9b156e7e2788c8cd4b0877fd922657" category="cell">24,02</block>
  <block id="aa3652d1dedca9375b76c8e59797d756" category="section-title">MLflow-Validierungsumgebung</block>
  <block id="c8d3451e7307fb1b46769ec23ea7906a" category="cell">MLflow</block>
  <block id="04d257103d25b778df7089d6dbb0cb44" category="inline-link-macro">MLflow Helm-Diagramm</block>
  <block id="4814bad32946214124af37f70a7bee91" category="cell">2.14.1, bereitgestellt über<block ref="4baf34adb826df0481d498e42290114c" category="inline-link-macro-rx"></block> 1.4.12</block>
  <block id="6eeb675638e9c361028379b88415e2de" category="section-title">Kubeflow-Validierungsumgebung</block>
  <block id="bb643a3a76aab569f9245a19f77d4b65" category="cell">Kubeflow</block>
  <block id="e0d8584ae6ed8fd534954ae8ed8755a3" category="inline-link-macro">deployKF</block>
  <block id="bb675cbb86ae4db4a1f3da16e57113cd" category="cell">1.7, bereitgestellt über<block ref="f0761e2008489c964db22d8d03da0a67" category="inline-link-macro-rx"></block> 0.1.1</block>
  <block id="32b2e96c4f6d14da1df5b25db372de8f" category="cell">1,26</block>
  <block id="217af7d1776d22530d98be04d104fd49" category="cell">23,07</block>
  <block id="db5eb84117d06047c97c9a0191b5fffe" category="section-title">Support</block>
  <block id="b2e75bbfb9933bc21b7f875e8676641d" category="inline-link-macro">NetApp kontaktieren</block>
  <block id="952c6ea6549ebf347f6aae3d6b029756" category="paragraph">NetApp bietet keinen Enterprise-Support für Apache Airflow, JupyterHub, MLflow, Kubeflow oder Kubernetes.  Wenn Sie an einer vollständig unterstützten MLOps-Plattform interessiert sind,<block ref="15a32e54137b30751a17b6bf2b412f99" category="inline-link-macro-rx"></block> über vollständig unterstützte MLOps-Lösungen, die NetApp gemeinsam mit Partnern anbietet.</block>
  <block id="6999319a5a39a9ca41436977f2cb8b8d" category="summary">Open Source MLOps mit NetApp – Technologieübersicht</block>
  <block id="4c9ffff73cd2c66ec9f6be3cb2b21333" category="paragraph">Dieser Abschnitt konzentriert sich auf den Technologieüberblick für OpenSource MLOps mit NetApp.</block>
  <block id="5cd2adc9e2a5254e4c1da803519f298b" category="section-title">Künstliche Intelligenz</block>
  <block id="c2fabc0982aa161064ff2b73f50800d5" category="paragraph">KI ist eine Disziplin der Informatik, in der Computer darauf trainiert werden, die kognitiven Funktionen des menschlichen Geistes nachzuahmen.  KI-Entwickler trainieren Computer, auf eine Weise zu lernen und Probleme zu lösen, die der des Menschen ähnelt oder dieser sogar überlegen ist.  Deep Learning und maschinelles Lernen sind Teilgebiete der KI.  Organisationen setzen zunehmend KI, ML und DL ein, um ihre kritischen Geschäftsanforderungen zu unterstützen.  Einige Beispiele sind wie folgt:</block>
  <block id="b3e764d3292b880c63140b20b9a90e6c" category="list-text">Analyse großer Datenmengen, um bisher unbekannte Geschäftserkenntnisse zu gewinnen</block>
  <block id="30512c04b26c269ec31ecd09f1f3a208" category="list-text">Direkte Interaktion mit Kunden durch die Verarbeitung natürlicher Sprache</block>
  <block id="4ee20869dbb821d3744d87176797401f" category="list-text">Automatisierung verschiedener Geschäftsprozesse und -funktionen</block>
  <block id="5919922c658bd2a4f33f0cf546be3ea9" category="paragraph">Moderne KI-Trainings- und Inferenz-Workloads erfordern massiv parallele Rechenkapazitäten.  Daher werden GPUs zunehmend zur Ausführung von KI-Operationen eingesetzt, da die Parallelverarbeitungskapazitäten von GPUs denen von Allzweck-CPUs weit überlegen sind.</block>
  <block id="5382aaf8b3d2fdeb6717f9805b0dd511" category="section-title">Behälter</block>
  <block id="2154bae452b2343b649ee4b088b399f6" category="paragraph">Container sind isolierte Benutzerbereichsinstanzen, die auf einem gemeinsam genutzten Host-Betriebssystemkernel ausgeführt werden.  Die Nutzung von Containern nimmt rasant zu.  Container bieten viele der gleichen Vorteile der Anwendungs-Sandboxing-Funktion wie virtuelle Maschinen (VMs).  Da jedoch die Hypervisor- und Gastbetriebssystemebenen, auf die VMs angewiesen sind, eliminiert wurden, sind Container wesentlich leichter.  Die folgende Abbildung zeigt eine Visualisierung von virtuellen Maschinen im Vergleich zu Containern.</block>
  <block id="91945d3c9ebb2261142b9c7fc516b559" category="inline-link">Docker-Website</block>
  <block id="d1920cb2aa1d83b6e74ea477546e30a3" category="paragraph">Container ermöglichen außerdem die effiziente Verpackung von Anwendungsabhängigkeiten, Laufzeiten usw. direkt mit einer Anwendung.  Das am häufigsten verwendete Container-Verpackungsformat ist der Docker-Container.  Eine Anwendung, die im Docker-Containerformat containerisiert wurde, kann auf jedem Computer ausgeführt werden, auf dem Docker-Container ausgeführt werden können.  Dies gilt auch dann, wenn die Abhängigkeiten der Anwendung nicht auf dem Computer vorhanden sind, da alle Abhängigkeiten im Container selbst verpackt sind.  Weitere Informationen finden Sie im<block ref="f3aa778c455b7c9002cc51cdc41e7924" category="inline-link-rx"></block> .</block>
  <block id="0d64529eaeaf491f582b2ba0df6149c7" category="paragraph"><block ref="0d64529eaeaf491f582b2ba0df6149c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1304134d4f70b5d09af5fb5a8bda1de8" category="inline-link">Kubernetes-Website</block>
  <block id="f0ce8ef614fdf23fe30bc43ff89f53d3" category="paragraph">Kubernetes ist eine Open-Source-Plattform zur verteilten Container-Orchestrierung, die ursprünglich von Google entwickelt wurde und jetzt von der Cloud Native Computing Foundation (CNCF) gepflegt wird.  Kubernetes ermöglicht die Automatisierung von Bereitstellungs-, Verwaltungs- und Skalierungsfunktionen für containerisierte Anwendungen.  In den letzten Jahren hat sich Kubernetes zur dominierenden Plattform für die Container-Orchestrierung entwickelt.  Weitere Informationen finden Sie im<block ref="b99a36b6d7a8af9ad1172136115f0275" category="inline-link-rx"></block> .</block>
  <block id="759b696484e9a0ab24afe3237dd85e66" category="paragraph"><block ref="0d26e0900d0eeb1b6e1c8f5cfee8510e" category="inline-link-macro-rx"></block>ermöglicht die Nutzung und Verwaltung von Speicherressourcen auf allen gängigen NetApp Speicherplattformen, in der öffentlichen Cloud oder vor Ort, einschließlich ONTAP (AFF, FAS, Select, Cloud, Amazon FSx ONTAP), Azure NetApp Files Dienst und Google Cloud NetApp Volumes.  Trident ist ein Container Storage Interface (CSI)-kompatibler dynamischer Speicher-Orchestrator, der nativ in Kubernetes integriert ist.</block>
  <block id="db7f413e96e248375d3fabd005ca4fee" category="paragraph">Der<block ref="c4bca757471e0afa8bcb4da8a5f5e802" category="inline-link-macro-rx"></block> ist ein Python-basiertes Tool, das die Verwaltung von Entwicklungs-/Schulungsarbeitsbereichen und Inferenzservern vereinfacht, die durch leistungsstarken, skalierbaren NetApp Speicher unterstützt werden.  Zu den wichtigsten Funktionen gehören:</block>
  <block id="b96dbbd391395e38a8ba72ae75c21dc9" category="list-text">Stellen Sie schnell neue Arbeitsbereiche mit hoher Kapazität bereit, die durch leistungsstarken, skalierbaren NetApp Speicher unterstützt werden.</block>
  <block id="629509198041b5749e015afa6a9b2629" category="list-text">Klonen Sie Arbeitsbereiche mit hoher Kapazität nahezu sofort, um Experimente oder schnelle Iterationen zu ermöglichen.</block>
  <block id="01f719401b5bc2f16f328b588b0bef97" category="list-text">Speichern Sie nahezu sofort Snapshots von Arbeitsbereichen mit hoher Kapazität für Backups und/oder zur Rückverfolgbarkeit/Baselining.</block>
  <block id="8b4d3b8f8e04f8cfef020d43ad93e87a" category="paragraph">Apache Airflow ist eine Open-Source-Plattform für Workflow-Management, die die programmgesteuerte Erstellung, Planung und Überwachung komplexer Unternehmens-Workflows ermöglicht.  Es wird häufig zur Automatisierung von ETL- und Datenpipeline-Workflows verwendet, ist jedoch nicht auf diese Arten von Workflows beschränkt.  Das Airflow-Projekt wurde von Airbnb ins Leben gerufen, erfreut sich seitdem jedoch großer Beliebtheit in der Branche und steht nun unter der Schirmherrschaft der Apache Software Foundation.  Airflow ist in Python geschrieben, Airflow-Workflows werden über Python-Skripte erstellt und Airflow ist nach dem Prinzip „Konfiguration als Code“ konzipiert.  Viele Airflow-Benutzer in Unternehmen führen Airflow jetzt auf Kubernetes aus.</block>
  <block id="8fb4a72500791f0bea82c5c9b4c33772" category="section-title">Gerichtete azyklische Graphen (DAGs)</block>
  <block id="afd712bbacf94fbaf2852bd23c6b1a84" category="paragraph">In Airflow werden Workflows als gerichtete azyklische Graphen (DAGs) bezeichnet.  DAGs bestehen aus Aufgaben, die je nach DAG-Definition nacheinander, parallel oder in einer Kombination aus beidem ausgeführt werden.  Der Airflow-Scheduler führt einzelne Aufgaben auf einer Reihe von Workern aus und hält sich dabei an die in der DAG-Definition angegebenen Abhängigkeiten auf Aufgabenebene.  DAGs werden über Python-Skripte definiert und erstellt.</block>
  <block id="802125395813e0bec35472d0403ab94e" category="section-title">Jupyter Notebook</block>
  <block id="a0b0430a41f582a12dac8f4d63ab450d" category="inline-link">Jupyter-Website</block>
  <block id="2ea401316bb56cd0dd460196fdb8bddc" category="paragraph">Jupyter-Notebooks sind Wiki-ähnliche Dokumente, die sowohl Live-Code als auch beschreibenden Text enthalten.  Jupyter Notebooks werden in der KI- und ML-Community häufig zum Dokumentieren, Speichern und Teilen von KI- und ML-Projekten verwendet.  Weitere Informationen zu Jupyter Notebooks finden Sie auf der<block ref="412a2c3f2a7af96a2a4f6a512ee2088e" category="inline-link-rx"></block> .</block>
  <block id="cc68740519bf7afc9dc5c17acc7db61e" category="section-title">Jupyter Notebook Server</block>
  <block id="1ceb0a3b747e9e685e69bf855aa91001" category="paragraph">Ein Jupyter Notebook Server ist eine Open-Source-Webanwendung, mit der Benutzer Jupyter Notebooks erstellen können.</block>
  <block id="d837769caeb4d9edfd53e4a5a4b94fce" category="inline-link">JupyterHub-Website</block>
  <block id="aa77da24b3b7d00c6c4b22044c64a028" category="paragraph">JupyterHub ist eine Mehrbenutzeranwendung, die es einem einzelnen Benutzer ermöglicht, seinen eigenen Jupyter Notebook-Server bereitzustellen und darauf zuzugreifen.  Weitere Informationen zu JupyterHub finden Sie auf der<block ref="8b235ac1daecf8d06ace248b8ac07b97" category="inline-link-rx"></block> .</block>
  <block id="891056fdef376263d6563716a06437cd" category="inline-link">MLflow-Website</block>
  <block id="ea79d93ff06996ce8a177ec9a6f59b26" category="paragraph">MLflow ist eine beliebte Open-Source-Plattform für das KI-Lebenszyklusmanagement.  Zu den Hauptfunktionen von MLflow gehören die Verfolgung von KI/ML-Experimenten und ein KI/ML-Modell-Repository.  Weitere Informationen zu MLflow finden Sie auf der<block ref="7d5e77d7cbcfeeed8850444afe1d66af" category="inline-link-rx"></block> .</block>
  <block id="173c35c4ef789d6956a0cd6fbd9a0cfc" category="inline-link">Kubeflow-Website</block>
  <block id="9a9c31b74376d75ed88c300dfd734acf" category="paragraph">Kubeflow ist ein Open-Source-KI- und ML-Toolkit für Kubernetes, das ursprünglich von Google entwickelt wurde.  Das Kubeflow-Projekt macht die Bereitstellung von KI- und ML-Workflows auf Kubernetes einfach, portabel und skalierbar.  Kubeflow abstrahiert die Feinheiten von Kubernetes und ermöglicht es Datenwissenschaftlern, sich auf das zu konzentrieren, was sie am besten können – Datenwissenschaft.  Eine Visualisierung finden Sie in der folgenden Abbildung.  Kubeflow ist eine gute Open-Source-Option für Organisationen, die eine All-in-One-MLOps-Plattform bevorzugen.  Weitere Informationen finden Sie im<block ref="bbfd4ba68f44e2ff98f04ea32205485d" category="inline-link-rx"></block> .</block>
  <block id="e569c07c88fe6f8af1f63410c200abd1" category="section-title">Kubeflow-Pipelines</block>
  <block id="7236436bac67d8eaadbf52811774b916" category="inline-link">offizielle Kubeflow-Dokumentation</block>
  <block id="f69bb06b79f60baced2f6faf97fc9e14" category="paragraph">Kubeflow-Pipelines sind eine Schlüsselkomponente von Kubeflow.  Kubeflow Pipelines sind eine Plattform und ein Standard zum Definieren und Bereitstellen portabler und skalierbarer KI- und ML-Workflows. Weitere Informationen finden Sie im<block ref="34d1e4686e190f53e3511c4faa8ac68b" category="inline-link-rx"></block> .</block>
  <block id="7724cfbda1ff4c3052c280f6b4af599c" category="section-title">Kubeflow-Notebooks</block>
  <block id="352ec4b0886cdd10b69d3efaa4071648" category="paragraph">Kubeflow vereinfacht die Bereitstellung und Implementierung von Jupyter Notebook-Servern auf Kubernetes.  Weitere Informationen zu Jupyter Notebooks im Kontext von Kubeflow finden Sie im<block ref="273f9b54e4f57ca19b4597f14d191196" category="inline-link-rx"></block> .</block>
  <block id="d8d51bb44e1cdcb1d7fde82b687339bd" category="section-title">Katib</block>
  <block id="8f5f81b63b950128a2104cb77339c846" category="paragraph">Katib ist ein Kubernetes-natives Projekt für automatisiertes maschinelles Lernen (AutoML).  Katib unterstützt Hyperparameter-Tuning, Early Stopping und die Suche nach neuronalen Architekturen (NAS).  Katib ist das Projekt, das unabhängig von Frameworks für maschinelles Lernen (ML) ist.  Es kann Hyperparameter von Anwendungen optimieren, die in einer beliebigen Sprache der Wahl des Benutzers geschrieben sind, und unterstützt nativ viele ML-Frameworks wie TensorFlow, MXNet, PyTorch, XGBoost und andere.  Katib unterstützt zahlreiche verschiedene AutoML-Algorithmen, wie etwa Bayes-Optimierung, Tree of Parzen-Schätzer, Zufallssuche, Covariance Matrix Adaptation Evolution Strategy, Hyperband, Efficient Neural Architecture Search, Differentiable Architecture Search und viele mehr.  Weitere Informationen zu Jupyter Notebooks im Kontext von Kubeflow finden Sie im<block ref="5b959b0f3dbfc4557138b63a781b201c" category="inline-link-rx"></block> .</block>
  <block id="592d6ad3868437ff65a70353ab870f50" category="list-text">Nahtlose Skalierung und unterbrechungsfreier Betrieb.  ONTAP unterstützt die unterbrechungsfreie Kapazitätserweiterung bestehender Controller und Scale-Out-Cluster.  Kunden können ohne kostspielige Datenmigrationen oder Ausfälle auf die neuesten Technologien upgraden.</block>
  <block id="49a023178611b07475bac0823fc2dd53" category="section-title">NetApp Snapshot-Kopien</block>
  <block id="42884680ea9780d61f4cce71fdc606b1" category="paragraph">Eine NetApp Snapshot-Kopie ist ein schreibgeschütztes Point-in-Time-Image eines Volumes.  Das Image verbraucht nur minimalen Speicherplatz und verursacht nur einen vernachlässigbaren Leistungsaufwand, da es nur Änderungen an Dateien aufzeichnet, die seit der letzten Snapshot-Kopie erstellt wurden, wie in der folgenden Abbildung dargestellt.</block>
  <block id="13455e6dd452fcc850acd6696e670600" category="paragraph">Ihre Effizienz verdanken Snapshot-Kopien der zentralen ONTAP Speichervirtualisierungstechnologie, dem Write Anywhere File Layout (WAFL).  Wie eine Datenbank verwendet WAFL Metadaten, um auf tatsächliche Datenblöcke auf der Festplatte zu verweisen.  Aber im Gegensatz zu einer Datenbank überschreibt WAFL keine vorhandenen Blöcke.  Es schreibt aktualisierte Daten in einen neuen Block und ändert die Metadaten.  Snapshot-Kopien sind deshalb so effizient, weil ONTAP beim Erstellen einer Snapshot-Kopie auf Metadaten verweist, anstatt Datenblöcke zu kopieren.  Dadurch entfallen die Suchzeit, die bei anderen Systemen zum Auffinden der zu kopierenden Blöcke erforderlich ist, sowie die Kosten für die Erstellung der Kopie selbst.</block>
  <block id="921d0d1d37872e6233bf4da3688b03ef" category="paragraph">Sie können eine Snapshot-Kopie verwenden, um einzelne Dateien oder LUNs wiederherzustellen oder den gesamten Inhalt eines Volumes wiederherzustellen.  ONTAP vergleicht Zeigerinformationen in der Snapshot-Kopie mit Daten auf der Festplatte, um das fehlende oder beschädigte Objekt ohne Ausfallzeiten oder erhebliche Leistungseinbußen zu rekonstruieren.</block>
  <block id="fbfe7fb9706620c5ddb7b53cd9e06fa0" category="paragraph"><block ref="fbfe7fb9706620c5ddb7b53cd9e06fa0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76a33b697177fedefd70387e86214ebd" category="section-title">NetApp FlexClone -Technologie</block>
  <block id="78e8cd917c99154d22a94ba80186ac33" category="paragraph">Die NetApp FlexClone -Technologie referenziert Snapshot-Metadaten, um beschreibbare Point-in-Time-Kopien eines Volumes zu erstellen.  Kopien teilen sich Datenblöcke mit ihren Eltern und verbrauchen keinen Speicherplatz außer dem, der für Metadaten benötigt wird, bis Änderungen in die Kopie geschrieben werden, wie in der folgenden Abbildung dargestellt.  Während die Erstellung herkömmlicher Kopien Minuten oder sogar Stunden dauern kann, können Sie mit der FlexClone -Software selbst die größten Datensätze nahezu augenblicklich kopieren.  Dadurch eignet es sich ideal für Situationen, in denen Sie mehrere Kopien identischer Datensätze (z. B. einen Entwicklungsarbeitsbereich) oder temporäre Kopien eines Datensatzes (Testen einer Anwendung anhand eines Produktionsdatensatzes) benötigen.</block>
  <block id="f28d7ba8bb28ad8ce873b4ec7ed61164" category="paragraph"><block ref="f28d7ba8bb28ad8ce873b4ec7ed61164" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f67824f4f94415299484432a092f76b1" category="section-title">NetApp SnapMirror Datenreplikationstechnologie</block>
  <block id="553416a55e03cc49df61e631d17b8011" category="paragraph">Die NetApp SnapMirror -Software ist eine kostengünstige, benutzerfreundliche, einheitliche Replikationslösung für die gesamte Datenstruktur.  Es repliziert Daten mit hoher Geschwindigkeit über LAN oder WAN.  Es bietet Ihnen hohe Datenverfügbarkeit und schnelle Datenreplikation für Anwendungen aller Art, einschließlich geschäftskritischer Anwendungen in virtuellen und herkömmlichen Umgebungen.  Wenn Sie Daten auf ein oder mehrere NetApp -Speichersysteme replizieren und die sekundären Daten kontinuierlich aktualisieren, bleiben Ihre Daten aktuell und stehen Ihnen jederzeit zur Verfügung.  Es sind keine externen Replikationsserver erforderlich.  In der folgenden Abbildung sehen Sie ein Beispiel für eine Architektur, die die SnapMirror -Technologie nutzt.</block>
  <block id="5a12ba5d186c9ffcce65438f531e7c47" category="paragraph">Die SnapMirror -Software nutzt die Speichereffizienz von NetApp ONTAP , indem sie nur geänderte Blöcke über das Netzwerk sendet.  Die SnapMirror -Software verwendet außerdem eine integrierte Netzwerkkomprimierung, um die Datenübertragung zu beschleunigen und die Netzwerkbandbreitenauslastung um bis zu 70 % zu reduzieren.  Mit der SnapMirror -Technologie können Sie einen Thin-Replication-Datenstrom nutzen, um ein einzelnes Repository zu erstellen, das sowohl den aktiven Spiegel als auch frühere Point-in-Time-Kopien verwaltet und so den Netzwerkverkehr um bis zu 50 % reduziert.</block>
  <block id="2ab1a10694bb0d67320839630a1c9ccb" category="paragraph"><block ref="c4152c5b1804294b9bc91a2fa3a92230" category="inline-link-macro-rx"></block>ist ein NetApp -Dienst für die schnelle und sichere Datensynchronisierung.  Unabhängig davon, ob Sie Dateien zwischen lokalen NFS- oder SMB-Dateifreigaben, NetApp StorageGRID, NetApp ONTAP S3, Google Cloud NetApp Volumes, Azure NetApp Files, AWS S3, AWS EFS, Azure Blob, Google Cloud Storage oder IBM Cloud Object Storage übertragen müssen, verschiebt BlueXP Copy and Sync die Dateien schnell und sicher dorthin, wo Sie sie benötigen.</block>
  <block id="7e333cc0e24ef7489559129fd944c91f" category="paragraph">Nachdem Ihre Daten übertragen wurden, stehen sie sowohl auf der Quelle als auch auf dem Ziel vollständig zur Verwendung zur Verfügung.  BlueXP Copy and Sync kann Daten bei Bedarf synchronisieren, wenn ein Update ausgelöst wird, oder Daten kontinuierlich basierend auf einem vordefinierten Zeitplan synchronisieren.  Unabhängig davon verschiebt BlueXP Copy and Sync nur die Deltas, sodass der Zeit- und Kostenaufwand für die Datenreplikation minimiert wird.</block>
  <block id="22716a1c6493f7fb09f4caf2084ad23c" category="paragraph">BlueXP Copy and Sync ist ein Software-as-a-Service-Tool (SaaS), das extrem einfach einzurichten und zu verwenden ist.  Datenübertragungen, die durch BlueXP Copy and Sync ausgelöst werden, werden von Datenbrokern durchgeführt.  BlueXP Copy and Sync-Datenbroker können in AWS, Azure, Google Cloud Platform oder vor Ort bereitgestellt werden.</block>
  <block id="204b9ffafe28e07fef53f08e2924e621" category="paragraph"><block ref="8eb894646a418e33ca3d088f11e4914c" category="inline-link-macro-rx"></block>ist eine clientbasierte Software für Datenmigrationen von beliebigen zu NetApp und von NetApp zu NetApp sowie Einblicke in Dateisysteme.  XCP ist auf Skalierbarkeit und maximale Leistung ausgelegt, indem alle verfügbaren Systemressourcen genutzt werden, um große Datensätze und leistungsstarke Migrationen zu verarbeiten.  XCP hilft Ihnen, einen vollständigen Einblick in das Dateisystem zu erhalten und bietet die Möglichkeit, Berichte zu erstellen.</block>
  <block id="957e30f73566564bd8a99a6fac13e015" category="section-title">NetApp ONTAP FlexGroup Volumes</block>
  <block id="22bd32dacc144ffc2601e6685260b4c3" category="paragraph">Ein Trainingsdatensatz kann eine Sammlung von potenziell Milliarden von Dateien sein.  Dateien können Text, Audio, Video und andere Formen unstrukturierter Daten enthalten, die gespeichert und verarbeitet werden müssen, um parallel gelesen werden zu können.  Das Speichersystem muss eine große Anzahl kleiner Dateien speichern und diese Dateien für sequenzielle und zufällige E/A-Vorgänge parallel lesen.</block>
  <block id="6d7d8c1311f5ac7d2ed289e012822f78" category="paragraph">Ein FlexGroup -Volume ist ein einzelner Namespace, der aus mehreren Mitgliedsvolumes besteht, wie in der folgenden Abbildung dargestellt.  Aus Sicht eines Speicheradministrators wird ein FlexGroup -Volume wie ein NetApp FlexVol volume verwaltet und verhält sich wie dieses.  Dateien in einem FlexGroup -Volume werden einzelnen Mitgliedsvolumes zugewiesen und nicht über Volumes oder Knoten verteilt.  Sie ermöglichen die folgenden Funktionen:</block>
  <block id="28f25e3d6de5d5fe801c8d194234f0a5" category="list-text">FlexGroup -Volumes bieten mehrere Petabyte an Kapazität und vorhersehbar niedrige Latenz für Workloads mit vielen Metadaten.</block>
  <block id="82b42713e1be50bb140b7e85eecdd91f" category="list-text">Sie unterstützen bis zu 400 Milliarden Dateien im selben Namespace.</block>
  <block id="50af21bd57d5360eb9ffc8dbc4b9a5bd" category="list-text">Sie unterstützen parallelisierte Vorgänge in NAS-Workloads über CPUs, Knoten, Aggregate und einzelne FlexVol Volumes hinweg.</block>
  <block id="b0d8567b3e8a1e892d0b59f7a3c27292" category="paragraph"><block ref="b0d8567b3e8a1e892d0b59f7a3c27292" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c6459218853a974bb2b38718e6db79ed" category="summary">Diese Lösung soll mehrere verschiedene Open-Source-Tools und Frameworks demonstrieren, die in einen MLOps-Workflow integriert werden können.  Diese verschiedenen Tools und Frameworks können je nach Anforderungen und Anwendungsfall zusammen oder einzeln verwendet werden.</block>
  <block id="eb1b19572557d2f13528a30754e9997a" category="doc">Open Source MLOps mit NetApp</block>
  <block id="aa27e598d8d01ff612acd83b47a13b21" category="paragraph">Mike Oglesby, NetApp Sufian Ahmad, NetApp Rick Huang, NetApp Mohan Acharya, NetApp</block>
  <block id="36160a80da6291faa3ebc68ede194279" category="paragraph">Unternehmen und Organisationen aller Größen und aus vielen Branchen setzen auf künstliche Intelligenz (KI), um reale Probleme zu lösen, innovative Produkte und Dienstleistungen anzubieten und sich auf einem zunehmend wettbewerbsorientierten Markt einen Vorteil zu verschaffen.  Viele Organisationen greifen auf Open-Source-MLOps-Tools zurück, um mit dem rasanten Innovationstempo in der Branche Schritt zu halten.  Diese Open-Source-Tools bieten erweiterte Funktionen und hochmoderne Features, berücksichtigen jedoch häufig nicht die Datenverfügbarkeit und Datensicherheit.  Leider bedeutet dies, dass hochqualifizierte Datenwissenschaftler viel Zeit damit verbringen müssen, auf den Zugriff auf Daten zu warten oder auf die Fertigstellung grundlegender datenbezogener Vorgänge.  Durch die Kombination beliebter Open-Source-MLOps-Tools mit einer intelligenten Dateninfrastruktur von NetApp können Unternehmen ihre Datenpipelines beschleunigen, was wiederum ihre KI-Initiativen beschleunigt.  Sie können den Wert ihrer Daten erschließen und gleichzeitig sicherstellen, dass diese geschützt und sicher bleiben.  Diese Lösung demonstriert die Kombination von NetApp Datenverwaltungsfunktionen mit mehreren gängigen Open-Source-Tools und -Frameworks, um diese Herausforderungen zu bewältigen.</block>
  <block id="ad3ca69dbfa62630ace9a188e93d1f45" category="paragraph">Die folgende Liste hebt einige wichtige Funktionen hervor, die durch diese Lösung ermöglicht werden:</block>
  <block id="e6ffdd80d6efdfae1a367b394ef6afdf" category="list-text">Benutzer können schnell neue Datenvolumes mit hoher Kapazität und Entwicklungsarbeitsbereiche bereitstellen, die durch leistungsstarken, skalierbaren NetApp Speicher unterstützt werden.</block>
  <block id="24f5e64e89b475fca21e0a2d5536aa48" category="list-text">Benutzer können Datenvolumes und Entwicklungsarbeitsbereiche mit hoher Kapazität nahezu augenblicklich klonen, um Experimente oder schnelle Iterationen zu ermöglichen.</block>
  <block id="4657d40d11cf0257f60a599a2bc266b6" category="list-text">Benutzer können Snapshots von Datenvolumes mit hoher Kapazität und Entwicklungsarbeitsbereichen nahezu augenblicklich für Backups und/oder zur Rückverfolgbarkeit/Baselining speichern.</block>
  <block id="953c95173b5d3944693633d3b6ae7711" category="paragraph"><block ref="953c95173b5d3944693633d3b6ae7711" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3e3d207c7705b0f7dc0142df9cc2790a" category="inline-link-macro">Jupyter-Notebooks</block>
  <block id="d1a5554bae0723fdaf349b8047aa0d08" category="paragraph">Ein typischer MLOps-Workflow umfasst Entwicklungsarbeitsbereiche, in der Regel in Form von<block ref="cd3acaabeea76372e8a706ccab36a6b8" category="inline-link-macro-rx"></block> ; Experimentverfolgung; automatisierte Trainingspipelines; Datenpipelines; und Inferenz/Bereitstellung.  Diese Lösung hebt mehrere verschiedene Tools und Frameworks hervor, die unabhängig oder zusammen verwendet werden können, um die verschiedenen Aspekte des Workflows zu berücksichtigen.  Wir demonstrieren außerdem die Kombination der NetApp Datenverwaltungsfunktionen mit jedem dieser Tools.  Diese Lösung soll Bausteine bieten, aus denen eine Organisation einen benutzerdefinierten MLOps-Workflow erstellen kann, der speziell auf ihre Anwendungsfälle und Anforderungen zugeschnitten ist.</block>
  <block id="0b34fcae55a765c46410fb4116433e75" category="paragraph">Die folgenden Tools/Frameworks sind in dieser Lösung enthalten:</block>
  <block id="074cd5ab3a3581efcb92b990cd4ed3b6" category="list-text"><block ref="074cd5ab3a3581efcb92b990cd4ed3b6" category="inline-link-macro-rx"></block></block>
  <block id="ac10ff0174545b18e3fd3b7ab41ebc08" category="list-text"><block ref="ac10ff0174545b18e3fd3b7ab41ebc08" category="inline-link-macro-rx"></block></block>
  <block id="4275daa2701a7c7ad4c1c5df1088ada8" category="list-text"><block ref="4275daa2701a7c7ad4c1c5df1088ada8" category="inline-link-macro-rx"></block></block>
  <block id="a0cf58c060e740cca7f48b1bb399e974" category="list-text"><block ref="a0cf58c060e740cca7f48b1bb399e974" category="inline-link-macro-rx"></block></block>
  <block id="9717b9722e82e47dc4445d7ffc90b79d" category="paragraph">In der folgenden Liste werden gängige Muster für die unabhängige oder kombinierte Bereitstellung dieser Tools beschrieben.</block>
  <block id="3f7626e711a1e660dae85d17fdc35882" category="list-text">Stellen Sie JupyterHub, MLflow und Apache Airflow gemeinsam bereit – JupyterHub für<block ref="cd3acaabeea76372e8a706ccab36a6b8" category="inline-link-macro-rx"></block> , MLflow für die Experimentverfolgung und Apache Airflow für automatisiertes Training und Datenpipelines.</block>
  <block id="1dceee44b0bde0ef7364704241dced5a" category="list-text">Stellen Sie Kubeflow und Apache Airflow gemeinsam bereit – Kubeflow für<block ref="cd3acaabeea76372e8a706ccab36a6b8" category="inline-link-macro-rx"></block> , Experimentverfolgung, automatisierte Trainingspipelines und Inferenz; und Apache Airflow für Datenpipelines.</block>
  <block id="aa815dfaf0c405504952ea2a361a2a3e" category="list-text">Stellen Sie Kubeflow als All-in-One-MLOps-Plattformlösung bereit für<block ref="cd3acaabeea76372e8a706ccab36a6b8" category="inline-link-macro-rx"></block> , Experimentverfolgung, automatisiertes Training und Datenpipelines sowie Inferenz.</block>
  <block id="6ca687fb1fabca3bf671bc9bf39dbf27" category="summary">Open Source MLOps mit NetApp – JupyterHub-Bereitstellung</block>
  <block id="09d2043b79460eb224957589f59ab494" category="doc">JupyterHub-Bereitstellung</block>
  <block id="2ab6902fa61e1ea6912baf903a3b0bf1" category="paragraph">In diesem Abschnitt werden die Aufgaben beschrieben, die Sie ausführen müssen, um JupyterHub in Ihrem Kubernetes-Cluster bereitzustellen.</block>
  <block id="26e29fcdb4d615c34b7fedb3a0564f8f" category="admonition">Es ist möglich, JupyterHub auf anderen Plattformen als Kubernetes bereitzustellen.  Die Bereitstellung von JupyterHub auf anderen Plattformen als Kubernetes liegt außerhalb des Umfangs dieser Lösung.</block>
  <block id="99b37bb800ce4a91a3634a32f40b891b" category="list-text">Sie haben NetApp Trident bereits in Ihrem Kubernetes-Cluster installiert und konfiguriert.  Weitere Einzelheiten zu Trident finden Sie im<block ref="81f3e4134a6f5ebea4459e5f629a42dc" category="inline-link-macro-rx"></block> .</block>
  <block id="2ac6b5f4951f689f17ae54334df0112f" category="paragraph">JupyterHub wird mit Helm bereitgestellt, einem beliebten Paketmanager für Kubernetes.  Bevor Sie JupyterHub bereitstellen, müssen Sie Helm auf Ihrem Kubernetes-Steuerknoten installieren.  Um Helm zu installieren, folgen Sie den<block ref="cf3f65305f288242c9d49061d26ec8ec" category="inline-link-rx"></block> in der offiziellen Helm-Dokumentation.</block>
  <block id="c0b1a9427c281e6178bd6cbeb95bc3a8" category="paragraph">Bevor Sie JupyterHub bereitstellen, müssen Sie eine Standard-StorageClass in Ihrem Kubernetes-Cluster festlegen.  Um eine Standard-StorageClass innerhalb Ihres Clusters festzulegen, folgen Sie den Anweisungen im<block ref="a8e87de8c7ac570587ad7744774f8330" category="inline-link-macro-rx"></block> Abschnitt.  Wenn Sie in Ihrem Cluster bereits eine Standard-StorageClass festgelegt haben, können Sie diesen Schritt überspringen.</block>
  <block id="771d8827304382e84db174fab916e726" category="section-title">JupyterHub bereitstellen</block>
  <block id="cca32ccd336a1d99e57fe4b732c1db03" category="paragraph">Nachdem Sie die oben genannten Schritte abgeschlossen haben, können Sie JupyterHub nun bereitstellen.  Für die Bereitstellung von JupyterHub sind die folgenden Schritte erforderlich:</block>
  <block id="02e6e3cd99fedc7e13d22d86bad5b831" category="section-title">JupyterHub-Bereitstellung konfigurieren</block>
  <block id="ce95551547fa8ef240a593be5a20f5ee" category="paragraph">Vor der Bereitstellung empfiehlt es sich, die JupyterHub-Bereitstellung für Ihre jeweilige Umgebung zu optimieren.  Sie können eine *config.yaml*-Datei erstellen und sie während der Bereitstellung mithilfe des Helm-Diagramms verwenden.</block>
  <block id="53db901aeed4328fe567404ccb21206d" category="paragraph">Eine Beispieldatei *config.yaml* finden Sie unter<block ref="8c152549701847c833121b3ad8e4af72" category="inline-link-rx"></block></block>
  <block id="d4acad87b1acbfd617a3b4988bfb1864" category="admonition">In dieser config.yaml-Datei können Sie den Parameter *(singleuser.storage.dynamic.storageClass)* für die NetApp Trident StorageClass festlegen.  Dies ist die Speicherklasse, die zum Bereitstellen der Volumes für einzelne Benutzerarbeitsbereiche verwendet wird.</block>
  <block id="fc1be4924094aec74f37b59bbd957af8" category="section-title">Hinzufügen freigegebener Volumes</block>
  <block id="67e834a52ce0a7019fd9a1bec4bae36f" category="paragraph">Wenn Sie ein gemeinsames Volume für alle JupyterHub-Benutzer verwenden möchten, können Sie Ihre *config.yaml* entsprechend anpassen.  Wenn Sie beispielsweise über einen freigegebenen PersistentVolumeClaim namens „jupyterhub-shared-volume“ verfügen, können Sie ihn in allen Benutzer-Pods wie folgt als /home/shared mounten:</block>
  <block id="a66a54102aa462ebdfe0146ca96eaf33" category="admonition">Dies ist ein optionaler Schritt. Sie können diese Parameter an Ihre Bedürfnisse anpassen.</block>
  <block id="67c7fe5cd005737db341f115281a5f71" category="section-title">JupyterHub mit Helm Chart bereitstellen</block>
  <block id="54ad8b66fcd369a80298610d95ca37d9" category="paragraph">Machen Sie Helm auf das JupyterHub Helm-Diagramm-Repository aufmerksam.</block>
  <block id="f98aad3b24c5bab5b4737b8fad3a723f" category="paragraph">Dies sollte eine Ausgabe wie die folgende anzeigen:</block>
  <block id="4e29332ac1db944879502e11ab327960" category="paragraph">Installieren Sie nun das von Ihrer config.yaml konfigurierte Diagramm, indem Sie diesen Befehl aus dem Verzeichnis ausführen, das Ihre config.yaml enthält:</block>
  <block id="be118fb1d0e987a9d25c71312374ffdf" category="admonition">In diesem Beispiel:</block>
  <block id="750e13a1159e4f2b96ba2d8fadfb1aab" category="paragraph">&lt;helm-release-name&gt; ist auf my-jupyterhub eingestellt, was der Name Ihrer JupyterHub-Version sein wird.  &lt;k8s-namespace&gt; ist auf my-namespace eingestellt, also den Namespace, in dem Sie JupyterHub installieren möchten.  Das Flag --create-namespace wird verwendet, um den Namespace zu erstellen, falls er noch nicht vorhanden ist.  Das Flag --values gibt die Datei config.yaml an, die Ihre gewünschten Konfigurationsoptionen enthält.</block>
  <block id="0873eec3dcb328f01cc596581047ae60" category="section-title">Bereitstellung prüfen</block>
  <block id="5b252fe874ba4bfb32f7c039993801ab" category="paragraph">Während Schritt 2 ausgeführt wird, können Sie sehen, wie die Pods mit dem folgenden Befehl erstellt werden:</block>
  <block id="828e0f094cad198231ffd340f281e098" category="paragraph">Warten Sie, bis der Hub und der Proxy-Pod in den Status „Laufen“ wechseln.</block>
  <block id="4f8f16ff2582a84eb01cbef90f467393" category="section-title">Zugriff auf JupyterHub</block>
  <block id="c7433009ea218afe4c1117491e4afccb" category="paragraph">Suchen Sie die IP, die wir für den Zugriff auf den JupyterHub verwenden können.  Führen Sie den folgenden Befehl aus, bis die EXTERNE IP des öffentlichen Proxy-Dienstes wie in der Beispielausgabe verfügbar ist.</block>
  <block id="7261a4593eb504b7857e5e4dd9a5459c" category="admonition">Wir haben den NodePort-Dienst in unserer Datei config.yaml verwendet. Sie können ihn basierend auf Ihrem Setup (z. B. LoadBalancer) an Ihre Umgebung anpassen.</block>
  <block id="a5673ab624b33fdb767b6ec77b9901ca" category="paragraph">Um JupyterHub zu verwenden, geben Sie die externe IP für den Proxy-Public-Dienst in einen Browser ein.</block>
  <block id="9b5d03606d5f2609a4b9a6f1ac626a8d" category="summary">Open Source MLOps mit NetApp – Verwenden Sie das NetApp DataOps Toolkit mit JupyterHub</block>
  <block id="8fc5f752dfcb57cd9232177f28b14765" category="doc">Verwenden Sie das NetApp DataOps Toolkit mit JupyterHub</block>
  <block id="0162e970f8577425266cb5c97d21c2a7" category="paragraph">Der<block ref="6bc4513613cdc996b868b94d9e9ded69" category="inline-link-rx"></block> kann in Verbindung mit JupyterHub verwendet werden.  Durch die Verwendung des NetApp DataOps Toolkit mit JupyterHub können Endbenutzer Volume-Snapshots für die Sicherung des Arbeitsbereichs und/oder die Rückverfolgbarkeit von Datensätzen zu Modellen direkt aus einem Jupyter-Notebook erstellen.</block>
  <block id="8f08aaf2916d1654fc96af766c150251" category="paragraph">Bevor Sie das DataOps Toolkit mit JupyterHub verwenden können, müssen Sie dem Kubernetes-Dienstkonto, das JupyterHub einzelnen Jupyter Notebook Server-Pods zuweist, die entsprechenden Berechtigungen erteilen.  JupyterHub verwendet das Dienstkonto, das durch den<block ref="b8c80a6db053e98d7341438c2eb0aea3" prefix=" " category="inline-code"></block> Variable in Ihrer JupyterHub Helm-Diagramm-Konfigurationsdatei.</block>
  <block id="a815fb28e94390b627bc7915911578cf" category="section-title">Clusterrolle für DataOps Toolkit erstellen</block>
  <block id="333372e6f3961af5df82304243a2d5ba" category="paragraph">Erstellen Sie zunächst eine Clusterrolle mit dem Namen „netapp-dataops“, die über die erforderlichen Kubernetes-API-Berechtigungen zum Erstellen von Volume-Snapshots verfügt.</block>
  <block id="3805f69a30879fb016e5c3d0a85fab77" category="section-title">Zuweisen der Clusterrolle zum Notebook-Server-Dienstkonto</block>
  <block id="19506ab4aa03158eeea933145bd0471d" category="paragraph">Erstellen Sie eine Rollenbindung, die die Clusterrolle „netapp-dataops-snapshots“ dem entsprechenden Dienstkonto im entsprechenden Namespace zuweist.  Wenn Sie beispielsweise JupyterHub im Namespace „jupyterhub“ installiert haben und das Dienstkonto „default“ über die<block ref="b8c80a6db053e98d7341438c2eb0aea3" prefix=" " category="inline-code"></block> Mit dieser Variable würden Sie die Clusterrolle „netapp-dataops-snapshots“ dem Dienstkonto „default“ im Namespace „jupyterhub“ zuweisen, wie im folgenden Beispiel gezeigt.</block>
  <block id="fe7233ebd9f644239a2437c55d3419e1" category="section-title">Erstellen Sie Volume-Snapshots innerhalb des Jupyter-Notebooks</block>
  <block id="02dd051970bea675e5def458342cd6e3" category="paragraph">Jetzt können JupyterHub-Benutzer das NetApp DataOps Toolkit verwenden, um Volume-Snapshots direkt aus einem Jupyter-Notebook heraus zu erstellen, wie im folgenden Beispiel gezeigt.</block>
  <block id="6bd0178572fd0f85ae777cd2c67d0907" category="paragraph"><block ref="6bd0178572fd0f85ae777cd2c67d0907" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4ffc4debfa03808ebe14380555e9a891" category="summary">Datenaufnahme mit NetApp SnapMirror</block>
  <block id="c9cfa55f76ce30116dc6c4a9d937fa9d" category="doc">Daten mit NetApp SnapMirror in JupyterHub einlesen</block>
  <block id="98aa5dbb610473a52540e5d0699bd079" category="paragraph">NetApp SnapMirror ist eine Replikationstechnologie, mit der Sie Daten zwischen NetApp Speichersystemen replizieren können.  SnapMirror kann verwendet werden, um Daten aus Remote-Umgebungen in JupyterHub zu übernehmen.</block>
  <block id="815eb616a6188ae082d3024fbb91e45e" category="section-title">Beispiel-Workflow und Demo</block>
  <block id="a3e50a098653f80e6a42662ee52e8b55" category="inline-link-macro">dieser Tech ONTAP -Blogbeitrag</block>
  <block id="5eae3f83c7f60bb551b097ccf3a4012b" category="paragraph">Siehe<block ref="585bdb2d9e21d8036a261701b86d814c" category="inline-link-macro-rx"></block> für einen detaillierten Beispiel-Workflow und eine Demo zur Verwendung von NetApp SnapMirror zum Einspeisen von Daten in JupyterHub.</block>
  <block id="ba47b65d29a2bcf968281d1e04ee29bb" category="summary">Open Source MLOps mit NetApp – Kubeflow-Bereitstellung</block>
  <block id="e560b8ed748180150ee1a196f2247fce" category="paragraph">In diesem Abschnitt werden die Aufgaben beschrieben, die Sie ausführen müssen, um Kubeflow in Ihrem Kubernetes-Cluster bereitzustellen.</block>
  <block id="f3538dfada37d551dd71f26249dd82c6" category="list-text">Sie verfügen bereits über einen funktionierenden Kubernetes-Cluster und führen eine Version von Kubernetes aus, die von der Kubeflow-Version unterstützt wird, die Sie bereitstellen möchten.  Eine Liste der unterstützten Kubernetes-Versionen finden Sie in den Abhängigkeiten für Ihre Kubeflow-Version im<block ref="b84967824090781ee960169bb3232fc6" category="inline-link-macro-rx"></block> .</block>
  <block id="84d21063d216560d873bc66cd38d62e8" category="paragraph">Bevor Sie Kubeflow bereitstellen, empfehlen wir, eine Standard-StorageClass in Ihrem Kubernetes-Cluster festzulegen.  Der Kubeflow-Bereitstellungsprozess versucht möglicherweise, neue persistente Volumes mithilfe der Standard-StorageClass bereitzustellen.  Wenn keine StorageClass als Standard-StorageClass festgelegt ist, kann die Bereitstellung fehlschlagen.  Um eine Standard-StorageClass innerhalb Ihres Clusters festzulegen, führen Sie die folgende Aufgabe vom Bereitstellungs-Jump-Host aus.  Wenn Sie in Ihrem Cluster bereits eine Standard-StorageClass festgelegt haben, können Sie diesen Schritt überspringen.</block>
  <block id="d371ec612c125519e69855ad89d4445b" category="list-text">Legen Sie eine Ihrer vorhandenen StorageClasses als Standard-StorageClass fest.  Die folgenden Beispielbefehle zeigen die Bezeichnung einer StorageClass namens<block ref="19a55e78496416c8db6565a114cfd5f3" prefix=" " category="inline-code"></block> als Standard-Speicherklasse.</block>
  <block id="f830a6eea70ae3a0e7af4606462ad281" category="admonition">Der<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> Der Typ Trident Backend hat eine ziemlich große Mindest-PVC-Größe.  Standardmäßig versucht Kubeflow, PVCs bereitzustellen, die nur wenige GB groß sind.  Daher sollten Sie keine StorageClass festlegen, die die<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> Backend-Typ als Standard-StorageClass für die Zwecke der Kubeflow-Bereitstellung.</block>
  <block id="7724a5f9edc284eef2e4bc112adc1dd9" category="section-title">Kubeflow-Bereitstellungsoptionen</block>
  <block id="e135506d2171533787a405262eeb67bc" category="paragraph">Es gibt viele verschiedene Optionen für die Bereitstellung von Kubeflow.  Weitere Informationen finden Sie im<block ref="59d814781a574912b676e75f9fe0e882" category="inline-link-macro-rx"></block> Klicken Sie auf „Weiter“, um eine Liste der Bereitstellungsoptionen anzuzeigen, und wählen Sie die Option aus, die Ihren Anforderungen am besten entspricht.</block>
  <block id="07379a7db414d96104f4d3ab35ee3d59" category="admonition">Zu Validierungszwecken haben wir Kubeflow 1.7 bereitgestellt mit<block ref="f36b6222867dc75589b32398e1411061" category="inline-link-macro-rx"></block> 0.1.1.</block>
  <block id="0dbcc7b3c9a4c5ed6afff19c771a989d" category="summary">Open Source MLOps mit NetApp – Verwenden Sie das NetApp DataOps Toolkit mit Kubeflow</block>
  <block id="3b70474868bce72e0d5d1fac42d1f643" category="doc">Verwenden Sie das NetApp DataOps Toolkit mit Kubeflow</block>
  <block id="6e4cd672cd8bd06c42a9e4ba697c61de" category="inline-link">NetApp Data Science Toolkit für Kubernetes</block>
  <block id="4065ea77b68b6d949a165c54fc532d2a" category="paragraph">Der<block ref="6f920cea43eeb6dd3a1bfb8ce1f9946a" category="inline-link-rx"></block> kann in Verbindung mit Kubeflow verwendet werden.  Die Verwendung des NetApp Data Science Toolkit mit Kubeflow bietet die folgenden Vorteile:</block>
  <block id="0a19b387d7028ea674dc64f74ecb97ea" category="list-text">Datenwissenschaftler können erweiterte NetApp Datenverwaltungsvorgänge, wie das Erstellen von Snapshots und Klonen, direkt aus einem Jupyter-Notebook heraus durchführen.</block>
  <block id="f4a972e1ae8aa85c6e67d7ad0ccc6dc4" category="list-text">Erweiterte NetApp Datenverwaltungsvorgänge, wie das Erstellen von Snapshots und Klonen, können mithilfe des Kubeflow Pipelines-Frameworks in automatisierte Workflows integriert werden.</block>
  <block id="5e646a4ae4330cb948544333980f9f49" category="inline-link">Kubeflow-Beispiele</block>
  <block id="f1db0bc6ea6a4eee559e5d9946fd92ea" category="paragraph">Weitere Informationen finden Sie im<block ref="a5886b5aa215f1fd67a69d09a2725b9d" category="inline-link-rx"></block> Weitere Informationen zur Verwendung des Toolkits mit Kubeflow finden Sie im Abschnitt „NetApp Data Science Toolkit GitHub-Repository“.</block>
  <block id="0e82e7615bc43e60306731cd1402df29" category="summary">Open Source MLOps mit NetApp – Bereitstellung eines Jupyter Notebook-Arbeitsbereichs für Datenwissenschaftler oder Entwickler</block>
  <block id="7fad49a67f130cbd7629be2d6c719aea" category="doc">Bereitstellen eines Jupyter Notebook-Arbeitsbereichs für die Verwendung durch Datenwissenschaftler oder Entwickler</block>
  <block id="b09a995a770ac7d1022303afcc4effb0" category="paragraph">Kubeflow kann schnell neue Jupyter Notebook-Server bereitstellen, die als Arbeitsbereiche für Datenwissenschaftler fungieren.  Weitere Informationen zu Jupyter Notebooks im Kubeflow-Kontext finden Sie im<block ref="05932219411c169f9e48f874e56f1ed3" category="inline-link-rx"></block> .</block>
  <block id="6b9617f7154782faea34239e9eb5ea4a" category="paragraph"><block ref="6b9617f7154782faea34239e9eb5ea4a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0e6dc629616db1f269870318e89e7522" category="summary">Open Source MLOps mit NetApp – Beispiel-Workflow – Trainieren Sie ein Bilderkennungsmodell mit Kubeflow und dem NetApp DataOps Toolkit</block>
  <block id="659e23f00660c05c4b7cf730eae0befe" category="doc">Beispiel-Workflow – Trainieren eines Bilderkennungsmodells mit Kubeflow und dem NetApp DataOps Toolkit</block>
  <block id="cc799f8653f5775220453347865834a9" category="paragraph">In diesem Abschnitt werden die Schritte zum Trainieren und Bereitstellen eines neuronalen Netzwerks für die Bilderkennung mit Kubeflow und dem NetApp DataOps Toolkit beschrieben.  Dies soll als Beispiel für einen Trainingsjob dienen, der NetApp -Speicher einbezieht.</block>
  <block id="b759ef76b26f922987fbf418c77766cb" category="paragraph">Erstellen Sie eine Docker-Datei mit den erforderlichen Konfigurationen für die Trainings- und Testschritte innerhalb der Kubeflow-Pipeline.  Hier ist ein Beispiel für eine Docker-Datei -</block>
  <block id="d1658ed5f5e35aee28cc518869591c5b" category="paragraph">Installieren Sie je nach Ihren Anforderungen alle erforderlichen Bibliotheken und Pakete, die zum Ausführen des Programms erforderlich sind.  Bevor Sie das Machine-Learning-Modell trainieren, wird davon ausgegangen, dass Sie bereits über eine funktionierende Kubeflow-Bereitstellung verfügen.</block>
  <block id="1d7fb7fa777edda515304ad19af75036" category="section-title">Trainieren Sie ein kleines neuronales Netzwerk anhand von MNIST-Daten mithilfe von PyTorch- und Kubeflow-Pipelines</block>
  <block id="a2d6c085b2bfbb3fc92caceedba6806e" category="paragraph">Wir verwenden das Beispiel eines kleinen neuronalen Netzwerks, das mit MNIST-Daten trainiert wurde.  Der MNIST-Datensatz besteht aus handschriftlichen Bildern der Ziffern 0-9.  Die Bilder haben eine Größe von 28 x 28 Pixel.  Der Datensatz ist in 60.000 Zugbilder und 10.000 Validierungsbilder unterteilt.  Das für dieses Experiment verwendete neuronale Netzwerk ist ein zweischichtiges Feedforward-Netzwerk.  Das Training wird mithilfe von Kubeflow Pipelines durchgeführt. Weitere Informationen finden Sie in der Dokumentation<block ref="bcb10ee1db2d847a3cadc06c872375ac" category="inline-link-rx"></block> für weitere Informationen.  Unsere Kubeflow-Pipeline enthält das Docker-Image aus dem Abschnitt „Voraussetzungen“.</block>
  <block id="edfa32db89306c0de4efde13667133a5" category="inline-image-macro">Visualisierung des Kubeflow-Pipeline-Laufs</block>
  <block id="c0bdd0d6d088108de0d2d172bd2f25be" category="paragraph"><block ref="c0bdd0d6d088108de0d2d172bd2f25be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e7d85cbff0f5dec5d5092004b5b8774e" category="section-title">Visualisieren Sie Ergebnisse mit Tensorboard</block>
  <block id="d3246eab9678602f9301a80184803dff" category="inline-link">Tensorboard</block>
  <block id="12e2a8be9c4e17ffc7dc66217d8530ff" category="paragraph">Sobald das Modell trainiert ist, können wir die Ergebnisse mit Tensorboard visualisieren.<block ref="a07862d9a0e51dec9c3587e87c541181" category="inline-link-rx"></block> ist als Funktion im Kubeflow-Dashboard verfügbar.  Sie können ein benutzerdefiniertes Tensorboard für Ihren Job erstellen.  Ein Beispiel unten zeigt die Darstellung der Trainingsgenauigkeit im Vergleich zur Anzahl der Epochen und des Trainingsverlusts im Vergleich zur Anzahl der Epochen.</block>
  <block id="1618fe0e500d9ed850d5e614c6620fd8" category="inline-image-macro">Tensorboard-Diagramm für Trainingsverlust und Genauigkeit</block>
  <block id="cd45b495d2fd4d214ea7c430a9980d0a" category="paragraph"><block ref="cd45b495d2fd4d214ea7c430a9980d0a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cbdd778d6f4497497010df3f4ae35a67" category="section-title">Experimentieren Sie mit Hyperparametern mit Katib</block>
  <block id="a47bff2eb2b867ca89a553eeb14da493" category="paragraph"><block ref="98b590f3a453d1e0809708b45d553c8f" category="inline-link-rx"></block>ist ein Tool innerhalb von Kubeflow, mit dem mit den Hyperparametern des Modells experimentiert werden kann.  Um ein Experiment zu erstellen, definieren Sie zuerst eine gewünschte Metrik/ein gewünschtes Ziel.  Dies ist normalerweise die Testgenauigkeit.  Sobald die Metrik definiert ist, wählen Sie Hyperparameter aus, mit denen Sie herumspielen möchten (Optimierer/Lernrate/Anzahl der Schichten).  Katib führt einen Hyperparameter-Sweep mit den benutzerdefinierten Werten durch, um die beste Parameterkombination zu finden, die die gewünschte Metrik erfüllt.  Sie können diese Parameter in jedem Abschnitt der Benutzeroberfläche definieren.  Alternativ können Sie eine *YAML*-Datei mit den erforderlichen Spezifikationen definieren.  Unten sehen Sie eine Illustration eines Katib-Experiments -</block>
  <block id="70e367edef0d0f2a63f6fff084365aa4" category="inline-image-macro">Katib Experiment Dashboard mit Hyperparametern</block>
  <block id="12f61d15ca34416b644cbd8238634541" category="paragraph"><block ref="12f61d15ca34416b644cbd8238634541" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd53955b02bf4a8bb0a318390df24ae6" category="inline-image-macro">Erfolgreicher Probecheck</block>
  <block id="600782cca16442259d603526a7cd0b29" category="paragraph"><block ref="600782cca16442259d603526a7cd0b29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18d3e96caf95415deff9bb8b5bc25063" category="section-title">Verwenden Sie NetApp Snapshots zum Speichern von Daten zur Rückverfolgbarkeit</block>
  <block id="0b6ef7f84e44ffbb76d4eef1ef587269" category="paragraph">Während des Modelltrainings möchten wir möglicherweise zur Rückverfolgbarkeit einen Snapshot des Trainingsdatensatzes speichern.  Dazu können wir der Pipeline einen Snapshot-Schritt hinzufügen, wie unten gezeigt.  Um den Snapshot zu erstellen, können wir die<block ref="6bc4513613cdc996b868b94d9e9ded69" category="inline-link-rx"></block> .</block>
  <block id="9f205d5330ff4142363e15d261753156" category="inline-image-macro">Code zum Erstellen einer Snapshot-Pipeline in Kubeflow</block>
  <block id="18242bdffd149a4d04c88b7208997f55" category="paragraph"><block ref="18242bdffd149a4d04c88b7208997f55" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe2b6f01ffb206a03c2e0fd0a802a4ca" category="inline-link">NetApp DataOps Toolkit-Beispiel für Kubeflow</block>
  <block id="7ba41dac79bc84ef4a806ce87fc4f97a" category="paragraph">Weitere Informationen finden Sie im <block ref="f0b3c05b3c22509c21d3296c77ee92d9" category="inline-link-rx"></block> für weitere Informationen.</block>
  <block id="8ec1b3ffcff14d3a7476fee4a3e80bbd" category="summary">Open Source MLOps mit NetApp – MLflow-Bereitstellung</block>
  <block id="1e24ddb7a6a8df2478eebd688cf1f1df" category="doc">MLflow-Bereitstellung</block>
  <block id="eba75f7702c8d580f100f5c6e819419a" category="paragraph">In diesem Abschnitt werden die Aufgaben beschrieben, die Sie ausführen müssen, um MLflow in Ihrem Kubernetes-Cluster bereitzustellen.</block>
  <block id="1988a9fc415911c1b6cb091f9672aa99" category="admonition">Es ist möglich, MLflow auf anderen Plattformen als Kubernetes bereitzustellen.  Die Bereitstellung von MLflow auf anderen Plattformen als Kubernetes liegt außerhalb des Umfangs dieser Lösung.</block>
  <block id="effe3b356a9db8beeafdbe3692a3df6b" category="paragraph">MLflow wird mit Helm bereitgestellt, einem beliebten Paketmanager für Kubernetes.  Bevor Sie MLflow bereitstellen, müssen Sie Helm auf Ihrem Kubernetes-Steuerknoten installieren.  Um Helm zu installieren, folgen Sie den<block ref="cf3f65305f288242c9d49061d26ec8ec" category="inline-link-rx"></block> in der offiziellen Helm-Dokumentation.</block>
  <block id="01fb0f36d01f7edcdcc66273b214f218" category="paragraph">Bevor Sie MLflow bereitstellen, müssen Sie eine Standard-StorageClass in Ihrem Kubernetes-Cluster festlegen.  Um eine Standard-StorageClass innerhalb Ihres Clusters festzulegen, folgen Sie den Anweisungen im<block ref="a8e87de8c7ac570587ad7744774f8330" category="inline-link-macro-rx"></block> Abschnitt.  Wenn Sie in Ihrem Cluster bereits eine Standard-StorageClass festgelegt haben, können Sie diesen Schritt überspringen.</block>
  <block id="6369a4aa768b1882566ceb106febe885" category="section-title">MLflow bereitstellen</block>
  <block id="4996360f41c2160eefec53bc938631c4" category="paragraph">Sobald die Voraussetzungen erfüllt sind, können Sie mit der MLflow-Bereitstellung mithilfe des Helm-Diagramms beginnen.</block>
  <block id="9b40c49f5b19b6b30c8e46c9a322cfa9" category="section-title">Konfigurieren Sie die Bereitstellung des MLflow Helm-Diagramms.</block>
  <block id="54662ab0339cacf58980938d0d2997f6" category="paragraph">Bevor wir MLflow mithilfe des Helm-Diagramms bereitstellen, können wir die Bereitstellung so konfigurieren, dass die NetApp Trident Storage Class verwendet wird, und mithilfe einer *config.yaml*-Datei andere Parameter an unsere Anforderungen anpassen.  Ein Beispiel für eine *config.yaml*-Datei finden Sie unter:<block ref="3fb631fe4b90fe5302819c1b11e0f768" category="inline-link-rx"></block></block>
  <block id="3ffd497fc5215b526be90b762ad3c730" category="admonition">Sie können die Trident -Speicherklasse unter dem Parameter *global.defaultStorageClass* in der Datei config.yaml festlegen (z. B. Speicherklasse: „ontap-flexvol“).</block>
  <block id="b0e9e89059c66feb24d2bae1faade5b4" category="section-title">Installieren des Helm-Diagramms</block>
  <block id="e2de44bdf60d5282b2d1f5dce8ef9fb8" category="paragraph">Das Helm-Diagramm kann mit der benutzerdefinierten Datei *config.yaml* für MLflow mithilfe des folgenden Befehls installiert werden:</block>
  <block id="b8fe21ea18633e2ba5c911e2b6c64135" category="admonition">Der Befehl stellt MLflow über die bereitgestellte Datei *config.yaml* in der benutzerdefinierten Konfiguration auf dem Kubernetes-Cluster bereit.  MLflow wird im angegebenen Namespace bereitgestellt und für die Version wird über Kubernetes ein zufälliger Versionsname vergeben.</block>
  <block id="fe92b5543c9bb0daa69543a737a9937a" category="paragraph">Nachdem die Bereitstellung des Helm-Diagramms abgeschlossen ist, können Sie mit folgendem Befehl überprüfen, ob auf den Dienst zugegriffen werden kann:</block>
  <block id="5001194091e3ac05acb36e50188181cd" category="admonition">Ersetzen Sie *jupyterhub* durch den Namespace, den Sie während der Bereitstellung verwendet haben.</block>
  <block id="624995aae5a71a1b6b698d125dfa593f" category="paragraph">Sie sollten die folgenden Dienste sehen:</block>
  <block id="0727c036d98dcf728bf3678abc379532" category="admonition">Wir haben die Datei config.yaml bearbeitet, um den NodePort-Dienst für den Zugriff auf MLflow über Port 30002 zu verwenden.</block>
  <block id="49ed0a1879305290bd3f5a83a6ebc4a2" category="section-title">Zugriff auf MLflow</block>
  <block id="4336069c7c6830c86e24b3590bc33968" category="paragraph">Sobald alle mit MLflow verbundenen Dienste betriebsbereit sind, können Sie über die angegebene NodePort- oder LoadBalancer-IP-Adresse darauf zugreifen (z. B.<block ref="4470100f30fdceb8d4bf43ad086f55fe" prefix=" " category="inline-code"></block> )</block>
  <block id="4cdff711c1556a59f967422b42a85088" category="summary">Open Source MLOps mit NetApp – Dataset-to-Model-Rückverfolgbarkeit mit NetApp und MLflow</block>
  <block id="96ea5f01f5435b957b4ccda05e9edc2a" category="doc">Rückverfolgbarkeit vom Datensatz zum Modell mit NetApp und MLflow</block>
  <block id="49f4e58115751b6e777c0881bed17f7b" category="paragraph">Der<block ref="6bc4513613cdc996b868b94d9e9ded69" category="inline-link-rx"></block> kann in Verbindung mit den Experimentverfolgungsfunktionen von MLflow verwendet werden, um die Rückverfolgbarkeit vom Datensatz zum Modell oder vom Arbeitsbereich zum Modell zu implementieren.</block>
  <block id="a6086bfa36daf4e19b000df54ab1dd1e" category="paragraph">Um die Rückverfolgbarkeit vom Datensatz zum Modell oder vom Arbeitsbereich zum Modell zu implementieren, erstellen Sie im Rahmen Ihres Trainingslaufs einfach einen Snapshot Ihres Datensatzes oder Arbeitsbereichsvolumens mithilfe des DataOps Toolkit, wie im folgenden Beispielcodeausschnitt gezeigt.  Dieser Code speichert den Datenvolumennamen und den Snapshot-Namen als Tags, die mit dem spezifischen Trainingslauf verknüpft sind, den Sie auf Ihrem MLflow-Experiment-Tracking-Server protokollieren.</block>
  <block id="f8e6fa4a88901fdc129b3ce376463f53" category="summary">Open Source MLOps mit NetApp – Ausführen einer synchronen verteilten KI-Workload</block>
  <block id="8725f0c1877790fea82aedbc23e26e70" category="doc">Ausführen einer synchronen verteilten KI-Workload</block>
  <block id="deb7f52575de614a91ae7472b76138ec" category="paragraph">Um einen synchronen Multinode-KI- und ML-Job in Ihrem Kubernetes-Cluster auszuführen, führen Sie die folgenden Aufgaben auf dem Bereitstellungs-Jump-Host aus.  Mit diesem Prozess können Sie die auf einem NetApp -Volume gespeicherten Daten nutzen und mehr GPUs verwenden, als ein einzelner Worker-Knoten bereitstellen kann.  In der folgenden Abbildung sehen Sie eine Darstellung eines synchronen verteilten KI-Jobs.</block>
  <block id="c073d47c72ebccdc821d9e6419b3008c" category="admonition">Synchron verteilte Jobs können im Vergleich zu asynchron verteilten Jobs dazu beitragen, die Leistung und Trainingsgenauigkeit zu verbessern.  Eine Diskussion der Vor- und Nachteile synchroner Jobs gegenüber asynchronen Jobs geht über den Rahmen dieses Dokuments hinaus.</block>
  <block id="dd02d155f88fd3ea2f5dfd5720641a55" category="paragraph"><block ref="dd02d155f88fd3ea2f5dfd5720641a55" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46300fa439cc237919f854816fc89fc2" category="inline-link-macro">Ausführen einer Single-Node-KI-Workload</block>
  <block id="252bb749f76608017bf1d4a822ebba6d" category="list-text">Die folgenden Beispielbefehle zeigen die Erstellung eines Workers, der an der synchronen verteilten Ausführung desselben TensorFlow-Benchmark-Jobs teilnimmt, der im Beispiel im Abschnitt auf einem einzelnen Knoten ausgeführt wurde.<block ref="055e86cc3668b8856dedbd3ee4c3f307" category="inline-link-macro-rx"></block> .  In diesem speziellen Beispiel wird nur ein einziger Worker bereitgestellt, da der Job auf zwei Worker-Knoten ausgeführt wird.</block>
  <block id="8f811f6151a10e9d15de57c2af8fcfed" category="inline-link">offizielle Kubernetes-Dokumentation</block>
  <block id="e3a5f2bdfc8576b6847bcbf0d53889d4" category="paragraph">Dieses Beispiel einer Worker-Bereitstellung erfordert acht GPUs und kann daher auf einem einzelnen GPU-Worker-Knoten ausgeführt werden, der über acht oder mehr GPUs verfügt.  Wenn Ihre GPU-Workerknoten über mehr als acht GPUs verfügen, sollten Sie diese Zahl zur Leistungsmaximierung erhöhen, sodass sie der Anzahl der GPUs Ihrer Workerknoten entspricht.  Weitere Informationen zu Kubernetes-Bereitstellungen finden Sie im<block ref="29c4feb256f061356947baec0e1bfcb2" category="inline-link-rx"></block> .</block>
  <block id="4b59e69845bd812b9cddcb0b700f3680" category="paragraph">In diesem Beispiel wird eine Kubernetes-Bereitstellung erstellt, da dieser spezielle Container-Worker von alleine nie fertig werden würde.  Daher ist es nicht sinnvoll, es mithilfe der Kubernetes-Jobkonstruktion bereitzustellen.  Wenn Ihr Worker so konzipiert oder geschrieben ist, dass er die Aufgabe selbstständig erledigt, kann es sinnvoll sein, zum Bereitstellen Ihres Workers die Jobkonstruktion zu verwenden.</block>
  <block id="57e84b8262eb9db582d9f861e85ed291" category="paragraph">Der in dieser Beispiel-Bereitstellungsspezifikation angegebene Pod erhält eine<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block> Wert von<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> .  Dieser Wert bedeutet, dass der Pod den Netzwerkstapel des Host-Workerknotens anstelle des virtuellen Netzwerkstapels verwendet, den Kubernetes normalerweise für jeden Pod erstellt.  Diese Anmerkung wird in diesem Fall verwendet, da die spezifische Arbeitslast auf Open MPI, NCCL und Horovod angewiesen ist, um die Arbeitslast synchron und verteilt auszuführen.  Daher ist Zugriff auf den Host-Netzwerkstapel erforderlich.  Eine Diskussion über Open MPI, NCCL und Horovod geht über den Rahmen dieses Dokuments hinaus.  Ob dies<block ref="02cbe2b15bc778c7658250053bbc5a5c" prefix=" " category="inline-code"></block> Ob eine Annotation erforderlich ist, hängt von den Anforderungen der spezifischen Arbeitslast ab, die Sie ausführen.  Weitere Informationen zum<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block> Feld finden Sie im<block ref="f46b1bf9e67570ceac06230c1e502909" category="inline-link-rx"></block> .</block>
  <block id="b3f8c0432fa807543e6e24f429362a32" category="list-text">Bestätigen Sie, dass die in Schritt 1 erstellte Worker-Bereitstellung erfolgreich gestartet wurde.  Die folgenden Beispielbefehle bestätigen, dass ein einzelner Worker-Pod für die Bereitstellung erstellt wurde, wie in der Bereitstellungsdefinition angegeben, und dass dieser Pod derzeit auf einem der GPU-Worker-Knoten ausgeführt wird.</block>
  <block id="77fed810b2a592adcab667c30e5c0bdb" category="list-text">Erstellen Sie einen Kubernetes-Job für einen Master, der den synchronen Multinode-Job startet, daran teilnimmt und seine Ausführung verfolgt.  Die folgenden Beispielbefehle erstellen einen Master, der die synchrone verteilte Ausführung desselben TensorFlow-Benchmark-Jobs startet, daran teilnimmt und verfolgt, der im Beispiel im Abschnitt auf einem einzelnen Knoten ausgeführt wurde.<block ref="055e86cc3668b8856dedbd3ee4c3f307" category="inline-link-macro-rx"></block> .</block>
  <block id="4161928cbea20386310894ea85fd3711" category="paragraph">Dieser beispielhafte Masterjob fordert acht GPUs an und kann daher auf einem einzelnen GPU-Workerknoten ausgeführt werden, der über acht oder mehr GPUs verfügt.  Wenn Ihre GPU-Workerknoten über mehr als acht GPUs verfügen, sollten Sie diese Zahl zur Leistungsmaximierung erhöhen, sodass sie der Anzahl der GPUs Ihrer Workerknoten entspricht.</block>
  <block id="3e04ef9469e6953d66ae9c7536ed9b26" category="paragraph">Der in dieser Beispiel-Jobdefinition angegebene Master-Pod erhält einen<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block> Wert von<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> , genau wie die Arbeiterkapsel eine<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block> Wert von<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> in Schritt 1.  Einzelheiten dazu, warum dieser Wert erforderlich ist, finden Sie in Schritt 1.</block>
  <block id="8600ba20f40fb5668a1b2c02f92e220d" category="list-text">Bestätigen Sie, dass der in Schritt 3 erstellte Masterjob ordnungsgemäß ausgeführt wird.  Der folgende Beispielbefehl bestätigt, dass für den Job ein einzelner Master-Pod erstellt wurde, wie in der Jobdefinition angegeben, und dass dieser Pod derzeit auf einem der GPU-Worker-Knoten ausgeführt wird.  Sie sollten auch sehen, dass der Worker-Pod, den Sie ursprünglich in Schritt 1 gesehen haben, noch ausgeführt wird und dass die Master- und Worker-Pods auf verschiedenen Knoten ausgeführt werden.</block>
  <block id="0f27ae3c630b411ce8f8dc123361f1b1" category="list-text">Bestätigen Sie, dass der in Schritt 3 erstellte Masterjob erfolgreich abgeschlossen wurde.  Die folgenden Beispielbefehle bestätigen, dass der Auftrag erfolgreich abgeschlossen wurde.</block>
  <block id="6fe5035373f479ed2a1c1d457e64ae9d" category="list-text">Löschen Sie die Worker-Bereitstellung, wenn Sie sie nicht mehr benötigen.  Die folgenden Beispielbefehle zeigen das Löschen des in Schritt 1 erstellten Worker-Bereitstellungsobjekts.</block>
  <block id="e3861d1527373e7d8eeea1704f818a15" category="paragraph">Wenn Sie das Worker-Bereitstellungsobjekt löschen, löscht Kubernetes automatisch alle zugehörigen Worker-Pods.</block>
  <block id="7e4d2c0ae78fc38eeb38ffe12f736290" category="list-text">*Optional:* Bereinigen Sie die Master-Job-Artefakte.  Die folgenden Beispielbefehle zeigen das Löschen des in Schritt 3 erstellten Master-Job-Objekts.</block>
  <block id="d844794bfc5a0949dc2c38fecacf9ff1" category="paragraph">Wenn Sie das Master-Job-Objekt löschen, löscht Kubernetes automatisch alle zugehörigen Master-Pods.</block>
  <block id="3b1ef0ea9661ba5d2eeba15fab13cf00" category="summary">Open Source MLOps mit NetApp – Ausführen einer Single-Node-KI-Workload</block>
  <block id="9e339bbe1fec0fc2a91b7c2f8dd9d7f7" category="paragraph">Um einen KI- und ML-Job mit einem Knoten in Ihrem Kubernetes-Cluster auszuführen, führen Sie die folgenden Aufgaben vom Bereitstellungs-Jump-Host aus.  Mit Trident können Sie schnell und einfach ein Datenvolumen, das möglicherweise Petabyte an Daten enthält, für eine Kubernetes-Workload zugänglich machen.  Um ein solches Datenvolumen innerhalb eines Kubernetes-Pods zugänglich zu machen, geben Sie einfach einen PVC in der Pod-Definition an.</block>
  <block id="e3305581bc1f67d1989e08e42a43c113" category="admonition">In diesem Abschnitt wird davon ausgegangen, dass Sie die spezifische KI- und ML-Workload, die Sie in Ihrem Kubernetes-Cluster ausführen möchten, bereits containerisiert haben (im Docker-Containerformat).</block>
  <block id="6bdbab1141be3c52dec1f29c4c5fdf52" category="inline-link">ImageNet-Website</block>
  <block id="08eb6cc7203ec1b36805e4767d450467" category="list-text">Die folgenden Beispielbefehle zeigen die Erstellung eines Kubernetes-Jobs für eine TensorFlow-Benchmark-Workload, die den ImageNet-Datensatz verwendet.  Weitere Informationen zum ImageNet-Datensatz finden Sie im<block ref="19a9693db577a40175aef26761f77fe7" category="inline-link-rx"></block> .</block>
  <block id="56920225f5c2d474925baad76ae3e7ce" category="paragraph">Dieser Beispieljob erfordert acht GPUs und kann daher auf einem einzelnen GPU-Workerknoten ausgeführt werden, der über acht oder mehr GPUs verfügt.  Dieser Beispieljob könnte in einem Cluster übermittelt werden, für den kein Worker-Knoten mit acht oder mehr GPUs vorhanden ist oder der derzeit mit einer anderen Arbeitslast belegt ist.  Wenn dies der Fall ist, verbleibt der Job im ausstehenden Status, bis ein solcher Worker-Knoten verfügbar wird.</block>
  <block id="dd36f0d653a70e6e6c7e838454ee7e20" category="paragraph">Um die Speicherbandbreite zu maximieren, wird das Volume, das die benötigten Trainingsdaten enthält, außerdem zweimal innerhalb des Pods gemountet, den dieser Job erstellt.  Ein weiteres Volumen ist ebenfalls in der Kapsel montiert.  Dieses zweite Volume wird zum Speichern von Ergebnissen und Metriken verwendet.  Auf diese Datenträger wird in der Jobdefinition mithilfe der Namen der PVCs verwiesen.  Weitere Informationen zu Kubernetes-Jobs finden Sie im<block ref="0ceaf9ba0112a862c5fa5f8d38bee04b" category="inline-link-rx"></block> .</block>
  <block id="c1cf1b159caffa27246be2b5201cdd54" category="paragraph">Ein<block ref="77ea5ef86c2c650eb37fa7374f084bbc" prefix=" " category="inline-code"></block> Volumen mit einem<block ref="075a3e36a0a52dcbc568c05788e8a713" prefix=" " category="inline-code"></block> Wert von<block ref="4789f23283b3a61f858b641a1bef19a3" prefix=" " category="inline-code"></block> ist montiert an<block ref="edd846be807ebc0ca06f1fcb0258172c" prefix=" " category="inline-code"></block> im Pod, den dieser Beispieljob erstellt.  Die Standardgröße des<block ref="edd846be807ebc0ca06f1fcb0258172c" prefix=" " category="inline-code"></block> Das von der Docker-Container-Laufzeit automatisch erstellte virtuelle Volume kann für die Anforderungen von TensorFlow manchmal nicht ausreichen.  Montage eines<block ref="77ea5ef86c2c650eb37fa7374f084bbc" prefix=" " category="inline-code"></block> Volumen wie im folgenden Beispiel bietet eine ausreichend große<block ref="edd846be807ebc0ca06f1fcb0258172c" prefix=" " category="inline-code"></block> virtuelles Volume.  Weitere Informationen zu<block ref="77ea5ef86c2c650eb37fa7374f084bbc" prefix=" " category="inline-code"></block> Bände finden Sie im<block ref="ad2ab91baa5517930a567ac7588e61fd" category="inline-link-rx"></block> .</block>
  <block id="ac5f33311bbfb696a5966510fc4a38b8" category="paragraph">Der einzelne Container, der in dieser Beispiel-Jobdefinition angegeben ist, erhält eine<block ref="616a0bdac22bb48049712f2f41741fd1" prefix=" " category="inline-code"></block> Wert von<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> .  Dieser Wert bedeutet, dass der Container effektiv Root-Zugriff auf dem Host hat.  Diese Anmerkung wird in diesem Fall verwendet, da für die spezifische Arbeitslast, die ausgeführt wird, Root-Zugriff erforderlich ist.  Insbesondere erfordert ein Cache-Löschvorgang, den die Arbeitslast durchführt, Root-Zugriff.  Ob dies<block ref="8be504a312b42bc24ff61c9c2c31990d" prefix=" " category="inline-code"></block> Ob eine Annotation erforderlich ist, hängt von den Anforderungen der spezifischen Arbeitslast ab, die Sie ausführen.</block>
  <block id="8db728b0062c29a77e48bcd3be77be7f" category="list-text">Bestätigen Sie, dass der in Schritt 1 erstellte Job ordnungsgemäß ausgeführt wird.  Der folgende Beispielbefehl bestätigt, dass ein einzelner Pod für den Job erstellt wurde, wie in der Jobdefinition angegeben, und dass dieser Pod derzeit auf einem der GPU-Workerknoten ausgeführt wird.</block>
  <block id="7b2880ed5066d8fda6f6d5a4ec8f39ac" category="list-text">Bestätigen Sie, dass der in Schritt 1 erstellte Job erfolgreich abgeschlossen wurde.  Die folgenden Beispielbefehle bestätigen, dass der Auftrag erfolgreich abgeschlossen wurde.</block>
  <block id="bead823acab8a06d478eb02c7ff84d35" category="list-text">*Optional:* Bereinigen Sie Jobartefakte.  Die folgenden Beispielbefehle zeigen das Löschen des in Schritt 1 erstellten Jobobjekts.</block>
  <block id="cb215cf0e9fb88bd1fc97b4ba53fd36f" category="paragraph">Wenn Sie das Jobobjekt löschen, löscht Kubernetes automatisch alle zugehörigen Pods.</block>
  <block id="91ab0152618ead1fcdc42eff8c2d0735" category="summary">Open Source MLOps mit NetApp – Beispiel Trident -Backends für NetApp AIPod Bereitstellungen</block>
  <block id="9137107e8d97a11b9174eb6766c2051f" category="doc">Beispiele für Trident -Backends für NetApp AIPod -Bereitstellungen</block>
  <block id="bf498d2b211c45a57e0eaa477b958b58" category="inline-link-macro">NetApp AIPod</block>
  <block id="8b57fa6d8107ac5ef8cc72bed591a355" category="paragraph">Bevor Sie Trident zur dynamischen Bereitstellung von Speicherressourcen in Ihrem Kubernetes-Cluster verwenden können, müssen Sie ein oder mehrere Trident -Backends erstellen.  Die folgenden Beispiele stellen verschiedene Arten von Backends dar, die Sie möglicherweise erstellen möchten, wenn Sie Komponenten dieser Lösung auf einem<block ref="b2fcf1ac0e8df6bdaefce420e27d6368" category="inline-link-macro-rx"></block> .  Weitere Informationen zu Backends und beispielsweise Backends für andere Plattformen/Umgebungen finden Sie im<block ref="81f3e4134a6f5ebea4459e5f629a42dc" category="inline-link-macro-rx"></block> .</block>
  <block id="5bce19d939aea54f55df565bb07b573b" category="list-text">NetApp empfiehlt die Erstellung eines FlexGroup-fähigen Trident -Backends für Ihren AIPod.</block>
  <block id="987adc3703d1f7aeb77e70a3d25e35ca" category="paragraph">Die folgenden Beispielbefehle zeigen die Erstellung eines FlexGroup-fähigen Trident -Backends für eine AIPod -Speicher-Virtual-Machine (SVM).  Dieses Backend verwendet die<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> Speichertreiber.  ONTAP unterstützt zwei Hauptdatenvolumentypen: FlexVol und FlexGroup.  FlexVol -Volumes sind größenbeschränkt (zum Zeitpunkt der Erstellung dieses Dokuments hängt die maximale Größe von der jeweiligen Bereitstellung ab).  FlexGroup -Volumes hingegen können linear auf bis zu 20 PB und 400 Milliarden Dateien skaliert werden und bieten einen einzigen Namespace, der die Datenverwaltung erheblich vereinfacht.  Daher sind FlexGroup Volumes optimal für KI- und ML-Workloads, die auf großen Datenmengen basieren.</block>
  <block id="ba9f56aafb45a750a8dffe5de6d2ed78" category="paragraph">Wenn Sie mit einer kleinen Datenmenge arbeiten und FlexVol -Volumes anstelle von FlexGroup Volumes verwenden möchten, können Sie Trident -Backends erstellen, die die<block ref="8321592ce24c8a122ecf26a63cfca407" prefix=" " category="inline-code"></block> Speichertreiber anstelle des<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> Speichertreiber.</block>
  <block id="112efecf6dc8105639ea7e0b2a19f0e1" category="list-text">NetApp empfiehlt außerdem die Erstellung eines FlexVol-fähigen Trident Backends.  Möglicherweise möchten Sie FlexVol -Volumes zum Hosten persistenter Anwendungen, zum Speichern von Ergebnissen, Ausgaben, Debug-Informationen usw. verwenden.  Wenn Sie FlexVol Volumes verwenden möchten, müssen Sie ein oder mehrere FlexVol-fähige Trident Backends erstellen.  Die folgenden Beispielbefehle zeigen die Erstellung eines einzelnen FlexVol-fähigen Trident Backends.</block>
  <block id="860fee506515550a9fba4086f9358bf0" category="summary">Open Source MLOps mit NetApp – Beispiel Trident Operations</block>
  <block id="3642f282b12269091ab196a3aabf0858" category="doc">Beispiel für Trident -Operationen</block>
  <block id="7f41e102595a65d30401b887b75060a4" category="paragraph">Dieser Abschnitt enthält Beispiele für verschiedene Vorgänge, die Sie möglicherweise mit Trident durchführen möchten.</block>
  <block id="5a95bc44d2d93c77b65585a52a71d631" category="section-title">Importieren eines vorhandenen Volumes</block>
  <block id="37e60d34ab15afa59aac0989309fc77a" category="paragraph">Wenn auf Ihrem NetApp Speichersystem/Ihrer NetApp-Speicherplattform Volumes vorhanden sind, die Sie auf Containern innerhalb Ihres Kubernetes-Clusters mounten möchten, die aber nicht an PVCs im Cluster gebunden sind, müssen Sie diese Volumes importieren.  Sie können die Volume-Importfunktion von Trident verwenden, um diese Volumes zu importieren.</block>
  <block id="8a87b71bee3405ddd29416b675ef7c61" category="paragraph">Die folgenden Beispielbefehle zeigen den Import eines Volumes mit dem Namen<block ref="49f0544a1f0d45f5d68ad2e883eaec4a" prefix=" " category="inline-code"></block> .  Weitere Informationen zu PVCs finden Sie im<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block> .  Weitere Informationen zur Funktion zum Importieren von Volumes finden Sie im<block ref="7e5b92b70f9fb8a6ea9680492953995f" category="inline-link-rx"></block> .</block>
  <block id="313da63dfeb95842dd6a105fdcf40ebc" category="paragraph">Ein<block ref="1963d17f24888bdf1f22d7ea7f72f607" prefix=" " category="inline-code"></block> Wert von<block ref="c24ad3d99a666c95edd149419c958ee0" prefix=" " category="inline-code"></block> ist in den Beispiel-PVC-Spezifikationsdateien angegeben.  Weitere Informationen zum<block ref="556f4fe5afbf7b3614f70dcf9e38c44c" prefix=" " category="inline-code"></block> Feld finden Sie im<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block> .</block>
  <block id="533fff63e0b7486b2768ad15b5e2981c" category="section-title">Bereitstellen eines neuen Volumes</block>
  <block id="6b2d9cc0e6416b1fddc173d87e1ebad4" category="paragraph">Sie können Trident verwenden, um ein neues Volume auf Ihrem NetApp Speichersystem oder Ihrer NetApp-Plattform bereitzustellen.</block>
  <block id="4268e244b7de91b44bea226a48855c28" category="section-title">Bereitstellen eines neuen Volumes mit kubectl</block>
  <block id="d5c5993dfd543be5e01f6d98516d64cb" category="paragraph">Die folgenden Beispielbefehle zeigen die Bereitstellung eines neuen FlexVol volume mit kubectl.</block>
  <block id="78b7c8c28867630a421236d6f1ff9ba3" category="paragraph">Ein<block ref="1963d17f24888bdf1f22d7ea7f72f607" prefix=" " category="inline-code"></block> Wert von<block ref="caa8dc1f4bb28d2d11226494cd05a123" prefix=" " category="inline-code"></block> ist in der folgenden Beispiel-PVC-Definitionsdatei angegeben.  Weitere Informationen zum<block ref="556f4fe5afbf7b3614f70dcf9e38c44c" prefix=" " category="inline-code"></block> Feld finden Sie im<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block> .</block>
  <block id="3b12f01a10ad45fb526861fc286c7953" category="section-title">Bereitstellen eines neuen Volumes mit dem NetApp DataOps Toolkit</block>
  <block id="55876228853abf632dec9346a4f372ec" category="inline-link-macro">Dokumentation</block>
  <block id="b1e49394b547d60433afdf0d608bc52b" category="paragraph">Sie können auch das NetApp DataOps Toolkit für Kubernetes verwenden, um ein neues Volume auf Ihrem NetApp -Speichersystem oder Ihrer NetApp-Plattform bereitzustellen.  Das NetApp DataOps Toolkit für Kubernetes nutzt Trident zur Bereitstellung von Volumes, vereinfacht den Prozess für den Benutzer jedoch. Weitere Informationen finden Sie im<block ref="37e4d77423419479f43c92e2fdd640ea" category="inline-link-macro-rx"></block> für Details.</block>
  <block id="fdc02d1c80a87a40b5361ca1abf33964" category="summary">Open Source MLOps mit NetApp – Beispielhafte Kubernetes StorageClasses für NetApp AIPod Bereitstellungen</block>
  <block id="d25894e802e87270d1f6b560c3332055" category="doc">Beispiele für Kubernetes-Speicherklassen für NetApp AIPod Bereitstellungen</block>
  <block id="98384d229f6fec246185f9bfa14fcb7a" category="paragraph">Bevor Sie Trident verwenden können, um Speicherressourcen in Ihrem Kubernetes-Cluster dynamisch bereitzustellen, müssen Sie eine oder mehrere Kubernetes-StorageClasses erstellen.  Die folgenden Beispiele stellen verschiedene Arten von StorageClasses dar, die Sie möglicherweise erstellen möchten, wenn Sie Komponenten dieser Lösung auf einem<block ref="b2fcf1ac0e8df6bdaefce420e27d6368" category="inline-link-macro-rx"></block> .  Weitere Informationen zu StorageClasses und beispielsweise StorageClasses für andere Plattformen/Umgebungen finden Sie im<block ref="81f3e4134a6f5ebea4459e5f629a42dc" category="inline-link-macro-rx"></block> .</block>
  <block id="3f91a2c4d8ba66304e817a6c1c8d8086" category="inline-link-macro">NFS über RDMA</block>
  <block id="5f9e4626ef73df529e1be620feb3c403" category="list-text">NetApp empfiehlt die Erstellung einer StorageClass für das FlexGroup-fähige Trident Backend, das Sie im Abschnitt<block ref="ba9f980165fbda795fa9abfedd793128" category="inline-link-macro-rx"></block> , Schritt 1.  Die folgenden Beispielbefehle zeigen die Erstellung mehrerer StorageClasses, die dem Beispiel-Backend entsprechen, das im Abschnitt erstellt wurde.<block ref="ba9f980165fbda795fa9abfedd793128" category="inline-link-macro-rx"></block> , Schritt 1 - einer, der nutzt<block ref="2f98f20aaeb2334cc6d03f1e60eea86f" category="inline-link-macro-rx"></block> und eine, die das nicht tut.</block>
  <block id="d9348d075dc7b3c91cff99d56dfc327b" category="inline-link">Kubernetes-Dokumentation</block>
  <block id="063f66d6e76f1f9cc44a56824e67f49c" category="paragraph">Damit ein persistentes Volume nicht gelöscht wird, wenn der entsprechende PersistentVolumeClaim (PVC) gelöscht wird, verwendet das folgende Beispiel ein<block ref="fa29931471789c6ada456d62b5bc803a" prefix=" " category="inline-code"></block> Wert von<block ref="afece4245269582cb2f1009d4fb52047" prefix=" " category="inline-code"></block> .  Weitere Informationen zum<block ref="fa29931471789c6ada456d62b5bc803a" prefix=" " category="inline-code"></block> Feld, siehe die offizielle<block ref="2b8f9bbf9efeff879b3debc5484f0056" category="inline-link-rx"></block> .</block>
  <block id="b1c0c18c267e82c16a2fb0fd855fea96" category="paragraph">Hinweis: Die folgenden Beispiel-StorageClasses verwenden eine maximale Übertragungsgröße von 262144.  Um diese maximale Übertragungsgröße zu verwenden, müssen Sie die maximale Übertragungsgröße auf Ihrem ONTAP System entsprechend konfigurieren. Weitere Informationen finden Sie im<block ref="e88143f84eca8f5af17b24d59e272642" category="inline-link-macro-rx"></block> für Details.</block>
  <block id="611c47063b50d4e29ff14b57ac5d1a76" category="paragraph">Hinweis: Um NFS über RDMA zu verwenden, müssen Sie NFS über RDMA auf Ihrem ONTAP System konfigurieren. Weitere Informationen finden Sie im<block ref="299f3386ca6234337ede91409b59779f" category="inline-link-macro-rx"></block> für Details.</block>
  <block id="8dffb2755e3c128c00970dd619da5b34" category="paragraph">Hinweis: Im folgenden Beispiel wird im Feld „storagePool“ in der StorageClass-Definitionsdatei ein bestimmtes Backend angegeben.</block>
  <block id="cce8016ccbbe58eeb47eb8596b78018e" category="inline-link-macro">Beispiele für Trident -Backends für AIPod -Bereitstellungen</block>
  <block id="6c9233cf2164bf9b74bbca02d5360c85" category="list-text">NetApp empfiehlt außerdem die Erstellung einer StorageClass, die dem FlexVol-fähigen Trident Backend entspricht, das Sie im Abschnitt<block ref="f93f354f4df9d1f116edb5ebdff3f7d5" category="inline-link-macro-rx"></block> , Schritt 2.  Die folgenden Beispielbefehle zeigen die Erstellung einer einzelnen StorageClass für FlexVol -Volumes.</block>
  <block id="fc614170d6c05a82aef1df8658cdddbb" category="paragraph">Hinweis: Im folgenden Beispiel ist im Feld „storagePool“ in der StorageClass-Definitionsdatei kein bestimmtes Backend angegeben.  Wenn Sie Kubernetes verwenden, um Volumes mit dieser StorageClass zu verwalten, versucht Trident , jedes verfügbare Backend zu verwenden, das die<block ref="8321592ce24c8a122ecf26a63cfca407" prefix=" " category="inline-code"></block> Treiber.</block>
  <block id="3ad98aba8e7b278dbcb8d707671576f7" category="list-text">Klonen Sie JupyterLab-Arbeitsbereiche mit hoher Kapazität nahezu augenblicklich, um Experimente oder schnelle Iterationen zu ermöglichen.</block>
  <block id="85ca8d103a016e6e8898855c4ecfa6e2" category="list-text">Speichern Sie Snapshots von JupyterLab-Arbeitsbereichen mit hoher Kapazität nahezu augenblicklich für Backups und/oder Rückverfolgbarkeit/Baselining.</block>
  <block id="60a1b5ff80d3333df7174eb4d8d7f4e1" category="list-text">Stellen Sie Datenvolumes mit hoher Kapazität und hoher Leistung nahezu augenblicklich bereit, klonen Sie sie und erstellen Sie Snapshots davon.</block>
  <block id="c4bca757471e0afa8bcb4da8a5f5e802" category="paragraph"><block ref="c4bca757471e0afa8bcb4da8a5f5e802" category="inline-link-macro-rx"></block></block>
  <block id="e74b9287ad8cc207ad48fbfdff9cf078" category="summary">Fazit – Vector Datenbanklösung für NetApp</block>
  <block id="b4eb3fd5fa52ba6b8d0eac43bac21d6f" category="paragraph">Dieser Abschnitt schließt die Vektordatenbanklösung für NetApp ab.</block>
  <block id="ec77b1d1c933a6b137ec223a695b5ace" category="paragraph">Zusammenfassend bietet dieses Dokument einen umfassenden Überblick über die Bereitstellung und Verwaltung von Vektordatenbanken wie Milvus und pgvector auf NetApp -Speicherlösungen.  Wir haben die Infrastrukturrichtlinien für die Nutzung von NetApp ONTAP und StorageGRID Objektspeicher besprochen und die Milvus-Datenbank in AWS FSx ONTAP über Datei- und Objektspeicher validiert.</block>
  <block id="9799eea6b7d21ae2ad3b8f14f6de8b57" category="paragraph">Wir haben die Datei-Objekt-Dualität von NetApp untersucht und ihren Nutzen nicht nur für Daten in Vektordatenbanken, sondern auch für andere Anwendungen demonstriert.  Wir haben auch hervorgehoben, wie SnapCenter, das Enterprise-Management-Produkt von NetApp, Sicherungs-, Wiederherstellungs- und Klonfunktionen für Vektordatenbankdaten bietet und so die Datenintegrität und -verfügbarkeit gewährleistet.</block>
  <block id="31068d7cc739be3f40f71a1c2165b247" category="paragraph">Das Dokument erläutert außerdem, wie die Hybrid Cloud-Lösung von NetApp Datenreplikation und -schutz in lokalen und Cloud-Umgebungen bietet und so ein nahtloses und sicheres Datenmanagement ermöglicht.  Wir gaben Einblicke in die Leistungsvalidierung von Vektordatenbanken wie Milvus und pgvecto auf NetApp ONTAP und lieferten wertvolle Informationen zu ihrer Effizienz und Skalierbarkeit.</block>
  <block id="48b5d59439c5cbfd986de5db0e4585aa" category="paragraph">Abschließend haben wir zwei Anwendungsfälle für generative KI besprochen: RAG mit LLM und die interne ChatAI von NetApp.  Diese praktischen Beispiele unterstreichen die realen Anwendungen und Vorteile der in diesem Dokument beschriebenen Konzepte und Praktiken.  Insgesamt dient dieses Dokument als umfassender Leitfaden für alle, die die leistungsstarken Speicherlösungen von NetApp für die Verwaltung von Vektordatenbanken nutzen möchten.</block>
  <block id="95ab8b5192fec6278c61d897cbcc59b7" category="paragraph">Der Autor möchte den unten aufgeführten Mitwirkenden und anderen Personen, die durch ihr Feedback und ihre Kommentare dazu beigetragen haben, dass dieses Dokument für NetApp Kunden und NetApp Bereiche wertvoll ist, herzlich danken.</block>
  <block id="cf069f89f8b650e3f6d927f7417a21f1" category="list-text">Sathish Thyagarajan, technischer Marketingingenieur, ONTAP AI &amp; Analytics, NetApp</block>
  <block id="74f47434914d29c7ec7d7d42593303b7" category="list-text">Mike Oglesby, Technischer Marketingingenieur, NetApp</block>
  <block id="633e7060d92a08658a3f5248a7c7cdf2" category="list-text">AJ Mahajan, Senior Director, NetApp</block>
  <block id="4963f582fdf68104e20554eb28bcf2ca" category="list-text">Joe Scott, Manager, Workload Performance Engineering, NetApp</block>
  <block id="710fcc80e2c0809a7239d471028d8f70" category="list-text">Puneet Dhawan, Senior Director, Produktmanagement Fsx, NetApp</block>
  <block id="7b62519a4ae964c6b307925c68166ca7" category="list-text">Yuval Kalderon, Senior Product Manager, FSx-Produktteam, NetApp</block>
  <block id="b97cdeb80b669ea57564c9bf0542d2ef" category="list-text">Milvus-Dokumentation -<block ref="35e085709f47cfca6bbc0746cd0ba49f" category="inline-link-rx"></block></block>
  <block id="f7356e8678620084b93884e3b7a23a9f" category="list-text">Eigenständige Milvus-Dokumentation -<block ref="a47fb3f2bfaa36fa0b44dc5f5ba452a4" category="inline-link-rx"></block></block>
  <block id="8b8bc5296c7be638754abb2f408d2099" category="list-text">NetApp Produktdokumentation<block ref="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link-rx"></block></block>
  <block id="3852b719e664b2ae1596e622f21daba3" category="inline-link-macro">Installclustr-Dokumentation</block>
  <block id="9351f6d4d819e15d23724c78a36aea99" category="list-text">instaclustr -<block ref="39b68163c56ae9979050121a6264d765" category="inline-link-macro-rx"></block></block>
  <block id="3b3d7bce734c0832c20ba464b1f2d199" category="cell">April 2024</block>
  <block id="123ffe6774f72f5d1c22607445987e46" category="summary">Daten für die Vektordatenbanklösung für NetApp vorbereiten</block>
  <block id="f7ab9b609aa315a4d224e6e33b2a10ee" category="doc">Anhang B: prepare_data_netapp_new.py</block>
  <block id="8d5099e275cc435c14417dc8e6bd49aa" category="paragraph">Dieser Abschnitt enthält ein Beispiel-Python-Skript zum Vorbereiten von Daten für die Vektordatenbank.</block>
  <block id="fe51a53701c4e0dd7696bed40b6f70db" category="summary">Vector-Datenbank-Bereitstellungsverfahren - Vector-Datenbanklösung für NetApp</block>
  <block id="19988795e8f88dfff005718f72472b6c" category="paragraph">In diesem Abschnitt wird das Bereitstellungsverfahren für die Vektordatenbanklösung für NetApp erläutert.</block>
  <block id="fa0b3671f099fc4fc4fbe3ac8374d92c" category="section-title">Bereitstellungsverfahren</block>
  <block id="b63c54c37cdb817c256ef1a7e50fc5fe" category="paragraph">In diesem Bereitstellungsabschnitt haben wir die Milvus-Vektordatenbank mit Kubernetes für die Laboreinrichtung wie unten beschrieben verwendet.</block>
  <block id="e275837fe1aa897ebc01eed7a7354278" category="paragraph"><block ref="e275837fe1aa897ebc01eed7a7354278" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76b4b9b6998f8b3056b486430aa9c6fd" category="paragraph">Der NetApp-Speicher stellt den Speicherplatz für den Cluster bereit, um Kundendaten und Milvus-Clusterdaten aufzubewahren.</block>
  <block id="46d201d3a5d870036bd7573752054979" category="section-title">NetApp -Speichereinrichtung – ONTAP</block>
  <block id="1fa9de5db47759d3e586f783f647d3e8" category="paragraph">Bitte befolgen Sie die folgenden Schritte für NFS (Network File System):</block>
  <block id="932d306add3eb18c39b41633590f1ad6" category="list-text">Erstellen Sie ein FlexGroup -Volume für NFSv4.  In unserem Setup für diese Validierung haben wir 48 SSDs verwendet, 1 SSD speziell für das Root-Volume des Controllers und 47 SSDs verteilt für NFSv4]].Überprüfen Sie, ob die NFS-Exportrichtlinie für das FlexGroup -Volume Lese-/Schreibberechtigungen für das Kubernetes-Knotennetzwerk (K8s) hat.  Wenn diese Berechtigungen nicht vorhanden sind, erteilen Sie Lese-/Schreibberechtigungen (rw) für das K8s-Knotennetzwerk.</block>
  <block id="a53a2ae8c8ba1b0def8ad999e086f94c" category="list-text">Erstellen Sie auf allen K8s-Knoten einen Ordner und mounten Sie das FlexGroup Volume über eine logische Schnittstelle (LIF) auf jedem K8s-Knoten in diesen Ordner.</block>
  <block id="b02cc86a747fc07392e2eceafa48816f" category="paragraph">Bitte befolgen Sie die folgenden Schritte für NAS S3 (Network Attached Storage Simple Storage Service):</block>
  <block id="a1ec6ff754c8c8958a577b43995e9caf" category="list-text">Erstellen Sie ein FlexGroup -Volume für NFS.</block>
  <block id="c550fe4970f3cf4781625e620b4e30a9" category="list-text">Erstellen Sie einen NAS-Bucket, indem Sie seinen Typ auf „nas“ festlegen und den Pfad zum NFSv3-Volume angeben.  Es ist auch möglich, zu diesem Zweck einen S3-Bucket zu verwenden.</block>
  <block id="81f40424ce0b0dbbc91e2bc42bee8924" category="section-title">NetApp -Speichereinrichtung – StorageGRID</block>
  <block id="c8462ad4cf62a8bf6b594e7929097b68" category="list-text">Installieren Sie die storageGRID-Software.</block>
  <block id="aec1f80331e64507a359fd96a93d2dee" category="list-text">Erstellen Sie einen Mandanten und einen Bucket.</block>
  <block id="6eea00d5693e3a2106cc3859939c6e8e" category="list-text">Erstellen Sie einen Benutzer mit der erforderlichen Berechtigung.</block>
  <block id="5288dc14a18d189389b382eda1a7f83a" category="paragraph">Weitere Einzelheiten finden Sie in<block ref="c095f7864703639165de914bdacb9488" category="inline-link-rx"></block></block>
  <block id="1b4b1bbd037e26c942386744e0c37fb6" category="summary">docker-compose.xml – Vektordatenbanklösung für NetApp</block>
  <block id="05b4af2cc796ae07ae3efb49a12abe45" category="doc">Anhang D: docker-compose.yml</block>
  <block id="4f50d45b7589f5ba7443aff7e641e0ce" category="paragraph">Dieser Abschnitt enthält Beispiel-YAML-Code für die Vektordatenbanklösung für NetApp.</block>
  <block id="1746460223f3daa35634698cf8a11429" category="summary">Vector-Datenbankschutz mit Snapcenter – Vector-Datenbanklösung für NetApp</block>
  <block id="72043cdd90d91317b18d2fcdc935eea8" category="doc">Vector-Datenbankschutz mit SnapCenter</block>
  <block id="0cbe53988249acb8210e165c8f9d4ff1" category="paragraph">In diesem Abschnitt wird beschrieben, wie Sie mit NetApp SnapCenter Datenschutz für die Vektordatenbank bereitstellen.</block>
  <block id="62e16ceab82346a15bf6bb06f5076498" category="section-title">Vector-Datenbankschutz mit NetApp SnapCenter.</block>
  <block id="03e2211bf15aaf80440217e34090ab7a" category="paragraph">In der Filmproduktionsbranche beispielsweise verfügen Kunden häufig über kritische eingebettete Daten wie Video- und Audiodateien.  Der Verlust dieser Daten aufgrund von Problemen wie Festplattenausfällen kann erhebliche Auswirkungen auf den Betrieb haben und möglicherweise Multimillionen-Dollar-Projekte gefährden.  Wir sind auf Fälle gestoßen, in denen wertvolle Inhalte verloren gingen, was zu erheblichen Störungen und finanziellen Verlusten führte.  Die Gewährleistung der Sicherheit und Integrität dieser wichtigen Daten ist daher in dieser Branche von größter Bedeutung.  In diesem Abschnitt gehen wir näher darauf ein, wie SnapCenter die in ONTAP gespeicherten Vektordatenbankdaten und Milvus-Daten schützt.  Für dieses Beispiel haben wir einen NAS-Bucket (milvusdbvol1) verwendet, der von einem NFS ONTAP Volume (vol1) für Kundendaten abgeleitet wurde, und ein separates NFS-Volume (vectordbpv) für Milvus-Cluster-Konfigurationsdaten. Bitte überprüfen Sie die<block ref="d81f12ee1ce058489f6dd74377fd8f1e" category="inline-link-macro-rx"></block> für den Snapcenter-Backup-Workflow</block>
  <block id="e159df91d2537b3f0b589d157dfbffd9" category="list-text">Richten Sie den Host ein, der zum Ausführen von SnapCenter -Befehlen verwendet wird.</block>
  <block id="0d3b27c161709a06da0484a310f325e3" category="paragraph"><block ref="0d3b27c161709a06da0484a310f325e3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="00ebf5cec061915cd0462d73602dcad8" category="inline-link-macro">NetApp Automation Store</block>
  <block id="e5dbb47baa2442a0c626c78cd3791dfb" category="list-text">Installieren und konfigurieren Sie das Speicher-Plugin.  Wählen Sie beim hinzugefügten Host „Weitere Optionen“ aus.  Navigieren Sie zum heruntergeladenen Speicher-Plugin und wählen Sie es aus dem<block ref="6d50396c8bd3accea0ce09d72830daea" category="inline-link-macro-rx"></block> .  Installieren Sie das Plugin und speichern Sie die Konfiguration.</block>
  <block id="4225308f0df24ace1516a7673df5f583" category="paragraph"><block ref="4225308f0df24ace1516a7673df5f583" category="inline-image-macro-rx" type="image"></block></block>
  <block id="56efc857e5b28976189acb94af8f4ac8" category="list-text">Richten Sie das Speichersystem und das Volume ein: Fügen Sie unter „Speichersystem“ das Speichersystem hinzu und wählen Sie die SVM (Storage Virtual Machine) aus.  In diesem Beispiel haben wir „vs_nvidia“ gewählt.</block>
  <block id="6d0b2d59ec18c3814b7e5430ff27609f" category="paragraph"><block ref="6d0b2d59ec18c3814b7e5430ff27609f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e2dcb622158143845f18538a410575a" category="list-text">Richten Sie eine Ressource für die Vektordatenbank ein, die eine Sicherungsrichtlinie und einen benutzerdefinierten Snapshot-Namen enthält.</block>
  <block id="a8f4ce53516fd9e67b7eb9a099d49120" category="list-text">Aktivieren Sie die Konsistenzgruppensicherung mit Standardwerten und aktivieren Sie SnapCenter ohne Dateisystemkonsistenz.</block>
  <block id="6230f7a2a3dc9bac46ff1cd677466af1" category="list-text">Wählen Sie im Abschnitt „Speicherbedarf“ die Volumes aus, die mit den Kundendaten der Vektordatenbank und den Milvus-Clusterdaten verknüpft sind.  In unserem Beispiel sind dies „vol1“ und „vectordbpv“.</block>
  <block id="61f90f32ea94cd1e612c6ce7a1713b45" category="list-text">Erstellen Sie eine Richtlinie zum Schutz der Vektordatenbank und schützen Sie die Vektordatenbankressource mithilfe der Richtlinie.</block>
  <block id="de59432e970871e34ec01050d133ea25" category="paragraph"><block ref="de59432e970871e34ec01050d133ea25" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc8a652b9ab6e0d4b7d2a344da503ff6" category="list-text">Fügen Sie mithilfe eines Python-Skripts Daten in den S3 NAS-Bucket ein.  In unserem Fall haben wir das von Milvus bereitgestellte Sicherungsskript „prepare_data_netapp.py“ geändert und den Befehl „sync“ ausgeführt, um die Daten aus dem Betriebssystem zu löschen.</block>
  <block id="3474edc9b3792a7404f86710df9ef875" category="list-text">Überprüfen Sie die Daten im S3 NAS-Bucket.  In unserem Beispiel wurden die Dateien mit dem Zeitstempel „2024-04-08 21:22“ vom Skript „prepare_data_netapp.py“ erstellt.</block>
  <block id="d47a679804c0cbffd0dc44fe5bb8fd17" category="list-text">Starten Sie eine Sicherung mithilfe des Consistency Group (CG)-Snapshots aus der Ressource „milvusdb“.</block>
  <block id="fe4f644e0cbbb28bc2dc58c59ba4712f" category="paragraph"><block ref="fe4f644e0cbbb28bc2dc58c59ba4712f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="511f6b9ef02b86884feaa7670c95ad25" category="list-text">Um die Sicherungsfunktionalität zu testen, haben wir nach dem Sicherungsvorgang entweder eine neue Tabelle hinzugefügt oder einige Daten aus dem NFS (S3 NAS-Bucket) entfernt.</block>
  <block id="b32454a703c99d763bb542ccb4127d18" category="paragraph">Stellen Sie sich für diesen Test ein Szenario vor, in dem jemand nach der Sicherung eine neue, unnötige oder unangemessene Sammlung erstellt hat.  In einem solchen Fall müssten wir die Vektordatenbank auf den Zustand vor dem Hinzufügen der neuen Sammlung zurücksetzen.  Beispielsweise wurden neue Sammlungen wie „hello_milvus_netapp_sc_testnew“ und „hello_milvus_netapp_sc_testnew2“ eingefügt.</block>
  <block id="90fecf651d0359e3ca580f04477241cd" category="list-text">Führen Sie eine vollständige Wiederherstellung des S3 NAS-Buckets aus dem vorherigen Snapshot durch.</block>
  <block id="aad1d0bff0a7a377e2981515a3b2b613" category="paragraph"><block ref="aad1d0bff0a7a377e2981515a3b2b613" category="inline-image-macro-rx" type="image"></block></block>
  <block id="78a091f299be6eaf4277ba82c2e35823" category="list-text">Verwenden Sie ein Python-Skript, um die Daten aus den Sammlungen „hello_milvus_netapp_sc_test“ und „hello_milvus_netapp_sc_test2“ zu überprüfen.</block>
  <block id="d680ce42e26a573726db92b9c2422bcc" category="list-text">Stellen Sie sicher, dass die unnötige oder unangemessene Sammlung nicht mehr in der Datenbank vorhanden ist.</block>
  <block id="9a792fb5937b90853e4c8d032e6cb887" category="paragraph">Zusammenfassend lässt sich sagen, dass die Verwendung von NetApp SnapCenter zum Schutz von Vektordatenbankdaten und Milvus-Daten in ONTAP den Kunden erhebliche Vorteile bietet, insbesondere in Branchen, in denen die Datenintegrität von größter Bedeutung ist, wie beispielsweise in der Filmproduktion.  Die Fähigkeit von SnapCenter, konsistente Backups zu erstellen und vollständige Datenwiederherstellungen durchzuführen, stellt sicher, dass kritische Daten wie eingebettete Video- und Audiodateien vor Verlust durch Festplattenausfälle oder andere Probleme geschützt sind.  Dadurch werden nicht nur Betriebsstörungen vermieden, sondern auch erhebliche finanzielle Verluste vermieden.</block>
  <block id="2f51cfb1dd79ff854c52264b771ee6f7" category="paragraph">In diesem Abschnitt haben wir gezeigt, wie SnapCenter zum Schutz von in ONTAP gespeicherten Daten konfiguriert werden kann, einschließlich der Einrichtung von Hosts, der Installation und Konfiguration von Speicher-Plugins und der Erstellung einer Ressource für die Vektordatenbank mit einem benutzerdefinierten Snapshot-Namen.  Wir haben auch gezeigt, wie man mithilfe des Consistency Group-Snapshots ein Backup durchführt und die Daten im S3 NAS-Bucket überprüft.</block>
  <block id="f3b4f7a7e2767144ed9c5f0d9d729580" category="paragraph">Darüber hinaus haben wir ein Szenario simuliert, in dem nach der Sicherung eine unnötige oder unangemessene Sammlung erstellt wurde.  In solchen Fällen stellt die Fähigkeit von SnapCenter, eine vollständige Wiederherstellung von einem vorherigen Snapshot durchzuführen, sicher, dass die Vektordatenbank in den Zustand vor dem Hinzufügen der neuen Sammlung zurückgesetzt werden kann, wodurch die Integrität der Datenbank gewahrt bleibt.  Diese Möglichkeit, Daten zu einem bestimmten Zeitpunkt wiederherzustellen, ist für Kunden von unschätzbarem Wert, da sie ihnen die Gewissheit gibt, dass ihre Daten nicht nur sicher, sondern auch ordnungsgemäß verwaltet werden.  Somit bietet das SnapCenter -Produkt von NetApp Kunden eine robuste und zuverlässige Lösung für Datenschutz und -verwaltung.</block>
  <block id="8ceee6fd58c3c198cf913f99da69f893" category="summary">Disaster Recovery mit NetApp SnapMirror – Vector-Datenbanklösung für NetApp</block>
  <block id="e55b3630a4d66c6bf27e22779ce5d63e" category="doc">Disaster Recovery mit NetApp SnapMirror</block>
  <block id="86e29a6d4e0a7a64c8112c7cec13c84f" category="paragraph">In diesem Abschnitt wird DR (Disaster Recovery) mit SnapMirror für die Vektordatenbanklösung für NetApp erläutert.</block>
  <block id="b8bf217f690a13ed504fd70caf142a75" category="paragraph"><block ref="b8bf217f690a13ed504fd70caf142a75" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b0f055a15ce6f9f633fb54c0d2436b6" category="paragraph">Die Notfallwiederherstellung ist für die Aufrechterhaltung der Integrität und Verfügbarkeit einer Vektordatenbank von entscheidender Bedeutung, insbesondere angesichts ihrer Rolle bei der Verwaltung hochdimensionaler Daten und der Durchführung komplexer Ähnlichkeitssuchen.  Eine gut geplante und implementierte Notfallwiederherstellungsstrategie stellt sicher, dass bei unvorhergesehenen Vorfällen wie Hardwareausfällen, Naturkatastrophen oder Cyberangriffen keine Daten verloren gehen oder gefährdet werden.  Dies ist insbesondere für Anwendungen von Bedeutung, die auf Vektordatenbanken basieren, bei denen der Verlust oder die Beschädigung von Daten zu erheblichen Betriebsstörungen und finanziellen Verlusten führen kann.  Darüber hinaus gewährleistet ein robuster Notfallwiederherstellungsplan auch die Geschäftskontinuität, indem er Ausfallzeiten minimiert und eine schnelle Wiederherstellung der Dienste ermöglicht.  Dies wird durch das NetApp Datenreplikationsprodukt SnapMirrror über verschiedene geografische Standorte, regelmäßige Backups und Failover-Mechanismen erreicht.  Daher ist die Notfallwiederherstellung nicht nur eine Schutzmaßnahme, sondern ein entscheidender Bestandteil einer verantwortungsvollen und effizienten Vektordatenbankverwaltung.</block>
  <block id="c37567d5fe01335124697e36ce452df7" category="paragraph">SnapMirror von NetApp ermöglicht die Datenreplikation von einem NetApp ONTAP Speichercontroller zu einem anderen und wird hauptsächlich für Disaster Recovery (DR) und Hybridlösungen verwendet.  Im Kontext einer Vektordatenbank erleichtert dieses Tool den reibungslosen Datenübergang zwischen lokalen und Cloud-Umgebungen.  Dieser Übergang wird ohne die Notwendigkeit von Datenkonvertierungen oder Anwendungsrefactoring erreicht, wodurch die Effizienz und Flexibilität der Datenverwaltung über mehrere Plattformen hinweg verbessert wird.</block>
  <block id="b6c8a7338bea39b5f253444e1d873d4d" category="paragraph">Die NetApp Hybrid-Lösung in einem Vektordatenbankszenario kann weitere Vorteile bringen:</block>
  <block id="bea498b35d669ee9af3e28b8fdb8e155" category="list-text">Skalierbarkeit: Die Hybrid-Cloud-Lösung von NetApp bietet die Möglichkeit, Ihre Ressourcen entsprechend Ihren Anforderungen zu skalieren.  Sie können lokale Ressourcen für regelmäßige, vorhersehbare Workloads und Cloud-Ressourcen wie Amazon FSx ONTAP für NetApp ONTAP und Google Cloud NetApp Volume (NetApp Volumes) für Spitzenzeiten oder unerwartete Belastungen nutzen.</block>
  <block id="c471a0669949fb6902a8ba657759604f" category="list-text">Kosteneffizienz: Mit dem Hybrid-Cloud-Modell von NetApp können Sie Ihre Kosten optimieren, indem Sie lokale Ressourcen für regelmäßige Workloads verwenden und nur dann für Cloud-Ressourcen zahlen, wenn Sie sie benötigen.  Dieses Pay-as-you-go-Modell kann mit einem NetApp Instaclustr-Serviceangebot recht kostengünstig sein.  Für On-Premise- und große Cloud-Service-Anbieter bietet instaclustr Support und Beratung.</block>
  <block id="6544e3cb40acee466e12bad4b51cee88" category="list-text">Flexibilität: Die Hybrid Cloud von NetApp bietet Ihnen die Flexibilität, den Ort der Datenverarbeitung zu wählen.  Sie können sich beispielsweise dafür entscheiden, komplexe Vektoroperationen vor Ort durchzuführen, wo Sie über leistungsfähigere Hardware verfügen, und weniger intensive Operationen in der Cloud.</block>
  <block id="2a11cdb9dd362247d7154c07bd516471" category="list-text">Geschäftskontinuität: Im Katastrophenfall kann die Speicherung Ihrer Daten in einer NetApp Hybrid Cloud die Geschäftskontinuität sicherstellen.  Sie können schnell auf die Cloud umsteigen, wenn Ihre lokalen Ressourcen betroffen sind.  Wir können NetApp SnapMirror nutzen, um die Daten vor Ort in die Cloud und umgekehrt zu verschieben.</block>
  <block id="3350f193c79eb670e977c23ae0a74f52" category="list-text">Innovation: Die Hybrid-Cloud-Lösungen von NetApp ermöglichen außerdem schnellere Innovationen, indem sie Zugriff auf hochmoderne Cloud-Dienste und -Technologien bieten.  NetApp Innovationen in der Cloud wie Amazon FSx ONTAP für NetApp ONTAP, Azure NetApp Files und Google Cloud NetApp Volumes sind innovative Produkte und bevorzugte NAS der Cloud-Service-Anbieter.</block>
  <block id="2adc0d5a06f39e5bd606c62ac1bdec94" category="summary">instaclustr mit pgvector – Vektordatenbanklösung für NetApp</block>
  <block id="8505d7d1a5bb8f0709861077b6053aac" category="doc">Vektordatenbank mit Instaclustr unter Verwendung von PostgreSQL: pgvector</block>
  <block id="45b4ccfe4060d903229f2ce1dcae0219" category="paragraph">In diesem Abschnitt werden die Einzelheiten der Integration des Instaclustr-Produkts mit PostgreSQL über die Pgvector-Funktionalität in der Vektordatenbanklösung für NetApp erläutert.</block>
  <block id="126ac9f6149081eb0e97c2e939eaad52" category="inline-link-macro">Blog</block>
  <block id="d2674849e623e64434efc8a6aa010be4" category="paragraph">In diesem Abschnitt gehen wir näher auf die Einzelheiten der Integration des Instaclustr-Produkts mit PostgreSQL auf der Grundlage der PgVector-Funktionalität ein.  Wir haben ein Beispiel für „So verbessern Sie die Genauigkeit und Leistung Ihres LLM mit PGVector und PostgreSQL: Einführung in Einbettungen und die Rolle von PGVector“.  Bitte überprüfen Sie die<block ref="f7c4562444dacce2474e07621eb487a5" category="inline-link-macro-rx"></block> um weitere Informationen zu erhalten.</block>
  <block id="755a3ba009d32e46dd37e73b1449ec79" category="summary">Einführung in die Vektordatenbanklösung für NetApp</block>
  <block id="65fe25204f25a29d6784b93a3361bbd8" category="paragraph">Dieser Abschnitt bietet eine Einführung in die Vektordatenbanklösung für NetApp.</block>
  <block id="16091ccd671260c1a85526587bdd6247" category="paragraph">Vektordatenbanken bewältigen effektiv die Herausforderungen, die für die Bewältigung der Komplexität der semantischen Suche in Large Language Models (LLMs) und generativer künstlicher Intelligenz (KI) entwickelt wurden.  Im Gegensatz zu herkömmlichen Datenverwaltungssystemen können Vektordatenbanken verschiedene Datentypen verarbeiten und durchsuchen, darunter Bilder, Videos, Text, Audio und andere Formen unstrukturierter Daten, indem sie den Inhalt der Daten selbst und nicht Beschriftungen oder Tags verwenden.</block>
  <block id="abd729dd7dfee14433df8341cdef1b8d" category="paragraph">Die Einschränkungen relationaler Datenbankmanagementsysteme (RDBMS) sind gut dokumentiert, insbesondere ihre Probleme mit hochdimensionalen Datendarstellungen und unstrukturierten Daten, die in KI-Anwendungen üblich sind.  RDBMS erfordern häufig einen zeitaufwändigen und fehleranfälligen Prozess zur Vereinfachung der Daten in besser handhabbare Strukturen, was zu Verzögerungen und Ineffizienzen bei der Suche führt.  Vektordatenbanken sind jedoch darauf ausgelegt, diese Probleme zu umgehen. Sie bieten eine effizientere und genauere Lösung für die Verwaltung und Suche in komplexen und hochdimensionalen Daten und erleichtern so die Weiterentwicklung von KI-Anwendungen.</block>
  <block id="5059454011de9c1f28ed1489b3d5e352" category="paragraph">Dieses Dokument dient als umfassender Leitfaden für Kunden, die derzeit Vektordatenbanken verwenden oder dies planen. Es beschreibt die Best Practices für die Verwendung von Vektordatenbanken auf Plattformen wie NetApp ONTAP, NetApp StorageGRID, Amazon FSx ONTAP für NetApp ONTAP und SnapCenter.  Die hier bereitgestellten Inhalte decken eine Reihe von Themen ab:</block>
  <block id="a7e003a045fea49874b32ab9648eeff1" category="list-text">Infrastrukturrichtlinien für Vektordatenbanken wie Milvus, bereitgestellt von NetApp Storage über NetApp ONTAP und StorageGRID Objektspeicher.</block>
  <block id="dad32bf9f8412e678e687e1cf7bb9ca2" category="list-text">Validierung der Milvus-Datenbank in AWS FSx ONTAP durch Datei- und Objektspeicher.</block>
  <block id="68c4bdd7361d54de76b6a70ce9e66b6e" category="list-text">Befasst sich eingehend mit der Datei-Objekt-Dualität von NetApp und demonstriert deren Nutzen für Daten in Vektordatenbanken sowie anderen Anwendungen.</block>
  <block id="8aa4f3c0608b2b5d04870a90085180a0" category="list-text">So bietet SnapCenter, das Data Protection Management-Produkt von NetApp, Sicherungs- und Wiederherstellungsfunktionen für Vektordatenbankdaten.</block>
  <block id="413963cd7c6051b3cbc48462a3167d68" category="list-text">So bietet die Hybrid Cloud von NetApp Datenreplikation und -schutz in lokalen und Cloud-Umgebungen.</block>
  <block id="73d0a81a7f19b02b2cf3e9084b655966" category="list-text">Bietet Einblicke in die Leistungsvalidierung von Vektordatenbanken wie Milvus und pgvector auf NetApp ONTAP.</block>
  <block id="de2054eca65b6e345160d8320bfa3d17" category="list-text">Zwei konkrete Anwendungsfälle: Retrieval Augmented Generation (RAG) mit Large Language Models (LLM) und ChatAI des NetApp IT-Teams, die praktische Beispiele für die beschriebenen Konzepte und Praktiken bieten.</block>
  <block id="11eb7151c13e504e17cca8ecf079bd88" category="summary">Vektordatenbank – Vektordatenbanklösung für NetApp</block>
  <block id="34e317d16a291e422cfed7563b8e4b74" category="doc">Vektordatenbank</block>
  <block id="bb6e7da57bf9b9f451aff5682584af81" category="paragraph">Dieser Abschnitt behandelt die Definition und Verwendung einer Vektordatenbank in NetApp KI-Lösungen.</block>
  <block id="02cf9216cd9290a38db4e591b2d891a3" category="paragraph">Eine Vektordatenbank ist ein spezialisierter Datenbanktyp, der für die Verarbeitung, Indizierung und Suche unstrukturierter Daten mithilfe von Einbettungen aus Modellen des maschinellen Lernens konzipiert ist.  Anstatt Daten in einem herkömmlichen Tabellenformat zu organisieren, werden sie als hochdimensionale Vektoren angeordnet, die auch als Vektoreinbettungen bezeichnet werden.  Diese einzigartige Struktur ermöglicht es der Datenbank, komplexe, mehrdimensionale Daten effizienter und genauer zu verarbeiten.</block>
  <block id="ee365553124acd5ca06a0026c4856306" category="paragraph">Eine der wichtigsten Fähigkeiten einer Vektordatenbank ist die Verwendung generativer KI zur Durchführung von Analysen.  Hierzu gehören Ähnlichkeitssuchen, bei denen die Datenbank Datenpunkte identifiziert, die einer bestimmten Eingabe ähneln, und die Anomalieerkennung, bei der sie Datenpunkte erkennen kann, die erheblich von der Norm abweichen.</block>
  <block id="145e8c4c44e4cdc9ac189d0799494e03" category="paragraph">Darüber hinaus eignen sich Vektordatenbanken gut für die Verarbeitung zeitlicher Daten oder mit Zeitstempeln versehener Daten.  Diese Art von Daten liefert Informationen darüber, „was“ passiert ist und wann es passiert ist, in der Reihenfolge und im Verhältnis zu allen anderen Ereignissen innerhalb eines bestimmten IT-Systems.  Diese Fähigkeit, zeitliche Daten zu verarbeiten und zu analysieren, macht Vektordatenbanken besonders nützlich für Anwendungen, die ein Verständnis von Ereignissen im Zeitverlauf erfordern.</block>
  <block id="196ef3e0d720a0c9b617f7c8c553f64f" category="section-title">Vorteile der Vektordatenbank für ML und KI:</block>
  <block id="2143262d5355c4a47b87575a67b2545b" category="list-text">Hochdimensionale Suche: Vektordatenbanken eignen sich hervorragend zum Verwalten und Abrufen hochdimensionaler Daten, die häufig in KI- und ML-Anwendungen generiert werden.</block>
  <block id="eaec9d6e0bc3d169492279c991b5c1e1" category="list-text">Skalierbarkeit: Sie können effizient skaliert werden, um große Datenmengen zu verarbeiten und so das Wachstum und die Expansion von KI- und ML-Projekten zu unterstützen.</block>
  <block id="1a581e9eb96703e6c387548283765d0f" category="list-text">Flexibilität: Vektordatenbanken bieten ein hohes Maß an Flexibilität und ermöglichen die Aufnahme unterschiedlicher Datentypen und -strukturen.</block>
  <block id="23f1f41790fda943f83f4fee180eb9c7" category="list-text">Leistung: Sie bieten leistungsstarkes Datenmanagement und -abruf, was für die Geschwindigkeit und Effizienz von KI- und ML-Operationen entscheidend ist.</block>
  <block id="5ec5f2c444dccfe97885b44e9f81c73a" category="list-text">Anpassbare Indizierung: Vector-Datenbanken bieten anpassbare Indizierungsoptionen, die eine optimierte Datenorganisation und -abfrage basierend auf spezifischen Anforderungen ermöglichen.</block>
  <block id="431b6b79e58c421f73a7d7653f3a2641" category="section-title">Vektordatenbanken und Anwendungsfälle.</block>
  <block id="03e65b2645d14a51684616a56e46e74b" category="paragraph">Dieser Abschnitt enthält verschiedene Vektordatenbanken und Einzelheiten zu ihren Anwendungsfällen.</block>
  <block id="4873dee9aab8428a3bad0247c8891122" category="section-title">Faiss und ScaNN</block>
  <block id="f8255a0712bd834e092674fb685b593d" category="paragraph">Es handelt sich um Bibliotheken, die als wichtige Werkzeuge im Bereich der Vektorsuche dienen.  Diese Bibliotheken bieten Funktionen, die für die Verwaltung und Suche in Vektordaten von entscheidender Bedeutung sind, und stellen somit unschätzbare Ressourcen in diesem speziellen Bereich der Datenverwaltung dar.</block>
  <block id="45e23a169652aaf95ce80da844f3df0d" category="section-title">Elasticsearch</block>
  <block id="7bdddec875d1ea093ba8b35566b1775c" category="paragraph">Es handelt sich um eine weit verbreitete Such- und Analyse-Engine, die seit kurzem auch über eine Vektorsuchfunktion verfügt.  Diese neue Funktion erweitert die Funktionalität und ermöglicht eine effektivere Verarbeitung und Suche in Vektordaten.</block>
  <block id="f6af38c920e468b8adbdd5793a09b4ca" category="section-title">Tannenzapfen</block>
  <block id="e50d3eac5e6bdb3d1ddd1f564ee13308" category="paragraph">Es handelt sich um eine robuste Vektordatenbank mit einem einzigartigen Funktionsumfang.  Es unterstützt in seiner Indexierungsfunktionalität sowohl dichte als auch spärliche Vektoren, was seine Flexibilität und Anpassungsfähigkeit verbessert.  Eine seiner Hauptstärken liegt in der Fähigkeit, traditionelle Suchmethoden mit KI-basierter dichter Vektorsuche zu kombinieren und so einen hybriden Suchansatz zu schaffen, der das Beste aus beiden Welten nutzt.</block>
  <block id="8a6b6fbe69ba556a5fee7b289943c80b" category="paragraph">Pinecone ist hauptsächlich cloudbasiert, für Anwendungen des maschinellen Lernens konzipiert und lässt sich gut in eine Vielzahl von Plattformen integrieren, darunter GCP, AWS, Open AI, GPT-3, GPT-3.5, GPT-4, Catgut Plus, Elasticsearch, Haystack und mehr.  Es ist wichtig zu beachten, dass Pinecone eine Closed-Source-Plattform ist und als Software-as-a-Service-Angebot (SaaS) verfügbar ist.</block>
  <block id="b30cd65a7e403a5d3e792a3c02cfe9ef" category="paragraph">Aufgrund seiner erweiterten Funktionen eignet sich Pinecone besonders gut für die Cybersicherheitsbranche, wo seine hochdimensionalen Such- und Hybridsuchfunktionen effektiv genutzt werden können, um Bedrohungen zu erkennen und darauf zu reagieren.</block>
  <block id="12f586b0171cf0f06960a27796d811d6" category="section-title">Chroma</block>
  <block id="44fcc1838437cfd155de42d2d5133fd3" category="paragraph">Es handelt sich um eine Vektordatenbank mit einer Core-API mit vier Hauptfunktionen, von denen eine einen In-Memory-Dokumentenvektorspeicher umfasst.  Es nutzt außerdem die Face Transformers-Bibliothek zum Vektorisieren von Dokumenten und verbessert so seine Funktionalität und Vielseitigkeit.  Chroma ist für den Betrieb sowohl in der Cloud als auch vor Ort konzipiert und bietet Flexibilität basierend auf den Benutzeranforderungen.  Es zeichnet sich insbesondere bei Audioanwendungen aus und ist daher eine ausgezeichnete Wahl für audiobasierte Suchmaschinen, Musikempfehlungssysteme und andere audiobezogene Anwendungsfälle.</block>
  <block id="2a1e8d184d8101d9d99e3d491cd7be71" category="section-title">Weaviate</block>
  <block id="bd8b2ae24665811d42f62aa51b8f92c4" category="paragraph">Es handelt sich um eine vielseitige Vektordatenbank, die es Benutzern ermöglicht, ihre Inhalte entweder mithilfe der integrierten oder benutzerdefinierten Module zu vektorisieren und so Flexibilität basierend auf spezifischen Anforderungen zu bieten.  Es bietet sowohl vollständig verwaltete als auch selbst gehostete Lösungen und berücksichtigt dabei eine Vielzahl von Bereitstellungspräferenzen.</block>
  <block id="5147cd0d10159454e367b25d270b0489" category="paragraph">Eine der Hauptfunktionen von Weaviate ist die Fähigkeit, sowohl Vektoren als auch Objekte zu speichern, wodurch die Datenverarbeitungsfunktionen verbessert werden.  Es wird häufig für eine Reihe von Anwendungen verwendet, darunter semantische Suche und Datenklassifizierung in ERP-Systemen.  Im E-Commerce-Sektor treibt es Such- und Empfehlungsmaschinen an.  Weaviate wird auch für die Bildsuche, Anomalieerkennung, automatisierte Datenharmonisierung und Cybersicherheitsbedrohungsanalyse verwendet und zeigt damit seine Vielseitigkeit in mehreren Bereichen.</block>
  <block id="e111446745a1825b862f8727ae63bce4" category="section-title">Redis</block>
  <block id="58cbcbf294faed43c2a7b44bb5dcafcc" category="paragraph">Redis ist eine leistungsstarke Vektordatenbank, die für ihre schnelle In-Memory-Speicherung bekannt ist und eine geringe Latenz für Lese-/Schreibvorgänge bietet.  Dies macht es zu einer ausgezeichneten Wahl für Empfehlungssysteme, Suchmaschinen und Datenanalyseanwendungen, die einen schnellen Datenzugriff erfordern.</block>
  <block id="4f9bdf8e8091be6f95cde54860bb88f7" category="paragraph">Redis unterstützt verschiedene Datenstrukturen für Vektoren, einschließlich Listen, Mengen und sortierte Mengen.  Es bietet auch Vektoroperationen wie das Berechnen von Abständen zwischen Vektoren oder das Finden von Schnittpunkten und Vereinigungen.  Diese Funktionen sind besonders nützlich für die Ähnlichkeitssuche, Clustering und inhaltsbasierte Empfehlungssysteme.</block>
  <block id="2391a64216fab42522be1700985c5a9e" category="paragraph">In Bezug auf Skalierbarkeit und Verfügbarkeit zeichnet sich Redis durch die Verarbeitung von Workloads mit hohem Durchsatz aus und bietet Datenreplikation.  Es lässt sich auch gut in andere Datentypen integrieren, einschließlich herkömmlicher relationaler Datenbanken (RDBMS).  Redis enthält eine Publish/Subscribe-Funktion (Pub/Sub) für Echtzeit-Updates, die für die Verwaltung von Echtzeit-Vektoren von Vorteil ist.  Darüber hinaus ist Redis leichtgewichtig und einfach zu verwenden, was es zu einer benutzerfreundlichen Lösung für die Verwaltung von Vektordaten macht.</block>
  <block id="4f3d528166032bacea5de8a509bb4d17" category="section-title">Milvus</block>
  <block id="e6aa3b4ef4ac18024fd88c49647d8277" category="paragraph">Es handelt sich um eine vielseitige Vektordatenbank, die eine API wie einen Dokumentenspeicher bietet, ähnlich wie MongoDB.  Es zeichnet sich durch die Unterstützung einer Vielzahl von Datentypen aus und ist daher eine beliebte Wahl in den Bereichen Datenwissenschaft und maschinelles Lernen.</block>
  <block id="4b4464f60a3dfd428d4c07edb8cac802" category="paragraph">Eine der einzigartigen Funktionen von Milvus ist die Multivektorisierungsfunktion, die es Benutzern ermöglicht, zur Laufzeit den für die Suche zu verwendenden Vektortyp anzugeben.  Darüber hinaus nutzt es Knowwhere, eine Bibliothek, die auf anderen Bibliotheken wie Faiss aufbaut, um die Kommunikation zwischen Abfragen und den Vektorsuchalgorithmen zu verwalten.</block>
  <block id="bd3a3ade101e0f6fe46ad769dbf3cfa0" category="paragraph">Dank seiner Kompatibilität mit PyTorch und TensorFlow bietet Milvus außerdem eine nahtlose Integration in Machine-Learning-Workflows.  Dies macht es zu einem hervorragenden Tool für eine Reihe von Anwendungen, darunter E-Commerce, Bild- und Videoanalyse, Objekterkennung, Bildähnlichkeitssuche und inhaltsbasierte Bildabfrage.  Im Bereich der natürlichen Sprachverarbeitung wird Milvus für die Dokumentenclusterung, semantische Suche und Frage-Antwort-Systeme verwendet.</block>
  <block id="df5acf267fd9d50988a9132e88ec089f" category="paragraph">Für diese Lösung haben wir Milvus zur Lösungsvalidierung ausgewählt.  Aus Leistungsgründen haben wir sowohl Milvus als auch Postgres (pgvecto.rs) verwendet.</block>
  <block id="6b9a995b1c19c83b6360f58654598ab0" category="section-title">Warum haben wir uns für diese Lösung für Milvus entschieden?</block>
  <block id="ac80bf421cb6dec4ca81d75401709fce" category="list-text">Open Source: Milvus ist eine Open-Source-Vektordatenbank, die eine von der Community gesteuerte Entwicklung und Verbesserung fördert.</block>
  <block id="72e0b014c4927b1166a4c34028bf0a94" category="list-text">KI-Integration: Es nutzt die Einbettung von Ähnlichkeitssuchen und KI-Anwendungen, um die Funktionalität der Vektordatenbank zu verbessern.</block>
  <block id="1f3d7f832f4c276984a989e5a4760e7d" category="list-text">Handhabung großer Datenmengen: Milvus verfügt über die Kapazität, über eine Milliarde Einbettungsvektoren zu speichern, zu indizieren und zu verwalten, die von Deep Neural Networks (DNN) und Machine Learning (ML)-Modellen generiert werden.</block>
  <block id="be23175f1d046ec7a81f41bbfbb7a710" category="list-text">Benutzerfreundlich: Die Verwendung ist einfach, die Einrichtung dauert weniger als eine Minute.  Milvus bietet auch SDKs für verschiedene Programmiersprachen an.</block>
  <block id="2c86f12d4bdb64f5ff99e182033e6664" category="list-text">Geschwindigkeit: Es bietet blitzschnelle Abrufgeschwindigkeiten, bis zu 10-mal schneller als einige Alternativen.</block>
  <block id="23a12a1d1c53642355185e4cf7fd3d30" category="list-text">Skalierbarkeit und Verfügbarkeit: Milvus ist hochgradig skalierbar und bietet Optionen zur Skalierung nach oben und unten nach Bedarf.</block>
  <block id="eaa6e5cbb0e6c82b8217f591711c391a" category="list-text">Funktionsreich: Es unterstützt verschiedene Datentypen, Attributfilterung, benutzerdefinierte Funktionen (UDF), konfigurierbare Konsistenzstufen und Reisezeiten und ist somit ein vielseitiges Tool für verschiedene Anwendungen.</block>
  <block id="cb1e9d4cfab2279dd63f9f75796dc14f" category="section-title">Milvus-Architekturübersicht</block>
  <block id="9c5b9910474e7d9e8c210fd3d649af4d" category="paragraph"><block ref="9c5b9910474e7d9e8c210fd3d649af4d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03bd3b894648d2e8a48d648b0fcedfac" category="paragraph">Dieser Abschnitt stellt Komponenten und Dienste höherer Ebene bereit, die in der Milvus-Architektur verwendet werden.  * Zugriffsebene – Sie besteht aus einer Gruppe zustandsloser Proxys und dient als Frontebene des Systems und Endpunkt für Benutzer.  * Koordinatordienst – er weist die Aufgaben den Arbeitsknoten zu und fungiert als Gehirn des Systems.  Es gibt drei Koordinatortypen: Stammkoordinate, Datenkoordinate und Abfragekoordinate.  * Worker-Knoten: Es folgt den Anweisungen des Koordinatordienstes und führt vom Benutzer ausgelöste DML/DDL-Befehle aus. Es gibt drei Arten von Worker-Knoten, nämlich Abfrageknoten, Datenknoten und Indexknoten.  * Speicher: Er ist für die Datenpersistenz verantwortlich.  Es umfasst Metaspeicher, Log Broker und Objektspeicher.  NetApp Speicher wie ONTAP und StorageGRID bieten Milvus Objektspeicher und dateibasierten Speicher sowohl für Kundendaten als auch für Vektordatenbankdaten.</block>
  <block id="3ad011fbf1a887f55fe5db0f1c95891f" category="summary">milvus mit Amazon FSx ONTAP für NetApp ONTAP – Vector-Datenbanklösung für NetApp</block>
  <block id="dd69e86c3dc6fbad2a761367a22a0552" category="doc">Milvus mit Amazon FSx ONTAP für NetApp ONTAP – Datei- und Objektdualität</block>
  <block id="8cec9207499fc7ae92bcaff5ffed4880" category="paragraph">In diesem Abschnitt wird die Einrichtung des Milvus-Clusters mit Amazon FSx ONTAP für die Vektordatenbanklösung für NetApp erläutert.</block>
  <block id="74126d145913f667c84fb0fae63d5f30" category="section-title">Milvus mit Amazon FSx ONTAP für NetApp ONTAP – Datei- und Objektdualität</block>
  <block id="de1f3a826ad4a683281aa07d427c615a" category="paragraph">In diesem Abschnitt erfahren Sie, warum wir die Vektordatenbank in der Cloud bereitstellen müssen, sowie die Schritte zum Bereitstellen der Vektordatenbank (Milvus Standalone) in Amazon FSx ONTAP für NetApp ONTAP innerhalb von Docker-Containern.</block>
  <block id="c7d712a8f39fa8b7654218edbb110e3e" category="paragraph">Die Bereitstellung einer Vektordatenbank in der Cloud bietet mehrere bedeutende Vorteile, insbesondere für Anwendungen, bei denen hochdimensionale Daten verarbeitet und Ähnlichkeitssuchen ausgeführt werden müssen.  Erstens bietet die Cloud-basierte Bereitstellung Skalierbarkeit und ermöglicht eine einfache Anpassung der Ressourcen an die wachsenden Datenmengen und Abfragelasten.  Dadurch wird sichergestellt, dass die Datenbank die erhöhte Nachfrage effizient bewältigen und gleichzeitig eine hohe Leistung aufrechterhalten kann.  Zweitens bietet die Cloud-Bereitstellung hohe Verfügbarkeit und Notfallwiederherstellung, da Daten über verschiedene geografische Standorte hinweg repliziert werden können, wodurch das Risiko eines Datenverlusts minimiert und ein kontinuierlicher Dienst auch bei unerwarteten Ereignissen sichergestellt wird.  Drittens ist es kosteneffizient, da Sie nur für die Ressourcen zahlen, die Sie tatsächlich nutzen, und je nach Bedarf hoch- oder herunterskalieren können, sodass keine erheblichen Vorabinvestitionen in Hardware erforderlich sind.  Und schließlich kann die Bereitstellung einer Vektordatenbank in der Cloud die Zusammenarbeit verbessern, da von überall auf die Daten zugegriffen und diese geteilt werden können, was die teambasierte Arbeit und datengesteuerte Entscheidungsfindung erleichtert.  Bitte überprüfen Sie die Architektur des Milvus-Standalone mit Amazon FSx ONTAP für NetApp ONTAP , das bei dieser Validierung verwendet wird.</block>
  <block id="f95a160e2c9ead1dd272587d85c4a8e3" category="paragraph"><block ref="f95a160e2c9ead1dd272587d85c4a8e3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f1e75d11a34279b79d1140edc8f509e3" category="list-text">Erstellen Sie eine Amazon FSx ONTAP für NetApp ONTAP Instanz und notieren Sie die Details der VPC, der VPC-Sicherheitsgruppen und des Subnetzes.  Diese Informationen werden beim Erstellen einer EC2-Instanz benötigt.  Weitere Details finden Sie hier -<block ref="600df3e2da0b9de1446fabf4802a063b" category="inline-link-rx"></block></block>
  <block id="d91af2df00186cd53f523a257cb2565a" category="list-text">Erstellen Sie eine EC2-Instance und stellen Sie sicher, dass VPC, Sicherheitsgruppen und Subnetz mit denen der Amazon FSx ONTAP für NetApp ONTAP -Instance übereinstimmen.</block>
  <block id="3f49259cc5a532eaad35643b8ddc6724" category="list-text">Installieren Sie nfs-common mit dem Befehl „apt-get install nfs-common“ und aktualisieren Sie die Paketinformationen mit „sudo apt-get update“.</block>
  <block id="7cd964c493dd7e6f0abd19075ad234a1" category="list-text">Erstellen Sie einen Mount-Ordner und mounten Sie Amazon FSx ONTAP für NetApp ONTAP darin.</block>
  <block id="79f2982e5eb61f29ccc9204d1e575199" category="list-text">Installieren Sie Docker und Docker Compose mit „apt-get install“.</block>
  <block id="8b2bc8a7f7a7f8a83a1a126f0f97c496" category="list-text">Richten Sie einen Milvus-Cluster basierend auf der Datei docker-compose.yaml ein, die von der Milvus-Website heruntergeladen werden kann.</block>
  <block id="6667d03b2d7af61cacf9ce4779fbb601" category="list-text">Ordnen Sie im Abschnitt „Volumes“ der Datei docker-compose.yml den NetApp NFS-Mount-Punkt dem entsprechenden Milvus-Containerpfad zu, insbesondere in etcd, minio und standalone.Check<block ref="cb2986bd8f2d29c4cca582736e0a680f" category="inline-link-macro-rx"></block> für Details zu Änderungen in YML</block>
  <block id="40722d15b9f6ad02c869cf6f587fd141" category="list-text">Überprüfen Sie die bereitgestellten Ordner und Dateien.</block>
  <block id="b1c44a1b47e0ee05938bd8b62a636917" category="list-text">Führen Sie „docker-compose up -d“ aus dem Verzeichnis aus, das die Datei docker-compose.yml enthält.</block>
  <block id="9a6325448af98c29154cb9ef7423c998" category="list-text">Überprüfen Sie den Status des Milvus-Containers.</block>
  <block id="e5666f40cd9052040de973832a6b5fb8" category="list-text">Um die Lese- und Schreibfunktionalität der Vektordatenbank und ihrer Daten in Amazon FSx ONTAP für NetApp ONTAP zu validieren, haben wir das Python Milvus SDK und ein Beispielprogramm von PyMilvus verwendet.  Installieren Sie die erforderlichen Pakete mit „apt-get install python3-numpy python3-pip“ und installieren Sie PyMilvus mit „pip3 install pymilvus“.</block>
  <block id="77b346f241703e75634a6437339f3874" category="list-text">Validieren Sie Datenschreib- und -lesevorgänge von Amazon FSx ONTAP für NetApp ONTAP in der Vektordatenbank.</block>
  <block id="edeedbd869dbb3831a9bfc7c26f04200" category="list-text">Überprüfen Sie den Lesevorgang mit dem Skript verify_data_netapp.py.</block>
  <block id="bda2d30c9f3f0d40ab873d7c99e8c13b" category="list-text">Wenn der Kunde für KI-Workloads über das S3-Protokoll auf in der Vektordatenbank getestete NFS-Daten zugreifen (lesen) möchte, kann dies mit einem einfachen Python-Programm validiert werden.  Ein Beispiel hierfür könnte eine Ähnlichkeitssuche von Bildern aus einer anderen Anwendung sein, wie im Bild am Anfang dieses Abschnitts erwähnt.</block>
  <block id="8b97e19802900809af55c42c509e614a" category="paragraph">Dieser Abschnitt zeigt effektiv, wie Kunden ein eigenständiges Milvus-Setup in Docker-Containern bereitstellen und betreiben können, indem sie Amazons NetApp FSx ONTAP für die NetApp ONTAP Datenspeicherung nutzen.  Mit diesem Setup können Kunden die Leistungsfähigkeit von Vektordatenbanken für die Verarbeitung hochdimensionaler Daten und die Ausführung komplexer Abfragen nutzen – und das alles in der skalierbaren und effizienten Umgebung von Docker-Containern.  Durch die Erstellung einer Amazon FSx ONTAP für NetApp ONTAP -Instanz und einer passenden EC2-Instanz können Kunden eine optimale Ressourcennutzung und Datenverwaltung sicherstellen.  Die erfolgreiche Validierung von Datenschreib- und -lesevorgängen von FSx ONTAP in der Vektordatenbank bietet Kunden die Gewissheit zuverlässiger und konsistenter Datenvorgänge.  Darüber hinaus bietet die Möglichkeit, Daten von KI-Workloads über das S3-Protokoll aufzulisten (lesen), eine verbesserte Datenzugänglichkeit.  Dieser umfassende Prozess bietet Kunden daher eine robuste und effiziente Lösung für die Verwaltung ihrer groß angelegten Datenvorgänge und nutzt dabei die Funktionen von Amazons FSx ONTAP für NetApp ONTAP.</block>
  <block id="80f3b490016fb09dd087c51b2a8b26f5" category="summary">Milvus-Cluster-Setup – Vektordatenbanklösung für NetApp</block>
  <block id="c0f2e2b603c0c8186341bf2945e1ad13" category="doc">Milvus-Cluster-Setup mit Kubernetes vor Ort</block>
  <block id="4a6f6b145c2d627bc6b03f4b1e6dd96a" category="paragraph">In diesem Abschnitt wird die Einrichtung des Milvus-Clusters für die Vector-Datenbanklösung für NetApp erläutert.</block>
  <block id="b5be4c6d053fbcf3d99fa7a27f14df10" category="section-title">Milvus-Cluster-Setup mit Kubernetes vor Ort</block>
  <block id="ae5afd2c726fae66bdccf19c83604efb" category="paragraph">Kunden stehen vor der Herausforderung, Speicher und Rechenleistung unabhängig zu skalieren und eine effektive Infrastruktur- und Datenverwaltung zu gewährleisten. Kubernetes und Vektordatenbanken bilden zusammen eine leistungsstarke, skalierbare Lösung für die Verwaltung großer Datenvorgänge.  Kubernetes optimiert Ressourcen und verwaltet Container, während Vektordatenbanken hochdimensionale Daten und Ähnlichkeitssuchen effizient verarbeiten.  Diese Kombination ermöglicht die schnelle Verarbeitung komplexer Abfragen großer Datensätze und lässt sich nahtlos mit wachsenden Datenmengen skalieren, was sie ideal für Big-Data-Anwendungen und KI-Workloads macht.</block>
  <block id="b74b373b546797287d3c21cceba52d3d" category="list-text">In diesem Abschnitt beschreiben wir detailliert den Prozess der Installation eines Milvus-Clusters auf Kubernetes unter Verwendung eines NetApp -Speichercontrollers sowohl für Clusterdaten als auch für Kundendaten.</block>
  <block id="65c0326e8e372682bfaae45cec62723f" category="list-text">Zur Installation eines Milvus-Clusters sind Persistent Volumes (PVs) zum Speichern von Daten aus verschiedenen Milvus-Clusterkomponenten erforderlich.  Zu diesen Komponenten gehören etcd (drei Instanzen), pulsar-bookie-journal (drei Instanzen), pulsar-bookie-ledgers (drei Instanzen) und pulsar-zookeeper-data (drei Instanzen).</block>
  <block id="c2e2fce3a995f59900d7afbbe58683f5" category="inline-link-macro">dieser Link</block>
  <block id="d33fb2ef35d69747411b9e87c7d3d69f" category="admonition">Im Milvus-Cluster können wir entweder Pulsar oder Kafka als zugrunde liegende Engine verwenden, die die zuverlässige Speicherung und Veröffentlichung/Abonnementierung von Nachrichtenströmen im Milvus-Cluster unterstützt.  Für Kafka mit NFS hat NetApp Verbesserungen in ONTAP 9.12.1 und höher vorgenommen. Diese Verbesserungen sowie NFSv4.1- und Linux-Änderungen, die in RHEL 8.7 oder 9.1 und höher enthalten sind, beheben das Problem der „dummen Umbenennung“, das beim Ausführen von Kafka über NFS auftreten kann. Wenn Sie an ausführlicheren Informationen zum Ausführen von Kafka mit der NetApp NFS-Lösung interessiert sind, lesen Sie bitte -<block ref="19b6a7adb53ddda340943365a4b691d7" category="inline-link-macro-rx"></block> .</block>
  <block id="eea5737b25740da376e769b4f799f861" category="list-text">Wir haben ein einzelnes NFS-Volume von NetApp ONTAP erstellt und 12 persistente Volumes mit jeweils 250 GB Speicher eingerichtet.  Die Speichergröße kann je nach Clustergröße variieren. Beispielsweise haben wir einen anderen Cluster, bei dem jedes PV über 50 GB verfügt.  Weitere Einzelheiten finden Sie unten in einer der PV-YAML-Dateien. Insgesamt hatten wir 12 solcher Dateien.  In jeder Datei ist der storageClassName auf „default“ gesetzt und Speicher und Pfad sind für jedes PV eindeutig.</block>
  <block id="4bd70516b6325446dd3ab13888cff57f" category="list-text">Führen Sie den Befehl „kubectl apply“ für jede PV-YAML-Datei aus, um die persistenten Volumes zu erstellen, und überprüfen Sie anschließend deren Erstellung mit „kubectl get pv“.</block>
  <block id="3468fc776a2c10c6b885c4b8f38fbb6f" category="list-text">Zum Speichern von Kundendaten unterstützt Milvus Objektspeicherlösungen wie MinIO, Azure Blob und S3.  In dieser Anleitung verwenden wir S3.  Die folgenden Schritte gelten sowohl für den ONTAP S3- als auch für den StorageGRID Objektspeicher.  Wir verwenden Helm, um den Milvus-Cluster bereitzustellen.  Laden Sie die Konfigurationsdatei values.yaml vom Milvus-Download-Speicherort herunter.  Die Datei values.yaml, die wir in diesem Dokument verwendet haben, finden Sie im Anhang.</block>
  <block id="ac8152f5c769ca08c180374241d9797c" category="list-text">Stellen Sie sicher, dass die „storageClass“ in jedem Abschnitt auf „default“ gesetzt ist, einschließlich der Abschnitte für Protokoll, etcd, Zookeeper und Bookkeeper.</block>
  <block id="3c27656d225ef946516e7bec88519049" category="list-text">Deaktivieren Sie MinIO im Abschnitt MinIO.</block>
  <block id="a9c572c8c594acac80d859b834139c09" category="list-text">Erstellen Sie einen NAS-Bucket aus dem ONTAP oder StorageGRID Objektspeicher und fügen Sie ihn mit den Objektspeicher-Anmeldeinformationen in ein externes S3 ein.</block>
  <block id="5c01f0212f13cb62a8e9c91143a9a0e8" category="list-text">Stellen Sie vor dem Erstellen des Milvus-Clusters sicher, dass der PersistentVolumeClaim (PVC) keine bereits vorhandenen Ressourcen enthält.</block>
  <block id="8916cc7e0054297b71b9453a888657d1" category="list-text">Verwenden Sie Helm und die Konfigurationsdatei values.yaml, um den Milvus-Cluster zu installieren und zu starten.</block>
  <block id="774a1cf197a96a839f6b770e85cb2445" category="list-text">Überprüfen Sie den Status der PersistentVolumeClaims (PVCs).</block>
  <block id="63b2b2b30427688208b8a24971cee62e" category="list-text">Überprüfen Sie den Status der Pods.</block>
  <block id="1d419f9c469484aa1d54fd468448977e" category="paragraph">Bitte stellen Sie sicher, dass der Pod-Status „läuft“ lautet und wie erwartet funktioniert.</block>
  <block id="890a387ef3d7768088115e7fea8a9ff6" category="list-text">Testen Sie das Schreiben und Lesen von Daten im Milvus- und NetApp Objektspeicher.</block>
  <block id="e5aef6bb28887bb265d168f37e539b38" category="list-text">Schreiben Sie Daten mit dem Python-Programm „prepare_data_netapp_new.py“.</block>
  <block id="db12c3e2840ba5032e784bab8e8fb917" category="list-text">Lesen Sie die Daten mithilfe der Python-Datei „verify_data_netapp.py“.</block>
  <block id="25ab62108c16e9b732c38f62755ec991" category="paragraph">Basierend auf der obigen Validierung bietet die Integration von Kubernetes mit einer Vektordatenbank, wie durch die Bereitstellung eines Milvus-Clusters auf Kubernetes unter Verwendung eines NetApp -Speichercontrollers demonstriert, Kunden eine robuste, skalierbare und effiziente Lösung für die Verwaltung umfangreicher Datenvorgänge.  Dieses Setup bietet Kunden die Möglichkeit, hochdimensionale Daten zu verarbeiten und komplexe Abfragen schnell und effizient auszuführen, was es zu einer idealen Lösung für Big-Data-Anwendungen und KI-Workloads macht.  Die Verwendung von Persistent Volumes (PVs) für verschiedene Clusterkomponenten sowie die Erstellung eines einzelnen NFS-Volumes aus NetApp ONTAP gewährleisten eine optimale Ressourcennutzung und Datenverwaltung.  Der Prozess der Überprüfung des Status von PersistentVolumeClaims (PVCs) und Pods sowie das Testen des Schreibens und Lesens von Daten bietet Kunden die Gewissheit zuverlässiger und konsistenter Datenvorgänge.  Die Verwendung von ONTAP oder StorageGRID -Objektspeicher für Kundendaten verbessert die Datenzugänglichkeit und -sicherheit zusätzlich.  Insgesamt bietet diese Konfiguration den Kunden eine robuste und leistungsstarke Datenverwaltungslösung, die sich nahtlos an ihren wachsenden Datenbedarf anpassen lässt.</block>
  <block id="34d3fa32b415d892eb0e14786cafccea" category="summary">Lösungsübersicht zur Vector-Datenbanklösung für NetApp</block>
  <block id="351df3cce379006f4ba6b903c32e39a0" category="paragraph">Dieser Abschnitt bietet einen Überblick über die NetApp Vector-Datenbanklösung.</block>
  <block id="84c35d4e8bb8f8f09d3728632bcee7ce" category="paragraph">Diese Lösung demonstriert die besonderen Vorteile und Fähigkeiten, die NetApp mitbringt, um die Herausforderungen zu bewältigen, vor denen Kunden von Vektordatenbanken stehen.  Durch die Nutzung von NetApp ONTAP, StorageGRID, den Cloud-Lösungen von NetApp und SnapCenter können Kunden ihren Geschäftsbetrieb erheblich aufwerten.  Diese Tools lösen nicht nur bestehende Probleme, sondern steigern auch die Effizienz und Produktivität und tragen so zum allgemeinen Unternehmenswachstum bei.</block>
  <block id="d383216ef38104a4ae0ac03e48c3f38c" category="section-title">Warum NetApp?</block>
  <block id="c8850228b08f24ab3b77cf8228b9b2cf" category="list-text">Die Angebote von NetApp, wie ONTAP und StorageGRID, ermöglichen die Trennung von Speicher und Rechenleistung und ermöglichen so eine optimale Ressourcennutzung basierend auf spezifischen Anforderungen.  Diese Flexibilität ermöglicht es Kunden, ihren Speicher mithilfe von NetApp Speicherlösungen unabhängig zu skalieren.</block>
  <block id="40251a62505d04ab7d80bacded5fec97" category="list-text">NetApp ONTAP bietet native Unterstützung für NAS- und Objektspeicher bei führenden Cloud-Service-Anbietern wie AWS, Azure und Google Cloud.  Diese umfassende Kompatibilität gewährleistet eine nahtlose Integration und ermöglicht Kundendatenmobilität, globale Zugänglichkeit, Notfallwiederherstellung, dynamische Skalierbarkeit und hohe Leistung.</block>
  <block id="6c1c83ac60affc59fcc3432ea130dd8f" category="list-text">Dank der robusten Datenverwaltungsfunktionen von NetApp können Kunden sicher sein, dass ihre Daten gut vor potenziellen Risiken und Bedrohungen geschützt sind.  NetApp legt größten Wert auf Datensicherheit und bietet seinen Kunden die Gewissheit, dass ihre wertvollen Informationen sicher und intakt sind.</block>
  <block id="738158dc90e1d60ff7273e21bc2d2c4e" category="summary">Leistungsvalidierung der Vector-Datenbank – Vector-Datenbanklösung für NetApp</block>
  <block id="39301670f58445b6e5aed7e2a2694632" category="doc">Leistungsvalidierung der Vektordatenbank</block>
  <block id="334e1c5c0681bc3d3d6b9321ff851f44" category="paragraph">In diesem Abschnitt wird die Leistungsvalidierung hervorgehoben, die an der Vektordatenbank durchgeführt wurde.</block>
  <block id="1eb24bd760e508043a3cfdfe91ba9489" category="section-title">Leistungsvalidierung</block>
  <block id="0dfe6e4dda5bda08f3b2f54fe5f51a3b" category="paragraph">Die Leistungsvalidierung spielt sowohl bei Vektordatenbanken als auch bei Speichersystemen eine entscheidende Rolle und ist ein Schlüsselfaktor für die Gewährleistung eines optimalen Betriebs und einer effizienten Ressourcennutzung.  Vektordatenbanken, die für die Verarbeitung hochdimensionaler Daten und die Durchführung von Ähnlichkeitssuchen bekannt sind, müssen ein hohes Leistungsniveau aufrechterhalten, um komplexe Abfragen schnell und genau verarbeiten zu können.  Mithilfe der Leistungsvalidierung können Engpässe identifiziert und Konfigurationen optimiert werden. Außerdem wird sichergestellt, dass das System die erwartete Belastung ohne Leistungseinbußen bewältigen kann.  Ebenso ist bei Speichersystemen eine Leistungsvalidierung unerlässlich, um sicherzustellen, dass Daten effizient gespeichert und abgerufen werden, ohne dass es zu Latenzproblemen oder Engpässen kommt, die die Gesamtleistung des Systems beeinträchtigen könnten.  Es hilft auch dabei, fundierte Entscheidungen über notwendige Upgrades oder Änderungen der Speicherinfrastruktur zu treffen.  Daher ist die Leistungsvalidierung ein entscheidender Aspekt des Systemmanagements und trägt erheblich zur Aufrechterhaltung einer hohen Servicequalität, Betriebseffizienz und allgemeinen Systemzuverlässigkeit bei.</block>
  <block id="9115de397cf08aaab47480ba37fbda9b" category="paragraph">In diesem Abschnitt möchten wir uns eingehend mit der Leistungsvalidierung von Vektordatenbanken wie Milvus und pgvecto.rs befassen und uns dabei auf ihre Speicherleistungsmerkmale wie E/A-Profil und Verhalten des NetApp-Speichercontrollers zur Unterstützung von RAG- und Inferenz-Workloads innerhalb des LLM-Lebenszyklus konzentrieren.  Wir werden alle Leistungsunterschiede bewerten und identifizieren, wenn diese Datenbanken mit der ONTAP Speicherlösung kombiniert werden.  Unsere Analyse basiert auf wichtigen Leistungsindikatoren, beispielsweise der Anzahl der pro Sekunde verarbeiteten Abfragen (QPS).</block>
  <block id="259349a97b2ad2022418ffa271915c7f" category="paragraph">Bitte überprüfen Sie unten die für Milvus und den Fortschritt verwendete Methodik.</block>
  <block id="3805969a7e504e8baa224367a87cc5a8" category="cell">Milvus (Standalone und Cluster)</block>
  <block id="1cfad7d7743394085072e5f7fcc3a203" category="cell">Postgres(pgvecto.rs) #</block>
  <block id="2af72f100c356273d46284f6fd1dfc08" category="cell">Version</block>
  <block id="c2ee74b62870d06b4b4ad6819b9bf142" category="cell">2.3.2</block>
  <block id="44b732a6709d52e07db0367d4938965c" category="cell">0.2.0</block>
  <block id="ac52cf637478f3656a1fdee5c02324fd" category="cell">Dateisystem</block>
  <block id="6f27ca3ac8a02564ce2eef7e706e1e50" category="cell">XFS auf iSCSI-LUNs</block>
  <block id="30b5bb1d010e4fe15e0541fa9b96dbdc" category="cell">Arbeitslastgenerator</block>
  <block id="73676a7da2a7cbd819e3a72dab6d2364" category="inline-link-macro">VectorDB-Bench</block>
  <block id="b9350528e041c5ef962f5553183ca801" category="cell"><block ref="5a4d2a4510eb4d9895b68971f8744a05" category="inline-link-macro-rx"></block>– Version 0.0.5</block>
  <block id="f1cb45f64cdd7b55480ba6aeecd7b797" category="cell">Datensätze</block>
  <block id="0adc231fd0cbf3d7d8d5a0ff68eb2783" category="cell">LAION-Datensatz * 10 Millionen Einbettungen * 768 Dimensionen * ~300 GB Datensatzgröße</block>
  <block id="3941cf702a750210280a88643fe83810" category="cell">AFF 800 * Version – 9.14.1 * 4 x 100GbE – für Milvus und 2x 100GbE für Postgres * iscsi</block>
  <block id="39138e4aea637ddf9fc568de53bed3af" category="section-title">VectorDB-Bench mit Milvus-Standalone-Cluster</block>
  <block id="3a82e1f5d5f2195d71ba779a6ede894f" category="paragraph">Wir haben die folgende Leistungsvalidierung auf dem eigenständigen Milvus-Cluster mit VectorDB-Bench durchgeführt.  Die Netzwerk- und Serverkonnektivität des eigenständigen Milvus-Clusters ist unten aufgeführt.</block>
  <block id="ef436c3d7bb0f3687e078dce4b9bdb28" category="paragraph"><block ref="ef436c3d7bb0f3687e078dce4b9bdb28" category="inline-image-macro-rx" type="image"></block></block>
  <block id="663c78b1d11f60d7440f91f77e4f328a" category="paragraph">In diesem Abschnitt teilen wir unsere Beobachtungen und Ergebnisse aus dem Testen der eigenständigen Milvus-Datenbank. .  Für diese Tests haben wir DiskANN als Indextyp ausgewählt. .  Das Aufnehmen, Optimieren und Erstellen von Indizes für einen Datensatz von etwa 100 GB dauerte etwa 5 Stunden.  Während des größten Teils dieser Dauer lief der mit 20 Kernen ausgestattete Milvus-Server (was bei aktiviertem Hyper-Threading 40 vcpus entspricht) mit seiner maximalen CPU-Kapazität von 100 %. Wir haben festgestellt, dass DiskANN besonders wichtig für große Datensätze ist, die die Größe des Systemspeichers überschreiten. .  In der Abfragephase beobachteten wir eine Abfragerate pro Sekunde (QPS) von 10,93 mit einem Rückruf von 0,9987.  Die Latenzzeit für Abfragen im 99. Perzentil wurde mit 708,2 Millisekunden gemessen.</block>
  <block id="624dbbdc3175c82e67aadff554ee1850" category="paragraph">Aus Speichersicht gab die Datenbank während der Aufnahme-, Post-Insert-Optimierungs- und Indexerstellungsphasen etwa 1.000 Operationen/Sekunde aus.  In der Abfragephase waren 32.000 Operationen/Sek. erforderlich.</block>
  <block id="2063cebb91be357ea64826c835821b9d" category="paragraph">Der folgende Abschnitt stellt die Speicherleistungsmetriken vor.</block>
  <block id="5805c53ecb86f7c7ae7765287eda00d6" category="cell">Arbeitslastphase</block>
  <block id="216ab40cda5c7c00ff42a4efb1827d89" category="cell">Metrisch</block>
  <block id="7f2bb2bf609fe39698d58a2d1d86863a" category="cell">Datenaufnahme und Optimierung nach dem Einfügen</block>
  <block id="79073619fba8242703524f16870ff858" category="cell">IOPS</block>
  <block id="648a472fd7585d9d0c15b90f36365597" category="cell">&lt; 1.000</block>
  <block id="26ae7bdd1d6fb8c4886e6fde8d12601c" category="cell">Latenz</block>
  <block id="822500fd5bb8ac11d944779a6703df98" category="cell">&lt; 400 µs</block>
  <block id="68eaabb91b0d1c52be44217a24f27b91" category="cell">Arbeitsbelastung</block>
  <block id="59829f7cd61cf1113b8214b47aaeacd8" category="cell">Lese-/Schreib-Mix, hauptsächlich Schreibvorgänge</block>
  <block id="991ff9e60b05b3e05e67404474611720" category="cell">IO-Größe</block>
  <block id="6b29aa131a7b968826c90e6801bacd23" category="cell">64 KB</block>
  <block id="66c1b4c7f3dc385b68a9fa903ccd016d" category="cell">Abfrage</block>
  <block id="7d38c4599a45db6312f66bfac2fbba0d" category="cell">Höchststand bei 32.000</block>
  <block id="866fc78d18122580af38eeff4375a3c0" category="cell">100 % zwischengespeicherte Lesevorgänge</block>
  <block id="9632dc4ffd7ab759c4fc53341977d887" category="cell">Hauptsächlich 8 KB</block>
  <block id="06b68ce1a31c0cdf5430d925dabff321" category="paragraph">Das VectorDB-Bench-Ergebnis ist unten.</block>
  <block id="2a8bd0e83a84e623eafaed41ef4a0b48" category="paragraph"><block ref="2a8bd0e83a84e623eafaed41ef4a0b48" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bf13afd123e82c2f8504d046ac979ce6" category="paragraph">Aus der Leistungsvalidierung der eigenständigen Milvus-Instanz geht hervor, dass die aktuelle Konfiguration nicht ausreicht, um einen Datensatz von 5 Millionen Vektoren mit einer Dimensionalität von 1536 zu unterstützen. Wir haben festgestellt, dass der Speicher über ausreichende Ressourcen verfügt und keinen Engpass im System darstellt.</block>
  <block id="7a2e31e50716ca1d05ae61faa264e4d9" category="section-title">VectorDB-Bench mit Milvus-Cluster</block>
  <block id="1a3dd3962bc3776e2a670ea2dccbf4aa" category="paragraph">In diesem Abschnitt besprechen wir die Bereitstellung eines Milvus-Clusters in einer Kubernetes-Umgebung.  Dieses Kubernetes-Setup wurde auf einer VMware vSphere-Bereitstellung erstellt, die die Kubernetes-Master- und Worker-Knoten hostete.</block>
  <block id="2f38e478e85318635a3c104d2f9689ea" category="paragraph">Die Details der VMware vSphere- und Kubernetes-Bereitstellungen werden in den folgenden Abschnitten vorgestellt.</block>
  <block id="6b38cbd988bc17810219001208570634" category="paragraph"><block ref="ef20c4495e84beca29aabf20791bc97a" category="inline-image-macro-rx" type="image"></block> <block ref="6f1c220e845ab7b8291a1a21a3646cac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09618a18978db1f9288bf0626e2e9d77" category="paragraph">In diesem Abschnitt stellen wir unsere Beobachtungen und Ergebnisse aus dem Testen der Milvus-Datenbank vor.  * Der verwendete Indextyp war DiskANN.  * Die folgende Tabelle bietet einen Vergleich zwischen den Standalone- und Cluster-Bereitstellungen bei der Arbeit mit 5 Millionen Vektoren bei einer Dimensionalität von 1536.  Wir haben festgestellt, dass die für die Datenaufnahme und die Optimierung nach dem Einfügen benötigte Zeit bei der Clusterbereitstellung kürzer war.  Die Latenzzeit für Abfragen im 99. Perzentil wurde im Cluster-Einsatz im Vergleich zum Standalone-Setup um das Sechsfache reduziert.  * Obwohl die Abfragerate pro Sekunde (QPS) bei der Clusterbereitstellung höher war, lag sie nicht auf dem gewünschten Niveau.</block>
  <block id="fa7bae8c4e9fc0bec05867545cb65c08" category="paragraph"><block ref="fa7bae8c4e9fc0bec05867545cb65c08" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec05b5e2e1b5d66f987712f952bfd377" category="paragraph">Die folgenden Bilder bieten eine Ansicht verschiedener Speichermetriken, einschließlich der Speicherclusterlatenz und der gesamten IOPS (Input/Output Operations Per Second).</block>
  <block id="866b04fa947dc783f0a1ca67687a0b46" category="paragraph"><block ref="866b04fa947dc783f0a1ca67687a0b46" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f34ceedf45c53ac5bfc4732c7e9eb992" category="paragraph">Der folgende Abschnitt stellt die wichtigsten Leistungskennzahlen für den Speicher vor.</block>
  <block id="40c9acf8f61419691d77b3dec178cdc9" category="cell">Höchststand bei 147.000</block>
  <block id="971ae6b3c89c8ab12e0eed4e70f3ad7a" category="paragraph">Basierend auf der Leistungsvalidierung sowohl des eigenständigen Milvus als auch des Milvus-Clusters präsentieren wir die Details des Speicher-E/A-Profils.  * Wir haben festgestellt, dass das E/A-Profil sowohl bei eigenständigen als auch bei Cluster-Bereitstellungen konsistent bleibt.  * Der beobachtete Unterschied bei den Spitzen-IOPS kann auf die größere Anzahl von Clients in der Clusterbereitstellung zurückgeführt werden.</block>
  <block id="537edb0aa02f73a246f084214ff9a1e4" category="section-title">vectorDB-Bench mit Postgres (pgvecto.rs)</block>
  <block id="62f6737d84249676fddeaa6678755d2a" category="paragraph">Wir haben die folgenden Aktionen mit VectorDB-Bench an PostgreSQL (pgvecto.rs) durchgeführt: Die Details zur Netzwerk- und Serverkonnektivität von PostgreSQL (insbesondere pgvecto.rs) lauten wie folgt:</block>
  <block id="467a4cd74d7adb713cf4f94b3dd642b7" category="paragraph"><block ref="467a4cd74d7adb713cf4f94b3dd642b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd9a767006e111bd203547a99e12e650" category="paragraph">In diesem Abschnitt teilen wir unsere Beobachtungen und Ergebnisse aus dem Testen der PostgreSQL-Datenbank, insbesondere mit pgvecto.rs.  * Wir haben HNSW als Indextyp für diese Tests ausgewählt, da DiskANN zum Zeitpunkt des Tests für pgvecto.rs nicht verfügbar war.  * Während der Datenaufnahmephase haben wir den Cohere-Datensatz geladen, der aus 10 Millionen Vektoren mit einer Dimensionalität von 768 besteht.  Dieser Vorgang dauerte ungefähr 4,5 Stunden.  * In der Abfragephase haben wir eine Abfragerate pro Sekunde (QPS) von 1.068 mit einem Rückruf von 0,6344 beobachtet.  Die Latenzzeit für Abfragen im 99. Perzentil wurde mit 20 Millisekunden gemessen.  Während des größten Teils der Laufzeit war die CPU des Clients zu 100 % ausgelastet.</block>
  <block id="1f3e94e90c6dc70493177c947144e128" category="paragraph">Die folgenden Bilder bieten eine Ansicht verschiedener Speichermetriken, einschließlich der Gesamt-IOPS (Input/Output Operations Per Second) der Speicherclusterlatenz.</block>
  <block id="887b48e40648d9beb4f86ffbf295813a" category="paragraph"><block ref="887b48e40648d9beb4f86ffbf295813a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59566b4d8c8fef1f2b244df87cbe1523" category="paragraph"><block ref="59566b4d8c8fef1f2b244df87cbe1523" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fa49276609916c00fd739a7d0474f2e0" category="section-title">Leistungsvergleich zwischen Milvus und Postgres auf Vector DB Bench</block>
  <block id="870f4bfca5a2e4c27797438cfbcdcafc" category="paragraph"><block ref="870f4bfca5a2e4c27797438cfbcdcafc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9a6bb1cc3086d7d67df39b7f25c55f2f" category="paragraph">Basierend auf unserer Leistungsvalidierung von Milvus und PostgreSQL mit VectorDBBench haben wir Folgendes beobachtet:</block>
  <block id="edec147efc5d9e9f8c60dd4f8475a94a" category="list-text">Indextyp: HNSW</block>
  <block id="2d14d931ff962fab0d69fc6c540c032e" category="list-text">Datensatz: Cohere mit 10 Millionen Vektoren in 768 Dimensionen</block>
  <block id="0e18fa0193d93ed358d7fdb6a65a8bbc" category="paragraph">Wir haben festgestellt, dass pgvecto.rs eine Abfragen-pro-Sekunde-Rate (QPS) von 1.068 mit einem Recall von 0,6344 erreichte, während Milvus eine QPS-Rate von 106 mit einem Recall von 0,9842 erreichte.</block>
  <block id="6f8820eba6bfb1c4427de7e140948640" category="paragraph">Wenn hohe Präzision bei Ihren Abfragen Priorität hat, ist Milvus besser als pgvecto.rs, da es einen höheren Anteil relevanter Elemente pro Abfrage abruft.  Wenn jedoch die Anzahl der Abfragen pro Sekunde ein entscheidenderer Faktor ist, übertrifft pgvecto.rs Milvus.  Es ist jedoch wichtig zu beachten, dass die Qualität der über pgvecto.rs abgerufenen Daten geringer ist, da etwa 37 % der Suchergebnisse irrelevante Elemente sind.</block>
  <block id="35a1dd67e98f2039e3b4dc79a35aaa3e" category="section-title">Beobachtung basierend auf unseren Leistungsvalidierungen:</block>
  <block id="e6b80e98176081ee739c8e730d3feb58" category="paragraph">Basierend auf unseren Leistungsvalidierungen haben wir folgende Beobachtungen gemacht:</block>
  <block id="9d57f733c58a90a624b060f00ad469bd" category="paragraph">In Milvus ähnelt das E/A-Profil stark einer OLTP-Workload, wie sie beispielsweise bei Oracle SLOB auftritt.  Der Benchmark besteht aus drei Phasen: Datenaufnahme, Nachoptimierung und Abfrage.  Die Anfangsphasen sind hauptsächlich durch 64-KB-Schreibvorgänge gekennzeichnet, während die Abfragephase überwiegend 8-KB-Lesevorgänge umfasst.  Wir erwarten, dass ONTAP die Milvus-E/A-Last effizient bewältigt.</block>
  <block id="e63d591f52bb0af8effc43c397a26a24" category="paragraph">Das PostgreSQL-E/A-Profil stellt keine anspruchsvolle Speicherarbeitslast dar.  Angesichts der derzeit laufenden In-Memory-Implementierung konnten wir während der Abfragephase keine Festplatten-E/A beobachten.</block>
  <block id="dca2ae788fda893b11a6e115cfbd0c5d" category="paragraph">DiskANN erweist sich als entscheidende Technologie zur Speicherdifferenzierung.  Es ermöglicht die effiziente Skalierung der Vektor-DB-Suche über die Systemspeichergrenze hinaus.  Es ist jedoch unwahrscheinlich, dass mit In-Memory-Vektor-DB-Indizes wie HNSW eine Differenzierung der Speicherleistung erreicht wird.</block>
  <block id="dc94ef6a238640d927556506c546662f" category="paragraph">Es ist auch erwähnenswert, dass der Speicher während der Abfragephase keine kritische Rolle spielt, wenn der Indextyp HSNW ist. Dies ist die wichtigste Betriebsphase für Vektordatenbanken, die RAG-Anwendungen unterstützen.  Dies bedeutet, dass die Speicherleistung keinen signifikanten Einfluss auf die Gesamtleistung dieser Anwendungen hat.</block>
  <block id="0a5775b4af8d3c53f18b8ccaf913945d" category="summary">Dies ist eine abstrakte Seite für die Vektordatenbanklösung mit Netapp.</block>
  <block id="8df98bd508b3983f9578ff172fd33def" category="doc">Vector Datenbanklösung mit NetApp</block>
  <block id="7dff0a79d9410666d77e5f2ac7d0344f" category="paragraph">Karthikeyan Nagalingam und Rodrigo Nascimento, NetApp</block>
  <block id="01fbfceb794af743cb563e2676923b70" category="paragraph">Dieses Dokument bietet eine umfassende Untersuchung der Bereitstellung und Verwaltung von Vektordatenbanken wie Milvus und pgvecto, einer Open-Source-PostgreSQL-Erweiterung, unter Verwendung der Speicherlösungen von NetApp.  Es beschreibt detailliert die Infrastrukturrichtlinien für die Verwendung von NetApp ONTAP und StorageGRID Objektspeicher und validiert die Anwendung der Milvus-Datenbank in AWS FSx ONTAP.  Das Dokument erläutert die Datei-Objekt-Dualität von NetApp und ihren Nutzen für Vektordatenbanken und Anwendungen, die Vektoreinbettungen unterstützen.  Es betont die Fähigkeiten von SnapCenter, dem Enterprise-Management-Produkt von NetApp, das Sicherungs- und Wiederherstellungsfunktionen für Vektordatenbanken bietet und so die Datenintegrität und -verfügbarkeit sicherstellt.  Das Dokument befasst sich eingehender mit der Hybrid-Cloud-Lösung von NetApp und erörtert ihre Rolle bei der Datenreplikation und -sicherung in lokalen und Cloud-Umgebungen.  Es enthält Einblicke in die Leistungsvalidierung von Vektordatenbanken auf NetApp ONTAP und schließt mit zwei praktischen Anwendungsfällen zur generativen KI: RAG mit LLM und NetApps internem ChatAI.  Dieses Dokument dient als umfassender Leitfaden zur Nutzung der Speicherlösungen von NetApp für die Verwaltung von Vektordatenbanken.</block>
  <block id="ad452e95198e544e4d893fc75ad47dd6" category="paragraph">Der Schwerpunkt der Referenzarchitektur liegt auf Folgendem:</block>
  <block id="710d95da54f78f69676ae8cb435c6e6e" category="list-text"><block ref="710d95da54f78f69676ae8cb435c6e6e" category="inline-link-macro-rx"></block></block>
  <block id="ada57c9cda1b1c751a4e899e578d38e3" category="list-text"><block ref="ada57c9cda1b1c751a4e899e578d38e3" category="inline-link-macro-rx"></block></block>
  <block id="82f4ace5dffbf97de80ca1ea103fbe56" category="list-text"><block ref="82f4ace5dffbf97de80ca1ea103fbe56" category="inline-link-macro-rx"></block></block>
  <block id="55496e6b06de6e72c19b578ad4ce71d8" category="inline-link-macro">Technologieanforderungen</block>
  <block id="4abf02f5e3deeb5036c0eded610de05a" category="list-text"><block ref="4abf02f5e3deeb5036c0eded610de05a" category="inline-link-macro-rx"></block></block>
  <block id="19c63a75039d0a9cb4cec3458cfe0581" category="list-text"><block ref="19c63a75039d0a9cb4cec3458cfe0581" category="inline-link-macro-rx"></block></block>
  <block id="8c8f8b93bc06c57499a04ec1b06dae28" category="inline-link-macro">Übersicht zur Lösungsüberprüfung</block>
  <block id="ca47b69088a672a9b65069106989453e" category="list-text"><block ref="ca47b69088a672a9b65069106989453e" category="inline-link-macro-rx"></block></block>
  <block id="55d7ef09813b4d6fdcb2c5626efe487e" category="list-text"><block ref="55d7ef09813b4d6fdcb2c5626efe487e" category="inline-link-macro-rx"></block></block>
  <block id="0bf83d510fcfec34ea35ee03c83ce577" category="list-text">link:vector-database-milvus-with-Amazon-FSx ONTAP-for- NetApp- ONTAP.html[Milvus mit Amazon FSx ONTAP für NetApp ONTAP – Datei- und Objektdualität]</block>
  <block id="d6b228867818081bf3ee3cecad050baf" category="list-text"><block ref="d6b228867818081bf3ee3cecad050baf" category="inline-link-macro-rx"></block></block>
  <block id="f7ba02d22d83dabd12f0465a68c210ea" category="list-text"><block ref="f7ba02d22d83dabd12f0465a68c210ea" category="inline-link-macro-rx"></block></block>
  <block id="9e30995c6d4864b29eb56e92d196baec" category="list-text"><block ref="9e30995c6d4864b29eb56e92d196baec" category="inline-link-macro-rx"></block></block>
  <block id="bd1287beca719fc00531ba3dd533f70c" category="list-text"><block ref="bd1287beca719fc00531ba3dd533f70c" category="inline-link-macro-rx"></block></block>
  <block id="a4349288a9fe8fecb32674ed8a0e5d15" category="inline-link-macro">Anwendungsfälle für Vektordatenbanken</block>
  <block id="b8d3dfdbfce37d26c1f4f9d8acee71ca" category="list-text"><block ref="b8d3dfdbfce37d26c1f4f9d8acee71ca" category="inline-link-macro-rx"></block></block>
  <block id="da73b8a757c1735375b56d959d388619" category="list-text"><block ref="da73b8a757c1735375b56d959d388619" category="inline-link-macro-rx"></block></block>
  <block id="fec04177b34fde0762c2d0f1cb5bcf85" category="inline-link-macro">Anhang A: values.yaml</block>
  <block id="4076746ca906dfd472a39281440bca63" category="list-text"><block ref="4076746ca906dfd472a39281440bca63" category="inline-link-macro-rx"></block></block>
  <block id="2c0fbb0e17a27b8dbff673fb6b03c50b" category="list-text"><block ref="2c0fbb0e17a27b8dbff673fb6b03c50b" category="inline-link-macro-rx"></block></block>
  <block id="016166f68a717d3a544b77970134fe92" category="inline-link-macro">Anhang C: verify_data_netapp.py</block>
  <block id="1fa29d4bb8db316d27c057bc2ab73bcb" category="list-text"><block ref="1fa29d4bb8db316d27c057bc2ab73bcb" category="inline-link-macro-rx"></block></block>
  <block id="cb2986bd8f2d29c4cca582736e0a680f" category="list-text"><block ref="cb2986bd8f2d29c4cca582736e0a680f" category="inline-link-macro-rx"></block></block>
  <block id="f60546114707495cbcefb83f806b47e2" category="summary">Technologieanforderung – Vector Datenbanklösung für Netapp</block>
  <block id="73877510aa37e2bcf501625512e358c3" category="paragraph">Dieser Abschnitt bietet einen Überblick über die Anforderungen für die NetApp Vector-Datenbanklösung.</block>
  <block id="1507fd593972e19976a48675eb11483a" category="paragraph">Für die Mehrzahl der in diesem Dokument durchgeführten Validierungen wurden die unten beschriebenen Hardware- und Softwarekonfigurationen verwendet, mit Ausnahme der Leistung.  Diese Konfigurationen dienen als Richtlinie und helfen Ihnen beim Einrichten Ihrer Umgebung.  Bitte beachten Sie jedoch, dass die konkreten Komponenten je nach individuellen Kundenanforderungen variieren können.</block>
  <block id="7e9534170bcf0d2cab4a69e22cdca79c" category="cell">* A800 * ONTAP 9.14.1 * 48 x 3,49 TB SSD-NVM * Zwei flexible Gruppenvolumes: Metadaten und Daten.  * Das Metadaten-NFS-Volume verfügt über 12 persistente Volumes mit 250 GB.  * Daten sind ein ONTAP NAS S3-Volume</block>
  <block id="bcb4d8bb0642dc62c114f2a0a31f5aa3" category="cell">6 x FUJITSU PRIMERGY RX2540 M4</block>
  <block id="891b7b85ad27bcf31f4d6b9d3e5f55eb" category="cell">* 64 CPUs * Intel(R) Xeon(R) Gold 6142 CPU @ 2,60 GHz * 256 GM physischer Speicher * 1 x 100GbE Netzwerkanschluss</block>
  <block id="4515188d6af40c03b16b310778b865c8" category="cell">* 1 x SG100, 3 x SGF6024 * 3 x 24 x 7,68 TB</block>
  <block id="e7f07d17d04d9ac60dd3ebc382a1d58b" category="cell">Milvus-Cluster</block>
  <block id="5c9a77f3be5149b25ef3dd4a0d42f61e" category="cell">* DIAGRAMM - milvus-4.1.11.  * APP-Version – 2.3.4 * Abhängige Pakete wie Bookkeeper, Zookeeper, Pulsar, etcd, Proxy, Querynode, Worker</block>
  <block id="b0654cc6796be715102b69214bddfb52" category="cell">* 5-Knoten-K8s-Cluster * 1 Masterknoten und 4 Workerknoten * Version – 1.7.2</block>
  <block id="5b8215321456694f36bc83a178e44856" category="cell">*3.10.12.</block>
  <block id="5a019cf3628ae4961c3ba86198ac5410" category="summary">Anwendungsfall – Vector-Datenbanklösung für NetApp</block>
  <block id="853fb1f37b200090af8f730400a34971" category="paragraph">Dieser Abschnitt bietet einen Überblick über die Anwendungsfälle für die NetApp Vector-Datenbanklösung.</block>
  <block id="61798ad0c56d51680f77d6b9f4694877" category="paragraph">In diesem Abschnitt besprechen wir zwei Anwendungsfälle, nämlich Retrieval Augmented Generation mit großen Sprachmodellen und NetApp IT-Chatbot.</block>
  <block id="2b376c37a6f0c2c21b8ba7b62ac86693" category="section-title">Retrieval Augmented Generation (RAG) mit großen Sprachmodellen (LLMs)</block>
  <block id="6a482cb4a386f8c0b7889b5dc11a997a" category="paragraph">Der NVIDIA Enterprise RAG LLM Operator ist ein nützliches Tool zur Implementierung von RAG im Unternehmen.  Mit diesem Operator kann eine vollständige RAG-Pipeline bereitgestellt werden.  Die RAG-Pipeline kann angepasst werden, um entweder Milvus oder pgvecto als Vektordatenbank zum Speichern von Wissensdatenbank-Einbettungen zu verwenden.  Weitere Einzelheiten finden Sie in der Dokumentation.</block>
  <block id="4c1729beb205806fa130c0dbf0364b59" category="paragraph">Abbildung 1) Enterprise RAG mit NVIDIA NeMo Microservices und NetApp</block>
  <block id="b14745e6302744b3b3c226e1fdee230a" category="paragraph"><block ref="b14745e6302744b3b3c226e1fdee230a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da66e40722180b5a0466a9ff253976af" category="section-title">Anwendungsfall für den NetApp IT-Chatbot</block>
  <block id="497416719429ff96f2462d991f6ea3f8" category="paragraph">Der Chatbot von NetApp dient als weiterer Echtzeit-Anwendungsfall für die Vektordatenbank.  In diesem Fall bietet die NetApp Private OpenAI Sandbox eine effektive, sichere und effiziente Plattform für die Verwaltung von Abfragen interner NetApp-Benutzer.  Durch die Integration strenger Sicherheitsprotokolle, effizienter Datenverwaltungssysteme und ausgefeilter KI-Verarbeitungsfunktionen werden den Benutzern über die SSO-Authentifizierung qualitativ hochwertige und präzise Antworten basierend auf ihren Rollen und Verantwortlichkeiten in der Organisation garantiert.  Diese Architektur unterstreicht das Potenzial der Zusammenführung fortschrittlicher Technologien zur Schaffung benutzerorientierter, intelligenter Systeme.</block>
  <block id="8afdd8df71939b23b5b37041b4b0e243" category="paragraph"><block ref="8afdd8df71939b23b5b37041b4b0e243" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ff2b3d5b17bdfc4a02990dd4115b7d4d" category="paragraph">Der Anwendungsfall kann in vier Hauptabschnitte unterteilt werden.</block>
  <block id="e21f69fe36aefc844dcebf8fb52262a3" category="section-title">Benutzerauthentifizierung und -verifizierung:</block>
  <block id="7457d61423f49fa817953d3c8e0c08cf" category="list-text">Benutzeranfragen durchlaufen zunächst den NetApp Single Sign-On (SSO)-Prozess, um die Identität des Benutzers zu bestätigen.</block>
  <block id="3dedad86d8ac55d8b2b034f0ff353ea5" category="list-text">Nach erfolgreicher Authentifizierung prüft das System die VPN-Verbindung, um eine sichere Datenübertragung zu gewährleisten.</block>
  <block id="34ef9101314d114f1bed9a4fc8c13666" category="section-title">Datenübertragung und -verarbeitung:</block>
  <block id="e5aa3164f4a76a72d1d074c0285a4d54" category="list-text">Sobald das VPN validiert ist, werden die Daten über die Webanwendungen NetAIChat oder NetAICreate an MariaDB gesendet.  MariaDB ist ein schnelles und effizientes Datenbanksystem zum Verwalten und Speichern von Benutzerdaten.</block>
  <block id="d0d4d700ca2ba3e943833a184fce15db" category="list-text">MariaDB sendet die Informationen dann an die NetApp Azure-Instanz, die die Benutzerdaten mit der KI-Verarbeitungseinheit verbindet.</block>
  <block id="b1cbaf6e413b3b5a92538942710197de" category="section-title">Interaktion mit OpenAI und Inhaltsfilterung:</block>
  <block id="e7a51c3da456741ac0fe5ae031a539a3" category="list-text">Die Azure-Instanz sendet die Fragen des Benutzers an ein Inhaltsfiltersystem.  Dieses System bereinigt die Abfrage und bereitet sie für die Verarbeitung vor.</block>
  <block id="8449bc1c7d0f0641656072f90d8d06db" category="list-text">Die bereinigte Eingabe wird dann an das Azure OpenAI-Basismodell gesendet, das basierend auf der Eingabe eine Antwort generiert.</block>
  <block id="ce4abebf9a6d91e3d12d3bd86ebd308f" category="section-title">Antwortgenerierung und -moderation:</block>
  <block id="70ee91d51a5da426448f1ed59462804d" category="list-text">Die Antwort des Basismodells wird zunächst überprüft, um sicherzustellen, dass sie korrekt ist und den Inhaltsstandards entspricht.</block>
  <block id="40d26f0ba80199b0eaf7b7e0525c7f34" category="list-text">Nach bestandener Prüfung wird die Antwort an den Benutzer zurückgesendet.  Dieser Prozess stellt sicher, dass der Benutzer eine klare, genaue und angemessene Antwort auf seine Anfrage erhält.</block>
  <block id="705451e750819c9ce68fb278a7b09839" category="summary">values-xml - Vektordatenbanklösung für NetApp</block>
  <block id="6e6c82b93338e2283cf42123803b79d4" category="doc">Anhang A: Values.yaml</block>
  <block id="42cb737e154e9abe53c3f800eae00d4e" category="paragraph">Dieser Abschnitt enthält Beispiel-YAML-Code für die in der NetApp -Vektordatenbanklösung verwendeten Werte.</block>
  <block id="bdcc26240ab0215ba46efad29038278d" category="summary">Übersicht zur Lösungsüberprüfung – Vector-Datenbanklösung für NetApp</block>
  <block id="a11dfa705c151f0af3e80cc954126655" category="paragraph">Wir haben eine umfassende Lösungsvalidierung mit Schwerpunkt auf fünf Schlüsselbereichen durchgeführt, deren Einzelheiten im Folgenden aufgeführt sind.  Jeder Abschnitt befasst sich eingehend mit den Herausforderungen, vor denen die Kunden stehen, den von NetApp bereitgestellten Lösungen und den daraus resultierenden Vorteilen für den Kunden.</block>
  <block id="748a76b95c3f380357377aefd2ed0474" category="list-text"><block ref="55d7ef09813b4d6fdcb2c5626efe487e" category="inline-link-macro-rx"></block>Kunden stehen vor der Herausforderung, Speicher und Rechenleistung unabhängig zu skalieren und die Infrastruktur und Daten effektiv zu verwalten.  In diesem Abschnitt beschreiben wir detailliert den Prozess der Installation eines Milvus-Clusters auf Kubernetes unter Verwendung eines NetApp -Speichercontrollers sowohl für Clusterdaten als auch für Kundendaten.</block>
  <block id="e840bff7e1e9715df98e16fead8076cb" category="list-text">link:vector-database-milvus-with-Amazon-FSx ONTAP-for- NetApp- ONTAP.html[Milvus mit Amazon FSx ONTAP für NetApp ONTAP – Datei- und Objektdualität] In diesem Abschnitt erfahren Sie, warum wir die Vektordatenbank in der Cloud bereitstellen müssen, sowie die Schritte zur Bereitstellung der Vektordatenbank (Milvus Standalone) in Amazon FSx ONTAP für NetApp ONTAP innerhalb von Docker-Containern.</block>
  <block id="6cce3de9e8bf8cabbfe260cc36d61ac3" category="list-text"><block ref="d6b228867818081bf3ee3cecad050baf" category="inline-link-macro-rx"></block>In diesem Abschnitt gehen wir näher darauf ein, wie SnapCenter die in ONTAP gespeicherten Vektordatenbankdaten und Milvus-Daten schützt.  Für dieses Beispiel haben wir einen NAS-Bucket (milvusdbvol1) verwendet, der aus einem NFS- ONTAP Volume (vol1) für Kundendaten abgeleitet wurde, und ein separates NFS-Volume (vectordbpv) für Milvus-Cluster-Konfigurationsdaten.</block>
  <block id="918f8a4912d6a98fb31ac7ba46e00ffc" category="list-text"><block ref="f7ba02d22d83dabd12f0465a68c210ea" category="inline-link-macro-rx"></block>In diesem Abschnitt besprechen wir die Bedeutung der Notfallwiederherstellung (DR) für die Vektordatenbank und wie das NetApp-Notfallwiederherstellungsprodukt SnapMirror eine DR-Lösung für die Vektordatenbank bereitstellt.</block>
  <block id="2f1a6b813251891cca144a8b91cde4f5" category="list-text"><block ref="9e30995c6d4864b29eb56e92d196baec" category="inline-link-macro-rx"></block>In diesem Abschnitt möchten wir uns eingehend mit der Leistungsvalidierung von Vektordatenbanken wie Milvus und pgvecto.rs befassen und uns dabei auf ihre Speicherleistungsmerkmale wie E/A-Profil und Verhalten des NetApp-Speichercontrollers zur Unterstützung von RAG- und Inferenz-Workloads innerhalb des LLM-Lebenszyklus konzentrieren.  Wir werden alle Leistungsunterschiede bewerten und identifizieren, wenn diese Datenbanken mit der ONTAP Speicherlösung kombiniert werden.  Unsere Analyse basiert auf wichtigen Leistungsindikatoren, beispielsweise der Anzahl der pro Sekunde verarbeiteten Abfragen (QPS).</block>
  <block id="87c3db9ccf444604c258b88ee8489364" category="summary">verify_data_netapp.py – Vektordatenbanklösung für NetApp</block>
  <block id="599675cccffd45ab676aea932c3fdfbd" category="paragraph">Dieser Abschnitt enthält ein Python-Beispielskript, das zur Validierung der Vektordatenbank in der NetApp Vektordatenbanklösung verwendet werden kann.</block>
  <block id="48e4e86482d1e72b17c82feb1e930352" category="doc">Sehen Sie sich Videos zu KI-Lösungen mit NetApp an</block>
  <block id="a9f5e6dcd1d44f9ba3dc3398020d2404" category="paragraph">Entdecken Sie, wie NetApp KI- und Machine-Learning-Initiativen unterstützt.  Diese kuratierten Video-Playlists präsentieren NetApp KI-Lösungen und MLOps-Workflows und heben Bereitstellungsstrategien, Automatisierung und Datenmanagement für erweiterte Analysen hervor.</block>
  <block id="145706f4acca44c289ff5ca8cc5b2b86" category="paragraph-title">NetApp AI -Lösungen</block>
  <block id="b4bf3d1dd932a4fb0e32b91623652e42" category="inline-link-macro">Sehen Sie sich die Playlist mit den NetApp KI-Lösungen an</block>
  <block id="d3e2da82e7d75fc2a126141e7169de49" category="paragraph">Umfassende Video-Playlist zu KI-Infrastruktur, konvergenten Systemen und KI-Bereitstellungen in Unternehmen.<block ref="af3f91668350fde9b89e361b330e6bf9" category="inline-link-macro-rx"></block></block>
  <block id="07aca6f404d3e6c525bac36328b0d27d" category="paragraph-title">Maschinelles Lernen (MLOps)</block>
  <block id="aee569e95a8498ede74e68ae8306e6e5" category="inline-link-macro">Sehen Sie sich die MLOps-Playlist an</block>
  <block id="d41374c7672e6e4fdbfbd6504b672d3c" category="paragraph">Videoserie zu MLOps-Workflows, Datenpipelines und betrieblichen Best Practices.<block ref="70aea7fc5134cd09b86d7ff27c954117" category="inline-link-macro-rx"></block></block>
  <block id="10b2aec15aae4d935355e27497e66c5f" category="summary">Eine Reihe von Videos und Demos, in denen die Funktionen vieler NetApp-Lösungen erläutert werden</block>
  <block id="6354d74cd74c1d9f49224ac4e6209bab" category="doc">NetApp -Lösungen: Videos und Demos</block>
  <block id="60b5065968cf0f66d862a344124f6415" category="paragraph">Übersicht über die Videos und Demos, die bestimmte Funktionen vieler NetApp-Lösungen hervorheben.</block>
  <block id="b0d7b47f43a6efe75ff49bfd5e21f6fd" category="list-text"><block ref="b0d7b47f43a6efe75ff49bfd5e21f6fd" category="inline-link-macro-rx"></block></block>
  <block id="895a85fc0a1a565ac547acc1bc9740f3" category="inline-link-macro">MLOps</block>
  <block id="90e97692c42b1eb0ec22c639049d78a1" category="list-text"><block ref="90e97692c42b1eb0ec22c639049d78a1" category="inline-link-macro-rx"></block></block>
  <block id="181a90cd4ce68792d6ce2049bb1ff6ec" category="summary">Protokoll der jüngsten Änderungen am Material zu den NetApp -Lösungen für künstliche Intelligenz.</block>
  <block id="232dfabf5b2a241a9f7473820c81bf15" category="doc">Neuigkeiten zu NetApp -Lösungen für künstliche Intelligenz</block>
  <block id="be647982bfc8c0837c019b8fdbc711b3" category="paragraph">Erfahren Sie, was es Neues bei Lösungen für künstliche Intelligenz gibt.</block>
  <block id="bab52961b58c502c7991d35556c25367" category="section-title">18. August 2025</block>
  <block id="47e26e0d5bbeef43c544dd9ae72e66b0" category="inline-link-macro">NetApp Lösungsfamilie</block>
  <block id="840125a006aee7dc0e8efd313e7b614e" category="paragraph">Die NetApp Solutions-Site ist jetzt die<block ref="f083b096ae581e72c5ab727ef8bd5732" category="inline-link-macro-rx"></block> , das die folgenden Websites umfasst:</block>
  <block id="e87298059f60b0844dc971f315184cf5" category="list-text">NetApp Lösungen für künstliche Intelligenz</block>
  <block id="9cae574c1dc1ca50a949c1e889637ba7" category="inline-link-macro">NetApp Container-Lösungen</block>
  <block id="31d1ae0120af1d791e4320e17eb10687" category="list-text"><block ref="31d1ae0120af1d791e4320e17eb10687" category="inline-link-macro-rx"></block></block>
  <block id="3947417923606d3599bcba7a82f71f1b" category="inline-link-macro">NetApp Datenmanagementlösungen</block>
  <block id="56c054d4bb919790ebe189f7a7d11c3c" category="list-text"><block ref="56c054d4bb919790ebe189f7a7d11c3c" category="inline-link-macro-rx"></block></block>
  <block id="9bb3e58246c5654a6d8e08a7bddd60ec" category="inline-link-macro">NetApp Datenbanklösungen</block>
  <block id="3e2420ab1ec1d6e02b32b017d3ba969a" category="list-text"><block ref="3e2420ab1ec1d6e02b32b017d3ba969a" category="inline-link-macro-rx"></block></block>
  <block id="a37049a2a78422ac5627c7987db5c337" category="inline-link-macro">NetApp Public- und Hybrid-Cloud-Lösungen</block>
  <block id="144417321224efbf0afc2ae665a84a46" category="list-text"><block ref="144417321224efbf0afc2ae665a84a46" category="inline-link-macro-rx"></block></block>
  <block id="2729aba3baa90aaaed37b282e515f6e4" category="inline-link-macro">NetApp Lösungen für SAP</block>
  <block id="5e056430559fb77ac659dbb71ecce256" category="list-text"><block ref="5e056430559fb77ac659dbb71ecce256" category="inline-link-macro-rx"></block></block>
  <block id="4ead908c2ca3b4c7156e0e703642415d" category="inline-link-macro">NetApp Virtualisierungslösungen</block>
  <block id="3100186c9f62cec85ac05309c5d10217" category="list-text"><block ref="3100186c9f62cec85ac05309c5d10217" category="inline-link-macro-rx"></block></block>
  <block id="fac83ccf1756a0c9cb3b8982d7f17073" category="sidebar">NetApp bietet umfassende KI-Lösungen, die Datenmanagement auf Unternehmensniveau, validierte Referenzarchitekturen und strategische Partnerschaften kombinieren, um Ihre KI-Initiativen zu beschleunigen und kritische Geschäftsergebnisse zu unterstützen.  Von der Infrastrukturbereitstellung bis zur MLOps-Automatisierung lassen sich unsere Lösungen nahtlos über Edge-, Rechenzentrums- und Hybrid-Cloud-Umgebungen skalieren.</block>
  <block id="be11c74c1dd7f307bb80183a90dc2067" category="sidebar">Erste Schritte</block>
  <block id="33871b6190a8d5adbe8b15282054766c" category="sidebar">Was ist neu</block>
  <block id="d6b9ea32b921a9f56de32062ba4b94f3" category="sidebar">Blogs</block>
  <block id="de42653a3a04e4aefa258105632011d4" category="sidebar">Videos und Demos</block>
  <block id="0356451dce8be030d34b4cddc51bd023" category="sidebar">KI-Infrastruktur und konvergente Systeme</block>
  <block id="9547dc55d95184a53ea1a8366b5aeced" category="sidebar">NetApp AIPod mit NVIDIA DGX-Systemen</block>
  <block id="1f403aa196fd2c94e882669641695d63" category="sidebar">NVIDIA DGX SuperPOD mit EF-Serie</block>
  <block id="ca2b44ea641055fab6c572a1ec645f40" category="sidebar">NetApp AIPod mit Lenovo für NVIDIA OVX</block>
  <block id="71194b59e7e6e05cdd5e38686d46dd11" category="sidebar">BeeGFS-Paralleldateisystem mit E-Serie</block>
  <block id="0490c28d4251b3da040883241b9a245b" category="sidebar">KI-Anwendungsfälle und -Anwendungen</block>
  <block id="03a2eeb037be2a65352a6ce833a5352d" category="sidebar">AIPod Mini für RAG-Inferenz</block>
  <block id="2a5e8ee0f85321457b5b5051848b33df" category="sidebar">KI-Inferenzierung am Edge</block>
  <block id="1f5ef80ba6fe60fcd8fc9b93428724ca" category="sidebar">Vector-Datenbanklösungen</block>
  <block id="1c2e519ac88b24b944e313f1528b25ca" category="sidebar">Arbeitsbelastung beim autonomen Fahren</block>
  <block id="1f2d4372bbd3f4944eec91b65eb55b69" category="sidebar">Quantum StorNext mit E-Serie</block>
  <block id="dd12d2c2197bdac0454f49eaf82efcb1" category="sidebar">MLOps und Datenmanagement</block>
  <block id="55200dead19623a5ed7fd47347cc531d" category="sidebar">Open Source MLOps mit NetApp</block>
  <block id="0fa95f40d436ae4b6b1a848a385c88f5" category="sidebar">Hybride Multicloud-MLOps mit Domino Data Lab</block>
  <block id="ec441b7e7e90b2ae639b5c9784b469f9" category="sidebar">FSx ONTAP für MLOps</block>
  <block id="072e5110aacde0c4952afb7fa86bd5bf" category="sidebar">Big Data und Hybrid Cloud-KI-Lösungen</block>
  <block id="248d62097e51f823fbf1797b8d71b837" category="sidebar">Hybride Cloud-Datenlösungen</block>
  <block id="01ba1aebae20e7ddfe20f3ea9572b0a6" category="sidebar">Apache Spark-Lösungen</block>
  <block id="8f0ff6e8178c4e8f4ea0f489063d7586" category="sidebar">Confluent Kafka mit NetApp ONTAP -Speicher</block>
  <block id="8e2406d586d4192dc66b85722da1c3b9" category="sidebar">NetApp StorageGRID mit Splunk SmartStore</block>
  <block id="76a3eb07a798a5ace45b8500ba2aae19" category="sidebar">Dremio Lakehouse mit NetApp Speicher</block>
  <block id="e95b75f557af9310f3d9c6299286a533" category="sidebar">Lösungsanfragen und Feedback</block>
  <block id="22d04ecae9fae88d0b8d4548a46a545b" category="sidebar">Automatisierung anfordern</block>
  <block id="776ab15fef436c9315c14738509d299e" category="sidebar">Schlagen Sie eine neue Lösung vor</block>
  <block id="cfdaac8ef24ac5b2612570c34da00954" category="sidebar">Geben Sie Feedback zur Lösung</block>
  <block id="9e34d9d231e4cd17fbacda95fb51929b" category="sidebar">Optimieren Sie Ihre KI/ML-Workflows mit den umfassenden MLOps- und Datenmanagementlösungen von NetApp.  Von Open-Source-Plattformen bis hin zu Tools auf Unternehmensebene ermöglichen unsere Lösungen eine effiziente Modellentwicklung, Bereitstellung und Skalierung in Hybrid-Cloud-Umgebungen und gewährleisten gleichzeitig Datenkonsistenz und Leistung.</block>
  <block id="e212a74da744d81b7be22fde8837f469" category="sidebar">NetApp MLOps- und Datenmanagementlösungen</block>
  <block id="7c9c1738224214245dd19322f112f008" category="sidebar">Open-Source-MLOps-Plattformen</block>
  <block id="8225e12837234b91ab0ddcd265042318" category="sidebar">NetApp Trident -Konfiguration für AIPod</block>
  <block id="8b4f0b6bb6bc359f491be13c6d4217c4" category="sidebar">Bereitstellung und Integration von Apache Airflow</block>
  <block id="948fee9aa5251e39df94d1c32d0c25cf" category="sidebar">JupyterHub-Bereitstellung und Datenvorgänge</block>
  <block id="73cee63b0ef47212c43598d623b858e0" category="sidebar">MLflow-Bereitstellung und Rückverfolgbarkeit</block>
  <block id="938ff6f66cfc08077aee20a94cb3555a" category="sidebar">Erweiterte MLOps-Workflows</block>
  <block id="e037812c032cd0d9c22b13bc85e9e8b0" category="sidebar">Kubeflow-Bereitstellung und Notebooks</block>
  <block id="3ff4473b7f6cd29fd2f032383a101ad3" category="sidebar">Trainieren Sie Bilderkennungsmodelle mit Kubeflow</block>
  <block id="4d72e4ce52deedeed5378320bb10ba60" category="sidebar">Ausführung von KI-Workloads auf einem einzelnen Knoten</block>
  <block id="d4090ff0c5d6e77994fe88d878931a09" category="sidebar">Verteilte KI-Workload-Ausführung</block>
  <block id="6d49da972d2b3e8021183d3dd882efc3" category="sidebar">Datenaufnahme mit SnapMirror</block>
  <block id="13c4fd018be37b2e07ac1e3c7bf940da" category="sidebar">Enterprise-MLOps-Lösungen</block>
  <block id="bf57be3e9bf09ff89214bcab0ffcd37f" category="sidebar">Hybrid MLOps mit Domino Data Lab</block>
  <block id="5a938de20177e2b1dcb267d6d7b4f069" category="sidebar">Umgebungsübergreifender Datenzugriff mit Domino</block>
  <block id="86c9440e933f2848898cd3a50e0d30c5" category="sidebar">NVIDIA NGC-Softwareintegration</block>
  <block id="e9eb61f514f368f5d8d0cf3ccfded4f9" category="sidebar">Cloud MLOps und AWS-Integration</block>
  <block id="b9a33eec860aee8b042190248e9c0978" category="sidebar">Amazon FSx für ONTAP MLOps</block>
  <block id="19f22745fb509faf9a35f2999167b4b3" category="sidebar">Integrieren Sie FSx ONTAP als privates S3 in SageMaker</block>
  <block id="958182d4c4d2fbecef5e794dd36a2fcd" category="sidebar">FSx ONTAP für SageMaker-Modelltraining</block>
  <block id="765bac8adf0ce0c27f43291f5f38e36e" category="sidebar">Erstellen Sie eine vereinfachte MLOps-Pipeline mit FSx</block>
  <block id="cff078ffafce4368253406707fe938e2" category="sidebar">Vektordatenbanken und KI-Anwendungen</block>
  <block id="8817647abcdf406ecb3f743ce1f4d0c3" category="sidebar">Vector Datenbanklösung mit NetApp</block>
  <block id="eac46f1424b8a5f784861bfb337632d5" category="sidebar">Milvus-Cluster-Setup mit Kubernetes</block>
  <block id="e557c94c22c1c941bd40b8277f7f7753" category="sidebar">Vector-Datenbankschutz mit SnapCenter</block>
  <block id="ba5dd0875f60bb8bfd1c4511266f65f1" category="sidebar">Leistungsvalidierung der Vektordatenbank</block>
  <block id="8d80ba264d116b7cc3e458ba8697ce83" category="sidebar">Anwendungsfälle für Vektordatenbanken</block>
  <block id="e90bb805ac6728252476dc4b6c9f33b8" category="sidebar">Datenverwaltungstools und -speicherung</block>
  <block id="8825002f133fae0b139e8325ac7730cf" category="sidebar">StorageGRID -Datensee für autonomes Fahren</block>
  <block id="bf25ffbc01db3077dbf625f1f66b0b81" category="sidebar">Notfallwiederherstellung mit SnapMirror</block>
  <block id="1e87a0e6a353196e3d5d6cd2e73a3e6e" category="sidebar">Stellen Sie mit den validierten Referenzarchitekturen und konvergenten Systemen von NetApp eine unternehmensreife KI-Infrastruktur bereit.  Von NetApp AIPod Lösungen bis hin zu Hochleistungsspeicherplattformen bieten unsere Designs die Leistung, Skalierbarkeit und Zuverlässigkeit, die für anspruchsvolle KI/ML-Workloads erforderlich sind.</block>
  <block id="994ec7a86f72507f5352d2b180d45f33" category="sidebar">NetApp KI-Infrastruktur und konvergente Systeme</block>
  <block id="1c869286ed71535693a9462972519af4" category="sidebar">NetApp AIPod Referenzarchitekturen</block>
  <block id="b4f767e2f090ec487aa796e06a450c3b" category="sidebar">AIPod -Architektur</block>
  <block id="b6c79f2c0318b6d7625fb67322575ef8" category="sidebar">Details zur AIPod -Bereitstellung</block>
  <block id="8c660d55cc308e8a0142574e6cb06bb2" category="sidebar">AIPod Validierungs- und Größenleitfaden</block>
  <block id="f5a73cfaecb9184b2e8146ed455050a9" category="sidebar">Hochleistungsspeicher für KI-Workloads</block>
  <block id="dca52c3c8e9f73ebf5e2f52c01c943af" category="sidebar">NVIDIA DGX SuperPOD mit Speicher der EF-Serie</block>
  <block id="0cdb4340f983739886aeeabf55ded9a0" category="sidebar">IBM Spectrum Scale mit E-Series-Speicher</block>
  <block id="103956252a2179a2f41c37f503662e57" category="sidebar">NetApp ONTAP mit Lenovo ThinkSystem</block>
  <block id="e5a53cbbfd61be59509da2fb28b87bd6" category="sidebar">Entdecken Sie reale KI-Implementierungen mit NetApp -Lösungen, von Enterprise-RAG-Systemen und Edge-Inferencing bis hin zu verantwortungsvollen KI-Praktiken und Datenmigrationsstrategien.  Diese Anwendungsfälle zeigen, wie NetApp es Unternehmen ermöglicht, KI-Anwendungen in unterschiedlichen Umgebungen einzusetzen und dabei Sicherheit, Leistung und Skalierbarkeit zu gewährleisten.</block>
  <block id="7438b9f1311e240ca42a988e9d13e00c" category="sidebar">NetApp KI-Anwendungsfälle und -Anwendungen</block>
  <block id="f5d80fd5b29670f59fa900f8c07fb329" category="sidebar">Entdecken Sie reale KI-Implementierungen mit NetApp -Lösungen, von Enterprise-RAG-Systemen und Edge-Inferencing bis hin zu verantwortungsvollen KI-Praktiken und Datenmigrationsstrategien.  Diese Anwendungsfälle zeigen, wie NetApp KI-Anwendungen in unterschiedlichen Umgebungen ermöglicht und gleichzeitig Sicherheit, Leistung und Skalierbarkeit gewährleistet.</block>
  <block id="0d6f02845b71bc324cd82a725369e788" category="sidebar">Enterprise-KI-Anwendungen und Anwendungsfälle</block>
  <block id="a67b9cee4655d6177295261e4bcd604d" category="sidebar">NetApp AIPod Mini für Enterprise RAG</block>
  <block id="f5d3d706e83df8136ffa361f6bf3de44" category="sidebar">Generative KI und NetApp -Wert</block>
  <block id="e2c8fd379213f568475a9fd8d939677a" category="sidebar">Edge-KI-Inferenz mit NetApp und Lenovo</block>
  <block id="7625f6572992d4d6884af97bd58e8555" category="sidebar">Migration von Big Data Analytics zur KI</block>
  <block id="58f52c07cacafd13bf7c2b75bd52297b" category="sidebar">Verantwortungsvolle KI</block>
  <block id="726a429bb7d3cf42471e4ef6d5064f39" category="sidebar">Verantwortungsvolle KI mit Protopia-Bildtransformation</block>
  <block id="9aadc819040333a6a70c083f60934127" category="sidebar">KI-Speicher- und Infrastrukturlösungen</block>
  <block id="4ec66dae70419b5536af92b7e6af12eb" category="sidebar">Entwerfen Sie Quantum StorNext mit Systemen der E-Serie</block>
  <block id="fdc9cddf0d9dda4d36a935baaa555437" category="sidebar">Setzen Sie Quantum StorNext mit E-Series-Systemen ein</block>
  <block id="2107e3f2176d1159c57518d8100b979c" category="sidebar">Transformieren Sie Ihre Datenanalyse-Infrastruktur mit den bewährten Lösungen von NetApp für Big Data-Workloads, darunter Apache Spark, Hadoop, Kafka und moderne Data Lake-Architekturen, die vom Edge bis zur Cloud skalierbar sind.</block>
  <block id="a4c306bc134438ffdcde3dc25d141930" category="sidebar">Moderne Datenanalyselösungen von NetApp</block>
  <block id="f6d439e305ff0317b08aeaad65bc202c" category="sidebar">Die modernen Datenanalyselösungen von NetApp umfassen eine Reihe strategischer und technologischer Funktionen, die die Leistungsfähigkeit von NetApp Storage im gesamten KI-Bereich demonstrieren.</block>
  <block id="0c5c9c87a184244b0a7327aaef882e8e" category="sidebar">Apache Kafka-Lösungen</block>
  <block id="7d576967253ca2f566f9693183407367" category="sidebar">Apache Kafka-Workloads mit NetApp NFS-Speicher</block>
  <block id="b98ea9630b58bea0f022799ecefe4062" category="sidebar">Confluent Kafka mit NetApp ONTAP -Speichercontrollern</block>
  <block id="7f8513139888dda0c0ecb82a93548af9" category="sidebar">Best Practices für Confluent Kafka</block>
  <block id="c9adcd46dfe28ab240bf984f9da39535" category="sidebar">Kafka-Leistungsvalidierung mit AWS</block>
  <block id="c6dc54040e7551a25c7f14dd83a3ca37" category="sidebar">Apache Spark- und Hadoop-Lösungen</block>
  <block id="75b5d408998484e1ea5a4ce3cc432cbe" category="sidebar">NetApp Storage-Lösungen für Apache Spark</block>
  <block id="d2e5b5510723b29c7f85a6f53b0b30fe" category="sidebar">Bereitstellen von Apache Spark-Workloads mit NetApp -Speicher</block>
  <block id="d142861488d42c2de042afc4375049da" category="sidebar">NetApp Hybrid Cloud-Datenlösungen für Spark und Hadoop</block>
  <block id="15b1a623b46c0553eb7e0a02392de6f9" category="sidebar">Anwendungsfälle und Architekturen</block>
  <block id="7bbc21a3294c0070a8663140370d1f39" category="sidebar">Apache Spark-Testergebnisse</block>
  <block id="8b809555e7e0cd658f51306db399d338" category="sidebar">Cloud-Datenmanagement und KI</block>
  <block id="1d2114df6a9f8f5d7e8f597e9c70a6c1" category="sidebar">Cloud-Datenmanagement mit NetApp File-Object Duality und AWS SageMaker</block>
  <block id="4f25c5c9b33cc2f12b098bd8cc026222" category="sidebar">Big Data Analytics: Daten zur künstlichen Intelligenz</block>
  <block id="55cd26df7471de5ffbc83646a94fddbb" category="sidebar">Amazon FSx for NetApp ONTAP für MLOps</block>
  <block id="2a15fc3906339e08c458c8e62e447da3" category="sidebar">Apache Spark Hybrid Cloud-Lösung</block>
  <block id="e0afb7c0b35ca1c50d576d490c1f6f83" category="sidebar">Moderne Data Lake- und Analyseplattformen</block>
  <block id="2f8caf1cb27d10780daee2d12dfe6cf5" category="sidebar">Die hybride Iceberg-Lakehouse-Lösung der nächsten Generation von NetApp und Dremio</block>
  <block id="5e3dc34b61f6a21ffd6549ee40d4631b" category="sidebar">NetApp E-Series E5700 und Splunk Enterprise</block>
  <block id="8cd58c89ff3d51a256ecfe3fe8bab20f" category="sidebar">Zusätzliche Ressourcen</block>
  <block id="7cc3c71ee2fdbff1fd2efbfcded89f90" category="sidebar">Unterschiedliche Lösungen für unterschiedliche Analysestrategien</block>
  <block id="8598954d073301b356199d49f5c02a69" category="sidebar">Blog: Apache Spark spielt im NetApp Data Analytics Playground</block>
  <block id="0795007b8521bf374f9ddd4eb68a4a2b" category="sidebar">Blog: Verwenden Sie XCP für die Datenmigration von einem Data Lake und HPC zu ONTAP NFS</block>
  <block id="c254d48fc85fff80674335af647fc2d3" category="sidebar">NetApp TV: Playlist zur Big Data-Analyse</block>
  <block id="5baf6ec1129c513e42641878b72ed0d8" category="sidebar">Lösungen für künstliche Intelligenz</block>
  <block id="554cfab3938e21d9270bd6b75931f96f" category="sidebar">Videos</block>
  <block id="45552f1d8df5302f6b20a45bdca4873c" category="sidebar">NetApp Trident -Konfiguration</block>
  <block id="629606c7cd29d3a21eb21c6ac5139f33" category="sidebar">Trident -Backends für AIPod Bereitstellungen</block>
  <block id="6c7cb31582a28a42e762b2046a1ce896" category="sidebar">Kubernetes StorageClasses für AIPod Bereitstellungen</block>
  <block id="d9fd1af737bab40d222131485c9bb808" category="sidebar">Apache Airflow-Bereitstellung</block>
  <block id="17f2e89c743299170fd62138fa80d495" category="sidebar">JupyterHub-Bereitstellung</block>
  <block id="471efd78e003975a601bfbdaf70136d2" category="sidebar">Datenaufnahme mit NetApp SnapMirror</block>
  <block id="7d6f6d1bc3093617ee4703c5e520774b" category="sidebar">MLflow-Bereitstellung</block>
  <block id="7174f04026f1e5e87367c72c1c073824" category="sidebar">Rückverfolgbarkeit vom Datensatz zum Modell mit NetApp und MLflow</block>
  <block id="a38d89f197f605418a88b686e0175fa2" category="sidebar">Kubeflow-Bereitstellung</block>
  <block id="b540e10006be068e5e5fd93d05b7b12c" category="sidebar">Bereitstellen des Jupyter Notebook-Arbeitsbereichs</block>
  <block id="e8816281bfd02443de2002db66789462" category="sidebar">Trainieren eines Bilderkennungsmodells – Beispiel-Workflow</block>
  <block id="4c71560715665aa3108585868c989cdc" category="sidebar">Beispiele für Trident -Operationen</block>
  <block id="1c6a3a6b23e40077c58b45d05d4d411f" category="sidebar">Beispiele für Hochleistungsjobs für AIPod Bereitstellungen</block>
  <block id="dcdebd18dbab6da6d511c220479f6460" category="sidebar">Ausführen einer KI-Workload auf einem einzelnen Knoten</block>
  <block id="98053e2b2531af18e4f885fb8a731327" category="sidebar">Ausführen einer synchronen verteilten KI-Workload</block>
  <block id="7406ea045ac944a9db15b50dba8cc04b" category="sidebar">Hybrid MLOps mit Domino Data Lab und NetApp</block>
  <block id="1231369e1218613623e1b520c27ce190" category="sidebar">Ersteinrichtung</block>
  <block id="e5726f3da1ad0304974cf103e75da470" category="sidebar">Bereitstellen vorhandener NetApp -Volumes für Domino</block>
  <block id="f62030848d7cb177a11eb3916356bb29" category="sidebar">Greifen Sie in verschiedenen Umgebungen auf dieselben Daten zu</block>
  <block id="0f68b904e33d9ac04605aecc958bcf52" category="sidebar">Weitere Informationen</block>
  <block id="f4c44872f09acb0f4e8f90890004d4ab" category="sidebar">Verwenden Sie die NVIDIA NGC-Software</block>
  <block id="a12d6a26832d73816bca1235e9f4d8a1" category="sidebar">Anwendungsfallbeispiel – TensorFlow-Trainingsjob</block>
  <block id="0975e7e38dac95fd7ce3d2e3966e26be" category="sidebar">Teil 1 – Integrieren Sie Amazon FSx for NetApp ONTAP als privaten S3-Bucket in AWS SageMaker</block>
  <block id="b675f3bab2742c1723ed556f8535349d" category="sidebar">Teil 2 – Nutzen Sie Amazon FSx for NetApp ONTAP als Datenquelle für das Modelltraining in SageMaker</block>
  <block id="7609ccc24e4c12c32d0ad617fe91161e" category="sidebar">Teil 3 – Erstellen einer vereinfachten MLOps-Pipeline</block>
  <block id="c79bd5ac7ebc0eae5588b9ad529a380f" category="sidebar">NetApp StorageGRID Data Lake für Workloads im Bereich autonomes Fahren</block>
  <block id="a20ee4ebc8e6614143815c881916cbba" category="sidebar">Vector Datenbanklösung mit NetApp</block>
  <block id="e5df4bbe7b124f2fe5398d42696d57b3" category="sidebar">Vektordatenbank</block>
  <block id="9934c7eb2c2161e05fedd3b280e4eedc" category="sidebar">Technologieanforderung</block>
  <block id="951de808fb87ba9bc035ce3cf467b064" category="sidebar">Vektordatenbankschutz mit SnapCenter</block>
  <block id="f0a132dd5ea90d189f80995d831f9b91" category="sidebar">Notfallwiederherstellung mit SnapMirror</block>
  <block id="e813a53d42d6bfe69e6907df9b0675d5" category="sidebar">Vektordatenbank mit Instaclustr unter Verwendung von PostGreSQL: pgvector</block>
  <block id="7fad254d8199fbf6d695e96590444cff" category="sidebar">Anhang B: prepare_data_netapp_new_py</block>
  <block id="4d4989117d6e4f26e57cc7135af8f508" category="sidebar">Anhang D: docker_compose.yml</block>
  <block id="46aa0a2ad138d7cd72baea1b2f96553c" category="sidebar">KI-konvergente Infrastrukturen</block>
  <block id="503011292be147bd4172e92de477a75e" category="sidebar">NVA-1173 NetApp AIPod mit NVIDIA DGX-Systemen</block>
  <block id="34df2039718349f1b8c838bff98ae8fa" category="sidebar">Hardwarekomponenten</block>
  <block id="7d19d593db0bb056876a9535cbced90a" category="sidebar">Softwarekomponenten</block>
  <block id="aee745c6de04f3d08c0e628809cab1e7" category="sidebar">Beispielbereitstellungsdetails</block>
  <block id="56d2d7506e6dac3733b0a45a9eaf441d" category="sidebar">Validierungs- und Größenleitfaden</block>
  <block id="db182982505626c6e79adca149851ca6" category="sidebar">Fazit und weitere Informationen</block>
  <block id="013e704990294f0b327123a61911f4cc" category="sidebar">NVIDIA DGX SuperPOD mit NetApp EF-Serie</block>
  <block id="944c042dcc47f293062f941954082ceb" category="sidebar">BeeGFS auf NetApp mit E-Series-Speicher</block>
  <block id="9af29e4b3d0045c948a7dd30b1c7f8ae" category="sidebar">Implementieren Sie IBM Spectrum Scale mit E-Series-Speicher</block>
  <block id="79bca636cb614580cfd2da67b668570e" category="sidebar">ONTAP und Lenovo ThinkSystem für KI</block>
  <block id="7e9b2db694c8b0a87a271e7085251d0e" category="sidebar">NetApp ONTAP und Lenovo ThinkSystem SR670 für KI</block>
  <block id="b669bc138f2f455218d4dce65e4693b4" category="sidebar">KI-Anwendungsfälle</block>
  <block id="adb8741d27ea996906508affc4dfbc75" category="sidebar">NetApp AIPod Mini für RAG-Inferencing</block>
  <block id="c94ba9961c97321b49a2f0af40a3c81b" category="sidebar">Verantwortungsvolle KI und vertrauliche Inferenz – NetApp AI mit Protopia Image Transformation</block>
  <block id="549d044fec039c71abf82f76a0d7969c" category="sidebar">Verschieben von Daten aus einer Big Data-Umgebung in eine KI-Umgebung</block>
  <block id="18e04180e0442e18a559941bb8de310c" category="sidebar">KI-Inferenz am Edge – NetApp mit Lenovo ThinkSystem – Lösungsdesign</block>
  <block id="df901f2197cd86d62a25f2f43e523352" category="sidebar">Designleitfaden für Quantum StorNext mit NetApp E-Series-Systemen</block>
  <block id="e313734313e7ef573613df8b6edae0af" category="sidebar">Bereitstellungshandbuch für Quantum StorNext mit NetApp E-Series-Systemen</block>
  <block id="78daadab78234c06769e4f331411d302" category="sidebar">Moderne Datenanalyse</block>
  <block id="a5428e6b4b42638886ab5870a883efb9" category="sidebar">NetApp -Lösung für das dumme Umbenennungsproblem bei der NFS-zu-Kafka-Workload</block>
  <block id="d7fd58c27a131209e8f320d109b293cc" category="sidebar">Leistungsübersicht und -validierung in AWS – Cloud Volume ONTAP</block>
  <block id="076002e1839cd6d440e56b26850e1223" category="sidebar">Leistungsübersicht und -validierung in AWS – FSx für NetApp ONTAP</block>
  <block id="0d7c7eeec9388fceaff3d06e03b45fe9" category="sidebar">Leistungsübersicht und -validierung mit AFF vor Ort</block>
  <block id="2835924be4bc657cfe3a5bd988b96845" category="sidebar">Confluent-Leistungsvalidierung</block>
  <block id="2ce0710320aace7b17c3af20eaac2918" category="sidebar">Zusammenfassung der Anwendungsfälle</block>
  <block id="713522228cb3164cc6e71ff6d49c3b13" category="sidebar">GPFS zu NFS – Detaillierte Schritte</block>
  <block id="497da8ae75854ffd62dc59e332c15252" category="sidebar">Konfluente, sich selbst ausbalancierende Cluster</block>
  <block id="c9f0818cde41901681a02b50763ec342" category="sidebar">NetApp Hybrid Cloud-Datenlösungen – Spark und Hadoop basierend auf Kundenanwendungsfällen</block>
  <block id="924f605d39858bdb10692c8d8f810464" category="sidebar">Anwendungsfall 1 – Sichern von Hadoop-Daten</block>
  <block id="c028df954696d2e4011963e651237b7c" category="sidebar">Anwendungsfall 2 – Sicherung und Notfallwiederherstellung aus der Cloud vor Ort</block>
  <block id="f1ab9c16fee4088d930b2a43e3d48f64" category="sidebar">Anwendungsfall 3 – DevTest für vorhandene Hadoop-Daten aktivieren</block>
  <block id="4e7c79467b7b25f0415a3a4538d3e2f5" category="sidebar">Anwendungsfall 4 – Datenschutz und Multicloud-Konnektivität</block>
  <block id="f38bc790ec57f948f20cbd270b996cc6" category="sidebar">Anwendungsfall 5 – Beschleunigen analytischer Workloads</block>
  <block id="2c1c3f6b0e9a17650f389f1aab405e8a" category="sidebar">Hybride Iceberg Lakehouse-Lösung der nächsten Generation von NetApp und Dremio</block>
  <block id="1256c51dea275f8f002d62c89274c4dc" category="sidebar">Kundenanwendungsfälle</block>
  <block id="df6654a22cda1b94cf0f51d6ae94bb69" category="sidebar">Verschiedene Lösungen für verschiedene Analysestrategien – Lösungsübersicht</block>
  <block id="2b95dd053e967c99de1428e8953dd453" category="sidebar">StorageGRID -Funktionen für Splunk SmartStore</block>
  <block id="42c2f45afefbd5150f5aa52986b2a3cc" category="sidebar">Staffelung und Kosteneinsparungen</block>
  <block id="039a70e0c8e34414c8b3f34333f95ca8" category="sidebar">SmartStore-Leistung für einzelne Standorte</block>
  <block id="427d072a2c1690c6d9ece23bef05477b" category="sidebar">Apache Spark Workload mit NetApp Storage-Lösung (Bereitstellungshandbuch)</block>
</blocks>