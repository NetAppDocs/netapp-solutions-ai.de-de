---
sidebar: sidebar 
permalink: software/ai-osmlops-mlflow-deploy.html 
keywords: AI, control plane, MLOps, MLflow 
summary: Open Source MLOps mit NetApp – MLflow-Bereitstellung 
---
= MLflow-Bereitstellung
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
In diesem Abschnitt werden die Aufgaben beschrieben, die Sie ausführen müssen, um MLflow in Ihrem Kubernetes-Cluster bereitzustellen.


NOTE: Es ist möglich, MLflow auf anderen Plattformen als Kubernetes bereitzustellen.  Die Bereitstellung von MLflow auf anderen Plattformen als Kubernetes liegt außerhalb des Umfangs dieser Lösung.



== Voraussetzungen

Bevor Sie die in diesem Abschnitt beschriebene Bereitstellungsübung durchführen, gehen wir davon aus, dass Sie die folgenden Aufgaben bereits ausgeführt haben:

. Sie verfügen bereits über einen funktionierenden Kubernetes-Cluster.
. Sie haben NetApp Trident bereits in Ihrem Kubernetes-Cluster installiert und konfiguriert.  Weitere Einzelheiten zu Trident finden Sie imlink:https://docs.netapp.com/us-en/trident/index.html["Trident -Dokumentation"^] .




== Helm installieren

MLflow wird mit Helm bereitgestellt, einem beliebten Paketmanager für Kubernetes.  Bevor Sie MLflow bereitstellen, müssen Sie Helm auf Ihrem Kubernetes-Steuerknoten installieren.  Um Helm zu installieren, folgen Sie den https://helm.sh/docs/intro/install/["Installationsanweisungen"^] in der offiziellen Helm-Dokumentation.



== Standardmäßige Kubernetes-Speicherklasse festlegen

Bevor Sie MLflow bereitstellen, müssen Sie eine Standard-StorageClass in Ihrem Kubernetes-Cluster festlegen.  Um eine Standard-StorageClass innerhalb Ihres Clusters festzulegen, folgen Sie den Anweisungen imlink:ai-osmlops-kubeflow-deploy.html["Kubeflow-Bereitstellung"] Abschnitt.  Wenn Sie in Ihrem Cluster bereits eine Standard-StorageClass festgelegt haben, können Sie diesen Schritt überspringen.



== MLflow bereitstellen

Sobald die Voraussetzungen erfüllt sind, können Sie mit der MLflow-Bereitstellung mithilfe des Helm-Diagramms beginnen.



=== Konfigurieren Sie die Bereitstellung des MLflow Helm-Diagramms.

Bevor wir MLflow mithilfe des Helm-Diagramms bereitstellen, können wir die Bereitstellung so konfigurieren, dass die NetApp Trident Storage Class verwendet wird, und mithilfe einer *config.yaml*-Datei andere Parameter an unsere Anforderungen anpassen.  Ein Beispiel für eine *config.yaml*-Datei finden Sie unter: https://github.com/bitnami/charts/blob/main/bitnami/mlflow/values.yaml[]


NOTE: Sie können die Trident -Speicherklasse unter dem Parameter *global.defaultStorageClass* in der Datei config.yaml festlegen (z. B. Speicherklasse: „ontap-flexvol“).



=== Installieren des Helm-Diagramms

Das Helm-Diagramm kann mit der benutzerdefinierten Datei *config.yaml* für MLflow mithilfe des folgenden Befehls installiert werden:

[source, shell]
----
helm install oci://registry-1.docker.io/bitnamicharts/mlflow -f config.yaml --generate-name --namespace jupyterhub
----

NOTE: Der Befehl stellt MLflow über die bereitgestellte Datei *config.yaml* in der benutzerdefinierten Konfiguration auf dem Kubernetes-Cluster bereit.  MLflow wird im angegebenen Namespace bereitgestellt und für die Version wird über Kubernetes ein zufälliger Versionsname vergeben.



=== Bereitstellung prüfen

Nachdem die Bereitstellung des Helm-Diagramms abgeschlossen ist, können Sie mit folgendem Befehl überprüfen, ob auf den Dienst zugegriffen werden kann:

[source, shell]
----
kubectl get service -n jupyterhub
----

NOTE: Ersetzen Sie *jupyterhub* durch den Namespace, den Sie während der Bereitstellung verwendet haben.

Sie sollten die folgenden Dienste sehen:

[source, shell]
----
NAME                              TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)           AGE
mlflow-1719843029-minio           ClusterIP   10.233.22.4     <none>        80/TCP,9001/TCP   25d
mlflow-1719843029-postgresql      ClusterIP   10.233.5.141    <none>        5432/TCP          25d
mlflow-1719843029-postgresql-hl   ClusterIP   None            <none>        5432/TCP          25d
mlflow-1719843029-tracking        NodePort    10.233.2.158    <none>        30002:30002/TCP   25d
----

NOTE: Wir haben die Datei config.yaml bearbeitet, um den NodePort-Dienst für den Zugriff auf MLflow über Port 30002 zu verwenden.



=== Zugriff auf MLflow

Sobald alle mit MLflow verbundenen Dienste betriebsbereit sind, können Sie über die angegebene NodePort- oder LoadBalancer-IP-Adresse darauf zugreifen (z. B. `http://10.61.181.109:30002` )
